INFO:root:the deviced being used is cuda:0
INFO:root:statistics used: {'mean': tensor([0.0613]), 'std': tensor([0.1623])}
INFO:root:test_indx used: 8237, 3382, 2361, 23748, 26770, 23949, 26217, 2657, 12907, 12557, 9901, 28753, 26388, 18315, 9953, 1279, 483, 29762, 10375, 15787, 19051, 2360, 15455, 3587, 18292, 15161, 23610, 3242, 14355, 6639, 26804, 8859, 23863, 8840, 14873, 7827, 20791, 4885, 26928, 3376, 13621, 29907, 25215, 22651, 14878, 23525, 26595, 3688, 17113, 26824, 25818, 5062, 30105, 24690, 3709, 28211, 21721, 2321, 25599, 29410, 21245, 31452, 4282, 29187, 24573, 9878, 8000, 3446, 644, 22650, 1335, 13040, 19767, 26185, 16244, 31665, 21214, 13237, 3835, 11641, 4531, 24304, 184, 32152, 2830, 3798, 2016, 5724, 14967, 23031, 4668, 19491, 8718, 24518, 18181, 24615, 24372, 6955, 25187, 19658, 14280, 11520, 7434, 23161, 18419, 9989, 7944, 1516, 13962, 25255, 494, 26071, 15251, 26837, 28784, 9727, 17183, 9126, 18414, 4571, 17614, 3525, 28278, 25052, 1204, 18733, 4201, 22394, 18005, 19869, 4714, 374, 10896, 13991, 20660, 22152, 18343, 5290, 16743, 8031, 16729, 3130, 821, 19211, 17013, 21072, 7150, 7269, 31594, 26072, 21791, 27380, 28244, 3787, 19620, 9722, 14850, 27137, 13317, 5825, 31670, 2478, 12442, 12667, 26485, 605, 15491, 28725, 10831, 22164, 4042, 31518, 20299, 10842, 20721, 23386, 24865, 29958, 6284, 16696, 7578, 7340, 15998, 3155, 281, 2502, 11972, 25068, 18715, 17557, 4092, 27294, 29398, 8727, 24955, 23843, 19948, 25833, 11, 7339, 6752, 26351, 7581, 28703, 22672, 16917, 23766, 10170, 21968, 14618, 23652, 30304, 19502, 6349, 9981, 6105, 29284, 31383, 11484, 723, 17148, 22157, 20793, 30586, 26887, 30567, 16194, 9103, 22575, 31661, 8018, 17678, 31432, 12527, 3405, 17967, 23714, 15446, 11855, 27814, 3005, 29645, 15198, 20116, 13329, 31738, 5200, 14352, 28782, 26009, 32106, 23850, 31657, 21179, 1524, 8133, 8033, 6404, 21969, 21166, 9264, 7751, 17431, 20037, 4184, 27590, 1097, 10211, 18290, 19859, 4984, 18502, 31241, 18262, 9229, 27825, 27387, 7263, 4955, 870, 21805, 15786, 30979, 20794, 639, 26601, 5265, 26069, 2545, 21116, 21041, 25149, 5844, 17633, 31103, 3494, 28466, 27043, 23506, 28407, 17139, 24015, 7542, 10597, 18466, 22357, 2967, 25492, 18219, 27109, 10483, 11859, 14654, 17022, 13340, 31428, 27430, 25244, 5593, 28534, 7121, 4296, 15091, 16119, 3550, 8274, 26397, 11655, 1666, 31688, 18596, 2524, 2381, 719, 26498, 9079, 9534, 28754, 22026, 16144, 11773, 17925, 24116, 1760, 25519, 12858, 29525, 8790, 2742, 19270, 8262, 6767, 2069, 15253, 22758, 11963, 19194, 24101, 1978, 3412, 15526, 14121, 7466, 31993, 16457, 26057, 28962, 20946, 27213, 137, 17838, 12030, 28502, 2225, 1183, 14440, 17182, 19985, 30974, 11158, 16765, 1567, 400, 25547, 7360, 14374, 5812, 2914, 21588, 16245, 12471, 4755, 6323, 2215, 7327, 29560, 17720, 16609, 19360, 11207, 5681, 20109, 5744, 140, 11868, 26510, 27553, 7433, 16271, 2243, 26212, 10574, 22537, 26935, 3485, 18131, 21135, 25744, 3613, 26242, 26295, 31987, 10943, 25884, 22205, 18910, 29941, 28069, 15292, 8037, 26146, 23384, 31834, 20731, 24913, 23944, 5049, 9159, 19341, 23958, 9661, 16330, 26324, 9548, 31580, 12232, 30522, 18473, 17061, 3048, 16233, 28617, 7647, 28866, 10111, 10229, 2701, 18109, 21319, 30064, 12051, 20733, 23915, 22478, 4290, 28408, 21310, 31275, 21329, 13159, 949, 8121, 29711, 10956, 9731, 19449, 12187, 27901, 28046, 3592, 3398, 29417, 956, 29536, 13459, 16834, 30927, 31161, 7440, 27701, 921, 10698, 9701, 8993, 20956, 6401, 30697, 30630, 24897, 11140, 25766, 25677, 18729, 677, 21785, 13228, 5650, 28779, 7529, 19577, 23857, 20048, 9699, 30863, 27881, 7276, 14153, 3045, 21274, 9030, 13789, 8633, 249, 30386, 29530, 4514, 13983, 5277, 29137, 25569, 22050, 25111, 4339, 20419, 2300, 671, 18565, 25020, 23791, 7428, 25437, 15064, 24799, 17860, 24662, 2986, 18849, 27083, 26632, 1184, 28469, 24777, 2955, 22692, 22281, 867, 9221, 9632, 12412, 30733, 14329, 21675, 20750, 8844, 11846, 7220, 30377, 24577, 10747, 23580, 27095, 12135, 27930, 24611, 28134, 22044, 20504, 17339, 12550, 28666, 10789, 25877, 31154, 19596, 6028, 3673, 9118, 23556, 14409, 26784, 24588, 1220, 28837, 10825, 29245, 10296, 9582, 8637, 31477, 9086, 28078, 31469, 2155, 4761, 18816, 28522, 30278, 18710, 975, 30354, 31948, 9149, 5293, 4789, 23950, 4827, 24961, 19281, 30465, 20730, 13300, 2601, 7379, 6820, 10741, 20136, 20663, 9184, 16769, 26328, 13772, 21302, 17365, 1342, 787, 29776, 27359, 31698, 7566, 4660, 4143, 19973, 17155, 6005, 24427, 16474, 1120, 764, 8480, 11008, 30742, 27745, 25212, 29715, 7783, 23804, 4864, 25556, 31339, 208, 21824, 9427, 4309, 521, 20044, 11974, 25074, 1339, 31437, 18033, 30773, 26059, 10655, 447, 18990, 9821, 28070, 28906, 29330, 24968, 7414, 9370, 31829, 25936, 6731, 14539, 13844, 9339, 27196, 16191, 19071, 10363, 10476, 19754, 15283, 14337, 10766, 339, 21477, 21173, 2448, 18339, 11244, 308, 15766, 765, 29901, 28077, 3535, 15338, 22828, 15578, 4500, 819, 18276, 3019, 19510, 26974, 7424, 19996, 19450, 672, 43, 2737, 13853, 13794, 31351, 9165, 9501, 20557, 18040, 1084, 2471, 19255, 22919, 23694, 13367, 8028, 3433, 30088, 26780, 15956, 21210, 21690, 12875, 31730, 10692, 5842, 9594, 12091, 25118, 18204, 28857, 30861, 21221, 11149, 26854, 21416, 28891, 25001, 31601, 31468, 25887, 26342, 25473, 6595, 7842, 3034, 26959, 17427, 8593, 11847, 19756, 24988, 4284, 16031, 8924, 17569, 31732, 10249, 14877, 29777, 17200, 31147, 22507, 15475, 9526, 24957, 3564, 26544, 31188, 12189, 21055, 2085, 14158, 7153, 22049, 6400, 15041, 4344, 6385, 16910, 25777, 25726, 890, 17541, 6539, 30984, 20756, 10749, 9016, 11511, 6930, 2572, 1062, 20790, 1246, 29106, 24920, 15457, 19599, 8776, 31516, 11902, 2124, 445, 8252, 4793, 16407, 32115, 15101, 7224, 14800, 2912, 14378, 25256, 11796, 31839, 3286, 29651, 26856, 21578, 20385, 11181, 14950, 23877, 18848, 17325, 11587, 27987, 17948, 12919, 9040, 21627, 1331, 10316, 11463, 1125, 8886, 10965, 29236, 16358, 26629, 12859, 30481, 26951, 20352, 7585, 23876, 6920, 29743, 7889, 28882, 14080, 6220, 2439, 24463, 30356, 13277, 24309, 23426, 11199, 19674, 21593, 1509, 10940, 19872, 14853, 16858, 7138, 11500, 11470, 26023, 18250, 18548, 18159, 25402, 14600, 29494, 22365, 12826, 12340, 29976, 14112, 19002, 31907, 16441, 23639, 1213, 12305, 7, 20588, 18855, 25038, 15940, 26752, 12096, 15716, 31376, 1648, 6844, 14495, 593, 15031, 12624, 264, 11085, 6709, 10009, 9651, 9122, 6317, 9643, 5309, 2858, 15148, 17961, 14855, 25309, 26257, 31964, 9074, 15236, 11635, 20994, 25121, 25448, 21684, 8631, 32221, 11789, 24459, 1405, 942, 12807, 31060, 16963, 26043, 30780, 30213, 25060, 1186, 15430, 1685, 29815, 5695, 27595, 4028, 11905, 27846, 16273, 26769, 9000, 14923, 5110, 17501, 4614, 30559, 5982, 17597, 10867, 28260, 15895, 26628, 26588, 15006, 4432, 280, 22748, 23038, 16655, 19538, 31861, 4118, 21664, 1455, 19048, 25137, 24894, 17897, 14266, 8191, 6086, 12903, 6366, 27914, 13223, 17081, 32233, 907, 28094, 2581, 15816, 22680, 22372, 10644, 24371, 876, 1529, 8873, 30242, 2077, 19889, 1259, 14545, 5499, 22765, 25642, 15702, 14433, 24972, 31041, 23218, 25082, 3506, 18869, 15137, 20966, 24675, 21209, 54, 18568, 25465, 8431, 6802, 10470, 15193, 30211, 25036, 2630, 7222, 12861, 5763, 9703, 25208, 1274, 882, 3324, 13022, 17172, 7164, 17128, 12687, 30678, 20257, 20881, 15808, 25580, 13952, 7331, 20182, 24107, 1114, 20957, 23824, 14647, 13805, 6109, 12976, 22501, 19992, 30887, 4037, 1140, 1308, 22894, 12148, 16016, 7574, 30023, 21162, 17184, 16651, 15051, 31527, 14714, 27288, 14784, 9589, 16579, 25911, 20414, 30367, 21013, 2740, 7501, 5371, 16490, 5440, 21841, 27838, 26325, 5250, 327, 6413, 7090, 29058, 24303, 3609, 14001, 21340, 32265, 25370, 19466, 24180, 29851, 4406, 6837, 24986, 10973, 16978, 20206, 14854, 13087, 20183, 4751, 15713, 20685, 22504, 13162, 226, 2262, 4404, 7296, 18388, 16644, 7936, 31369, 9573, 2627, 14429, 6344, 26129, 26656, 26038, 22103, 24625, 4508, 10138, 19991, 19402, 24815, 13118, 3760, 14096, 30541, 30017, 888, 2101, 31710, 23882, 32005, 5785, 22821, 29946, 884, 6883, 13857, 2506, 16062, 7375, 24457, 3674, 20917, 30384, 11830, 10693, 26688, 18089, 31439, 10742, 14649, 18612, 13615, 5319, 23928, 24438, 25451, 11072, 24395, 29881, 1719, 16738, 12439, 11049, 29027, 19633, 10953, 16930, 11423, 23983, 8719, 30056, 3336, 1245, 8452, 6535, 17655, 12229, 12584, 22363, 21265, 3911, 5624, 16276, 28825, 8444, 12566, 2008, 8657, 197, 21843, 17639, 23679, 17358, 9207, 6970, 8984, 10804, 1287, 3069, 1494, 15431, 29493, 18481, 22342, 12587, 22341, 11792, 12245, 22291, 14679, 7877, 6341, 4157, 1268, 19277, 31529, 6775, 19657, 19989, 30880, 27847, 1263, 4684, 7354, 15520, 23816, 19803, 22654, 25950, 13597, 10502, 3151, 31989, 6097, 4491, 14972, 11981, 3900, 20458, 7839, 18335, 21827, 11039, 2417, 15752, 15289, 15428, 2172, 26019, 9022, 16209, 29981, 23711, 29471, 32196, 7003, 4357, 23878, 9629, 28272, 23110, 14331, 9687, 23226, 8964, 6586, 16589, 11033, 2213, 4695, 22708, 16692, 15021, 16602, 10411, 11857, 1008, 20482, 169, 4079, 17645, 11130, 22697, 10936, 15233, 17438, 29473, 19417, 15931, 6974, 10270, 2982, 1452, 9474, 2276, 23343, 3620, 25913, 25819, 26457, 5980, 28201, 11376, 9174, 17464, 23196, 31930, 22732, 11209, 4504, 31209, 2120, 23137, 9900, 10208, 22448, 22881, 9347, 18141, 15473, 19815, 13992, 27280, 9434, 16952, 10186, 7870, 13734, 17849, 4393, 21718, 32133, 31471, 20122, 11840, 15648, 22845, 30126, 1537, 12603, 17770, 9664, 20736, 20275, 6650, 2419, 30285, 29721, 15103, 30123, 15965, 15901, 26934, 14777, 13780, 7111, 4685, 15708, 15217, 8130, 21409, 14081, 5345, 28328, 28307, 8740, 22611, 19490, 10365, 305, 18645, 19679, 1278, 8559, 17670, 31783, 23591, 2455, 17802, 27609, 17637, 14265, 13347, 2096, 12298, 19501, 15652, 1054, 13099, 21366, 9626, 27611, 14049, 27500, 24592, 23054, 5334, 27247, 29616, 7069, 1736, 8223, 11255, 14821, 23939, 27517, 6303, 17079, 10271, 8538, 10877, 30461, 27376, 15144, 9862, 20173, 16161, 28308, 26625, 27061, 20523, 18628, 21301, 16976, 23817, 30051, 4166, 23124, 2499, 899, 8503, 26910, 14024, 1089, 5075, 11050, 16518, 15516, 1823, 24143, 17932, 23311, 19800, 12682, 16059, 17271, 6636, 29948, 8685, 29865, 11147, 6507, 18340, 8699, 27835, 3191, 28654, 24357, 29565, 29729, 32173, 26381, 4259, 859, 21410, 4099, 27666, 4008, 8640, 6438, 17987, 19616, 25823, 26298, 1497, 27134, 5936, 18460, 10954, 10460, 5818, 8507, 1726, 32066, 3676, 7490, 8188, 20311, 25115, 31049, 22149, 21529, 7278, 14496, 3645, 1686, 14341, 31828, 5352, 31123, 22588, 1320, 28323, 1700, 9817, 18075, 30782, 24622, 20478, 22780, 31666, 21983, 21206, 3519, 28888, 12729, 25419, 19977, 28277, 29546, 26539, 5356, 23285, 4346, 15392, 16827, 20008, 19126, 26925, 511, 9223, 1348, 11251, 3213, 999, 31089, 25459, 10408, 18149, 8598, 6926, 6651, 16691, 16224, 15098, 20397, 4197, 21960, 18237, 27002, 12373, 12537, 23756, 20188, 6672, 28671, 10453, 29824, 23155, 10472, 5539, 10533, 16403, 2573, 20989, 18479, 1875, 6420, 31838, 5940, 14893, 6403, 4093, 15821, 13207, 18859, 8902, 21138, 25938, 11178, 6122, 13320, 31567, 3219, 18974, 12586, 29304, 15179, 12672, 10769, 22840, 30225, 15026, 30776, 31944, 21513, 29327, 30163, 21596, 10473, 17761, 29773, 26953, 14187, 16114, 18240, 2659, 14567, 15932, 18078, 23515, 26036, 2280, 19670, 20518, 31108, 11668, 23029, 12706, 22295, 31322, 216, 21984, 8330, 2888, 15948, 12509, 29692, 6626, 5688, 22477, 15048, 12287, 22570, 5311, 17419, 11022, 31733, 23337, 1495, 13333, 15227, 14446, 23961, 2458, 8627, 13895, 29778, 23096, 27863, 18238, 17455, 11913, 18213, 31668, 6255, 3729, 22045, 18947, 9237, 25326, 74, 16735, 30467, 32147, 12502, 29900, 27250, 630, 4526, 2513, 15728, 10521, 5141, 9255, 13619, 25487, 18592, 9317, 14479, 570, 31227, 22239, 11617, 11229, 23920, 17587, 17654, 13883, 12786, 19779, 30961, 7240, 10711, 27574, 3892, 3375, 17319, 7972, 11414, 28404, 7037, 31232, 26134, 13975, 7910, 14792, 3970, 29375, 18403, 18377, 15631, 9536, 16344, 26710, 15657, 15499, 15010, 8717, 3093, 27776, 22585, 21090, 12061, 19858, 28165, 21580, 23034, 4276, 10146, 959, 8187, 16082, 15335, 52, 29420, 26015, 30615, 20082, 1007, 24331, 10740, 3995, 27084, 30700, 31765, 25724, 6218, 14881, 18360, 19865, 17240, 30856, 28342, 778, 3431, 18563, 28532, 18202, 9825, 8663, 26386, 28836, 13463, 31412, 28509, 20761, 23237, 6083, 10761, 28817, 4240, 6503, 21736, 5943, 21819, 15037, 7230, 8417, 1908, 13707, 15605, 29001, 23051, 21204, 15426, 8609, 29975, 28313, 15921, 529, 28647, 17248, 25706, 31346, 26054, 21818, 23326, 30632, 27608, 16616, 12261, 3834, 21811, 3499, 30068, 1749, 7767, 798, 31750, 3419, 19110, 23405, 6804, 19293, 11097, 15421, 22126, 13033, 8275, 29730, 16645, 20374, 16552, 7097, 19615, 19956, 18172, 19480, 15820, 28928, 3921, 3393, 12169, 28974, 13750, 25701, 4196, 27099, 28935, 3300, 23310, 26265, 6197, 4502, 27026, 17680, 15237, 4999, 2870, 24077, 6684, 21018, 31082, 20462, 4341, 25312, 25509, 17432, 31484, 11738, 18654, 22921, 12464, 25254, 12474, 9697, 15302, 12841, 12408, 9719, 7306, 6725, 8085, 550, 27644, 10350, 25219, 15372, 9013, 8005, 28748, 3094, 2151, 3972, 8548, 24153, 1459, 8635, 21532, 18690, 13535, 16865, 16256, 27893, 10959, 27045, 10593, 19980, 14196, 23830, 5958, 27642, 3157, 24734, 15724, 5872, 22658, 26139, 15171, 18092, 30082, 5007, 20833, 15680, 27174, 18080, 27675, 7322, 27929, 27576, 18731, 30790, 11896, 24486, 6302, 5879, 24651, 19953, 18173, 343, 142, 27055, 3651, 18662, 10925, 15662, 17762, 23242, 19376, 26878, 9425, 6575, 22897, 18585, 858, 6965, 20555, 15813, 21283, 12777, 10200, 23754, 8746, 7163, 22936, 24339, 14097, 18137, 10580, 6673, 14680, 30237, 13020, 11524, 25644, 20824, 20466, 21577, 15867, 10094, 4046, 6838, 30542, 12529, 2979, 30346, 17605, 7503, 22211, 1340, 15564, 9782, 26300, 615, 646, 13927, 27248, 26542, 5231, 19418, 6191, 32071, 22717, 830, 918, 24052, 26533, 31873, 2854, 22767, 15399, 2777, 148, 18318, 14753, 2780, 12467, 21950, 30715, 22310, 13762, 23450, 14559, 13310, 1271, 20239, 12146, 4174, 25835, 12762, 750, 29217, 8378, 7682, 25695, 12226, 194, 19845, 31924, 21854, 1166, 6299, 357, 10116, 18933, 20914, 28757, 5283, 13722, 5279, 4004, 17449, 10503, 7038, 19287, 13471, 19247, 5153, 19649, 3531, 23581, 5511, 10003, 6616, 8695, 20408, 30628, 9974, 13997, 15740, 12863, 21999, 1221, 5662, 396, 1804, 2765, 24728, 26705, 3206, 15401, 29225, 19410, 26446, 13731, 8329, 27799, 12775, 20403, 5991, 10439, 8132, 21202, 9295, 22313, 10191, 27472, 24824, 16981, 748, 12748, 11875, 14973, 28439, 23333, 20106, 30335, 17276, 29850, 19612, 17429, 4712, 19748, 28246, 26560, 16685, 8875, 30477, 25563, 16639, 6777, 18441, 29594, 25144, 27433, 9604, 15109, 5995, 21348, 25453, 22012, 11481, 7730, 22877, 6409, 22700, 15733, 27076, 32042, 23803, 3714, 19580, 15477, 16225, 11082, 12739, 10485, 199, 16372, 29335, 28301, 11248, 14817, 9571, 23062, 13130, 10517, 8603, 31449, 3772, 190, 769, 30720, 17719, 30592, 31228, 32215, 14750, 3560, 5015, 31127, 11735, 23647, 3032, 7869, 27904, 2135, 18070, 11746, 25117, 26763, 20603, 4723, 1267, 10809, 31448, 12497, 27398, 30, 9084, 6139, 4264, 16318, 8567, 10760, 2984, 13760, 7216, 15699, 20906, 29866, 6776, 28058, 20715, 923, 8166, 15944, 6226, 4401, 7351, 12120, 26402, 40, 16666, 6842, 27710, 6206, 7016, 28724, 29596, 23348, 16763, 5180, 24, 118, 14452, 19877, 2148, 21153, 25817, 13149, 25456, 31669, 8457, 1751, 3041, 3091, 31012, 20795, 26106, 20317, 18935, 25405, 20604, 24784, 27983, 9806, 24912, 11518, 1446, 5391, 5273, 12158, 31336, 4939, 2815, 1565, 17090, 13242, 210, 23924, 26942, 16681, 19663, 27792, 21097, 17250, 20704, 20406, 19597, 1202, 12145, 2309, 2037, 594, 18437, 4302, 9218, 27241, 30124, 27848, 20404, 4692, 24991, 23838, 26263, 25838, 7248, 22246, 12734, 1261, 20639, 24355, 9653, 22679, 4878, 22252, 1444, 26756, 31910, 14305, 31796, 24204, 29591, 22506, 1761, 13925, 29099, 10241, 7894, 2767, 19757, 3180, 6015, 25653, 13044, 16730, 19512, 14652, 31584, 2980, 17865, 14309, 19622, 18490, 7557, 31005, 2074, 3708, 3218, 30328, 16453, 19613, 27720, 13945, 7820, 31848, 25645, 18815, 23345, 2704, 17471, 146, 2523, 28075, 18424, 17750, 17234, 24629, 16961, 25942, 16551, 7718, 21630, 26440, 15674, 6612, 24149, 18411, 30624, 9702, 23859, 16385, 21401, 25789, 13522, 16207, 19061, 28495, 13108, 30330, 31068, 14, 23043, 10122, 19887, 2269, 21461, 12248, 5145, 14050, 11562, 5292, 26535, 25989, 6452, 9847, 28065, 17843, 11865, 22104, 17370, 11151, 8094, 21010, 7745, 27916, 13143, 5834, 3566, 25890, 11477, 9923, 7076, 17992, 14614, 22480, 1750, 27667, 14333, 28412, 30310, 21536, 15106, 11897, 12493, 27053, 1240, 21350, 16949, 29441, 23757, 12462, 11739, 18409, 19155, 13811, 31318, 2103, 5126, 9794, 26151, 11314, 7811, 8721, 15968, 2597, 30371, 1779, 2526, 7661, 23484, 29402, 17033, 31895, 6863, 18436, 16915, 26897, 29713, 713, 1596, 12855, 3472, 185, 29397, 1309, 16994, 13995, 1995, 19310, 1661, 1924, 13376, 5165, 611, 6262, 31920, 1559, 11984, 3529, 13600, 15057, 2709, 5142, 12791, 12278, 1086, 6319, 11123, 15452, 31712, 12447, 3297, 6223, 29138, 2395, 30638, 14682, 9770, 29325, 31289, 29653, 1892, 4863, 26860, 32199, 16847, 16140, 7382, 30301, 1807, 50, 2610, 20889, 18902, 1463, 20595, 25691, 2019, 14262, 14686, 21043, 9954, 9251, 14302, 21782, 2390, 5326, 21894, 9959, 17623, 24800, 4176, 23126, 22125, 7497, 28011, 7632, 23462, 23774, 30654, 18429, 4926, 20574, 31559, 15329, 28222, 15258, 8492, 27682, 9105, 29745, 27290, 8095, 701, 5888, 23200, 19, 2050, 20270, 28911, 247, 29323, 15938, 24742, 8159, 365, 10595, 26020, 10345, 25012, 19018, 23283, 23763, 15332, 3000, 3655, 4209, 32256, 17157, 25486, 3424, 7132, 8110, 26290, 9637, 19550, 27686, 9739, 16132, 29884, 4142, 22178, 20249, 7071, 3008, 19204, 27344, 20203, 30291, 26492, 6482, 19629, 2466, 9771, 14515, 23175, 27781, 22961, 15991, 11825, 21189, 4888, 18919, 1448, 30999, 9222, 6331, 15519, 3953, 29443, 13049, 24082, 4877, 26987, 20307, 19294, 16436, 26364, 17629, 8244, 21831, 6058, 31966, 9217, 25601, 30871, 30257, 7707, 13054, 8212, 9160, 25986, 2757, 252, 24346, 17447, 31957, 20240, 3040, 24731, 11117, 19714, 5118, 5014, 5981, 31176, 7615, 27601, 19695, 31430, 16154, 5000, 20990, 26166, 15243, 11783, 2643, 28321, 8885, 28862, 31453, 30169, 26818, 22208, 2073, 4615, 7875, 22714, 14628, 20411, 12468, 31680, 23159, 3362, 21885, 7741, 10524, 8338, 24410, 1713, 5930, 17789, 1927, 11387, 11499, 18918, 22251, 29472, 14588, 27200, 7044, 24378, 8733, 4770, 3912, 10462, 3347, 26611, 20378, 11297, 19132, 26733, 22716, 29780, 2931, 5904, 26808, 20103, 30032, 30594, 23122, 7425, 11539, 9757, 31248, 26279, 8210, 14536, 13095, 32012, 16761, 11716, 985, 30004, 29332, 19879, 30235, 17586, 28961, 14691, 19994, 6877, 29016, 3601, 17377, 12705, 14052, 21272, 5649, 29334, 31748, 29404, 9422, 21865, 13953, 11582, 24112, 19130, 27797, 11372, 16954, 297, 14413, 16020, 8354, 15515, 6081, 23179, 13873, 27393, 28056, 4254, 678, 13127, 16373, 30719, 8176, 11586, 19473, 23374, 23017, 18800, 4333, 22218, 1354, 6908, 23511, 25314, 11765, 25893, 22174, 17894, 3195, 7668, 24758, 3497, 14580, 1464, 5295, 19906, 17044, 6379, 872, 9483, 29654, 17170, 26280, 2287, 26040, 9864, 3580, 31496, 27158, 8517, 5252, 10141, 15447, 11447, 6129, 9288, 16007, 19974, 16678, 7732, 23006, 8910, 26981, 11242, 27680, 11740, 15339, 24637, 4701, 19979, 2154, 6760, 16890, 5177, 2751, 18155, 18829, 5146, 30143, 20228, 11517, 22999, 23614, 24283, 30040, 2948, 364, 26427, 26035, 10451, 128, 27034, 8554, 5312, 31658, 7109, 22321, 12974, 22820, 20107, 28375, 21311, 22349, 14312, 7300, 22655, 13003, 9206, 25697, 6959, 26074, 8209, 17565, 25367, 24587, 4648, 28645, 7198, 27157, 4168, 25325, 30793, 28596, 30881, 5436, 25424, 19978, 25418, 19229, 1413, 18586, 28670, 24607, 10325, 21849, 17353, 21762, 10768, 27336, 17580, 28976, 10185, 13344, 19687, 24335, 26392, 23111, 31967, 22, 3307, 15984, 24943, 27022, 2181, 26285, 19691, 10103, 31380, 6417, 24614, 3367, 8907, 26990, 26975, 29867, 20015, 31314, 10275, 29366, 2182, 2505, 14250, 17300, 28304, 8380, 15538, 9982, 4441, 13684, 2747, 26453, 4239, 2987, 29078, 24760, 13080, 16236, 528, 9097, 13666, 17209, 6020, 22934, 6451, 29788, 12180, 20108, 6098, 17579, 4433, 13512, 17123, 8951, 602, 6562, 29083, 3552, 8313, 18527, 13343, 7711, 17064, 4158, 30976, 16795, 7527, 30593, 117, 29456, 9131, 19721, 28677, 350, 3853, 22324, 30308, 2748, 19241, 29025, 14075, 27480, 24061, 31931, 8622, 13039, 31479, 10628, 7962, 20431, 2336, 13468, 29833, 6254, 4833, 16054, 24092, 23297, 1178, 16878, 8039, 2079, 15493, 28903, 17813, 31233, 21386, 16267, 2916, 10305, 6954, 28942, 20931, 28319, 3397, 6696, 25343, 22933, 32183, 13433, 20297, 22707, 4036, 31189, 22860, 24964, 21954, 16266, 7495, 27015, 5975, 1013, 11161, 4835, 9373, 9278, 4687, 25286, 138, 17165, 9990, 11460, 24464, 14918, 10690, 1384, 6305, 30455, 29967, 14288, 20569, 11844, 20325, 26545, 22460, 29313, 21109, 24382, 30402, 18027, 25662, 8160, 4644, 352, 13700, 12813, 24044, 11941, 7564, 391, 13328, 24638, 27259, 16135, 9249, 5832, 19645, 21769, 26832, 10713, 27232, 3220, 29483, 16001, 20762, 8677, 23491, 22811, 28390, 1959, 19045, 1791, 25799, 13917, 17690, 6770, 1638, 7526, 4679, 6405, 27509, 14834, 29983, 12466, 727, 4855, 31778, 25288, 3198, 12286, 14945, 15803, 427, 28166, 30573, 7856, 21691, 14743, 26494, 2618, 16780, 27180, 18246, 5769, 13234, 2245, 13435, 22240, 2720, 4551, 15634, 18461, 27181, 19013, 17908, 15141, 21938, 25875, 30406, 17194, 1821, 10882, 12519, 8596, 23825, 24099, 23898, 4476, 15700, 31673, 5680, 1050, 6394, 27672, 29468, 4330, 15444, 30246, 7422, 24316, 9939, 22207, 26169, 14314, 18892, 6960, 30309, 21917, 3503, 10256, 18108, 30274, 19514, 5799, 20702, 4804, 8174, 6702, 28496, 30576, 17029, 18885, 29705, 13012, 11476, 22487, 11263, 24795, 7334, 21545, 24809, 31531, 14386, 15923, 28180, 16354, 29376, 8242, 25796, 5555, 1083, 10725, 8799, 248, 30067, 29545, 21962, 12312, 17945, 16987, 17242, 25004, 17672, 30820, 18726, 30202, 21468, 25031, 8773, 21563, 25661, 9835, 24858, 8250, 29899, 13291, 16049, 22074, 13813, 1314, 13161, 4492, 3150, 618, 17168, 11269, 1351, 19527, 4485, 8236, 7452, 21346, 14047, 27491, 26076, 31031, 21738, 17793, 23451, 10235, 18750, 11292, 27626, 14538, 17189, 15800, 7313, 26529, 27593, 31292, 31744, 28380, 31813, 10552, 22041, 4894, 31208, 26830, 26802, 23202, 932, 29119, 25017, 27841, 14172, 3701, 21369, 13674, 9958, 4415, 10137, 7544, 1952, 15594, 1866, 7486, 27834, 13928, 7131, 17917, 19311, 21944, 19626, 30434, 28437, 24903, 10053, 15412, 13658, 2032, 9018, 12653, 30933, 10049, 14092, 28786, 26606, 14846, 27912, 797, 5884, 4389, 26371, 17514, 20321, 9543, 19397, 22947, 9542, 1972, 15448, 17530, 12902, 29289, 11985, 32065, 9996, 26210, 28706, 26586, 21485, 7207, 4851, 2450, 26884, 29672, 18410, 26754, 21081, 106, 1987, 13282, 4620, 6145, 23373, 17944, 4010, 31976, 26228, 25257, 30326, 18307, 10223, 16703, 6367, 10636, 30440, 7963, 9488, 18773, 18201, 8710, 12581, 2446, 25462, 23976, 27448, 25227, 11249, 9468, 1090, 3748, 25120, 21082, 5464, 12941, 1311, 4821, 17485, 5488, 12443, 24697, 32021, 11658, 25452, 31092, 9520, 23759, 561, 31061, 20265, 19102, 25925, 14353, 2494, 22325, 30109, 18334, 15112, 3906, 3299, 31804, 14976, 180, 30862, 20722, 31406, 30053, 24019, 3342, 10516, 14400, 17369, 3885, 29156, 742, 5191, 3211, 31849, 13914, 30336, 1321, 8731, 1702, 9885, 20255, 20631, 16025, 20130, 29682, 6995, 29746, 10013, 29014, 6568, 8061, 28150, 10952, 21543, 430, 25204, 11872, 13202, 31358, 12461, 13213, 25279, 3224, 20101, 16237, 5589, 3186, 27124, 10088, 30468, 18907, 3699, 13372, 10433, 7113, 10264, 29748, 7627, 12664, 19261, 11722, 1805, 5109, 19267, 30315, 13402, 7367, 18299, 17930, 4831, 22599, 5028, 9714, 2921, 24882, 13969, 13057, 22112, 5073, 11619, 15545, 5272, 32254, 13240, 18044, 24627, 11510, 2641, 23888, 20613, 9054, 5508, 11924, 3126, 22215, 10617, 9749, 7595, 19609, 30251, 27277, 4808, 13103, 15717, 21759, 8564, 13356, 31356, 6119, 21882, 7396, 7474, 8126, 3851, 5781, 23776, 22411, 3828, 31144, 24177, 2408, 3166, 3073, 22959, 2706, 7699, 16122, 17034, 10132, 23014, 24792, 25171, 1168, 27419, 24055, 30232, 26489, 30572, 23627, 26999, 2415, 589, 22514, 9133, 25959, 28627, 10957, 28865, 8493, 20217, 11923, 5032, 16536, 6412, 361, 17884, 12909, 14593, 20312, 1879, 6088, 22525, 21498, 31674, 22533, 15424, 7350, 12434, 17445, 17403, 8170, 21644, 31, 18009, 12241, 18936, 23956, 19430, 10860, 15574, 16657, 31528, 15296, 12621, 10482, 20692, 24978, 22139, 29244, 10571, 31950, 14678, 20820, 22607, 6806, 28875, 2220, 30292, 6596, 20515, 26180, 27573, 6131, 26943, 22344, 23271, 10856, 5406, 28995, 14206, 21900, 7782, 18677, 23078, 14695, 18753, 16105, 14454, 8700, 1096, 11404, 9734, 27252, 7750, 15513, 9050, 15877, 25974, 3929, 18646, 18597, 29181, 25043, 12972, 30819, 14328, 1667, 10064, 10057, 29868, 4934, 30807, 7932, 25987, 29065, 23726, 27251, 11824, 8514, 4581, 28626, 16611, 19356, 23589, 685, 17293, 23113, 28858, 16659, 27994, 14327, 5382, 3833, 16781, 6705, 24141, 24334, 9401, 21361, 28760, 30777, 25643, 22786, 3830, 21168, 29864, 12479, 4289, 920, 23678, 29566, 25745, 27347, 298, 19181, 29671, 5122, 5735, 3979, 14162, 6011, 20195, 2461, 25100, 18618, 13503, 24387, 19854, 21328, 17159, 9308, 28577, 3824, 24640, 24804, 21773, 2029, 18963, 28127, 31971, 3141, 6689, 9212, 7187, 29998, 7120, 909, 24379, 8053, 23583, 24084, 1670, 17450, 22572, 24572, 27765, 16922, 4451, 28462, 7778, 30297, 3083, 15961, 10010, 29128, 11646, 30483, 4958, 23885, 28363, 9435, 4170, 22376, 9353, 6386, 5204, 3182, 31617, 22114, 9331, 30850, 23305, 9557, 30084, 20649, 22461, 22932, 3724, 13270, 288, 4018, 18637, 27309, 699, 7029, 23762, 3156, 19162, 20640, 31763, 29714, 16199, 18041, 16439, 4464, 9685, 2750, 14557, 30534, 6578, 7508, 27390, 10377, 7543, 722, 17740, 1945, 3735, 7622, 28861, 18650, 26343, 5517, 9480, 30012, 25590, 29753, 30229, 23986, 26089, 26883, 16313, 25855, 12926, 5615, 9121, 19098, 16622, 17251, 24170, 151, 4587, 23742, 9117, 13078, 6246, 5784, 12472, 22806, 24008, 16252, 14042, 1815, 253, 29147, 20204, 7249, 25006, 26487, 3337, 2184, 20087, 18175, 25594, 18926, 3444, 21859, 832, 11427, 27895, 681, 21459, 14948, 12917, 663, 14069, 23430, 17538, 5780, 18996, 19732, 1800, 21165, 17018, 26996, 3994, 5894, 10513, 7223, 29673, 7621, 19342, 9950, 25587, 29790, 21199, 15946, 7705, 5474, 9521, 25973, 12427, 24472, 12441, 9859, 14664, 15909, 15122, 23605, 7127, 22248, 16286, 9290, 9929, 31386, 2758, 9495, 24540, 31025, 14926, 14359, 24660, 737, 25104, 20461, 15206, 31579, 32239, 16523, 2375, 13038, 1944, 5765, 21457, 19063, 7516, 26709, 17267, 9227, 913, 13551, 18115, 29979, 27193, 24451, 27059, 29652, 21923, 20671, 13867, 18471, 310, 32181, 26437, 16939, 6056, 17266, 22419, 29219, 16635, 27255, 31328, 6280, 9019, 12561, 24698, 428, 26924, 31421, 7801, 30387, 14787, 31589, 4686, 28710, 15090, 24058, 1426, 10653, 6907, 28153, 20643, 15027, 21467, 11458, 6583, 22415, 13239, 26661, 22193, 14029, 17299, 4997, 24212, 29797, 15633, 5490, 2723, 19160, 5716, 23340, 7966, 7245, 5776, 26058, 30277, 9020, 30920, 17904, 6012, 8182, 881, 1167, 18688, 27207, 17259, 30028, 30395, 8777, 23145, 32052, 18701, 17619, 28275, 1264, 16073, 23076, 5881, 9779, 11706, 10144, 9781, 18779, 16264, 28483, 13275, 24095, 18737, 2250, 9726, 1617, 10303, 5910, 5690, 2296, 5577, 32014, 17069, 17487, 20158, 30250, 23241, 6318, 24041, 13821, 23981, 25122, 17292, 9992, 10511, 70, 18971, 17533, 14879, 10855, 26992, 21198, 10888, 14362, 12752, 22953, 16193, 31224, 29183, 30935, 5048, 31047, 7210, 22347, 26775, 3899, 3275, 17411, 19035, 17156, 12839, 8438, 26892, 6092, 27844, 16188, 17546, 10723, 20153, 8158, 15197, 8302, 16755, 19448, 27940, 738, 20904, 9355, 14046, 11975, 16770, 237, 19921, 17389, 6360, 7982, 19839, 6667, 30173, 16149, 11669, 32143, 17878, 26357, 4017, 15104, 4574, 25514, 21466, 1017, 18129, 17382, 30735, 20575, 17140, 22323, 31048, 601, 20180, 23633, 12632, 3496, 1272, 9554, 28735, 18474, 3395, 10629, 12115, 11012, 27883, 11250, 22849, 14865, 22261, 28081, 31002, 14176, 18493, 929, 5696, 27031, 28564, 18320, 21288, 16229, 3043, 30646, 9350, 31629, 10002, 6296, 15407, 15649, 3082, 18874, 19809, 23190, 20837, 7573, 23630, 26707, 14236, 7832, 22909, 3335, 27041, 1619, 1401, 22459, 31401, 31566, 14736, 3309, 3632, 6112, 21549, 17428, 11682, 6570, 6831, 17110, 21780, 18642, 5987, 21481, 11697, 21528, 17400, 30763, 8605, 20991, 6906, 13010, 26984, 1442, 695, 377, 28880, 31459, 7630, 4801, 18986, 344, 9475, 25758, 23854, 30831, 19008, 12449, 1211, 16901, 25670, 25152, 16841, 15727, 30110, 31856, 2308, 13461, 19208, 22184, 16838, 6969, 12834, 7404, 17863, 17824, 9127, 31623, 18054, 31694, 15586, 11845, 7380, 14875, 8485, 18349, 19966, 15751, 6046, 2968, 24851, 3481, 11622, 28358, 24677, 614, 14505, 15154, 31979, 29478, 28410, 5117, 7421, 2698, 19675, 6748, 30986, 9352, 20911, 8062, 5717, 6301, 13279, 3484, 21540, 20006, 31628, 19576, 22022, 28149, 26655, 12831, 20254, 27977, 18842, 7618, 4826, 14181, 17795, 24591, 17065, 20608, 21734, 4430, 9066, 23760, 24215, 24887, 4288, 25376, 7292, 16120, 7032, 1171, 1996, 28557, 15868, 15152, 19955, 37, 19056, 26360, 25461, 11432, 11395, 9587, 25180, 16178, 24460, 6304, 29287, 14561, 768, 2212, 14499, 9240, 23475, 20202, 30648, 26571, 5294, 25605, 27246, 20806, 12332, 19268, 16548, 23463, 29427, 10603, 19886, 19218, 13411, 30494, 29229, 1163, 10567, 31575, 17942, 3586, 6533, 9431, 7841, 19773, 17175, 3072, 18722, 9828, 31393, 14009, 16324, 9389, 941, 9665, 31447, 10632, 17352, 11116, 13863, 23811, 4930, 30527, 23716, 24152, 7110, 6740, 4151, 13395, 24120, 27004, 30463, 7341, 29980, 18176, 18598, 21429, 16029, 6259, 24632, 7301, 15298, 25336, 13807, 31199, 11333, 9819, 17379, 27542, 5360, 3761, 3183, 13197, 22756, 31833, 6864, 19265, 11373, 10355, 11171, 23066, 866, 20250, 31781, 24441, 2293, 19777, 22854, 2894, 28512, 25272, 2823, 2444, 4465, 2413, 28173, 29015, 23007, 12680, 17361, 25525, 31495, 23082, 19452, 11170, 1031, 5552, 9635, 13439, 31784, 8874, 4117, 10913, 15238, 23441, 457, 10828, 12253, 11350, 16338, 2267, 12531, 26562, 28337, 17499, 24779, 21874, 25185, 19870, 5854, 14577, 12401, 15190, 9116, 1349, 27733, 14783, 15834, 7887, 2826, 12065, 7169, 14003, 29112, 7174, 26969, 28112, 28573, 22766, 21713, 29584, 12657, 15914, 267, 2509, 26762, 4119, 29667, 15380, 18128, 23046, 4906, 30992, 24220, 25975, 19572, 3855, 13560, 12768, 13860, 1292, 31505, 6983, 11174, 10336, 30374, 28292, 4599, 10962, 15216, 928, 23980, 5493, 19107, 16418, 23385, 7882, 25982, 1106, 5002, 15370, 10691, 23146, 10181, 26012, 6320, 8327, 14525, 17286, 27104, 8857, 19436, 23442, 28230, 21196, 20581, 31297, 22918, 13491, 17435, 15825, 13602, 7643, 24926, 2566, 10790, 5595, 10125, 7748, 22308, 19444, 444, 468, 19070, 5495, 4849, 26753, 26363, 11336, 1855, 10210, 11909, 19363, 31259, 11799, 4769, 18943, 29926, 15123, 24258, 7664, 5563, 20209, 31253, 11726, 14859, 26296, 30418, 13757, 2303, 13383, 19788, 1087, 12223, 25879, 19925, 13168, 16411, 28711, 23787, 29135, 20176, 21904, 19394, 16581, 163, 25495, 22545, 29863, 7083, 10066, 26284, 1818, 21685, 24293, 14026, 5813, 1889, 18209, 4011, 8064, 28797, 30816, 31212, 5811, 3867, 30604, 17684, 12897, 21208, 4102, 19292, 15052, 14142, 5603, 26461, 11537, 13632, 4469, 19710, 20454, 27917, 25686, 12796, 26734, 13790, 12543, 13730, 4647, 30128, 2562, 2481, 13993, 4242, 14653, 26486, 25347, 5210, 29947, 8989, 8919, 16103, 25978, 17949, 30248, 24879, 26760, 23820, 9192, 8977, 4278, 24930, 9439, 22887, 19587, 23395, 16640, 19787, 8458, 1137, 27417, 5380, 31506, 11176, 23818, 24620, 31943, 1668, 7441, 2171, 26954, 12303, 29522, 19290, 27164, 30394, 20848, 23460, 19062, 1641, 1902, 29069, 27817, 5974, 20095, 31544, 8760, 18229, 28020, 19148, 5237, 9767, 24578, 9497, 883, 359, 2936, 8055, 6519, 15415, 28448, 6966, 9196, 21660, 3417, 12738, 6726, 22510, 10990, 17952, 30692, 6228, 30946, 10328, 22879, 6265, 28082, 25360, 31715, 25910, 3540, 19536, 6384, 8811, 27239, 18730, 6410, 24568, 18983, 2290, 21778, 631, 12579, 460, 13636, 23534, 17295, 31801, 3416, 5909, 26569, 19548, 15280, 11127, 19761, 11139, 29874, 25390, 6008, 8778, 20669, 16786, 2787, 8192, 11299, 12556, 2756, 3690, 25366, 4876, 20737, 25408, 6486, 24593, 19273, 15366, 11541, 25480, 149, 15753, 1485, 289, 26173, 2080, 18802, 13180, 20635, 22624, 28804, 22200, 31338, 566, 6830, 31585, 25848, 10801, 24096, 11230, 31095, 14527, 26553, 19214, 31532, 501, 31882, 29943, 6240, 14712, 11346, 18486, 20134, 20559, 30317, 24506, 1605, 12425, 23622, 5164, 17668, 21876, 588, 9300, 28803, 12302, 27299, 4842, 17994, 31357, 15270, 22542, 8526, 8035, 16960, 22058, 10569, 8269, 28982, 2683, 8201, 26055, 17270, 3287, 14439, 23847, 27702, 1657, 24716, 9924, 21977, 22623, 20624, 9418, 29241, 27110, 14734, 12246, 10490, 13884, 2402, 8802, 25947, 4138, 12414, 14519, 16746, 23093, 15769, 2398, 8001, 14668, 28416, 13827, 22356, 9948, 22117, 8550, 21356, 12948, 22132, 5381, 24308, 6961, 18060, 7218, 25625, 9944, 1318, 11498, 23540, 21303, 20785, 10889, 26132, 19355, 648, 5664, 22118, 624, 27341, 18804, 19813, 12023, 32023, 11774, 30305, 25960, 22973, 12103, 15772, 25246, 662, 28472, 13753, 5941, 27395, 31880, 5206, 13536, 2663, 9195, 31347, 10243, 20666, 24059, 30561, 10370, 20524, 5379, 4207, 13838, 5129, 17899, 1992, 4813, 20086, 16873, 27700, 20873, 8151, 23538, 879, 4204, 19655, 707, 22982, 491, 13269, 10351, 12370, 1711, 31274, 7915, 23042, 21394, 2382, 27742, 24270, 14531, 14267, 19221, 3501, 7052, 16412, 96, 11514, 8309, 26786, 11588, 15312, 18647, 27685, 8585, 30482, 5375, 24719, 13770, 27622, 10849, 11561, 3117, 22036, 15139, 13109, 1843, 17424, 20369, 9691, 3516, 11560, 11379, 13448, 32013, 29008, 13392, 4816, 4413, 30484, 25687, 26765, 8996, 1862, 22329, 15517, 3067, 1510, 27, 11624, 25968, 24458, 19993, 23987, 21435, 12124, 19935, 15175, 30115, 8664, 15709, 17716, 15667, 5667, 13591, 22105, 19715, 25920, 14586, 18587, 28377, 8077, 14115, 334, 22466, 29460, 27128, 2385, 12052, 22923, 21943, 12186, 14154, 25700, 7589, 3598, 18718, 22336, 27541, 28868, 15533, 14644, 4165, 4140, 27971, 20912, 5332, 4582, 24598, 29606, 30750, 28575, 24938, 2703, 6251, 8083, 11733, 23797, 2734, 18552, 16914, 965, 763, 14045, 12942, 31955, 5358, 16826, 7749, 25737, 3223, 15295, 10557, 27507, 7462, 30853, 25565, 5051, 22285, 7409, 21987, 30814, 2118, 26604, 8319, 23129, 23219, 17344, 2273, 23624, 24407, 762, 11576, 3443, 3910, 9659, 5330, 24271, 29755, 14136, 4275, 30410, 9676, 15262, 15892, 5476, 21628, 12382, 13738, 29760, 12674, 24069, 19133, 25631, 24822, 10914, 28896, 15646, 29122, 8195, 5133, 1573, 9822, 28831, 3504, 9262, 32184, 10104, 3860, 16998, 24706, 21681, 13091, 8097, 10119, 12155, 4973, 20525, 16406, 8181, 5713, 32041, 10732, 22014, 16129, 19517, 7143, 23319, 10018, 10069, 1965, 18015, 3746, 30408, 22454, 4610, 3449, 20489, 7549, 17198, 32208, 10835, 26407, 10177, 10432, 14285, 258, 4050, 12335, 28747, 20207, 31899, 17691, 11106, 9809, 12829, 1393, 15458, 4054, 31745, 14958, 30579, 21729, 16311, 22703, 29759, 10233, 14183, 24848, 8821, 29836, 6504, 157, 26243, 21661, 31888, 28199, 1857, 22928, 25430, 19307, 895, 9934, 13158, 21538, 27332, 4794, 30789, 24453, 12121, 25280, 5183, 23366, 25161, 27757, 3838, 16700, 21637, 26472, 20434, 23084, 21584, 7376, 4328, 5185, 19780, 3554, 8042, 14448, 14729, 676, 32046, 25648, 19096, 24650, 1193, 3770, 15880, 3455, 15941, 27898, 23777, 16821, 20971, 30382, 26739, 30228, 10906, 24242, 32171, 18387, 27878, 16819, 27176, 7597, 25772, 21052, 29050, 24740, 23120, 32085, 15675, 25218, 10645, 16417, 5486, 27423, 790, 25490, 32182, 10570, 24225, 28236, 23892, 26376, 8027, 22762, 12967, 25813, 13121, 4449, 20169, 27729, 15780, 19336, 6327, 30754, 15718, 27038, 3744, 9673, 14964, 8108, 24664, 2699, 17488, 11926, 586, 4322, 5613, 5264, 1936, 18337, 10285, 25449, 13251, 16159, 22950, 18475, 23413, 25166, 20822, 9253, 21453, 966, 30378, 8381, 17326, 9881, 10919, 31709, 1652, 24429, 19141, 28785, 14321, 15933, 5885, 17525, 2965, 1358, 3047, 27442, 26757, 21044, 17796, 22130, 20144, 22150, 10545, 26989, 24137, 5587, 25650, 21503, 27127, 7570, 13387, 25533, 22362, 14210, 23500, 16542, 17951, 11501, 28270, 25566, 13217, 597, 28682, 32192, 2903, 17378, 2928, 23004, 4747, 22052, 11718, 4499, 2517, 14177, 31084, 9695, 17588, 15855, 3357, 25088, 26896, 20360, 26662, 28460, 28039, 7010, 11185, 13345, 4774, 20335, 21752, 13990, 7975, 11218, 6560, 31215, 22315, 4584, 27525, 1390, 26862, 10705, 25189, 20802, 24768, 24935, 19933, 8148, 11986, 28353, 4218, 26509, 31954, 24494, 29570, 23590, 1997, 21003, 15024, 14737, 28543, 3464, 3366, 24693, 5621, 398, 29929, 20805, 21505, 8891, 17839, 31906, 25196, 12505, 19406, 10007, 8498, 8399, 9837, 24227, 657, 22098, 2864, 24793, 10497, 20626, 3064, 7817, 30025, 32130, 29044, 917, 5441, 536, 6823, 9999, 12508, 21598, 7273, 11689, 13355, 22954, 29655, 690, 1983, 31055, 14048, 30967, 628, 9152, 29796, 29696, 10084, 15182, 25832, 21881, 4267, 11584, 24884, 28676, 17608, 5905, 14962, 20251, 2790, 28241, 20609, 23547, 23058, 6611, 30182, 16512, 27042, 29728, 5105, 18959, 32158, 25553, 26633, 10777, 9873, 3795, 3298, 11843, 18381, 11569, 20975, 6925, 18435, 22747, 5638, 32150, 3949, 9951, 13782, 28352, 29712, 12220, 45, 12191, 6230, 28106, 8128, 10033, 24016, 22647, 15859, 8652, 10886, 31787, 29438, 1301, 27713, 4152, 28826, 1074, 29352, 20544, 18755, 17071, 11928, 21525, 21297, 12750, 20054, 22617, 27936, 7196, 8193, 4634, 4429, 22875, 19656, 21989, 98, 14789, 6461, 14776, 13635, 30922, 13803, 16003, 5162, 562, 4867, 26609, 25714, 1562, 6890, 24148, 1752, 5341, 30205, 32072, 9890, 28877, 15848, 4076, 21974, 11124, 19567, 599, 6138, 21755, 13146, 20825, 9226, 28133, 11445, 18594, 326, 4722, 15543, 2849, 21421, 4719, 7639, 31125, 984, 2774, 18077, 8051, 3296, 20792, 29170, 25069, 8946, 20030, 1504, 1696, 28183, 19726, 7183, 1132, 25688, 32026, 16606, 31009, 7498, 13923, 6337, 10858, 5796, 18803, 9426, 7017, 3101, 25902, 20668, 5654, 28434, 25548, 15007, 20442, 11079, 1198, 1000, 6248, 16283, 3819, 2072, 5308, 21100, 31142, 31729, 22653, 18783, 21758, 25593, 15436, 7935, 25399, 7530, 27274, 11644, 29639, 6252, 27671, 29567, 29450, 5895, 8826, 4366, 17766, 26493, 25895, 7033, 16628, 27559, 23490, 17304, 3898, 12692, 15593, 6094, 20542, 9937, 12874, 29415, 3753, 31863, 4380, 32209, 16158, 28668, 160, 7787, 13225, 19919, 13986, 16549, 20538, 2109, 19275, 14093, 3579, 28400, 19659, 3757, 17681, 2829, 22530, 30536, 23569, 4498, 2291, 20426, 18660, 2128, 10684, 6756, 17815, 30266, 7694, 7823, 11755, 11482, 29139, 4298, 10863, 18862, 19816, 13578, 4410, 11800, 16235, 3328, 5278, 24319, 7999, 27177, 23702, 18636, 21756, 552, 5507, 18311, 23831, 29210, 3608, 6497, 31652, 30027, 9575, 1477, 19740, 29484, 16437, 11115, 25972, 30127, 24240, 13786, 23585, 31592, 3517, 18453, 3279, 23520, 6075, 17152, 9988, 6921, 13764, 10201, 5157, 2933, 3341, 1070, 5261, 18255, 31130, 29917, 1682, 5396, 19497, 2012, 22551, 15916, 23260, 19124, 20861, 28498, 21309, 12727, 27968, 27085, 17205, 24417, 17166, 5839, 12279, 28811, 27997, 1853, 752, 14809, 31222, 12235, 9539, 15334, 13870, 25195, 15263, 23422, 9750, 15528, 30841, 29341, 436, 28594, 30141, 25611, 20127, 24526, 20928, 3505, 11167, 5100, 23660, 10859, 8772, 27087, 11475, 18941, 807, 3985, 21533, 25516, 12592, 14209, 2233, 10802, 12406, 26706, 4044, 1871, 21883, 11093, 28840, 12345, 17036, 29457, 8583, 9360, 11208, 30198, 12243, 30118, 5652, 7202, 2539, 16450, 12569, 1704, 13052, 3777, 11066, 11389, 25203, 15364, 29605, 14277, 13101, 16647, 28912, 5316, 24269, 5131, 14888, 6778, 24688, 26473, 19828, 3687, 16911, 31097, 1633, 9909, 26903, 20184, 29703, 9993, 23165, 4125, 17511, 12255, 29508, 2812, 2275, 18121, 25667, 3192, 30385, 4890, 30283, 12997, 5531, 9713, 29075, 29153, 12904, 7104, 18830, 21820, 29904, 26644, 27708, 21338, 32113, 13783, 8986, 7776, 6607, 29196, 11444, 18656, 14788, 28461, 16408, 30740, 25222, 4974, 20913, 14592, 23698, 10252, 18426, 28357, 4287, 19431, 23725, 1904, 31021, 4680, 2312, 18839, 12608, 12119, 16138, 23554, 31513, 23769, 10306, 20278, 27372, 26067, 21215, 27483, 31014, 17804, 18438, 28834, 19135, 3775, 17147, 28129, 1755, 31757, 23699, 3380, 10945, 30422, 23177, 15187, 16303, 2902, 18814, 3318, 18305, 9320, 17974, 13272, 19428, 18448, 27204, 19999, 6336, 7681, 13714, 7478, 28714, 9547, 5791, 731, 29102, 12164, 30039, 27627, 3401, 8716, 9949, 11595, 12289, 21585, 11851, 24261, 11035, 17869, 27907, 20422, 2196, 25928, 3802, 13112, 8339, 8476, 23187, 18399, 22675, 14796, 22696, 1473, 4935, 30575, 4929, 22151, 22038, 3893, 9428, 1860, 14021, 31017, 6593, 31502, 10989, 1101, 2534, 11061, 8847, 8292, 21760, 6841, 6511, 6932, 26985, 26895, 13820, 13364, 27122, 5021, 21548, 26598, 27149, 8871, 22316, 10352, 17832, 8117, 17063, 26374, 12534, 29333, 23116, 29593, 17638, 16707, 6860, 8533, 28656, 2149, 29216, 130, 6018, 14913, 22018, 25205, 28331, 31422, 17882, 12512, 31051, 3200, 188, 8078, 25575, 23052, 24366, 4104, 8036, 5597, 4583, 1778, 11764, 6828, 27357, 31295, 27638, 13832, 24554, 18522, 28642, 20485, 5339, 30666, 7606, 8131, 5962, 10048, 15573, 8179, 10327, 728, 13836, 7092, 10910, 1337, 21959, 7080, 27656, 9569, 4596, 22902, 31633, 17364, 15945, 3468, 16147, 23609, 10131, 22757, 30414, 2728, 24344, 4368, 10566, 25234, 17706, 21669, 27240, 24105, 20073, 5263, 28655, 15629, 3142, 6426, 18324, 6660, 5887, 23304, 9356, 23369, 28174, 22690, 11192, 4177, 8087, 20860, 12352, 30710, 25084, 26528, 12317, 5648, 12767, 31603, 3882, 31510, 5590, 16213, 5232, 30370, 31679, 20242, 6669, 13431, 29528, 28540, 13705, 23248, 6679, 4897, 26001, 15614, 18252, 25676, 6997, 2647, 26639, 17323, 31283, 3750, 28743, 11613, 8010, 7483, 17947, 19874, 1746, 14322, 16799, 22986, 17127, 13307, 23474, 7106, 28403, 31099, 11947, 15569, 16725, 27762, 9443, 6620, 25431, 12965, 5860, 20145, 8745, 2658, 20779, 14356, 25116, 12843, 892, 24192, 11162, 2482, 30340, 13763, 24599, 7330, 24739, 9151, 24583, 17188, 12132, 19057, 17554, 22274, 20071, 28314, 20695, 19981, 25849, 12862, 7461, 25298, 323, 8098, 12946, 22189, 6724, 15665, 29130, 31000, 18203, 25534, 14916, 11999, 1542, 25864, 31146, 1774, 3977, 28368, 30452, 19082, 1695, 26480, 18178, 29658, 9507, 24221, 8704, 19837, 21175, 17493, 20528, 28640, 15864, 10871, 15146, 12981, 1942, 6832, 11519, 4481, 21414, 3295, 7938, 15130, 32243, 2614, 5090, 3559, 16301, 25146, 19631, 22269, 23930, 4916, 10112, 7743, 20799, 13793, 5644, 15987, 1060, 10826, 13267, 14102, 22338, 18732, 17143, 31706, 13389, 31631, 10744, 14782, 27046, 28055, 31303, 27718, 31362, 28338, 28111, 875, 13745, 26144, 1637, 20113, 29744, 16594, 31904, 9700, 15611, 8521, 16282, 12179, 7518, 181, 9274, 10619, 21570, 9636, 14368, 26045, 17214, 20985, 1540, 9161, 27160, 23485, 29809, 11534, 20932, 23593, 7231, 15588, 7275, 23010, 15271, 17497, 27340, 31264, 16041, 23592, 20698, 25374, 30311, 14406, 3311, 19798, 14319, 26482, 9032, 25892, 16111, 2584, 38, 25432, 14036, 14896, 3658, 9065, 15632, 3968, 7493, 12964, 15729, 12994, 3400, 29115, 27633, 15854, 25540, 27445, 20959, 20843, 11473, 13524, 8122, 14523, 29060, 15554, 4486, 20857, 19316, 1439, 3482, 9324, 23640, 26267, 17898, 6277, 24222, 8189, 28429, 21112, 28958, 8205, 6526, 16015, 14665, 14524, 16985, 3021, 8681, 2131, 22158, 27691, 30872, 19603, 18029, 15488, 22608, 27897, 20798, 4746
INFO:root:train dataset: 68117, validation dataset: 3872, test dataset: 6454
INFO:root:used only channels: [1]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.04979770
INFO:root:[1,   100] training loss: 0.04069257
INFO:root:[1,   150] training loss: 0.03671851
INFO:root:[1,   200] training loss: 0.03590856
INFO:root:[1,   250] training loss: 0.03592505
INFO:root:[1,   300] training loss: 0.03751227
INFO:root:[1,   350] training loss: 0.02968915
INFO:root:[1,   400] training loss: 0.00078155
INFO:root:[1,   450] training loss: 0.00037488
INFO:root:[1,   500] training loss: 0.00685674
INFO:root:[1,   550] training loss: 0.00711417
INFO:root:[1,   600] training loss: 0.02659399
INFO:root:[1,   650] training loss: 0.00001078
INFO:root:[1,   700] training loss: 0.00000683
INFO:root:[1,   750] training loss: 0.00000664
INFO:root:[1,   800] training loss: 0.00000551
INFO:root:[1,   850] training loss: 0.00000769
INFO:root:[1,   900] training loss: 0.09638854
INFO:root:[1,   950] training loss: 0.02511125
INFO:root:[1,  1000] training loss: 0.00000068
INFO:root:[1,  1050] training loss: 0.00000077
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.12638743
INFO:root:[2,   100] training loss: 0.06844150
INFO:root:[2,   150] training loss: 0.06509987
INFO:root:[2,   200] training loss: 0.08476713
INFO:root:[2,   250] training loss: 0.04272735
INFO:root:[2,   300] training loss: 0.09120849
INFO:root:[2,   350] training loss: 0.04323503
INFO:root:[2,   400] training loss: 0.00111439
INFO:root:[2,   450] training loss: 0.00031223
INFO:root:[2,   500] training loss: 0.00958603
INFO:root:[2,   550] training loss: 0.00503923
INFO:root:[2,   600] training loss: 0.04589069
INFO:root:[2,   650] training loss: 0.00000255
INFO:root:[2,   700] training loss: 0.00000253
INFO:root:[2,   750] training loss: 0.00000299
INFO:root:[2,   800] training loss: 0.00000206
INFO:root:[2,   850] training loss: 0.00000267
INFO:root:[2,   900] training loss: 0.08525384
INFO:root:[2,   950] training loss: 0.02138757
INFO:root:[2,  1000] training loss: 0.00005366
INFO:root:[2,  1050] training loss: 0.00004523
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.08396757
INFO:root:[3,   100] training loss: 0.04239886
INFO:root:[3,   150] training loss: 0.04366707
INFO:root:[3,   200] training loss: 0.03770990
INFO:root:[3,   250] training loss: 0.03344815
INFO:root:[3,   300] training loss: 0.03562519
INFO:root:[3,   350] training loss: 0.03657602
INFO:root:[3,   400] training loss: 0.00358045
INFO:root:[3,   450] training loss: 0.00029683
INFO:root:[3,   500] training loss: 0.00907922
INFO:root:[3,   550] training loss: 0.00568729
INFO:root:[3,   600] training loss: 0.02199275
INFO:root:[3,   650] training loss: 0.00000522
INFO:root:[3,   700] training loss: 0.00000622
INFO:root:[3,   750] training loss: 0.00000562
INFO:root:[3,   800] training loss: 0.00000429
INFO:root:[3,   850] training loss: 0.00000534
INFO:root:[3,   900] training loss: 0.06713350
INFO:root:[3,   950] training loss: 0.01653142
INFO:root:[3,  1000] training loss: 0.00001314
INFO:root:[3,  1050] training loss: 0.00001262
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.07442053
INFO:root:[4,   100] training loss: 0.03317414
INFO:root:[4,   150] training loss: 0.03290793
INFO:root:[4,   200] training loss: 0.03614883
INFO:root:[4,   250] training loss: 0.03502633
INFO:root:[4,   300] training loss: 0.03156559
INFO:root:[4,   350] training loss: 0.02986272
INFO:root:[4,   400] training loss: 0.00136313
INFO:root:[4,   450] training loss: 0.00025452
INFO:root:[4,   500] training loss: 0.00809732
INFO:root:[4,   550] training loss: 0.00747881
INFO:root:[4,   600] training loss: 0.02236252
INFO:root:[4,   650] training loss: 0.00000131
INFO:root:[4,   700] training loss: 0.00000145
INFO:root:[4,   750] training loss: 0.00000198
INFO:root:[4,   800] training loss: 0.00000183
INFO:root:[4,   850] training loss: 0.00000226
INFO:root:[4,   900] training loss: 0.06896468
INFO:root:[4,   950] training loss: 0.01618221
INFO:root:[4,  1000] training loss: 0.00003798
INFO:root:[4,  1050] training loss: 0.00002229
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.06599123
INFO:root:[5,   100] training loss: 0.02867000
INFO:root:[5,   150] training loss: 0.02831773
INFO:root:[5,   200] training loss: 0.02533898
INFO:root:[5,   250] training loss: 0.02730330
INFO:root:[5,   300] training loss: 0.03134522
INFO:root:[5,   350] training loss: 0.02672388
INFO:root:[5,   400] training loss: 0.00158294
INFO:root:[5,   450] training loss: 0.00035831
INFO:root:[5,   500] training loss: 0.00748226
INFO:root:[5,   550] training loss: 0.00692697
INFO:root:[5,   600] training loss: 0.02262537
INFO:root:[5,   650] training loss: 0.00000465
INFO:root:[5,   700] training loss: 0.00000424
INFO:root:[5,   750] training loss: 0.00000534
INFO:root:[5,   800] training loss: 0.00000535
INFO:root:[5,   850] training loss: 0.00000415
INFO:root:[5,   900] training loss: 0.06185928
INFO:root:[5,   950] training loss: 0.01686698
INFO:root:[5,  1000] training loss: 0.00002899
INFO:root:[5,  1050] training loss: 0.00002473
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.06274338
INFO:root:[6,   100] training loss: 0.02969502
INFO:root:[6,   150] training loss: 0.03851845
INFO:root:[6,   200] training loss: 0.04531999
INFO:root:[6,   250] training loss: 0.02960564
INFO:root:[6,   300] training loss: 0.02953336
INFO:root:[6,   350] training loss: 0.02671614
INFO:root:[6,   400] training loss: 0.00192785
INFO:root:[6,   450] training loss: 0.00029937
INFO:root:[6,   500] training loss: 0.00702339
INFO:root:[6,   550] training loss: 0.00802977
INFO:root:[6,   600] training loss: 0.02403263
INFO:root:[6,   650] training loss: 0.00001468
INFO:root:[6,   700] training loss: 0.00001188
INFO:root:[6,   750] training loss: 0.00001139
INFO:root:[6,   800] training loss: 0.00001323
INFO:root:[6,   850] training loss: 0.00001037
INFO:root:[6,   900] training loss: 0.06758637
INFO:root:[6,   950] training loss: 0.01601730
INFO:root:[6,  1000] training loss: 0.00003745
INFO:root:[6,  1050] training loss: 0.00003029
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2672    1.0000    0.4217      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0602      3872
weighted avg     0.0714    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.06643768
INFO:root:[7,   100] training loss: 0.02714294
INFO:root:[7,   150] training loss: 0.02666806
INFO:root:[7,   200] training loss: 0.02566107
INFO:root:[7,   250] training loss: 0.02609442
INFO:root:[7,   300] training loss: 0.02853173
INFO:root:[7,   350] training loss: 0.02544914
INFO:root:[7,   400] training loss: 0.00138943
INFO:root:[7,   450] training loss: 0.00026288
INFO:root:[7,   500] training loss: 0.00727646
INFO:root:[7,   550] training loss: 0.00858449
INFO:root:[7,   600] training loss: 0.02248954
INFO:root:[7,   650] training loss: 0.00002419
INFO:root:[7,   700] training loss: 0.00001698
INFO:root:[7,   750] training loss: 0.00001900
INFO:root:[7,   800] training loss: 0.00001704
INFO:root:[7,   850] training loss: 0.00001716
INFO:root:[7,   900] training loss: 0.06080393
INFO:root:[7,   950] training loss: 0.01544764
INFO:root:[7,  1000] training loss: 0.00004505
INFO:root:[7,  1050] training loss: 0.00003282
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.06127837
INFO:root:[8,   100] training loss: 0.02521932
INFO:root:[8,   150] training loss: 0.02728133
INFO:root:[8,   200] training loss: 0.02306269
INFO:root:[8,   250] training loss: 0.02453872
INFO:root:[8,   300] training loss: 0.02820719
INFO:root:[8,   350] training loss: 0.02478395
INFO:root:[8,   400] training loss: 0.00113538
INFO:root:[8,   450] training loss: 0.00046628
INFO:root:[8,   500] training loss: 0.00647452
INFO:root:[8,   550] training loss: 0.00847430
INFO:root:[8,   600] training loss: 0.02328973
INFO:root:[8,   650] training loss: 0.00001735
INFO:root:[8,   700] training loss: 0.00001468
INFO:root:[8,   750] training loss: 0.00002250
INFO:root:[8,   800] training loss: 0.00002006
INFO:root:[8,   850] training loss: 0.00001410
INFO:root:[8,   900] training loss: 0.05813637
INFO:root:[8,   950] training loss: 0.01517284
INFO:root:[8,  1000] training loss: 0.00009693
INFO:root:[8,  1050] training loss: 0.00005829
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.05776108
INFO:root:[9,   100] training loss: 0.02342006
INFO:root:[9,   150] training loss: 0.02442589
INFO:root:[9,   200] training loss: 0.02161722
INFO:root:[9,   250] training loss: 0.02509970
INFO:root:[9,   300] training loss: 0.02595127
INFO:root:[9,   350] training loss: 0.02444575
INFO:root:[9,   400] training loss: 0.00155034
INFO:root:[9,   450] training loss: 0.00022622
INFO:root:[9,   500] training loss: 0.00575127
INFO:root:[9,   550] training loss: 0.00755305
INFO:root:[9,   600] training loss: 0.02484731
INFO:root:[9,   650] training loss: 0.00001173
INFO:root:[9,   700] training loss: 0.00001122
INFO:root:[9,   750] training loss: 0.00001216
INFO:root:[9,   800] training loss: 0.00001058
INFO:root:[9,   850] training loss: 0.00000923
INFO:root:[9,   900] training loss: 0.05630671
INFO:root:[9,   950] training loss: 0.01564142
INFO:root:[9,  1000] training loss: 0.00009237
INFO:root:[9,  1050] training loss: 0.00006343
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2673    1.0000    0.4218      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0603      3872
weighted avg     0.0714    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.05463600
INFO:root:[10,   100] training loss: 0.02255098
INFO:root:[10,   150] training loss: 0.02217320
INFO:root:[10,   200] training loss: 0.02183034
INFO:root:[10,   250] training loss: 0.02171959
INFO:root:[10,   300] training loss: 0.02586041
INFO:root:[10,   350] training loss: 0.02332682
INFO:root:[10,   400] training loss: 0.00135534
INFO:root:[10,   450] training loss: 0.00034534
INFO:root:[10,   500] training loss: 0.00569416
INFO:root:[10,   550] training loss: 0.00620461
INFO:root:[10,   600] training loss: 0.02625443
INFO:root:[10,   650] training loss: 0.00000950
INFO:root:[10,   700] training loss: 0.00001123
INFO:root:[10,   750] training loss: 0.00001120
INFO:root:[10,   800] training loss: 0.00001106
INFO:root:[10,   850] training loss: 0.00000980
INFO:root:[10,   900] training loss: 0.05809453
INFO:root:[10,   950] training loss: 0.01657335
INFO:root:[10,  1000] training loss: 0.00002901
INFO:root:[10,  1050] training loss: 0.00002516
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.05809789
INFO:root:[11,   100] training loss: 0.02211201
INFO:root:[11,   150] training loss: 0.02613727
INFO:root:[11,   200] training loss: 0.02249966
INFO:root:[11,   250] training loss: 0.02087559
INFO:root:[11,   300] training loss: 0.02433555
INFO:root:[11,   350] training loss: 0.02069654
INFO:root:[11,   400] training loss: 0.00131141
INFO:root:[11,   450] training loss: 0.00028651
INFO:root:[11,   500] training loss: 0.00561825
INFO:root:[11,   550] training loss: 0.00642425
INFO:root:[11,   600] training loss: 0.02589856
INFO:root:[11,   650] training loss: 0.00001251
INFO:root:[11,   700] training loss: 0.00001337
INFO:root:[11,   750] training loss: 0.00001308
INFO:root:[11,   800] training loss: 0.00001236
INFO:root:[11,   850] training loss: 0.00001137
INFO:root:[11,   900] training loss: 0.06017847
INFO:root:[11,   950] training loss: 0.01805182
INFO:root:[11,  1000] training loss: 0.00007048
INFO:root:[11,  1050] training loss: 0.00004579
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2670    1.0000    0.4215      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.05526702
INFO:root:[12,   100] training loss: 0.02225051
INFO:root:[12,   150] training loss: 0.02499347
INFO:root:[12,   200] training loss: 0.02122821
INFO:root:[12,   250] training loss: 0.02121160
INFO:root:[12,   300] training loss: 0.02413310
INFO:root:[12,   350] training loss: 0.02237247
INFO:root:[12,   400] training loss: 0.00130954
INFO:root:[12,   450] training loss: 0.00018824
INFO:root:[12,   500] training loss: 0.00526445
INFO:root:[12,   550] training loss: 0.00605453
INFO:root:[12,   600] training loss: 0.02562754
INFO:root:[12,   650] training loss: 0.00002843
INFO:root:[12,   700] training loss: 0.00002534
INFO:root:[12,   750] training loss: 0.00002027
INFO:root:[12,   800] training loss: 0.00001991
INFO:root:[12,   850] training loss: 0.00002092
INFO:root:[12,   900] training loss: 0.05470691
INFO:root:[12,   950] training loss: 0.01703905
INFO:root:[12,  1000] training loss: 0.00011749
INFO:root:[12,  1050] training loss: 0.00007516
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2672    1.0000    0.4217      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0602      3872
weighted avg     0.0714    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.05289278
INFO:root:[13,   100] training loss: 0.02098901
INFO:root:[13,   150] training loss: 0.02344479
INFO:root:[13,   200] training loss: 0.02203012
INFO:root:[13,   250] training loss: 0.02386246
INFO:root:[13,   300] training loss: 0.02541806
INFO:root:[13,   350] training loss: 0.02025687
INFO:root:[13,   400] training loss: 0.00158638
INFO:root:[13,   450] training loss: 0.00042856
INFO:root:[13,   500] training loss: 0.00542116
INFO:root:[13,   550] training loss: 0.00592277
INFO:root:[13,   600] training loss: 0.02639765
INFO:root:[13,   650] training loss: 0.00002949
INFO:root:[13,   700] training loss: 0.00002931
INFO:root:[13,   750] training loss: 0.00002710
INFO:root:[13,   800] training loss: 0.00002629
INFO:root:[13,   850] training loss: 0.00002419
INFO:root:[13,   900] training loss: 0.05319507
INFO:root:[13,   950] training loss: 0.01641589
INFO:root:[13,  1000] training loss: 0.00014133
INFO:root:[13,  1050] training loss: 0.00009070
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2671    1.0000    0.4216      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2673      3872
   macro avg     0.1810    0.1905    0.1317      3872
weighted avg     0.0721    0.2673    0.1130      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.04761891
INFO:root:[14,   100] training loss: 0.02142799
INFO:root:[14,   150] training loss: 0.02261579
INFO:root:[14,   200] training loss: 0.02069498
INFO:root:[14,   250] training loss: 0.02211787
INFO:root:[14,   300] training loss: 0.02200022
INFO:root:[14,   350] training loss: 0.02194271
INFO:root:[14,   400] training loss: 0.00069234
INFO:root:[14,   450] training loss: 0.00026433
INFO:root:[14,   500] training loss: 0.00582120
INFO:root:[14,   550] training loss: 0.00617075
INFO:root:[14,   600] training loss: 0.02599996
INFO:root:[14,   650] training loss: 0.00002317
INFO:root:[14,   700] training loss: 0.00002112
INFO:root:[14,   750] training loss: 0.00002300
INFO:root:[14,   800] training loss: 0.00002252
INFO:root:[14,   850] training loss: 0.00002066
INFO:root:[14,   900] training loss: 0.04958666
INFO:root:[14,   950] training loss: 0.01713432
INFO:root:[14,  1000] training loss: 0.00013659
INFO:root:[14,  1050] training loss: 0.00008132
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2673    1.0000    0.4219      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0603      3872
weighted avg     0.0714    0.2670    0.1127      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.04627470
INFO:root:[15,   100] training loss: 0.02093149
INFO:root:[15,   150] training loss: 0.02323943
INFO:root:[15,   200] training loss: 0.02131763
INFO:root:[15,   250] training loss: 0.01939700
INFO:root:[15,   300] training loss: 0.02344324
INFO:root:[15,   350] training loss: 0.01910867
INFO:root:[15,   400] training loss: 0.00072100
INFO:root:[15,   450] training loss: 0.00024491
INFO:root:[15,   500] training loss: 0.00555587
INFO:root:[15,   550] training loss: 0.00667426
INFO:root:[15,   600] training loss: 0.02645011
INFO:root:[15,   650] training loss: 0.00003175
INFO:root:[15,   700] training loss: 0.00003009
INFO:root:[15,   750] training loss: 0.00002805
INFO:root:[15,   800] training loss: 0.00002706
INFO:root:[15,   850] training loss: 0.00002600
INFO:root:[15,   900] training loss: 0.04859024
INFO:root:[15,   950] training loss: 0.01721108
INFO:root:[15,  1000] training loss: 0.00013815
INFO:root:[15,  1050] training loss: 0.00009857
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.6667    0.2500    0.3636         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2676    1.0000    0.4222      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2676      3872
   macro avg     0.1335    0.1786    0.1123      3872
weighted avg     0.0728    0.2676    0.1135      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.04476848
INFO:root:[16,   100] training loss: 0.01978006
INFO:root:[16,   150] training loss: 0.02285225
INFO:root:[16,   200] training loss: 0.02006526
INFO:root:[16,   250] training loss: 0.02231976
INFO:root:[16,   300] training loss: 0.02370240
INFO:root:[16,   350] training loss: 0.01869718
INFO:root:[16,   400] training loss: 0.00071294
INFO:root:[16,   450] training loss: 0.00021178
INFO:root:[16,   500] training loss: 0.00500504
INFO:root:[16,   550] training loss: 0.00657810
INFO:root:[16,   600] training loss: 0.02701377
INFO:root:[16,   650] training loss: 0.00004350
INFO:root:[16,   700] training loss: 0.00003673
INFO:root:[16,   750] training loss: 0.00003692
INFO:root:[16,   800] training loss: 0.00003227
INFO:root:[16,   850] training loss: 0.00003425
INFO:root:[16,   900] training loss: 0.05050527
INFO:root:[16,   950] training loss: 0.01787239
INFO:root:[16,  1000] training loss: 0.00010382
INFO:root:[16,  1050] training loss: 0.00007489
INFO:root:              precision    recall  f1-score   support

          G1     0.1250    0.5000    0.2000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2676    1.0000    0.4222      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.0561    0.2143    0.0889      3872
weighted avg     0.0715    0.2673    0.1129      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.04392114
INFO:root:[17,   100] training loss: 0.02052338
INFO:root:[17,   150] training loss: 0.02392227
INFO:root:[17,   200] training loss: 0.01994651
INFO:root:[17,   250] training loss: 0.02068785
INFO:root:[17,   300] training loss: 0.02261902
INFO:root:[17,   350] training loss: 0.01987404
INFO:root:[17,   400] training loss: 0.00078643
INFO:root:[17,   450] training loss: 0.00019408
INFO:root:[17,   500] training loss: 0.00492095
INFO:root:[17,   550] training loss: 0.00646509
INFO:root:[17,   600] training loss: 0.02667734
INFO:root:[17,   650] training loss: 0.00004928
INFO:root:[17,   700] training loss: 0.00004245
INFO:root:[17,   750] training loss: 0.00004494
INFO:root:[17,   800] training loss: 0.00004630
INFO:root:[17,   850] training loss: 0.00003907
INFO:root:[17,   900] training loss: 0.04853335
INFO:root:[17,   950] training loss: 0.01770098
INFO:root:[17,  1000] training loss: 0.00021089
INFO:root:[17,  1050] training loss: 0.00012767
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     1.0000    0.1250    0.2222         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2673    1.0000    0.4218      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.1810    0.1607    0.0920      3872
weighted avg     0.0734    0.2673    0.1131      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.04558931
INFO:root:[18,   100] training loss: 0.02025756
INFO:root:[18,   150] training loss: 0.02244414
INFO:root:[18,   200] training loss: 0.02086354
INFO:root:[18,   250] training loss: 0.02008311
INFO:root:[18,   300] training loss: 0.02237222
INFO:root:[18,   350] training loss: 0.02042045
INFO:root:[18,   400] training loss: 0.00070670
INFO:root:[18,   450] training loss: 0.00014298
INFO:root:[18,   500] training loss: 0.00501658
INFO:root:[18,   550] training loss: 0.00678465
INFO:root:[18,   600] training loss: 0.02751164
INFO:root:[18,   650] training loss: 0.00007304
INFO:root:[18,   700] training loss: 0.00005581
INFO:root:[18,   750] training loss: 0.00006324
INFO:root:[18,   800] training loss: 0.00005609
INFO:root:[18,   850] training loss: 0.00004995
INFO:root:[18,   900] training loss: 0.04766676
INFO:root:[18,   950] training loss: 0.01760193
INFO:root:[18,  1000] training loss: 0.00016587
INFO:root:[18,  1050] training loss: 0.00009178
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     1.0000    0.0274    0.0533        73
    Prophase     0.2674    1.0000    0.4220      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2678      3872
   macro avg     0.3239    0.1944    0.1393      3872
weighted avg     0.0910    0.2678    0.1141      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.04101091
INFO:root:[19,   100] training loss: 0.01990746
INFO:root:[19,   150] training loss: 0.01893184
INFO:root:[19,   200] training loss: 0.01769606
INFO:root:[19,   250] training loss: 0.01817048
INFO:root:[19,   300] training loss: 0.02161264
INFO:root:[19,   350] training loss: 0.01819896
INFO:root:[19,   400] training loss: 0.00068672
INFO:root:[19,   450] training loss: 0.00028148
INFO:root:[19,   500] training loss: 0.00517877
INFO:root:[19,   550] training loss: 0.00643966
INFO:root:[19,   600] training loss: 0.02761656
INFO:root:[19,   650] training loss: 0.00009238
INFO:root:[19,   700] training loss: 0.00007463
INFO:root:[19,   750] training loss: 0.00007848
INFO:root:[19,   800] training loss: 0.00006852
INFO:root:[19,   850] training loss: 0.00006178
INFO:root:[19,   900] training loss: 0.04669285
INFO:root:[19,   950] training loss: 0.01839705
INFO:root:[19,  1000] training loss: 0.00023676
INFO:root:[19,  1050] training loss: 0.00014744
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4000    0.2500    0.3077         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2677    1.0000    0.4223      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2678      3872
   macro avg     0.1311    0.2500    0.1519      3872
weighted avg     0.0724    0.2678    0.1136      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.04258892
INFO:root:[20,   100] training loss: 0.01989501
INFO:root:[20,   150] training loss: 0.01992933
INFO:root:[20,   200] training loss: 0.01916292
INFO:root:[20,   250] training loss: 0.01948683
INFO:root:[20,   300] training loss: 0.02227291
INFO:root:[20,   350] training loss: 0.01813430
INFO:root:[20,   400] training loss: 0.00071688
INFO:root:[20,   450] training loss: 0.00015024
INFO:root:[20,   500] training loss: 0.00514017
INFO:root:[20,   550] training loss: 0.00688075
INFO:root:[20,   600] training loss: 0.02737871
INFO:root:[20,   650] training loss: 0.00013821
INFO:root:[20,   700] training loss: 0.00010156
INFO:root:[20,   750] training loss: 0.00009709
INFO:root:[20,   800] training loss: 0.00008777
INFO:root:[20,   850] training loss: 0.00007162
INFO:root:[20,   900] training loss: 0.04505636
INFO:root:[20,   950] training loss: 0.01962695
INFO:root:[20,  1000] training loss: 0.00028997
INFO:root:[20,  1050] training loss: 0.00017727
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.2857    0.2500    0.2667         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2678    1.0000    0.4225      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2681      3872
   macro avg     0.2696    0.2976    0.2270      3872
weighted avg     0.0731    0.2681    0.1140      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.04037126
INFO:root:[21,   100] training loss: 0.02069529
INFO:root:[21,   150] training loss: 0.02281811
INFO:root:[21,   200] training loss: 0.01780058
INFO:root:[21,   250] training loss: 0.01893048
INFO:root:[21,   300] training loss: 0.02422217
INFO:root:[21,   350] training loss: 0.01842461
INFO:root:[21,   400] training loss: 0.00089110
INFO:root:[21,   450] training loss: 0.00014062
INFO:root:[21,   500] training loss: 0.00506030
INFO:root:[21,   550] training loss: 0.00703539
INFO:root:[21,   600] training loss: 0.02711929
INFO:root:[21,   650] training loss: 0.00016328
INFO:root:[21,   700] training loss: 0.00011988
INFO:root:[21,   750] training loss: 0.00011718
INFO:root:[21,   800] training loss: 0.00010252
INFO:root:[21,   850] training loss: 0.00008413
INFO:root:[21,   900] training loss: 0.04713841
INFO:root:[21,   950] training loss: 0.02056536
INFO:root:[21,  1000] training loss: 0.00035876
INFO:root:[21,  1050] training loss: 0.00020388
INFO:root:              precision    recall  f1-score   support

          G1     0.2000    0.5000    0.2857         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.2857    0.2500    0.2667         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2679    1.0000    0.4226      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2678      3872
   macro avg     0.1077    0.2500    0.1393      3872
weighted avg     0.0722    0.2678    0.1135      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.04410969
INFO:root:[22,   100] training loss: 0.02037092
INFO:root:[22,   150] training loss: 0.02024749
INFO:root:[22,   200] training loss: 0.01938349
INFO:root:[22,   250] training loss: 0.02083717
INFO:root:[22,   300] training loss: 0.02312232
INFO:root:[22,   350] training loss: 0.01629888
INFO:root:[22,   400] training loss: 0.00039398
INFO:root:[22,   450] training loss: 0.00022303
INFO:root:[22,   500] training loss: 0.00513742
INFO:root:[22,   550] training loss: 0.00792479
INFO:root:[22,   600] training loss: 0.02799991
INFO:root:[22,   650] training loss: 0.00018739
INFO:root:[22,   700] training loss: 0.00015084
INFO:root:[22,   750] training loss: 0.00013808
INFO:root:[22,   800] training loss: 0.00012148
INFO:root:[22,   850] training loss: 0.00009960
INFO:root:[22,   900] training loss: 0.04536662
INFO:root:[22,   950] training loss: 0.02009484
INFO:root:[22,  1000] training loss: 0.00030622
INFO:root:[22,  1050] training loss: 0.00026126
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3750    0.3750    0.3750         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2679    1.0000    0.4226      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2681      3872
   macro avg     0.1276    0.2679    0.1616      3872
weighted avg     0.0724    0.2681    0.1138      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.04028376
INFO:root:[23,   100] training loss: 0.01880807
INFO:root:[23,   150] training loss: 0.01941976
INFO:root:[23,   200] training loss: 0.02070116
INFO:root:[23,   250] training loss: 0.01840292
INFO:root:[23,   300] training loss: 0.02202058
INFO:root:[23,   350] training loss: 0.01735120
INFO:root:[23,   400] training loss: 0.00062095
INFO:root:[23,   450] training loss: 0.00020364
INFO:root:[23,   500] training loss: 0.00517838
INFO:root:[23,   550] training loss: 0.00788175
INFO:root:[23,   600] training loss: 0.02746638
INFO:root:[23,   650] training loss: 0.00023360
INFO:root:[23,   700] training loss: 0.00016148
INFO:root:[23,   750] training loss: 0.00016345
INFO:root:[23,   800] training loss: 0.00012948
INFO:root:[23,   850] training loss: 0.00011665
INFO:root:[23,   900] training loss: 0.04422687
INFO:root:[23,   950] training loss: 0.01868270
INFO:root:[23,  1000] training loss: 0.00035377
INFO:root:[23,  1050] training loss: 0.00022448
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.2632    0.6250    0.3704         8
    Anaphase     1.0000    0.0274    0.0533        73
    Prophase     0.2685    0.9990    0.4233      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2689      3872
   macro avg     0.2545    0.3073    0.1686      3872
weighted avg     0.0912    0.2689    0.1150      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.03950521
INFO:root:[24,   100] training loss: 0.01746103
INFO:root:[24,   150] training loss: 0.01893162
INFO:root:[24,   200] training loss: 0.01940147
INFO:root:[24,   250] training loss: 0.01946733
INFO:root:[24,   300] training loss: 0.02402435
INFO:root:[24,   350] training loss: 0.01930024
INFO:root:[24,   400] training loss: 0.00041881
INFO:root:[24,   450] training loss: 0.00035999
INFO:root:[24,   500] training loss: 0.00487796
INFO:root:[24,   550] training loss: 0.00813999
INFO:root:[24,   600] training loss: 0.02728408
INFO:root:[24,   650] training loss: 0.00028103
INFO:root:[24,   700] training loss: 0.00020601
INFO:root:[24,   750] training loss: 0.00018731
INFO:root:[24,   800] training loss: 0.00014974
INFO:root:[24,   850] training loss: 0.00012496
INFO:root:[24,   900] training loss: 0.04535668
INFO:root:[24,   950] training loss: 0.01993975
INFO:root:[24,  1000] training loss: 0.00055517
INFO:root:[24,  1050] training loss: 0.00030356
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.2500    0.3333         8
    Anaphase     0.6667    0.0274    0.0526        73
    Prophase     0.2678    1.0000    0.4225      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2683      3872
   macro avg     0.2406    0.2539    0.1631      3872
weighted avg     0.0852    0.2683    0.1147      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.04123828
INFO:root:[25,   100] training loss: 0.01876543
INFO:root:[25,   150] training loss: 0.01954293
INFO:root:[25,   200] training loss: 0.01747816
INFO:root:[25,   250] training loss: 0.01959300
INFO:root:[25,   300] training loss: 0.02216597
INFO:root:[25,   350] training loss: 0.01801731
INFO:root:[25,   400] training loss: 0.00046353
INFO:root:[25,   450] training loss: 0.00014365
INFO:root:[25,   500] training loss: 0.00500176
INFO:root:[25,   550] training loss: 0.00803256
INFO:root:[25,   600] training loss: 0.02785946
INFO:root:[25,   650] training loss: 0.00028825
INFO:root:[25,   700] training loss: 0.00021039
INFO:root:[25,   750] training loss: 0.00017894
INFO:root:[25,   800] training loss: 0.00016592
INFO:root:[25,   850] training loss: 0.00013865
INFO:root:[25,   900] training loss: 0.04441892
INFO:root:[25,   950] training loss: 0.02032218
INFO:root:[25,  1000] training loss: 0.00048608
INFO:root:[25,  1050] training loss: 0.00028438
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.2500    0.2500    0.2500         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2679    1.0000    0.4226      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2681      3872
   macro avg     0.2645    0.2976    0.2247      3872
weighted avg     0.0730    0.2681    0.1140      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.03877566
INFO:root:[26,   100] training loss: 0.01854352
INFO:root:[26,   150] training loss: 0.01985822
INFO:root:[26,   200] training loss: 0.01759811
INFO:root:[26,   250] training loss: 0.01947208
INFO:root:[26,   300] training loss: 0.02164956
INFO:root:[26,   350] training loss: 0.01628648
INFO:root:[26,   400] training loss: 0.00039911
INFO:root:[26,   450] training loss: 0.00031063
INFO:root:[26,   500] training loss: 0.00500182
INFO:root:[26,   550] training loss: 0.00811966
INFO:root:[26,   600] training loss: 0.02676674
INFO:root:[26,   650] training loss: 0.00037933
INFO:root:[26,   700] training loss: 0.00027325
INFO:root:[26,   750] training loss: 0.00021960
INFO:root:[26,   800] training loss: 0.00018179
INFO:root:[26,   850] training loss: 0.00016051
INFO:root:[26,   900] training loss: 0.04424197
INFO:root:[26,   950] training loss: 0.02034356
INFO:root:[26,  1000] training loss: 0.00057645
INFO:root:[26,  1050] training loss: 0.00035011
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4000    0.5000    0.4444         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2681    1.0000    0.4228      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2686      3872
   macro avg     0.2740    0.3333    0.2429      3872
weighted avg     0.0733    0.2686    0.1144      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.03873402
INFO:root:[27,   100] training loss: 0.01879774
INFO:root:[27,   150] training loss: 0.02125529
INFO:root:[27,   200] training loss: 0.01987257
INFO:root:[27,   250] training loss: 0.01858614
INFO:root:[27,   300] training loss: 0.02137622
INFO:root:[27,   350] training loss: 0.01663399
INFO:root:[27,   400] training loss: 0.00066260
INFO:root:[27,   450] training loss: 0.00022954
INFO:root:[27,   500] training loss: 0.00504812
INFO:root:[27,   550] training loss: 0.00824491
INFO:root:[27,   600] training loss: 0.02896878
INFO:root:[27,   650] training loss: 0.00046118
INFO:root:[27,   700] training loss: 0.00029984
INFO:root:[27,   750] training loss: 0.00024228
INFO:root:[27,   800] training loss: 0.00020355
INFO:root:[27,   850] training loss: 0.00016416
INFO:root:[27,   900] training loss: 0.04333667
INFO:root:[27,   950] training loss: 0.02063405
INFO:root:[27,  1000] training loss: 0.00058977
INFO:root:[27,  1050] training loss: 0.00033458
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.2500    0.3333         8
    Anaphase     1.0000    0.0411    0.0789        73
    Prophase     0.2679    1.0000    0.4226      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2691      3872
   macro avg     0.4526    0.3749    0.2723      3872
weighted avg     0.0924    0.2691    0.1157      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.03848789
INFO:root:[28,   100] training loss: 0.01756853
INFO:root:[28,   150] training loss: 0.01856292
INFO:root:[28,   200] training loss: 0.01930277
INFO:root:[28,   250] training loss: 0.01982247
INFO:root:[28,   300] training loss: 0.02071943
INFO:root:[28,   350] training loss: 0.01555564
INFO:root:[28,   400] training loss: 0.00055477
INFO:root:[28,   450] training loss: 0.00019302
INFO:root:[28,   500] training loss: 0.00486513
INFO:root:[28,   550] training loss: 0.00842429
INFO:root:[28,   600] training loss: 0.02796824
INFO:root:[28,   650] training loss: 0.00054281
INFO:root:[28,   700] training loss: 0.00034419
INFO:root:[28,   750] training loss: 0.00025706
INFO:root:[28,   800] training loss: 0.00022560
INFO:root:[28,   850] training loss: 0.00018278
INFO:root:[28,   900] training loss: 0.04263858
INFO:root:[28,   950] training loss: 0.02113498
INFO:root:[28,  1000] training loss: 0.00055197
INFO:root:[28,  1050] training loss: 0.00033222
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3750    0.3750    0.3750         8
    Anaphase     0.6000    0.0411    0.0769        73
    Prophase     0.2682    1.0000    0.4229      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2689      3872
   macro avg     0.3205    0.2499    0.1964      3872
weighted avg     0.0845    0.2689    0.1155      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.03780514
INFO:root:[29,   100] training loss: 0.01730410
INFO:root:[29,   150] training loss: 0.01789953
INFO:root:[29,   200] training loss: 0.01708442
INFO:root:[29,   250] training loss: 0.02000919
INFO:root:[29,   300] training loss: 0.02048931
INFO:root:[29,   350] training loss: 0.01772488
INFO:root:[29,   400] training loss: 0.00024279
INFO:root:[29,   450] training loss: 0.00018425
INFO:root:[29,   500] training loss: 0.00480563
INFO:root:[29,   550] training loss: 0.00865783
INFO:root:[29,   600] training loss: 0.02850486
INFO:root:[29,   650] training loss: 0.00058543
INFO:root:[29,   700] training loss: 0.00038335
INFO:root:[29,   750] training loss: 0.00030521
INFO:root:[29,   800] training loss: 0.00023989
INFO:root:[29,   850] training loss: 0.00019636
INFO:root:[29,   900] training loss: 0.04578622
INFO:root:[29,   950] training loss: 0.02188079
INFO:root:[29,  1000] training loss: 0.00065989
INFO:root:[29,  1050] training loss: 0.00032140
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.6000    0.3750    0.4615         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2679    1.0000    0.4226      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2691      3872
   macro avg     0.3383    0.4821    0.3644      3872
weighted avg     0.0738    0.2691    0.1149      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.03690596
INFO:root:[30,   100] training loss: 0.01828416
INFO:root:[30,   150] training loss: 0.02078238
INFO:root:[30,   200] training loss: 0.01850677
INFO:root:[30,   250] training loss: 0.01874723
INFO:root:[30,   300] training loss: 0.02030949
INFO:root:[30,   350] training loss: 0.01751790
INFO:root:[30,   400] training loss: 0.00065643
INFO:root:[30,   450] training loss: 0.00030391
INFO:root:[30,   500] training loss: 0.00507232
INFO:root:[30,   550] training loss: 0.00898080
INFO:root:[30,   600] training loss: 0.02734819
INFO:root:[30,   650] training loss: 0.00060015
INFO:root:[30,   700] training loss: 0.00039951
INFO:root:[30,   750] training loss: 0.00030976
INFO:root:[30,   800] training loss: 0.00025145
INFO:root:[30,   850] training loss: 0.00021403
INFO:root:[30,   900] training loss: 0.04394694
INFO:root:[30,   950] training loss: 0.02099627
INFO:root:[30,  1000] training loss: 0.00074636
INFO:root:[30,  1050] training loss: 0.00041669
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4444    0.5000    0.4706         8
    Anaphase     0.5000    0.0274    0.0519        73
    Prophase     0.2682    1.0000    0.4230      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2691      3872
   macro avg     0.3637    0.3372    0.2636      3872
weighted avg     0.0829    0.2691    0.1155      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.03870020
INFO:root:[31,   100] training loss: 0.01828895
INFO:root:[31,   150] training loss: 0.01920443
INFO:root:[31,   200] training loss: 0.01695519
INFO:root:[31,   250] training loss: 0.01933399
INFO:root:[31,   300] training loss: 0.02186883
INFO:root:[31,   350] training loss: 0.01846534
INFO:root:[31,   400] training loss: 0.00042406
INFO:root:[31,   450] training loss: 0.00011285
INFO:root:[31,   500] training loss: 0.00482619
INFO:root:[31,   550] training loss: 0.00931547
INFO:root:[31,   600] training loss: 0.02794105
INFO:root:[31,   650] training loss: 0.00065063
INFO:root:[31,   700] training loss: 0.00037929
INFO:root:[31,   750] training loss: 0.00032778
INFO:root:[31,   800] training loss: 0.00026388
INFO:root:[31,   850] training loss: 0.00021836
INFO:root:[31,   900] training loss: 0.04317929
INFO:root:[31,   950] training loss: 0.02077945
INFO:root:[31,  1000] training loss: 0.00067747
INFO:root:[31,  1050] training loss: 0.00033675
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3571    0.6250    0.4545         8
    Anaphase     0.3750    0.0411    0.0741        73
    Prophase     0.2689    1.0000    0.4238      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2696      3872
   macro avg     0.3335    0.3571    0.2646      3872
weighted avg     0.0806    0.2696    0.1161      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.03579728
INFO:root:[32,   100] training loss: 0.01700422
INFO:root:[32,   150] training loss: 0.01881262
INFO:root:[32,   200] training loss: 0.01711510
INFO:root:[32,   250] training loss: 0.01849369
INFO:root:[32,   300] training loss: 0.02051375
INFO:root:[32,   350] training loss: 0.01851094
INFO:root:[32,   400] training loss: 0.00044794
INFO:root:[32,   450] training loss: 0.00011689
INFO:root:[32,   500] training loss: 0.00479063
INFO:root:[32,   550] training loss: 0.00959775
INFO:root:[32,   600] training loss: 0.02888688
INFO:root:[32,   650] training loss: 0.00077620
INFO:root:[32,   700] training loss: 0.00047991
INFO:root:[32,   750] training loss: 0.00038249
INFO:root:[32,   800] training loss: 0.00028204
INFO:root:[32,   850] training loss: 0.00022760
INFO:root:[32,   900] training loss: 0.04323112
INFO:root:[32,   950] training loss: 0.02174932
INFO:root:[32,  1000] training loss: 0.00095308
INFO:root:[32,  1050] training loss: 0.00041538
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3333    0.3750    0.3529         8
    Anaphase     0.0000    0.0000    0.0000        73
    Prophase     0.2680    1.0000    0.4227      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2686      3872
   macro avg     0.2764    0.3631    0.2822      3872
weighted avg     0.0732    0.2686    0.1144      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.03846410
INFO:root:[33,   100] training loss: 0.01838682
INFO:root:[33,   150] training loss: 0.01882624
INFO:root:[33,   200] training loss: 0.01710683
INFO:root:[33,   250] training loss: 0.01849812
INFO:root:[33,   300] training loss: 0.02044110
INFO:root:[33,   350] training loss: 0.01636000
INFO:root:[33,   400] training loss: 0.00042476
INFO:root:[33,   450] training loss: 0.00013601
INFO:root:[33,   500] training loss: 0.00495843
INFO:root:[33,   550] training loss: 0.00905911
INFO:root:[33,   600] training loss: 0.02816991
INFO:root:[33,   650] training loss: 0.00091229
INFO:root:[33,   700] training loss: 0.00046573
INFO:root:[33,   750] training loss: 0.00041349
INFO:root:[33,   800] training loss: 0.00028374
INFO:root:[33,   850] training loss: 0.00024422
INFO:root:[33,   900] training loss: 0.04558671
INFO:root:[33,   950] training loss: 0.02277430
INFO:root:[33,  1000] training loss: 0.00107864
INFO:root:[33,  1050] training loss: 0.00054918
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.2500    0.3333         8
    Anaphase     1.0000    0.0137    0.0270        73
    Prophase     0.2677    1.0000    0.4224      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2686      3872
   macro avg     0.4430    0.3472    0.2832      3872
weighted avg     0.0923    0.2686    0.1148      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.03850310
INFO:root:[34,   100] training loss: 0.01761043
INFO:root:[34,   150] training loss: 0.01932763
INFO:root:[34,   200] training loss: 0.01743531
INFO:root:[34,   250] training loss: 0.01972526
INFO:root:[34,   300] training loss: 0.02287322
INFO:root:[34,   350] training loss: 0.01569350
INFO:root:[34,   400] training loss: 0.00067597
INFO:root:[34,   450] training loss: 0.00016010
INFO:root:[34,   500] training loss: 0.00491778
INFO:root:[34,   550] training loss: 0.00957495
INFO:root:[34,   600] training loss: 0.02752863
INFO:root:[34,   650] training loss: 0.00096083
INFO:root:[34,   700] training loss: 0.00059773
INFO:root:[34,   750] training loss: 0.00040984
INFO:root:[34,   800] training loss: 0.00028589
INFO:root:[34,   850] training loss: 0.00025090
INFO:root:[34,   900] training loss: 0.04170610
INFO:root:[34,   950] training loss: 0.02328910
INFO:root:[34,  1000] training loss: 0.00084294
INFO:root:[34,  1050] training loss: 0.00046536
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4000    0.5000    0.4444         8
    Anaphase     0.3750    0.0411    0.0741        73
    Prophase     0.2685    0.9990    0.4232      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2696      3872
   macro avg     0.3634    0.4581    0.3441      3872
weighted avg     0.0806    0.2696    0.1163      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.03703029
INFO:root:[35,   100] training loss: 0.01775693
INFO:root:[35,   150] training loss: 0.02164875
INFO:root:[35,   200] training loss: 0.01725341
INFO:root:[35,   250] training loss: 0.01736652
INFO:root:[35,   300] training loss: 0.01978679
INFO:root:[35,   350] training loss: 0.01435748
INFO:root:[35,   400] training loss: 0.00048508
INFO:root:[35,   450] training loss: 0.00016196
INFO:root:[35,   500] training loss: 0.00512582
INFO:root:[35,   550] training loss: 0.01020026
INFO:root:[35,   600] training loss: 0.02863655
INFO:root:[35,   650] training loss: 0.00110426
INFO:root:[35,   700] training loss: 0.00067125
INFO:root:[35,   750] training loss: 0.00044439
INFO:root:[35,   800] training loss: 0.00031922
INFO:root:[35,   850] training loss: 0.00024312
INFO:root:[35,   900] training loss: 0.04057166
INFO:root:[35,   950] training loss: 0.02333257
INFO:root:[35,  1000] training loss: 0.00092088
INFO:root:[35,  1050] training loss: 0.00043973
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4167    0.6250    0.5000         8
    Anaphase     0.3333    0.0411    0.0732        73
    Prophase     0.2688    1.0000    0.4237      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2701      3872
   macro avg     0.4313    0.4523    0.3805      3872
weighted avg     0.0802    0.2701    0.1167      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.03553869
INFO:root:[36,   100] training loss: 0.01653920
INFO:root:[36,   150] training loss: 0.01906893
INFO:root:[36,   200] training loss: 0.01647173
INFO:root:[36,   250] training loss: 0.01742990
INFO:root:[36,   300] training loss: 0.01917833
INFO:root:[36,   350] training loss: 0.01570241
INFO:root:[36,   400] training loss: 0.00031516
INFO:root:[36,   450] training loss: 0.00012439
INFO:root:[36,   500] training loss: 0.00505412
INFO:root:[36,   550] training loss: 0.00985003
INFO:root:[36,   600] training loss: 0.02765836
INFO:root:[36,   650] training loss: 0.00126594
INFO:root:[36,   700] training loss: 0.00073712
INFO:root:[36,   750] training loss: 0.00047818
INFO:root:[36,   800] training loss: 0.00035450
INFO:root:[36,   850] training loss: 0.00027674
INFO:root:[36,   900] training loss: 0.03898374
INFO:root:[36,   950] training loss: 0.02370356
INFO:root:[36,  1000] training loss: 0.00102579
INFO:root:[36,  1050] training loss: 0.00045829
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3636    0.5000    0.4211         8
    Anaphase     0.3750    0.0411    0.0741        73
    Prophase     0.2685    0.9990    0.4233      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2699      3872
   macro avg     0.3820    0.5057    0.3883      3872
weighted avg     0.0806    0.2699    0.1165      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.03454311
INFO:root:[37,   100] training loss: 0.01763351
INFO:root:[37,   150] training loss: 0.01836565
INFO:root:[37,   200] training loss: 0.01680945
INFO:root:[37,   250] training loss: 0.01707935
INFO:root:[37,   300] training loss: 0.01816033
INFO:root:[37,   350] training loss: 0.01535458
INFO:root:[37,   400] training loss: 0.00035169
INFO:root:[37,   450] training loss: 0.00009745
INFO:root:[37,   500] training loss: 0.00503972
INFO:root:[37,   550] training loss: 0.01005124
INFO:root:[37,   600] training loss: 0.02787212
INFO:root:[37,   650] training loss: 0.00145349
INFO:root:[37,   700] training loss: 0.00066964
INFO:root:[37,   750] training loss: 0.00054169
INFO:root:[37,   800] training loss: 0.00039462
INFO:root:[37,   850] training loss: 0.00029088
INFO:root:[37,   900] training loss: 0.03904769
INFO:root:[37,   950] training loss: 0.02269964
INFO:root:[37,  1000] training loss: 0.00086565
INFO:root:[37,  1050] training loss: 0.00037853
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4000    0.5000    0.4444         8
    Anaphase     0.6000    0.0822    0.1446        73
    Prophase     0.2687    1.0000    0.4236      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2707      3872
   macro avg     0.4670    0.4403    0.3828      3872
weighted avg     0.0852    0.2707    0.1179      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.03524697
INFO:root:[38,   100] training loss: 0.02074507
INFO:root:[38,   150] training loss: 0.01978328
INFO:root:[38,   200] training loss: 0.01796171
INFO:root:[38,   250] training loss: 0.02006722
INFO:root:[38,   300] training loss: 0.01984245
INFO:root:[38,   350] training loss: 0.01478751
INFO:root:[38,   400] training loss: 0.00025385
INFO:root:[38,   450] training loss: 0.00009916
INFO:root:[38,   500] training loss: 0.00494296
INFO:root:[38,   550] training loss: 0.01123430
INFO:root:[38,   600] training loss: 0.02917071
INFO:root:[38,   650] training loss: 0.00161593
INFO:root:[38,   700] training loss: 0.00082111
INFO:root:[38,   750] training loss: 0.00058159
INFO:root:[38,   800] training loss: 0.00043602
INFO:root:[38,   850] training loss: 0.00031803
INFO:root:[38,   900] training loss: 0.04020953
INFO:root:[38,   950] training loss: 0.02443755
INFO:root:[38,  1000] training loss: 0.00093664
INFO:root:[38,  1050] training loss: 0.00026294
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
    Anaphase     0.5000    0.0137    0.0267        73
    Prophase     0.2673    1.0000    0.4218      1034
   Metaphase     0.0000    0.0000    0.0000         3

    accuracy                         0.2676      3872
   macro avg     0.2525    0.2162    0.1593      3872
weighted avg     0.0813    0.2676    0.1135      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.04006927
INFO:root:[39,   100] training loss: 0.01810239
INFO:root:[39,   150] training loss: 0.01883326
INFO:root:[39,   200] training loss: 0.01681035
INFO:root:[39,   250] training loss: 0.01728380
INFO:root:[39,   300] training loss: 0.01778540
INFO:root:[39,   350] training loss: 0.01723027
INFO:root:[39,   400] training loss: 0.00025185
INFO:root:[39,   450] training loss: 0.00026295
INFO:root:[39,   500] training loss: 0.00505848
INFO:root:[39,   550] training loss: 0.01196531
INFO:root:[39,   600] training loss: 0.02987319
INFO:root:[39,   650] training loss: 0.00162497
INFO:root:[39,   700] training loss: 0.00084303
INFO:root:[39,   750] training loss: 0.00052195
INFO:root:[39,   800] training loss: 0.00041407
INFO:root:[39,   850] training loss: 0.00032106
INFO:root:[39,   900] training loss: 0.04101429
INFO:root:[39,   950] training loss: 0.02615631
INFO:root:[39,  1000] training loss: 0.00109206
INFO:root:[39,  1050] training loss: 0.00044613
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.1250    0.2000         8
    Anaphase     0.5000    0.0137    0.0267        73
    Prophase     0.2675    1.0000    0.4221      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2681      3872
   macro avg     0.3239    0.2579    0.2070      3872
weighted avg     0.0827    0.2681    0.1143      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.03974429
INFO:root:[40,   100] training loss: 0.01827049
INFO:root:[40,   150] training loss: 0.01931447
INFO:root:[40,   200] training loss: 0.01657412
INFO:root:[40,   250] training loss: 0.01719519
INFO:root:[40,   300] training loss: 0.02018246
INFO:root:[40,   350] training loss: 0.01565566
INFO:root:[40,   400] training loss: 0.00023997
INFO:root:[40,   450] training loss: 0.00010371
INFO:root:[40,   500] training loss: 0.00498932
INFO:root:[40,   550] training loss: 0.01197714
INFO:root:[40,   600] training loss: 0.02861481
INFO:root:[40,   650] training loss: 0.00158490
INFO:root:[40,   700] training loss: 0.00088091
INFO:root:[40,   750] training loss: 0.00057448
INFO:root:[40,   800] training loss: 0.00045002
INFO:root:[40,   850] training loss: 0.00033737
INFO:root:[40,   900] training loss: 0.03971782
INFO:root:[40,   950] training loss: 0.02580849
INFO:root:[40,  1000] training loss: 0.00139740
INFO:root:[40,  1050] training loss: 0.00057069
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.2500    0.6250    0.3571         8
    Anaphase     0.2083    0.0685    0.1031        73
    Prophase     0.2701    0.9990    0.4253      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2701      3872
   macro avg     0.3184    0.4085    0.3122      3872
weighted avg     0.0776    0.2701    0.1171      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.03576775
INFO:root:[41,   100] training loss: 0.01687919
INFO:root:[41,   150] training loss: 0.01705473
INFO:root:[41,   200] training loss: 0.01772528
INFO:root:[41,   250] training loss: 0.01755717
INFO:root:[41,   300] training loss: 0.02002680
INFO:root:[41,   350] training loss: 0.01432826
INFO:root:[41,   400] training loss: 0.00047229
INFO:root:[41,   450] training loss: 0.00030962
INFO:root:[41,   500] training loss: 0.00507407
INFO:root:[41,   550] training loss: 0.01256345
INFO:root:[41,   600] training loss: 0.03022559
INFO:root:[41,   650] training loss: 0.00178722
INFO:root:[41,   700] training loss: 0.00095026
INFO:root:[41,   750] training loss: 0.00054133
INFO:root:[41,   800] training loss: 0.00041104
INFO:root:[41,   850] training loss: 0.00034218
INFO:root:[41,   900] training loss: 0.04008127
INFO:root:[41,   950] training loss: 0.02599673
INFO:root:[41,  1000] training loss: 0.00164062
INFO:root:[41,  1050] training loss: 0.00071543
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4167    0.6250    0.5000         8
    Anaphase     0.5455    0.0822    0.1429        73
    Prophase     0.2687    0.9990    0.4234      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2704      3872
   macro avg     0.3901    0.4104    0.3380      3872
weighted avg     0.0839    0.2704    0.1177      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.03434603
INFO:root:[42,   100] training loss: 0.01680686
INFO:root:[42,   150] training loss: 0.01724340
INFO:root:[42,   200] training loss: 0.01608422
INFO:root:[42,   250] training loss: 0.02000827
INFO:root:[42,   300] training loss: 0.01963955
INFO:root:[42,   350] training loss: 0.01636216
INFO:root:[42,   400] training loss: 0.00037377
INFO:root:[42,   450] training loss: 0.00013314
INFO:root:[42,   500] training loss: 0.00505248
INFO:root:[42,   550] training loss: 0.01240607
INFO:root:[42,   600] training loss: 0.02961075
INFO:root:[42,   650] training loss: 0.00103696
INFO:root:[42,   700] training loss: 0.00012265
INFO:root:[42,   750] training loss: 0.00009347
INFO:root:[42,   800] training loss: 0.00005337
INFO:root:[42,   850] training loss: 0.00002589
INFO:root:[42,   900] training loss: 0.04814435
INFO:root:[42,   950] training loss: 0.02323186
INFO:root:[42,  1000] training loss: 0.00151769
INFO:root:[42,  1050] training loss: 0.00061666
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5556    0.6250    0.5882         8
    Anaphase     1.0000    0.0137    0.0270        73
    Prophase     0.2680    1.0000    0.4227      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2696      3872
   macro avg     0.5462    0.4484    0.3864      3872
weighted avg     0.0929    0.2696    0.1157      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.03973611
INFO:root:[43,   100] training loss: 0.01795891
INFO:root:[43,   150] training loss: 0.01780844
INFO:root:[43,   200] training loss: 0.01700904
INFO:root:[43,   250] training loss: 0.01832654
INFO:root:[43,   300] training loss: 0.02475830
INFO:root:[43,   350] training loss: 0.01509088
INFO:root:[43,   400] training loss: 0.00033745
INFO:root:[43,   450] training loss: 0.00018294
INFO:root:[43,   500] training loss: 0.00478934
INFO:root:[43,   550] training loss: 0.01213311
INFO:root:[43,   600] training loss: 0.03153281
INFO:root:[43,   650] training loss: 0.00240138
INFO:root:[43,   700] training loss: 0.00102006
INFO:root:[43,   750] training loss: 0.00066629
INFO:root:[43,   800] training loss: 0.00043956
INFO:root:[43,   850] training loss: 0.00036008
INFO:root:[43,   900] training loss: 0.04044216
INFO:root:[43,   950] training loss: 0.02534073
INFO:root:[43,  1000] training loss: 0.00156066
INFO:root:[43,  1050] training loss: 0.00069327
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.5000    0.5000         8
    Anaphase     0.4286    0.0411    0.0750        73
    Prophase     0.2684    1.0000    0.4232      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2694      3872
   macro avg     0.3615    0.3392    0.2712      3872
weighted avg     0.0817    0.2694    0.1160      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.03649457
INFO:root:[44,   100] training loss: 0.01847876
INFO:root:[44,   150] training loss: 0.02028625
INFO:root:[44,   200] training loss: 0.01740832
INFO:root:[44,   250] training loss: 0.01838591
INFO:root:[44,   300] training loss: 0.02161678
INFO:root:[44,   350] training loss: 0.01575962
INFO:root:[44,   400] training loss: 0.00035005
INFO:root:[44,   450] training loss: 0.00014112
INFO:root:[44,   500] training loss: 0.00452324
INFO:root:[44,   550] training loss: 0.01154021
INFO:root:[44,   600] training loss: 0.02923706
INFO:root:[44,   650] training loss: 0.00177785
INFO:root:[44,   700] training loss: 0.00076289
INFO:root:[44,   750] training loss: 0.00047768
INFO:root:[44,   800] training loss: 0.00032152
INFO:root:[44,   850] training loss: 0.00024285
INFO:root:[44,   900] training loss: 0.04193122
INFO:root:[44,   950] training loss: 0.02347592
INFO:root:[44,  1000] training loss: 0.00164254
INFO:root:[44,  1050] training loss: 0.00072342
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5556    0.6250    0.5882         8
    Anaphase     1.0000    0.0137    0.0270        73
    Prophase     0.2680    1.0000    0.4227      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2694      3872
   macro avg     0.4748    0.4008    0.3340      3872
weighted avg     0.0926    0.2694    0.1155      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.03633728
INFO:root:[45,   100] training loss: 0.01813798
INFO:root:[45,   150] training loss: 0.01896619
INFO:root:[45,   200] training loss: 0.01695516
INFO:root:[45,   250] training loss: 0.01884105
INFO:root:[45,   300] training loss: 0.02096513
INFO:root:[45,   350] training loss: 0.01581827
INFO:root:[45,   400] training loss: 0.00039400
INFO:root:[45,   450] training loss: 0.00014024
INFO:root:[45,   500] training loss: 0.00473698
INFO:root:[45,   550] training loss: 0.01294385
INFO:root:[45,   600] training loss: 0.03042586
INFO:root:[45,   650] training loss: 0.00216166
INFO:root:[45,   700] training loss: 0.00096443
INFO:root:[45,   750] training loss: 0.00057304
INFO:root:[45,   800] training loss: 0.00034822
INFO:root:[45,   850] training loss: 0.00025289
INFO:root:[45,   900] training loss: 0.03992335
INFO:root:[45,   950] training loss: 0.02559653
INFO:root:[45,  1000] training loss: 0.00181460
INFO:root:[45,  1050] training loss: 0.00073434
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4545    0.6250    0.5263         8
    Anaphase     1.0000    0.0274    0.0533        73
    Prophase     0.2682    1.0000    0.4230      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2696      3872
   macro avg     0.4604    0.4027    0.3289      3872
weighted avg     0.0925    0.2696    0.1159      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.03459609
INFO:root:[46,   100] training loss: 0.01713959
INFO:root:[46,   150] training loss: 0.01762892
INFO:root:[46,   200] training loss: 0.01876553
INFO:root:[46,   250] training loss: 0.01836913
INFO:root:[46,   300] training loss: 0.02016903
INFO:root:[46,   350] training loss: 0.01507672
INFO:root:[46,   400] training loss: 0.00022629
INFO:root:[46,   450] training loss: 0.00017027
INFO:root:[46,   500] training loss: 0.00532387
INFO:root:[46,   550] training loss: 0.01425429
INFO:root:[46,   600] training loss: 0.03151705
INFO:root:[46,   650] training loss: 0.00239351
INFO:root:[46,   700] training loss: 0.00096651
INFO:root:[46,   750] training loss: 0.00062442
INFO:root:[46,   800] training loss: 0.00043884
INFO:root:[46,   850] training loss: 0.00032426
INFO:root:[46,   900] training loss: 0.03848020
INFO:root:[46,   950] training loss: 0.02443795
INFO:root:[46,  1000] training loss: 0.00166874
INFO:root:[46,  1050] training loss: 0.00076790
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.5000    0.5000         8
    Anaphase     0.6667    0.0822    0.1463        73
    Prophase     0.2683    0.9990    0.4230      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2704      3872
   macro avg     0.4193    0.4402    0.3671      3872
weighted avg     0.0863    0.2704    0.1178      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.03590352
INFO:root:[47,   100] training loss: 0.01857075
INFO:root:[47,   150] training loss: 0.02271466
INFO:root:[47,   200] training loss: 0.01743479
INFO:root:[47,   250] training loss: 0.01833098
INFO:root:[47,   300] training loss: 0.02003043
INFO:root:[47,   350] training loss: 0.01442792
INFO:root:[47,   400] training loss: 0.00034258
INFO:root:[47,   450] training loss: 0.00016759
INFO:root:[47,   500] training loss: 0.00496484
INFO:root:[47,   550] training loss: 0.01400998
INFO:root:[47,   600] training loss: 0.03184012
INFO:root:[47,   650] training loss: 0.00248690
INFO:root:[47,   700] training loss: 0.00102875
INFO:root:[47,   750] training loss: 0.00068804
INFO:root:[47,   800] training loss: 0.00045844
INFO:root:[47,   850] training loss: 0.00036555
INFO:root:[47,   900] training loss: 0.03820128
INFO:root:[47,   950] training loss: 0.02320956
INFO:root:[47,  1000] training loss: 0.00138892
INFO:root:[47,  1050] training loss: 0.00050568
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3636    0.5000    0.4211         8
    Anaphase     0.2632    0.0685    0.1087        73
    Prophase     0.2689    0.9981    0.4236      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2696      3872
   macro avg     0.3422    0.3905    0.3219      3872
weighted avg     0.0786    0.2696    0.1169      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.03467008
INFO:root:[48,   100] training loss: 0.01806633
INFO:root:[48,   150] training loss: 0.01906771
INFO:root:[48,   200] training loss: 0.01784061
INFO:root:[48,   250] training loss: 0.01816663
INFO:root:[48,   300] training loss: 0.01924963
INFO:root:[48,   350] training loss: 0.01446275
INFO:root:[48,   400] training loss: 0.00032079
INFO:root:[48,   450] training loss: 0.00013021
INFO:root:[48,   500] training loss: 0.00484292
INFO:root:[48,   550] training loss: 0.01242954
INFO:root:[48,   600] training loss: 0.03084182
INFO:root:[48,   650] training loss: 0.00250282
INFO:root:[48,   700] training loss: 0.00108439
INFO:root:[48,   750] training loss: 0.00063258
INFO:root:[48,   800] training loss: 0.00040993
INFO:root:[48,   850] training loss: 0.00030755
INFO:root:[48,   900] training loss: 0.03648926
INFO:root:[48,   950] training loss: 0.02538400
INFO:root:[48,  1000] training loss: 0.00145196
INFO:root:[48,  1050] training loss: 0.00065084
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4545    0.6250    0.5263         8
    Anaphase     0.2500    0.0685    0.1075        73
    Prophase     0.2692    0.9990    0.4241      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2704      3872
   macro avg     0.4248    0.4561    0.3892      3872
weighted avg     0.0788    0.2704    0.1175      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.03374645
INFO:root:[49,   100] training loss: 0.01778355
INFO:root:[49,   150] training loss: 0.01884301
INFO:root:[49,   200] training loss: 0.01563529
INFO:root:[49,   250] training loss: 0.01666152
INFO:root:[49,   300] training loss: 0.01863148
INFO:root:[49,   350] training loss: 0.01659921
INFO:root:[49,   400] training loss: 0.00057079
INFO:root:[49,   450] training loss: 0.00008709
INFO:root:[49,   500] training loss: 0.00496331
INFO:root:[49,   550] training loss: 0.01475355
INFO:root:[49,   600] training loss: 0.03182418
INFO:root:[49,   650] training loss: 0.00295339
INFO:root:[49,   700] training loss: 0.00119233
INFO:root:[49,   750] training loss: 0.00069234
INFO:root:[49,   800] training loss: 0.00048937
INFO:root:[49,   850] training loss: 0.00034151
INFO:root:[49,   900] training loss: 0.03951224
INFO:root:[49,   950] training loss: 0.02198753
INFO:root:[49,  1000] training loss: 0.00070022
INFO:root:[49,  1050] training loss: 0.00007252
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4167    0.6250    0.5000         8
    Anaphase     0.1789    0.3014    0.2245        73
    Prophase     0.2758    0.9952    0.4319      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2740      3872
   macro avg     0.3626    0.5602    0.4223      3872
weighted avg     0.0790    0.2740    0.1218      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.03133997
INFO:root:[50,   100] training loss: 0.01892682
INFO:root:[50,   150] training loss: 0.01827123
INFO:root:[50,   200] training loss: 0.01813517
INFO:root:[50,   250] training loss: 0.02048584
INFO:root:[50,   300] training loss: 0.01997304
INFO:root:[50,   350] training loss: 0.01569721
INFO:root:[50,   400] training loss: 0.00044095
INFO:root:[50,   450] training loss: 0.00008617
INFO:root:[50,   500] training loss: 0.00447052
INFO:root:[50,   550] training loss: 0.01275674
INFO:root:[50,   600] training loss: 0.03108962
INFO:root:[50,   650] training loss: 0.00258440
INFO:root:[50,   700] training loss: 0.00097376
INFO:root:[50,   750] training loss: 0.00058231
INFO:root:[50,   800] training loss: 0.00036503
INFO:root:[50,   850] training loss: 0.00025328
INFO:root:[50,   900] training loss: 0.03836459
INFO:root:[50,   950] training loss: 0.02250990
INFO:root:[50,  1000] training loss: 0.00099576
INFO:root:[50,  1050] training loss: 0.00047239
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4000    0.5000    0.4444         8
    Anaphase     0.2473    0.3151    0.2771        73
    Prophase     0.2742    0.9981    0.4303      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2743      3872
   macro avg     0.3317    0.4495    0.3176      3872
weighted avg     0.0797    0.2743    0.1217      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch50
INFO:root:[51,    50] training loss: 0.03382634
INFO:root:[51,   100] training loss: 0.01860900
INFO:root:[51,   150] training loss: 0.01805410
INFO:root:[51,   200] training loss: 0.01658753
INFO:root:[51,   250] training loss: 0.01748485
INFO:root:[51,   300] training loss: 0.01956897
INFO:root:[51,   350] training loss: 0.01474029
INFO:root:[51,   400] training loss: 0.00022354
INFO:root:[51,   450] training loss: 0.00009764
INFO:root:[51,   500] training loss: 0.00496813
INFO:root:[51,   550] training loss: 0.01349697
INFO:root:[51,   600] training loss: 0.03067344
INFO:root:[51,   650] training loss: 0.00278912
INFO:root:[51,   700] training loss: 0.00111219
INFO:root:[51,   750] training loss: 0.00063966
INFO:root:[51,   800] training loss: 0.00043578
INFO:root:[51,   850] training loss: 0.00031955
INFO:root:[51,   900] training loss: 0.03562788
INFO:root:[51,   950] training loss: 0.02297364
INFO:root:[51,  1000] training loss: 0.00103751
INFO:root:[51,  1050] training loss: 0.00031543
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3846    0.6250    0.4762         8
    Anaphase     0.2255    0.3151    0.2629        73
    Prophase     0.2751    0.9981    0.4313      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2751      3872
   macro avg     0.3646    0.5626    0.4243      3872
weighted avg     0.0796    0.2751    0.1223      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch51
INFO:root:[52,    50] training loss: 0.03340859
INFO:root:[52,   100] training loss: 0.01840566
INFO:root:[52,   150] training loss: 0.01712204
INFO:root:[52,   200] training loss: 0.01766497
INFO:root:[52,   250] training loss: 0.01673305
INFO:root:[52,   300] training loss: 0.01901398
INFO:root:[52,   350] training loss: 0.01539875
INFO:root:[52,   400] training loss: 0.00036527
INFO:root:[52,   450] training loss: 0.00011193
INFO:root:[52,   500] training loss: 0.00473896
INFO:root:[52,   550] training loss: 0.01175565
INFO:root:[52,   600] training loss: 0.03090948
INFO:root:[52,   650] training loss: 0.00276881
INFO:root:[52,   700] training loss: 0.00103269
INFO:root:[52,   750] training loss: 0.00064651
INFO:root:[52,   800] training loss: 0.00046032
INFO:root:[52,   850] training loss: 0.00032787
INFO:root:[52,   900] training loss: 0.03819117
INFO:root:[52,   950] training loss: 0.02286934
INFO:root:[52,  1000] training loss: 0.00123251
INFO:root:[52,  1050] training loss: 0.00042282
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.4545    0.6250    0.5263         8
    Anaphase     0.2472    0.3014    0.2716        73
    Prophase     0.2741    0.9981    0.4301      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2748      3872
   macro avg     0.3537    0.5606    0.4135      3872
weighted avg     0.0798    0.2748    0.1222      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch52
INFO:root:[53,    50] training loss: 0.03318619
INFO:root:[53,   100] training loss: 0.01811411
INFO:root:[53,   150] training loss: 0.01774364
INFO:root:[53,   200] training loss: 0.01663367
INFO:root:[53,   250] training loss: 0.01669884
INFO:root:[53,   300] training loss: 0.01862891
INFO:root:[53,   350] training loss: 0.01441952
INFO:root:[53,   400] training loss: 0.00032145
INFO:root:[53,   450] training loss: 0.00010253
INFO:root:[53,   500] training loss: 0.00490804
INFO:root:[53,   550] training loss: 0.01141560
INFO:root:[53,   600] training loss: 0.02972448
INFO:root:[53,   650] training loss: 0.00254210
INFO:root:[53,   700] training loss: 0.00104812
INFO:root:[53,   750] training loss: 0.00057725
INFO:root:[53,   800] training loss: 0.00037988
INFO:root:[53,   850] training loss: 0.00028423
INFO:root:[53,   900] training loss: 0.03624633
INFO:root:[53,   950] training loss: 0.02078779
INFO:root:[53,  1000] training loss: 0.00101105
INFO:root:[53,  1050] training loss: 0.00047284
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.2609    0.7500    0.3871         8
    Anaphase     0.3200    0.2192    0.2602        73
    Prophase     0.2716    0.9961    0.4268      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2725      3872
   macro avg     0.3218    0.4712    0.3065      3872
weighted avg     0.0801    0.2725    0.1204      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch53
INFO:root:[54,    50] training loss: 0.03377468
INFO:root:[54,   100] training loss: 0.01796457
INFO:root:[54,   150] training loss: 0.01771895
INFO:root:[54,   200] training loss: 0.01674874
INFO:root:[54,   250] training loss: 0.01699117
INFO:root:[54,   300] training loss: 0.01860215
INFO:root:[54,   350] training loss: 0.01395000
INFO:root:[54,   400] training loss: 0.00036949
INFO:root:[54,   450] training loss: 0.00011823
INFO:root:[54,   500] training loss: 0.00454657
INFO:root:[54,   550] training loss: 0.01059438
INFO:root:[54,   600] training loss: 0.02989934
INFO:root:[54,   650] training loss: 0.00262791
INFO:root:[54,   700] training loss: 0.00096443
INFO:root:[54,   750] training loss: 0.00071136
INFO:root:[54,   800] training loss: 0.00047190
INFO:root:[54,   850] training loss: 0.00032254
INFO:root:[54,   900] training loss: 0.03374132
INFO:root:[54,   950] training loss: 0.02380407
INFO:root:[54,  1000] training loss: 0.00127214
INFO:root:[54,  1050] training loss: 0.00042873
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3529    0.7500    0.4800         8
    Anaphase     0.3373    0.3836    0.3590        73
    Prophase     0.2740    0.9981    0.4300      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2766      3872
   macro avg     0.3759    0.5902    0.4384      3872
weighted avg     0.0814    0.2766    0.1238      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch54
INFO:root:[55,    50] training loss: 0.03262552
INFO:root:[55,   100] training loss: 0.01973650
INFO:root:[55,   150] training loss: 0.01686636
INFO:root:[55,   200] training loss: 0.01677174
INFO:root:[55,   250] training loss: 0.01571871
INFO:root:[55,   300] training loss: 0.01983379
INFO:root:[55,   350] training loss: 0.01679227
INFO:root:[55,   400] training loss: 0.00041393
INFO:root:[55,   450] training loss: 0.00015732
INFO:root:[55,   500] training loss: 0.00489914
INFO:root:[55,   550] training loss: 0.00984018
INFO:root:[55,   600] training loss: 0.02887201
INFO:root:[55,   650] training loss: 0.00262084
INFO:root:[55,   700] training loss: 0.00106339
INFO:root:[55,   750] training loss: 0.00070873
INFO:root:[55,   800] training loss: 0.00045629
INFO:root:[55,   850] training loss: 0.00035481
INFO:root:[55,   900] training loss: 0.03754172
INFO:root:[55,   950] training loss: 0.02335400
INFO:root:[55,  1000] training loss: 0.00111430
INFO:root:[55,  1050] training loss: 0.00046132
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3333    0.5000    0.4000         8
    Anaphase     0.3171    0.3562    0.3355        73
    Prophase     0.2731    0.9961    0.4286      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2745      3872
   macro avg     0.3319    0.4551    0.3194      3872
weighted avg     0.0806    0.2745    0.1223      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch55
INFO:root:[56,    50] training loss: 0.03136307
INFO:root:[56,   100] training loss: 0.01733923
INFO:root:[56,   150] training loss: 0.01682279
INFO:root:[56,   200] training loss: 0.01621077
INFO:root:[56,   250] training loss: 0.01688303
INFO:root:[56,   300] training loss: 0.01814322
INFO:root:[56,   350] training loss: 0.01417570
INFO:root:[56,   400] training loss: 0.00028896
INFO:root:[56,   450] training loss: 0.00011167
INFO:root:[56,   500] training loss: 0.00437396
INFO:root:[56,   550] training loss: 0.00921132
INFO:root:[56,   600] training loss: 0.02860638
INFO:root:[56,   650] training loss: 0.00257654
INFO:root:[56,   700] training loss: 0.00103165
INFO:root:[56,   750] training loss: 0.00058442
INFO:root:[56,   800] training loss: 0.00036057
INFO:root:[56,   850] training loss: 0.00026836
INFO:root:[56,   900] training loss: 0.03539337
INFO:root:[56,   950] training loss: 0.02254314
INFO:root:[56,  1000] training loss: 0.00143612
INFO:root:[56,  1050] training loss: 0.00058536
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3636    0.5000    0.4211         8
    Anaphase     0.3438    0.3014    0.3212        73
    Prophase     0.2725    0.9990    0.4282      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2748      3872
   macro avg     0.3781    0.5429    0.4243      3872
weighted avg     0.0811    0.2748    0.1225      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch56
INFO:root:[57,    50] training loss: 0.03034574
INFO:root:[57,   100] training loss: 0.01628797
INFO:root:[57,   150] training loss: 0.01792254
INFO:root:[57,   200] training loss: 0.01509303
INFO:root:[57,   250] training loss: 0.01675480
INFO:root:[57,   300] training loss: 0.01757413
INFO:root:[57,   350] training loss: 0.01587682
INFO:root:[57,   400] training loss: 0.00018681
INFO:root:[57,   450] training loss: 0.00010301
INFO:root:[57,   500] training loss: 0.00449706
INFO:root:[57,   550] training loss: 0.00846347
INFO:root:[57,   600] training loss: 0.02714487
INFO:root:[57,   650] training loss: 0.00219061
INFO:root:[57,   700] training loss: 0.00093000
INFO:root:[57,   750] training loss: 0.00052827
INFO:root:[57,   800] training loss: 0.00030640
INFO:root:[57,   850] training loss: 0.00023741
INFO:root:[57,   900] training loss: 0.03407504
INFO:root:[57,   950] training loss: 0.02133916
INFO:root:[57,  1000] training loss: 0.00147775
INFO:root:[57,  1050] training loss: 0.00060502
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3158    0.7500    0.4444         8
    Anaphase     0.3333    0.3288    0.3310        73
    Prophase     0.2731    0.9971    0.4288      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2753      3872
   macro avg     0.3698    0.5823    0.4292      3872
weighted avg     0.0810    0.2753    0.1229      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch57
INFO:root:[58,    50] training loss: 0.02910098
INFO:root:[58,   100] training loss: 0.01667967
INFO:root:[58,   150] training loss: 0.01637075
INFO:root:[58,   200] training loss: 0.01458898
INFO:root:[58,   250] training loss: 0.01747436
INFO:root:[58,   300] training loss: 0.01910342
INFO:root:[58,   350] training loss: 0.01520891
INFO:root:[58,   400] training loss: 0.00028079
INFO:root:[58,   450] training loss: 0.00011213
INFO:root:[58,   500] training loss: 0.00433997
INFO:root:[58,   550] training loss: 0.00893280
INFO:root:[58,   600] training loss: 0.02519724
INFO:root:[58,   650] training loss: 0.00198338
INFO:root:[58,   700] training loss: 0.00081331
INFO:root:[58,   750] training loss: 0.00042510
INFO:root:[58,   800] training loss: 0.00025660
INFO:root:[58,   850] training loss: 0.00018440
INFO:root:[58,   900] training loss: 0.03280609
INFO:root:[58,   950] training loss: 0.01930066
INFO:root:[58,  1000] training loss: 0.00129229
INFO:root:[58,  1050] training loss: 0.00039717
INFO:root:              precision    recall  f1-score   support

          G1     0.2857    1.0000    0.4444         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.3000    0.7500    0.4286         8
    Anaphase     0.2105    0.3288    0.2567        73
    Prophase     0.2754    0.9932    0.4312      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2740      3872
   macro avg     0.2959    0.5341    0.3373      3872
weighted avg     0.0791    0.2740    0.1217      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch58
INFO:root:[59,    50] training loss: 0.02853824
INFO:root:[59,   100] training loss: 0.01668656
INFO:root:[59,   150] training loss: 0.01562958
INFO:root:[59,   200] training loss: 0.01502860
INFO:root:[59,   250] training loss: 0.01818365
INFO:root:[59,   300] training loss: 0.01998798
INFO:root:[59,   350] training loss: 0.01337179
INFO:root:[59,   400] training loss: 0.00034133
INFO:root:[59,   450] training loss: 0.00018237
INFO:root:[59,   500] training loss: 0.00470815
INFO:root:[59,   550] training loss: 0.00988343
INFO:root:[59,   600] training loss: 0.02509077
INFO:root:[59,   650] training loss: 0.00183414
INFO:root:[59,   700] training loss: 0.00083237
INFO:root:[59,   750] training loss: 0.00049033
INFO:root:[59,   800] training loss: 0.00035606
INFO:root:[59,   850] training loss: 0.00025625
INFO:root:[59,   900] training loss: 0.03237217
INFO:root:[59,   950] training loss: 0.01885702
INFO:root:[59,  1000] training loss: 0.00101905
INFO:root:[59,  1050] training loss: 0.00047272
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
          G2     0.1667    0.7500    0.2727         8
    Anaphase     0.1500    0.4521    0.2253        73
    Prophase     0.2810    0.9807    0.4368      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2732      3872
   macro avg     0.2997    0.5975    0.3716      3872
weighted avg     0.0792    0.2732    0.1226      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch59
INFO:root:[60,    50] training loss: 0.02773948
INFO:root:[60,   100] training loss: 0.01668873
INFO:root:[60,   150] training loss: 0.01582190
INFO:root:[60,   200] training loss: 0.01434823
INFO:root:[60,   250] training loss: 0.01528881
INFO:root:[60,   300] training loss: 0.01757400
INFO:root:[60,   350] training loss: 0.01370766
INFO:root:[60,   400] training loss: 0.00018453
INFO:root:[60,   450] training loss: 0.00011418
INFO:root:[60,   500] training loss: 0.00504692
INFO:root:[60,   550] training loss: 0.01067729
INFO:root:[60,   600] training loss: 0.02355561
INFO:root:[60,   650] training loss: 0.00178626
INFO:root:[60,   700] training loss: 0.00079566
INFO:root:[60,   750] training loss: 0.00053717
INFO:root:[60,   800] training loss: 0.00034281
INFO:root:[60,   850] training loss: 0.00026410
INFO:root:[60,   900] training loss: 0.03113805
INFO:root:[60,   950] training loss: 0.02053009
INFO:root:[60,  1000] training loss: 0.00096671
INFO:root:[60,  1050] training loss: 0.00039705
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0010    0.0019      1032
          G2     0.2000    0.7500    0.3158         8
    Anaphase     0.4400    0.1507    0.2245        73
    Prophase     0.2701    0.9952    0.4249      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2712      3872
   macro avg     0.4729    0.4615    0.2912      3872
weighted avg     0.3483    0.2712    0.1195      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch60
INFO:root:[61,    50] training loss: 0.02981534
INFO:root:[61,   100] training loss: 0.01557442
INFO:root:[61,   150] training loss: 0.01599062
INFO:root:[61,   200] training loss: 0.02036960
INFO:root:[61,   250] training loss: 0.01671950
INFO:root:[61,   300] training loss: 0.01841641
INFO:root:[61,   350] training loss: 0.01385596
INFO:root:[61,   400] training loss: 0.00023050
INFO:root:[61,   450] training loss: 0.00009073
INFO:root:[61,   500] training loss: 0.00456910
INFO:root:[61,   550] training loss: 0.00889944
INFO:root:[61,   600] training loss: 0.02337647
INFO:root:[61,   650] training loss: 0.00183584
INFO:root:[61,   700] training loss: 0.00079496
INFO:root:[61,   750] training loss: 0.00054517
INFO:root:[61,   800] training loss: 0.00037562
INFO:root:[61,   850] training loss: 0.00027491
INFO:root:[61,   900] training loss: 0.03100709
INFO:root:[61,   950] training loss: 0.01677556
INFO:root:[61,  1000] training loss: 0.00072624
INFO:root:[61,  1050] training loss: 0.00030326
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    1.0000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.7600    0.0184    0.0360      1032
          G2     0.1786    0.6250    0.2778         8
    Anaphase     0.1567    0.5753    0.2463        73
    Prophase     0.2840    0.9729    0.4397      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2782      3872
   macro avg     0.3875    0.5988    0.3571      3872
weighted avg     0.2827    0.2782    0.1332      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch61
INFO:root:[62,    50] training loss: 0.02939631
INFO:root:[62,   100] training loss: 0.01637388
INFO:root:[62,   150] training loss: 0.01581404
INFO:root:[62,   200] training loss: 0.01550779
INFO:root:[62,   250] training loss: 0.01468452
INFO:root:[62,   300] training loss: 0.01869061
INFO:root:[62,   350] training loss: 0.01640786
INFO:root:[62,   400] training loss: 0.00022115
INFO:root:[62,   450] training loss: 0.00010914
INFO:root:[62,   500] training loss: 0.00443300
INFO:root:[62,   550] training loss: 0.00726242
INFO:root:[62,   600] training loss: 0.02281143
INFO:root:[62,   650] training loss: 0.00197256
INFO:root:[62,   700] training loss: 0.00096168
INFO:root:[62,   750] training loss: 0.00062528
INFO:root:[62,   800] training loss: 0.00042308
INFO:root:[62,   850] training loss: 0.00031721
INFO:root:[62,   900] training loss: 0.03101162
INFO:root:[62,   950] training loss: 0.01779765
INFO:root:[62,  1000] training loss: 0.00078064
INFO:root:[62,  1050] training loss: 0.00033455
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.8125    0.0252    0.0489      1032
          G2     0.3000    0.7500    0.4286         8
    Anaphase     0.1496    0.5616    0.2363        73
    Prophase     0.2867    0.9816    0.4438      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2823      3872
   macro avg     0.4594    0.6169    0.4225      3872
weighted avg     0.2977    0.2823    0.1381      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch62
INFO:root:[63,    50] training loss: 0.02594625
INFO:root:[63,   100] training loss: 0.01617757
INFO:root:[63,   150] training loss: 0.01721319
INFO:root:[63,   200] training loss: 0.01612685
INFO:root:[63,   250] training loss: 0.01649065
INFO:root:[63,   300] training loss: 0.01721303
INFO:root:[63,   350] training loss: 0.01593409
INFO:root:[63,   400] training loss: 0.00021816
INFO:root:[63,   450] training loss: 0.00017916
INFO:root:[63,   500] training loss: 0.00462135
INFO:root:[63,   550] training loss: 0.00764175
INFO:root:[63,   600] training loss: 0.02067657
INFO:root:[63,   650] training loss: 0.00161897
INFO:root:[63,   700] training loss: 0.00084447
INFO:root:[63,   750] training loss: 0.00059997
INFO:root:[63,   800] training loss: 0.00039059
INFO:root:[63,   850] training loss: 0.00029334
INFO:root:[63,   900] training loss: 0.02719131
INFO:root:[63,   950] training loss: 0.01549045
INFO:root:[63,  1000] training loss: 0.00051416
INFO:root:[63,  1050] training loss: 0.00022299
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.5078    0.0950    0.1600      1032
          G2     0.1579    0.7500    0.2609         8
    Anaphase     0.1311    0.8082    0.2256        73
    Prophase     0.2750    0.8472    0.4153      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2694      3872
   macro avg     0.3674    0.5953    0.3612      3872
weighted avg     0.2126    0.2694    0.1593      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch63
INFO:root:[64,    50] training loss: 0.02468406
INFO:root:[64,   100] training loss: 0.01843678
INFO:root:[64,   150] training loss: 0.01651584
INFO:root:[64,   200] training loss: 0.01589270
INFO:root:[64,   250] training loss: 0.01546860
INFO:root:[64,   300] training loss: 0.01651816
INFO:root:[64,   350] training loss: 0.01382749
INFO:root:[64,   400] training loss: 0.00037180
INFO:root:[64,   450] training loss: 0.00008255
INFO:root:[64,   500] training loss: 0.00430302
INFO:root:[64,   550] training loss: 0.00564010
INFO:root:[64,   600] training loss: 0.01893828
INFO:root:[64,   650] training loss: 0.00157171
INFO:root:[64,   700] training loss: 0.00083880
INFO:root:[64,   750] training loss: 0.00065234
INFO:root:[64,   800] training loss: 0.00044031
INFO:root:[64,   850] training loss: 0.00030169
INFO:root:[64,   900] training loss: 0.03054063
INFO:root:[64,   950] training loss: 0.01479505
INFO:root:[64,  1000] training loss: 0.00043802
INFO:root:[64,  1050] training loss: 0.00021708
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.6031    0.1134    0.1909      1032
          G2     0.1224    0.7500    0.2105         8
    Anaphase     0.1296    0.7260    0.2199        73
    Prophase     0.2853    0.8868    0.4317      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2836      3872
   macro avg     0.4010    0.6395    0.4076      3872
weighted avg     0.2407    0.2836    0.1719      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch64
INFO:root:[65,    50] training loss: 0.02384730
INFO:root:[65,   100] training loss: 0.01580145
INFO:root:[65,   150] training loss: 0.01576798
INFO:root:[65,   200] training loss: 0.01478405
INFO:root:[65,   250] training loss: 0.01560675
INFO:root:[65,   300] training loss: 0.01690097
INFO:root:[65,   350] training loss: 0.01295350
INFO:root:[65,   400] training loss: 0.00023816
INFO:root:[65,   450] training loss: 0.00009315
INFO:root:[65,   500] training loss: 0.00398596
INFO:root:[65,   550] training loss: 0.00458235
INFO:root:[65,   600] training loss: 0.01804360
INFO:root:[65,   650] training loss: 0.00151756
INFO:root:[65,   700] training loss: 0.00081123
INFO:root:[65,   750] training loss: 0.00065003
INFO:root:[65,   800] training loss: 0.00044582
INFO:root:[65,   850] training loss: 0.00030931
INFO:root:[65,   900] training loss: 0.02994575
INFO:root:[65,   950] training loss: 0.01365607
INFO:root:[65,  1000] training loss: 0.00039165
INFO:root:[65,  1050] training loss: 0.00017844
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.6423    0.2209    0.3288      1032
          G2     0.1277    0.7500    0.2182         8
    Anaphase     0.1083    0.7123    0.1881        73
    Prophase     0.2859    0.8250    0.4246      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2952      3872
   macro avg     0.3806    0.5964    0.3752      3872
weighted avg     0.2509    0.2952    0.2060      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch65
INFO:root:[66,    50] training loss: 0.02271324
INFO:root:[66,   100] training loss: 0.01469715
INFO:root:[66,   150] training loss: 0.01704516
INFO:root:[66,   200] training loss: 0.01504490
INFO:root:[66,   250] training loss: 0.01539278
INFO:root:[66,   300] training loss: 0.01733797
INFO:root:[66,   350] training loss: 0.01584080
INFO:root:[66,   400] training loss: 0.00023688
INFO:root:[66,   450] training loss: 0.00009098
INFO:root:[66,   500] training loss: 0.00329125
INFO:root:[66,   550] training loss: 0.00367449
INFO:root:[66,   600] training loss: 0.01699114
INFO:root:[66,   650] training loss: 0.00161296
INFO:root:[66,   700] training loss: 0.00083406
INFO:root:[66,   750] training loss: 0.00066407
INFO:root:[66,   800] training loss: 0.00042351
INFO:root:[66,   850] training loss: 0.00030582
INFO:root:[66,   900] training loss: 0.02759585
INFO:root:[66,   950] training loss: 0.01122499
INFO:root:[66,  1000] training loss: 0.00025823
INFO:root:[66,  1050] training loss: 0.00015511
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     1.0000    0.0012    0.0023      1720
   Telophase     0.4383    0.3130    0.3652      1032
          G2     0.0946    0.8750    0.1707         8
    Anaphase     0.1048    0.8356    0.1863        73
    Prophase     0.2534    0.6054    0.3573      1034
   Metaphase     0.6667    0.6667    0.6667         3

    accuracy                         0.2642      3872
   macro avg     0.4368    0.6138    0.3450      3872
weighted avg     0.6317    0.2642    0.1985      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch66
INFO:root:[67,    50] training loss: 0.02064107
INFO:root:[67,   100] training loss: 0.01576828
INFO:root:[67,   150] training loss: 0.01525563
INFO:root:[67,   200] training loss: 0.01466541
INFO:root:[67,   250] training loss: 0.01782951
INFO:root:[67,   300] training loss: 0.01672048
INFO:root:[67,   350] training loss: 0.01233169
INFO:root:[67,   400] training loss: 0.00017630
INFO:root:[67,   450] training loss: 0.00009197
INFO:root:[67,   500] training loss: 0.00321553
INFO:root:[67,   550] training loss: 0.00269551
INFO:root:[67,   600] training loss: 0.01519121
INFO:root:[67,   650] training loss: 0.00145836
INFO:root:[67,   700] training loss: 0.00072121
INFO:root:[67,   750] training loss: 0.00067344
INFO:root:[67,   800] training loss: 0.00042741
INFO:root:[67,   850] training loss: 0.00028610
INFO:root:[67,   900] training loss: 0.02858164
INFO:root:[67,   950] training loss: 0.01162410
INFO:root:[67,  1000] training loss: 0.00024800
INFO:root:[67,  1050] training loss: 0.00013815
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     1.0000    0.0006    0.0012      1720
   Telophase     0.4930    0.3430    0.4046      1032
          G2     0.1522    0.8750    0.2593         8
    Anaphase     0.1038    0.7534    0.1824        73
    Prophase     0.2644    0.6576    0.3771      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.2843      3872
   macro avg     0.5257    0.6138    0.4035      3872
weighted avg     0.6496    0.2843    0.2141      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch67
INFO:root:[68,    50] training loss: 0.01858747
INFO:root:[68,   100] training loss: 0.01439723
INFO:root:[68,   150] training loss: 0.01548466
INFO:root:[68,   200] training loss: 0.01380344
INFO:root:[68,   250] training loss: 0.01459755
INFO:root:[68,   300] training loss: 0.01523519
INFO:root:[68,   350] training loss: 0.01278325
INFO:root:[68,   400] training loss: 0.00014047
INFO:root:[68,   450] training loss: 0.00008452
INFO:root:[68,   500] training loss: 0.00291602
INFO:root:[68,   550] training loss: 0.00211308
INFO:root:[68,   600] training loss: 0.01477514
INFO:root:[68,   650] training loss: 0.00149052
INFO:root:[68,   700] training loss: 0.00080022
INFO:root:[68,   750] training loss: 0.00067731
INFO:root:[68,   800] training loss: 0.00046305
INFO:root:[68,   850] training loss: 0.00032465
INFO:root:[68,   900] training loss: 0.02738049
INFO:root:[68,   950] training loss: 0.01090322
INFO:root:[68,  1000] training loss: 0.00020950
INFO:root:[68,  1050] training loss: 0.00012652
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     1.0000    0.0064    0.0127      1720
   Telophase     0.3237    0.2500    0.2821      1032
          G2     0.0833    0.7500    0.1500         8
    Anaphase     0.0958    0.9041    0.1732        73
    Prophase     0.2552    0.5667    0.3520      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.2407      3872
   macro avg     0.4535    0.6396    0.3753      3872
weighted avg     0.6016    0.2407    0.1795      3872

INFO:root:Accuracy of the network on the 3872 validation images: 24 %
INFO:root:epoch68
INFO:root:[69,    50] training loss: 0.01897459
INFO:root:[69,   100] training loss: 0.01408006
INFO:root:[69,   150] training loss: 0.01461443
INFO:root:[69,   200] training loss: 0.01348466
INFO:root:[69,   250] training loss: 0.01488947
INFO:root:[69,   300] training loss: 0.01582058
INFO:root:[69,   350] training loss: 0.01286408
INFO:root:[69,   400] training loss: 0.00015916
INFO:root:[69,   450] training loss: 0.00011441
INFO:root:[69,   500] training loss: 0.00288839
INFO:root:[69,   550] training loss: 0.00235561
INFO:root:[69,   600] training loss: 0.01408531
INFO:root:[69,   650] training loss: 0.00131291
INFO:root:[69,   700] training loss: 0.00070038
INFO:root:[69,   750] training loss: 0.00064315
INFO:root:[69,   800] training loss: 0.00042528
INFO:root:[69,   850] training loss: 0.00030514
INFO:root:[69,   900] training loss: 0.02912425
INFO:root:[69,   950] training loss: 0.01136917
INFO:root:[69,  1000] training loss: 0.00013282
INFO:root:[69,  1050] training loss: 0.00006836
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    1.0000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.3723    0.2190    0.2758      1032
          G2     0.1296    0.8750    0.2258         8
    Anaphase     0.0906    0.6712    0.1596        73
    Prophase     0.2619    0.6741    0.3773      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2536      3872
   macro avg     0.3006    0.5389    0.2769      3872
weighted avg     0.1721    0.2536    0.1783      3872

INFO:root:Accuracy of the network on the 3872 validation images: 25 %
INFO:root:epoch69
INFO:root:[70,    50] training loss: 0.02345783
INFO:root:[70,   100] training loss: 0.01578926
INFO:root:[70,   150] training loss: 0.01996403
INFO:root:[70,   200] training loss: 0.01488810
INFO:root:[70,   250] training loss: 0.01416360
INFO:root:[70,   300] training loss: 0.01560059
INFO:root:[70,   350] training loss: 0.01346636
INFO:root:[70,   400] training loss: 0.00021026
INFO:root:[70,   450] training loss: 0.00007916
INFO:root:[70,   500] training loss: 0.00272702
INFO:root:[70,   550] training loss: 0.00212062
INFO:root:[70,   600] training loss: 0.01438793
INFO:root:[70,   650] training loss: 0.00130361
INFO:root:[70,   700] training loss: 0.00072931
INFO:root:[70,   750] training loss: 0.00066244
INFO:root:[70,   800] training loss: 0.00042328
INFO:root:[70,   850] training loss: 0.00029923
INFO:root:[70,   900] training loss: 0.02652557
INFO:root:[70,   950] training loss: 0.01039567
INFO:root:[70,  1000] training loss: 0.00016450
INFO:root:[70,  1050] training loss: 0.00010122
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     1.0000    0.0035    0.0070      1720
   Telophase     0.4087    0.3837    0.3958      1032
          G2     0.1250    0.8750    0.2188         8
    Anaphase     0.0808    0.7397    0.1457        73
    Prophase     0.2533    0.5309    0.3430      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2621      3872
   macro avg     0.4668    0.5523    0.3117      3872
weighted avg     0.6236    0.2621    0.2041      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch70
INFO:root:[71,    50] training loss: 0.01869146
INFO:root:[71,   100] training loss: 0.01472657
INFO:root:[71,   150] training loss: 0.01437866
INFO:root:[71,   200] training loss: 0.01653357
INFO:root:[71,   250] training loss: 0.01466588
INFO:root:[71,   300] training loss: 0.01595152
INFO:root:[71,   350] training loss: 0.01283197
INFO:root:[71,   400] training loss: 0.00021233
INFO:root:[71,   450] training loss: 0.00006809
INFO:root:[71,   500] training loss: 0.00296362
INFO:root:[71,   550] training loss: 0.00238968
INFO:root:[71,   600] training loss: 0.01264191
INFO:root:[71,   650] training loss: 0.00124752
INFO:root:[71,   700] training loss: 0.00071388
INFO:root:[71,   750] training loss: 0.00073535
INFO:root:[71,   800] training loss: 0.00043990
INFO:root:[71,   850] training loss: 0.00030243
INFO:root:[71,   900] training loss: 0.02621180
INFO:root:[71,   950] training loss: 0.00762566
INFO:root:[71,  1000] training loss: 0.00011172
INFO:root:[71,  1050] training loss: 0.00007384
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.9474    0.0105    0.0207      1720
   Telophase     0.2702    0.3266    0.2957      1032
          G2     0.0700    0.8750    0.1296         8
    Anaphase     0.0707    0.8219    0.1302        73
    Prophase     0.1993    0.3182    0.2451      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.1950      3872
   macro avg     0.4368    0.5741    0.3269      3872
weighted avg     0.5486    0.1950    0.1571      3872

INFO:root:Accuracy of the network on the 3872 validation images: 19 %
INFO:root:epoch71
INFO:root:[72,    50] training loss: 0.01898109
INFO:root:[72,   100] training loss: 0.01330492
INFO:root:[72,   150] training loss: 0.01467632
INFO:root:[72,   200] training loss: 0.01578939
INFO:root:[72,   250] training loss: 0.01431110
INFO:root:[72,   300] training loss: 0.01637751
INFO:root:[72,   350] training loss: 0.01637333
INFO:root:[72,   400] training loss: 0.00014998
INFO:root:[72,   450] training loss: 0.00009925
INFO:root:[72,   500] training loss: 0.00253755
INFO:root:[72,   550] training loss: 0.00200405
INFO:root:[72,   600] training loss: 0.01157116
INFO:root:[72,   650] training loss: 0.00122154
INFO:root:[72,   700] training loss: 0.00070227
INFO:root:[72,   750] training loss: 0.00069058
INFO:root:[72,   800] training loss: 0.00045700
INFO:root:[72,   850] training loss: 0.00029591
INFO:root:[72,   900] training loss: 0.02751585
INFO:root:[72,   950] training loss: 0.00685014
INFO:root:[72,  1000] training loss: 0.00009709
INFO:root:[72,  1050] training loss: 0.00006345
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    1.0000    0.5000         2
           S     0.9615    0.0145    0.0286      1720
   Telophase     0.2821    0.3517    0.3131      1032
          G2     0.0693    0.8750    0.1284         8
    Anaphase     0.0703    0.8356    0.1296        73
    Prophase     0.1783    0.2727    0.2156      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.1916      3872
   macro avg     0.4135    0.5738    0.3022      3872
weighted avg     0.5523    0.1916    0.1573      3872

INFO:root:Accuracy of the network on the 3872 validation images: 19 %
INFO:root:epoch72
INFO:root:[73,    50] training loss: 0.01857368
INFO:root:[73,   100] training loss: 0.01439296
INFO:root:[73,   150] training loss: 0.01442576
INFO:root:[73,   200] training loss: 0.01515820
INFO:root:[73,   250] training loss: 0.01461852
INFO:root:[73,   300] training loss: 0.01549353
INFO:root:[73,   350] training loss: 0.01294309
INFO:root:[73,   400] training loss: 0.00009978
INFO:root:[73,   450] training loss: 0.00008910
INFO:root:[73,   500] training loss: 0.00205993
INFO:root:[73,   550] training loss: 0.00182490
INFO:root:[73,   600] training loss: 0.01014247
INFO:root:[73,   650] training loss: 0.00115395
INFO:root:[73,   700] training loss: 0.00067131
INFO:root:[73,   750] training loss: 0.00064402
INFO:root:[73,   800] training loss: 0.00042350
INFO:root:[73,   850] training loss: 0.00027391
INFO:root:[73,   900] training loss: 0.02592065
INFO:root:[73,   950] training loss: 0.00650796
INFO:root:[73,  1000] training loss: 0.00009691
INFO:root:[73,  1050] training loss: 0.00005630
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     1.0000    0.0110    0.0219      1720
   Telophase     0.2696    0.2529    0.2610      1032
          G2     0.0946    0.8750    0.1707         8
    Anaphase     0.0623    0.8767    0.1163        73
    Prophase     0.1778    0.3056    0.2248      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.1733      3872
   macro avg     0.4435    0.5697    0.3230      3872
weighted avg     0.5660    0.1733    0.1428      3872

INFO:root:Accuracy of the network on the 3872 validation images: 17 %
INFO:root:epoch73
INFO:root:[74,    50] training loss: 0.01818420
INFO:root:[74,   100] training loss: 0.01534364
INFO:root:[74,   150] training loss: 0.01492915
INFO:root:[74,   200] training loss: 0.01499095
INFO:root:[74,   250] training loss: 0.01523858
INFO:root:[74,   300] training loss: 0.01511932
INFO:root:[74,   350] training loss: 0.01262564
INFO:root:[74,   400] training loss: 0.00023489
INFO:root:[74,   450] training loss: 0.00006485
INFO:root:[74,   500] training loss: 0.00177580
INFO:root:[74,   550] training loss: 0.00118234
INFO:root:[74,   600] training loss: 0.00818429
INFO:root:[74,   650] training loss: 0.00102420
INFO:root:[74,   700] training loss: 0.00060153
INFO:root:[74,   750] training loss: 0.00059331
INFO:root:[74,   800] training loss: 0.00035681
INFO:root:[74,   850] training loss: 0.00023656
INFO:root:[74,   900] training loss: 0.02475924
INFO:root:[74,   950] training loss: 0.00596895
INFO:root:[74,  1000] training loss: 0.00008081
INFO:root:[74,  1050] training loss: 0.00003968
INFO:root:              precision    recall  f1-score   support

          G1     0.1429    0.5000    0.2222         2
           S     1.0000    0.0198    0.0388      1720
   Telophase     0.4466    0.4777    0.4616      1032
          G2     0.1094    0.8750    0.1944         8
    Anaphase     0.0806    0.7671    0.1458        73
    Prophase     0.2093    0.3975    0.2742      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.2596      3872
   macro avg     0.3912    0.5767    0.3135      3872
weighted avg     0.6215    0.2596    0.2174      3872

INFO:root:Accuracy of the network on the 3872 validation images: 25 %
INFO:root:epoch74
INFO:root:[75,    50] training loss: 0.01759128
INFO:root:[75,   100] training loss: 0.01306247
INFO:root:[75,   150] training loss: 0.01529474
INFO:root:[75,   200] training loss: 0.01553350
INFO:root:[75,   250] training loss: 0.01441151
INFO:root:[75,   300] training loss: 0.01493256
INFO:root:[75,   350] training loss: 0.01361389
INFO:root:[75,   400] training loss: 0.00031631
INFO:root:[75,   450] training loss: 0.00006492
INFO:root:[75,   500] training loss: 0.00163549
INFO:root:[75,   550] training loss: 0.00116335
INFO:root:[75,   600] training loss: 0.00866374
INFO:root:[75,   650] training loss: 0.00094498
INFO:root:[75,   700] training loss: 0.00054145
INFO:root:[75,   750] training loss: 0.00057211
INFO:root:[75,   800] training loss: 0.00035499
INFO:root:[75,   850] training loss: 0.00025176
INFO:root:[75,   900] training loss: 0.02667288
INFO:root:[75,   950] training loss: 0.00685658
INFO:root:[75,  1000] training loss: 0.00005799
INFO:root:[75,  1050] training loss: 0.00003588
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    1.0000    0.4000         2
           S     0.9688    0.0180    0.0354      1720
   Telophase     0.4899    0.4012    0.4411      1032
          G2     0.1364    0.7500    0.2308         8
    Anaphase     0.0768    0.7945    0.1401        73
    Prophase     0.2339    0.4942    0.3175      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2647      3872
   macro avg     0.4508    0.6368    0.3664      3872
weighted avg     0.6260    0.2647    0.2222      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch75
INFO:root:[76,    50] training loss: 0.01707960
INFO:root:[76,   100] training loss: 0.01611301
INFO:root:[76,   150] training loss: 0.01885219
INFO:root:[76,   200] training loss: 0.01440092
INFO:root:[76,   250] training loss: 0.01618079
INFO:root:[76,   300] training loss: 0.01603592
INFO:root:[76,   350] training loss: 0.01253419
INFO:root:[76,   400] training loss: 0.00025509
INFO:root:[76,   450] training loss: 0.00006930
INFO:root:[76,   500] training loss: 0.00179877
INFO:root:[76,   550] training loss: 0.00117391
INFO:root:[76,   600] training loss: 0.00790478
INFO:root:[76,   650] training loss: 0.00102788
INFO:root:[76,   700] training loss: 0.00060403
INFO:root:[76,   750] training loss: 0.00062342
INFO:root:[76,   800] training loss: 0.00038122
INFO:root:[76,   850] training loss: 0.00026086
INFO:root:[76,   900] training loss: 0.02640641
INFO:root:[76,   950] training loss: 0.00742841
INFO:root:[76,  1000] training loss: 0.00003985
INFO:root:[76,  1050] training loss: 0.00002983
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    1.0000    0.4000         2
           S     1.0000    0.0110    0.0219      1720
   Telophase     0.5701    0.4215    0.4847      1032
          G2     0.1373    0.8750    0.2373         8
    Anaphase     0.0804    0.7945    0.1461        73
    Prophase     0.2601    0.5803    0.3592      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2903      3872
   macro avg     0.4711    0.6689    0.3784      3872
weighted avg     0.6683    0.2903    0.2390      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch76
INFO:root:[77,    50] training loss: 0.01743767
INFO:root:[77,   100] training loss: 0.01390390
INFO:root:[77,   150] training loss: 0.01512546
INFO:root:[77,   200] training loss: 0.01404248
INFO:root:[77,   250] training loss: 0.01421485
INFO:root:[77,   300] training loss: 0.01478002
INFO:root:[77,   350] training loss: 0.01231014
INFO:root:[77,   400] training loss: 0.00015992
INFO:root:[77,   450] training loss: 0.00008183
INFO:root:[77,   500] training loss: 0.00157249
INFO:root:[77,   550] training loss: 0.00111059
INFO:root:[77,   600] training loss: 0.00857562
INFO:root:[77,   650] training loss: 0.00092220
INFO:root:[77,   700] training loss: 0.00058790
INFO:root:[77,   750] training loss: 0.00057360
INFO:root:[77,   800] training loss: 0.00032428
INFO:root:[77,   850] training loss: 0.00025098
INFO:root:[77,   900] training loss: 0.02373564
INFO:root:[77,   950] training loss: 0.00726285
INFO:root:[77,  1000] training loss: 0.00004950
INFO:root:[77,  1050] training loss: 0.00003286
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.9500    0.0110    0.0218      1720
   Telophase     0.4258    0.4981    0.4591      1032
          G2     0.1014    0.8750    0.1818         8
    Anaphase     0.0828    0.7534    0.1493        73
    Prophase     0.2174    0.4004    0.2818      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2619      3872
   macro avg     0.4539    0.6483    0.3808      3872
weighted avg     0.5963    0.2619    0.2116      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch77
INFO:root:[78,    50] training loss: 0.01679610
INFO:root:[78,   100] training loss: 0.01311889
INFO:root:[78,   150] training loss: 0.01362635
INFO:root:[78,   200] training loss: 0.01287202
INFO:root:[78,   250] training loss: 0.01550135
INFO:root:[78,   300] training loss: 0.01551766
INFO:root:[78,   350] training loss: 0.01230457
INFO:root:[78,   400] training loss: 0.00036227
INFO:root:[78,   450] training loss: 0.00007502
INFO:root:[78,   500] training loss: 0.00173032
INFO:root:[78,   550] training loss: 0.00118887
INFO:root:[78,   600] training loss: 0.00776799
INFO:root:[78,   650] training loss: 0.00093563
INFO:root:[78,   700] training loss: 0.00056483
INFO:root:[78,   750] training loss: 0.00062724
INFO:root:[78,   800] training loss: 0.00031567
INFO:root:[78,   850] training loss: 0.00023059
INFO:root:[78,   900] training loss: 0.02436716
INFO:root:[78,   950] training loss: 0.00678964
INFO:root:[78,  1000] training loss: 0.00005677
INFO:root:[78,  1050] training loss: 0.00004171
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     1.0000    0.0058    0.0116      1720
   Telophase     0.4285    0.6037    0.5012      1032
          G2     0.0909    0.8750    0.1647         8
    Anaphase     0.0795    0.6712    0.1422        73
    Prophase     0.1892    0.3124    0.2357      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2627      3872
   macro avg     0.4554    0.6383    0.3753      3872
weighted avg     0.6116    0.2627    0.2058      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch78
INFO:root:[79,    50] training loss: 0.01719311
INFO:root:[79,   100] training loss: 0.01320773
INFO:root:[79,   150] training loss: 0.01360736
INFO:root:[79,   200] training loss: 0.01337679
INFO:root:[79,   250] training loss: 0.01713061
INFO:root:[79,   300] training loss: 0.01811218
INFO:root:[79,   350] training loss: 0.01431324
INFO:root:[79,   400] training loss: 0.00010580
INFO:root:[79,   450] training loss: 0.00007481
INFO:root:[79,   500] training loss: 0.00204126
INFO:root:[79,   550] training loss: 0.00108752
INFO:root:[79,   600] training loss: 0.00769256
INFO:root:[79,   650] training loss: 0.00103778
INFO:root:[79,   700] training loss: 0.00060431
INFO:root:[79,   750] training loss: 0.00060180
INFO:root:[79,   800] training loss: 0.00032212
INFO:root:[79,   850] training loss: 0.00024024
INFO:root:[79,   900] training loss: 0.02539553
INFO:root:[79,   950] training loss: 0.00672145
INFO:root:[79,  1000] training loss: 0.00006215
INFO:root:[79,  1050] training loss: 0.00004442
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
   Telophase     0.3127    0.4409    0.3659      1032
          G2     0.1186    0.8750    0.2090         8
    Anaphase     0.0707    0.8082    0.1301        73
    Prophase     0.2042    0.2998    0.2429      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2154      3872
   macro avg     0.3009    0.5368    0.2885      3872
weighted avg     0.1404    0.2154    0.1660      3872

INFO:root:Accuracy of the network on the 3872 validation images: 21 %
INFO:root:epoch79
INFO:root:[80,    50] training loss: 0.02010936
INFO:root:[80,   100] training loss: 0.01378880
INFO:root:[80,   150] training loss: 0.01476328
INFO:root:[80,   200] training loss: 0.01452292
INFO:root:[80,   250] training loss: 0.01386106
INFO:root:[80,   300] training loss: 0.01401560
INFO:root:[80,   350] training loss: 0.01450576
INFO:root:[80,   400] training loss: 0.00018666
INFO:root:[80,   450] training loss: 0.00009132
INFO:root:[80,   500] training loss: 0.00220809
INFO:root:[80,   550] training loss: 0.00119191
INFO:root:[80,   600] training loss: 0.00839513
INFO:root:[80,   650] training loss: 0.00097217
INFO:root:[80,   700] training loss: 0.00054343
INFO:root:[80,   750] training loss: 0.00058985
INFO:root:[80,   800] training loss: 0.00038960
INFO:root:[80,   850] training loss: 0.00028376
INFO:root:[80,   900] training loss: 0.02529475
INFO:root:[80,   950] training loss: 0.00767556
INFO:root:[80,  1000] training loss: 0.00005252
INFO:root:[80,  1050] training loss: 0.00003699
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     1.0000    0.0006    0.0012      1720
   Telophase     0.2904    0.3324    0.3100      1032
          G2     0.0606    0.7500    0.1121         8
    Anaphase     0.0787    0.9178    0.1450        73
    Prophase     0.2168    0.3636    0.2717      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.2061      3872
   macro avg     0.4733    0.6235    0.3771      3872
weighted avg     0.5823    0.2061    0.1598      3872

INFO:root:Accuracy of the network on the 3872 validation images: 20 %
INFO:root:epoch80
INFO:root:[81,    50] training loss: 0.01906602
INFO:root:[81,   100] training loss: 0.01347226
INFO:root:[81,   150] training loss: 0.01402976
INFO:root:[81,   200] training loss: 0.01737013
INFO:root:[81,   250] training loss: 0.01519400
INFO:root:[81,   300] training loss: 0.01486532
INFO:root:[81,   350] training loss: 0.01343889
INFO:root:[81,   400] training loss: 0.00015855
INFO:root:[81,   450] training loss: 0.00007341
INFO:root:[81,   500] training loss: 0.00194032
INFO:root:[81,   550] training loss: 0.00093726
INFO:root:[81,   600] training loss: 0.00729246
INFO:root:[81,   650] training loss: 0.00093991
INFO:root:[81,   700] training loss: 0.00056765
INFO:root:[81,   750] training loss: 0.00060787
INFO:root:[81,   800] training loss: 0.00038040
INFO:root:[81,   850] training loss: 0.00022670
INFO:root:[81,   900] training loss: 0.02370883
INFO:root:[81,   950] training loss: 0.00588633
INFO:root:[81,  1000] training loss: 0.00008157
INFO:root:[81,  1050] training loss: 0.00004866
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     1.0000    0.0128    0.0253      1720
   Telophase     0.2457    0.3721    0.2960      1032
          G2     0.0696    1.0000    0.1301         8
    Anaphase     0.0735    0.8493    0.1352        73
    Prophase     0.1573    0.2012    0.1766      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.1779      3872
   macro avg     0.4590    0.6336    0.3662      3872
weighted avg     0.5544    0.1779    0.1413      3872

INFO:root:Accuracy of the network on the 3872 validation images: 17 %
INFO:root:epoch81
INFO:root:[82,    50] training loss: 0.01791723
INFO:root:[82,   100] training loss: 0.01464719
INFO:root:[82,   150] training loss: 0.01450861
INFO:root:[82,   200] training loss: 0.01507964
INFO:root:[82,   250] training loss: 0.01449526
INFO:root:[82,   300] training loss: 0.01457251
INFO:root:[82,   350] training loss: 0.01291584
INFO:root:[82,   400] training loss: 0.00013810
INFO:root:[82,   450] training loss: 0.00006385
INFO:root:[82,   500] training loss: 0.00141101
INFO:root:[82,   550] training loss: 0.00075542
INFO:root:[82,   600] training loss: 0.00693407
INFO:root:[82,   650] training loss: 0.00089703
INFO:root:[82,   700] training loss: 0.00054800
INFO:root:[82,   750] training loss: 0.00065354
INFO:root:[82,   800] training loss: 0.00039188
INFO:root:[82,   850] training loss: 0.00027245
INFO:root:[82,   900] training loss: 0.02416103
INFO:root:[82,   950] training loss: 0.00504658
INFO:root:[82,  1000] training loss: 0.00007847
INFO:root:[82,  1050] training loss: 0.00007362
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9667    0.0337    0.0652      1720
   Telophase     0.2558    0.3731    0.3035      1032
          G2     0.0854    0.8750    0.1556         8
    Anaphase     0.0707    0.9041    0.1312        73
    Prophase     0.1423    0.1770    0.1578      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.1818      3872
   macro avg     0.4554    0.6233    0.3733      3872
weighted avg     0.5382    0.1818    0.1560      3872

INFO:root:Accuracy of the network on the 3872 validation images: 18 %
INFO:root:epoch82
INFO:root:[83,    50] training loss: 0.01752563
INFO:root:[83,   100] training loss: 0.01345276
INFO:root:[83,   150] training loss: 0.01700617
INFO:root:[83,   200] training loss: 0.01455615
INFO:root:[83,   250] training loss: 0.01751889
INFO:root:[83,   300] training loss: 0.01580434
INFO:root:[83,   350] training loss: 0.01286582
INFO:root:[83,   400] training loss: 0.00034314
INFO:root:[83,   450] training loss: 0.00007916
INFO:root:[83,   500] training loss: 0.00162924
INFO:root:[83,   550] training loss: 0.00086144
INFO:root:[83,   600] training loss: 0.00629742
INFO:root:[83,   650] training loss: 0.00089382
INFO:root:[83,   700] training loss: 0.00055407
INFO:root:[83,   750] training loss: 0.00067561
INFO:root:[83,   800] training loss: 0.00034170
INFO:root:[83,   850] training loss: 0.00024230
INFO:root:[83,   900] training loss: 0.02358748
INFO:root:[83,   950] training loss: 0.00475684
INFO:root:[83,  1000] training loss: 0.00007722
INFO:root:[83,  1050] training loss: 0.00004151
INFO:root:              precision    recall  f1-score   support

          G1     0.2857    1.0000    0.4444         2
           S     0.9638    0.2320    0.3739      1720
   Telophase     0.3097    0.4535    0.3681      1032
          G2     0.0933    0.8750    0.1687         8
    Anaphase     0.0744    0.7945    0.1360        73
    Prophase     0.1900    0.1992    0.1945      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.2947      3872
   macro avg     0.4167    0.5554    0.3122      3872
weighted avg     0.5639    0.2947    0.3197      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch83
INFO:root:[84,    50] training loss: 0.01760054
INFO:root:[84,   100] training loss: 0.01411600
INFO:root:[84,   150] training loss: 0.01472772
INFO:root:[84,   200] training loss: 0.01355234
INFO:root:[84,   250] training loss: 0.01443449
INFO:root:[84,   300] training loss: 0.01436966
INFO:root:[84,   350] training loss: 0.01195976
INFO:root:[84,   400] training loss: 0.00028326
INFO:root:[84,   450] training loss: 0.00006290
INFO:root:[84,   500] training loss: 0.00133055
INFO:root:[84,   550] training loss: 0.00059378
INFO:root:[84,   600] training loss: 0.00551869
INFO:root:[84,   650] training loss: 0.00081564
INFO:root:[84,   700] training loss: 0.00047868
INFO:root:[84,   750] training loss: 0.00067922
INFO:root:[84,   800] training loss: 0.00035727
INFO:root:[84,   850] training loss: 0.00025885
INFO:root:[84,   900] training loss: 0.02229833
INFO:root:[84,   950] training loss: 0.00526590
INFO:root:[84,  1000] training loss: 0.00006898
INFO:root:[84,  1050] training loss: 0.00005102
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9173    0.4000    0.5571      1720
   Telophase     0.4194    0.5271    0.4672      1032
          G2     0.0737    0.8750    0.1359         8
    Anaphase     0.0783    0.7123    0.1411        73
    Prophase     0.2540    0.2602    0.2570      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.4042      3872
   macro avg     0.4513    0.6821    0.4594      3872
weighted avg     0.5897    0.4042    0.4446      3872

INFO:root:Accuracy of the network on the 3872 validation images: 40 %
INFO:root:epoch84
INFO:root:[85,    50] training loss: 0.01585324
INFO:root:[85,   100] training loss: 0.01380905
INFO:root:[85,   150] training loss: 0.01536095
INFO:root:[85,   200] training loss: 0.01438056
INFO:root:[85,   250] training loss: 0.01550234
INFO:root:[85,   300] training loss: 0.01371890
INFO:root:[85,   350] training loss: 0.01267955
INFO:root:[85,   400] training loss: 0.00011593
INFO:root:[85,   450] training loss: 0.00005561
INFO:root:[85,   500] training loss: 0.00126112
INFO:root:[85,   550] training loss: 0.00052759
INFO:root:[85,   600] training loss: 0.00536500
INFO:root:[85,   650] training loss: 0.00072497
INFO:root:[85,   700] training loss: 0.00050176
INFO:root:[85,   750] training loss: 0.00064165
INFO:root:[85,   800] training loss: 0.00034924
INFO:root:[85,   850] training loss: 0.00024454
INFO:root:[85,   900] training loss: 0.02371496
INFO:root:[85,   950] training loss: 0.00497728
INFO:root:[85,  1000] training loss: 0.00004496
INFO:root:[85,  1050] training loss: 0.00003775
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.8987    0.3302    0.4830      1720
   Telophase     0.4982    0.5271    0.5122      1032
          G2     0.1207    0.8750    0.2121         8
    Anaphase     0.0699    0.6164    0.1255        73
    Prophase     0.3097    0.4304    0.3602      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.4168      3872
   macro avg     0.4353    0.6827    0.4459      3872
weighted avg     0.6171    0.4168    0.4510      3872

INFO:root:Accuracy of the network on the 3872 validation images: 41 %
INFO:root:epoch85
INFO:root:[86,    50] training loss: 0.01558475
INFO:root:[86,   100] training loss: 0.01285031
INFO:root:[86,   150] training loss: 0.01361004
INFO:root:[86,   200] training loss: 0.01304014
INFO:root:[86,   250] training loss: 0.01429252
INFO:root:[86,   300] training loss: 0.01520556
INFO:root:[86,   350] training loss: 0.01208430
INFO:root:[86,   400] training loss: 0.00016307
INFO:root:[86,   450] training loss: 0.00005292
INFO:root:[86,   500] training loss: 0.00098949
INFO:root:[86,   550] training loss: 0.00058366
INFO:root:[86,   600] training loss: 0.00465312
INFO:root:[86,   650] training loss: 0.00075646
INFO:root:[86,   700] training loss: 0.00047793
INFO:root:[86,   750] training loss: 0.00069941
INFO:root:[86,   800] training loss: 0.00034034
INFO:root:[86,   850] training loss: 0.00022928
INFO:root:[86,   900] training loss: 0.02333210
INFO:root:[86,   950] training loss: 0.00418426
INFO:root:[86,  1000] training loss: 0.00004903
INFO:root:[86,  1050] training loss: 0.00002723
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.8526    0.6122    0.7127      1720
   Telophase     0.5621    0.6318    0.5949      1032
          G2     0.1707    0.8750    0.2857         8
    Anaphase     0.1200    0.7808    0.2080        73
    Prophase     0.3960    0.3646    0.3797      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.5555      3872
   macro avg     0.4645    0.7521    0.5157      3872
weighted avg     0.6377    0.5555    0.5820      3872

INFO:root:Accuracy of the network on the 3872 validation images: 55 %
INFO:root:epoch86
INFO:root:[87,    50] training loss: 0.01450489
INFO:root:[87,   100] training loss: 0.01357810
INFO:root:[87,   150] training loss: 0.01461498
INFO:root:[87,   200] training loss: 0.01314475
INFO:root:[87,   250] training loss: 0.01330214
INFO:root:[87,   300] training loss: 0.01391377
INFO:root:[87,   350] training loss: 0.01098376
INFO:root:[87,   400] training loss: 0.00013463
INFO:root:[87,   450] training loss: 0.00005148
INFO:root:[87,   500] training loss: 0.00107264
INFO:root:[87,   550] training loss: 0.00056582
INFO:root:[87,   600] training loss: 0.00424596
INFO:root:[87,   650] training loss: 0.00071326
INFO:root:[87,   700] training loss: 0.00043287
INFO:root:[87,   750] training loss: 0.00062460
INFO:root:[87,   800] training loss: 0.00035740
INFO:root:[87,   850] training loss: 0.00021921
INFO:root:[87,   900] training loss: 0.02137201
INFO:root:[87,   950] training loss: 0.00388923
INFO:root:[87,  1000] training loss: 0.00004847
INFO:root:[87,  1050] training loss: 0.00002767
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8869    0.5744    0.6972      1720
   Telophase     0.4765    0.5504    0.5108      1032
          G2     0.1373    0.8750    0.2373         8
    Anaphase     0.0981    0.8493    0.1759        73
    Prophase     0.3390    0.2872    0.3110      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.4977      3872
   macro avg     0.4911    0.7338    0.5141      3872
weighted avg     0.6147    0.4977    0.5338      3872

INFO:root:Accuracy of the network on the 3872 validation images: 49 %
INFO:root:epoch87
INFO:root:[88,    50] training loss: 0.01420040
INFO:root:[88,   100] training loss: 0.01465949
INFO:root:[88,   150] training loss: 0.01424399
INFO:root:[88,   200] training loss: 0.01336170
INFO:root:[88,   250] training loss: 0.01330561
INFO:root:[88,   300] training loss: 0.01321157
INFO:root:[88,   350] training loss: 0.01129307
INFO:root:[88,   400] training loss: 0.00006823
INFO:root:[88,   450] training loss: 0.00004562
INFO:root:[88,   500] training loss: 0.00091025
INFO:root:[88,   550] training loss: 0.00056035
INFO:root:[88,   600] training loss: 0.00389965
INFO:root:[88,   650] training loss: 0.00076273
INFO:root:[88,   700] training loss: 0.00041073
INFO:root:[88,   750] training loss: 0.00069914
INFO:root:[88,   800] training loss: 0.00031703
INFO:root:[88,   850] training loss: 0.00020702
INFO:root:[88,   900] training loss: 0.02160500
INFO:root:[88,   950] training loss: 0.00427757
INFO:root:[88,  1000] training loss: 0.00006375
INFO:root:[88,  1050] training loss: 0.00003887
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9004    0.6203    0.7346      1720
   Telophase     0.5262    0.6512    0.5821      1032
          G2     0.1296    0.8750    0.2258         8
    Anaphase     0.1070    0.7123    0.1860        73
    Prophase     0.3611    0.3017    0.3288      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.5462      3872
   macro avg     0.5273    0.7372    0.5510      3872
weighted avg     0.6401    0.5462    0.5744      3872

INFO:root:Accuracy of the network on the 3872 validation images: 54 %
INFO:root:epoch88
INFO:root:[89,    50] training loss: 0.01362814
INFO:root:[89,   100] training loss: 0.01325117
INFO:root:[89,   150] training loss: 0.01422650
INFO:root:[89,   200] training loss: 0.01533731
INFO:root:[89,   250] training loss: 0.01357441
INFO:root:[89,   300] training loss: 0.01358209
INFO:root:[89,   350] training loss: 0.01273124
INFO:root:[89,   400] training loss: 0.00011749
INFO:root:[89,   450] training loss: 0.00005013
INFO:root:[89,   500] training loss: 0.00070923
INFO:root:[89,   550] training loss: 0.00064667
INFO:root:[89,   600] training loss: 0.00408709
INFO:root:[89,   650] training loss: 0.00073783
INFO:root:[89,   700] training loss: 0.00045285
INFO:root:[89,   750] training loss: 0.00062047
INFO:root:[89,   800] training loss: 0.00033373
INFO:root:[89,   850] training loss: 0.00022087
INFO:root:[89,   900] training loss: 0.02079178
INFO:root:[89,   950] training loss: 0.00378687
INFO:root:[89,  1000] training loss: 0.00006551
INFO:root:[89,  1050] training loss: 0.00003128
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8524    0.7756    0.8122      1720
   Telophase     0.6000    0.6453    0.6218      1032
          G2     0.1489    0.8750    0.2545         8
    Anaphase     0.1195    0.7123    0.2047        73
    Prophase     0.5120    0.3511    0.4165      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6268      3872
   macro avg     0.5571    0.7656    0.5871      3872
weighted avg     0.6790    0.6268    0.6433      3872

INFO:root:Accuracy of the network on the 3872 validation images: 62 %
INFO:root:epoch89
INFO:root:[90,    50] training loss: 0.01506371
INFO:root:[90,   100] training loss: 0.01384097
INFO:root:[90,   150] training loss: 0.01388152
INFO:root:[90,   200] training loss: 0.01465578
INFO:root:[90,   250] training loss: 0.01278317
INFO:root:[90,   300] training loss: 0.01341664
INFO:root:[90,   350] training loss: 0.01615277
INFO:root:[90,   400] training loss: 0.00010269
INFO:root:[90,   450] training loss: 0.00011562
INFO:root:[90,   500] training loss: 0.00103690
INFO:root:[90,   550] training loss: 0.00061957
INFO:root:[90,   600] training loss: 0.00385390
INFO:root:[90,   650] training loss: 0.00074440
INFO:root:[90,   700] training loss: 0.00043709
INFO:root:[90,   750] training loss: 0.00069059
INFO:root:[90,   800] training loss: 0.00034255
INFO:root:[90,   850] training loss: 0.00023104
INFO:root:[90,   900] training loss: 0.02264513
INFO:root:[90,   950] training loss: 0.00447556
INFO:root:[90,  1000] training loss: 0.00004181
INFO:root:[90,  1050] training loss: 0.00002441
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.8849    0.6837    0.7714      1720
   Telophase     0.6328    0.6279    0.6304      1032
          G2     0.1373    0.8750    0.2373         8
    Anaphase     0.1119    0.6301    0.1901        73
    Prophase     0.4719    0.4797    0.4758      1034
   Metaphase     1.0000    0.3333    0.5000         3

    accuracy                         0.6136      3872
   macro avg     0.5198    0.6614    0.4823      3872
weighted avg     0.6911    0.6136    0.6425      3872

INFO:root:Accuracy of the network on the 3872 validation images: 61 %
INFO:root:epoch90
INFO:root:[91,    50] training loss: 0.01468424
INFO:root:[91,   100] training loss: 0.01292459
INFO:root:[91,   150] training loss: 0.01532979
INFO:root:[91,   200] training loss: 0.01338512
INFO:root:[91,   250] training loss: 0.01365900
INFO:root:[91,   300] training loss: 0.01344678
INFO:root:[91,   350] training loss: 0.01155502
INFO:root:[91,   400] training loss: 0.00005688
INFO:root:[91,   450] training loss: 0.00008821
INFO:root:[91,   500] training loss: 0.00049648
INFO:root:[91,   550] training loss: 0.00050448
INFO:root:[91,   600] training loss: 0.00366372
INFO:root:[91,   650] training loss: 0.00061508
INFO:root:[91,   700] training loss: 0.00038884
INFO:root:[91,   750] training loss: 0.00078232
INFO:root:[91,   800] training loss: 0.00028968
INFO:root:[91,   850] training loss: 0.00019055
INFO:root:[91,   900] training loss: 0.02015638
INFO:root:[91,   950] training loss: 0.00411434
INFO:root:[91,  1000] training loss: 0.00006843
INFO:root:[91,  1050] training loss: 0.00002584
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8796    0.7645    0.8180      1720
   Telophase     0.6305    0.7093    0.6676      1032
          G2     0.1522    0.8750    0.2593         8
    Anaphase     0.1337    0.6027    0.2189        73
    Prophase     0.5288    0.4265    0.4722      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6570      3872
   macro avg     0.5464    0.7683    0.5861      3872
weighted avg     0.7039    0.6570    0.6732      3872

INFO:root:Accuracy of the network on the 3872 validation images: 65 %
INFO:root:epoch91
INFO:root:[92,    50] training loss: 0.01319254
INFO:root:[92,   100] training loss: 0.01675415
INFO:root:[92,   150] training loss: 0.01357633
INFO:root:[92,   200] training loss: 0.01353810
INFO:root:[92,   250] training loss: 0.01278981
INFO:root:[92,   300] training loss: 0.01365570
INFO:root:[92,   350] training loss: 0.01141226
INFO:root:[92,   400] training loss: 0.00006047
INFO:root:[92,   450] training loss: 0.00004869
INFO:root:[92,   500] training loss: 0.00052778
INFO:root:[92,   550] training loss: 0.00047593
INFO:root:[92,   600] training loss: 0.00328591
INFO:root:[92,   650] training loss: 0.00065204
INFO:root:[92,   700] training loss: 0.00037939
INFO:root:[92,   750] training loss: 0.00068443
INFO:root:[92,   800] training loss: 0.00032673
INFO:root:[92,   850] training loss: 0.00021312
INFO:root:[92,   900] training loss: 0.01916839
INFO:root:[92,   950] training loss: 0.00348408
INFO:root:[92,  1000] training loss: 0.00005480
INFO:root:[92,  1050] training loss: 0.00003618
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8874    0.7884    0.8350      1720
   Telophase     0.6260    0.6812    0.6524      1032
          G2     0.1228    0.8750    0.2154         8
    Anaphase     0.1149    0.6438    0.1950        73
    Prophase     0.5588    0.4043    0.4691      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6550      3872
   macro avg     0.5443    0.7704    0.5762      3872
weighted avg     0.7137    0.6550    0.6753      3872

INFO:root:Accuracy of the network on the 3872 validation images: 65 %
INFO:root:epoch92
INFO:root:[93,    50] training loss: 0.01359837
INFO:root:[93,   100] training loss: 0.01289761
INFO:root:[93,   150] training loss: 0.01375164
INFO:root:[93,   200] training loss: 0.01244457
INFO:root:[93,   250] training loss: 0.01295200
INFO:root:[93,   300] training loss: 0.01278658
INFO:root:[93,   350] training loss: 0.01103090
INFO:root:[93,   400] training loss: 0.00007574
INFO:root:[93,   450] training loss: 0.00010398
INFO:root:[93,   500] training loss: 0.00068622
INFO:root:[93,   550] training loss: 0.00048294
INFO:root:[93,   600] training loss: 0.00280692
INFO:root:[93,   650] training loss: 0.00056366
INFO:root:[93,   700] training loss: 0.00033299
INFO:root:[93,   750] training loss: 0.00076523
INFO:root:[93,   800] training loss: 0.00027687
INFO:root:[93,   850] training loss: 0.00017572
INFO:root:[93,   900] training loss: 0.01909676
INFO:root:[93,   950] training loss: 0.00415038
INFO:root:[93,  1000] training loss: 0.00005781
INFO:root:[93,  1050] training loss: 0.00003647
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.8109    0.8424    0.8263      1720
   Telophase     0.6186    0.5659    0.5911      1032
          G2     0.2000    1.0000    0.3333         8
    Anaphase     0.1130    0.7397    0.1960        73
    Prophase     0.5480    0.3259    0.4087      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6294      3872
   macro avg     0.5272    0.7820    0.5610      3872
weighted avg     0.6749    0.6294    0.6392      3872

INFO:root:Accuracy of the network on the 3872 validation images: 62 %
INFO:root:epoch93
INFO:root:[94,    50] training loss: 0.01335046
INFO:root:[94,   100] training loss: 0.01338692
INFO:root:[94,   150] training loss: 0.01318496
INFO:root:[94,   200] training loss: 0.01398796
INFO:root:[94,   250] training loss: 0.01337257
INFO:root:[94,   300] training loss: 0.01415176
INFO:root:[94,   350] training loss: 0.01193448
INFO:root:[94,   400] training loss: 0.00010076
INFO:root:[94,   450] training loss: 0.00004934
INFO:root:[94,   500] training loss: 0.00075532
INFO:root:[94,   550] training loss: 0.00042441
INFO:root:[94,   600] training loss: 0.00292640
INFO:root:[94,   650] training loss: 0.00057180
INFO:root:[94,   700] training loss: 0.00036759
INFO:root:[94,   750] training loss: 0.00068297
INFO:root:[94,   800] training loss: 0.00029277
INFO:root:[94,   850] training loss: 0.00020002
INFO:root:[94,   900] training loss: 0.02044864
INFO:root:[94,   950] training loss: 0.00434079
INFO:root:[94,  1000] training loss: 0.00004441
INFO:root:[94,  1050] training loss: 0.00002587
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.8524    0.7587    0.8028      1720
   Telophase     0.6271    0.4971    0.5546      1032
          G2     0.0824    0.8750    0.1505         8
    Anaphase     0.0829    0.6438    0.1469        73
    Prophase     0.5098    0.4255    0.4639      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.5984      3872
   macro avg     0.5078    0.7429    0.5272      3872
weighted avg     0.6847    0.5984    0.6325      3872

INFO:root:Accuracy of the network on the 3872 validation images: 59 %
INFO:root:epoch94
INFO:root:[95,    50] training loss: 0.01475860
INFO:root:[95,   100] training loss: 0.01620943
INFO:root:[95,   150] training loss: 0.01310092
INFO:root:[95,   200] training loss: 0.01301468
INFO:root:[95,   250] training loss: 0.01459500
INFO:root:[95,   300] training loss: 0.01311079
INFO:root:[95,   350] training loss: 0.01045798
INFO:root:[95,   400] training loss: 0.00008095
INFO:root:[95,   450] training loss: 0.00004790
INFO:root:[95,   500] training loss: 0.00063862
INFO:root:[95,   550] training loss: 0.00050981
INFO:root:[95,   600] training loss: 0.00265994
INFO:root:[95,   650] training loss: 0.00052947
INFO:root:[95,   700] training loss: 0.00035468
INFO:root:[95,   750] training loss: 0.00070855
INFO:root:[95,   800] training loss: 0.00031950
INFO:root:[95,   850] training loss: 0.00018383
INFO:root:[95,   900] training loss: 0.01904735
INFO:root:[95,   950] training loss: 0.00397941
INFO:root:[95,  1000] training loss: 0.00005544
INFO:root:[95,  1050] training loss: 0.00003542
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8669    0.7651    0.8128      1720
   Telophase     0.6646    0.6163    0.6395      1032
          G2     0.2258    0.8750    0.3590         8
    Anaphase     0.1281    0.7671    0.2196        73
    Prophase     0.5395    0.4816    0.5089      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6503      3872
   macro avg     0.5845    0.7864    0.6200      3872
weighted avg     0.7103    0.6503    0.6735      3872

INFO:root:Accuracy of the network on the 3872 validation images: 65 %
INFO:root:epoch95
INFO:root:[96,    50] training loss: 0.01321350
INFO:root:[96,   100] training loss: 0.01365684
INFO:root:[96,   150] training loss: 0.01316411
INFO:root:[96,   200] training loss: 0.01292363
INFO:root:[96,   250] training loss: 0.01405558
INFO:root:[96,   300] training loss: 0.01372460
INFO:root:[96,   350] training loss: 0.01200614
INFO:root:[96,   400] training loss: 0.00006937
INFO:root:[96,   450] training loss: 0.00003933
INFO:root:[96,   500] training loss: 0.00050247
INFO:root:[96,   550] training loss: 0.00031326
INFO:root:[96,   600] training loss: 0.00237418
INFO:root:[96,   650] training loss: 0.00045196
INFO:root:[96,   700] training loss: 0.00030574
INFO:root:[96,   750] training loss: 0.00069283
INFO:root:[96,   800] training loss: 0.00030775
INFO:root:[96,   850] training loss: 0.00016214
INFO:root:[96,   900] training loss: 0.01842753
INFO:root:[96,   950] training loss: 0.00370372
INFO:root:[96,  1000] training loss: 0.00006769
INFO:root:[96,  1050] training loss: 0.00003661
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8256    0.8640    0.8443      1720
   Telophase     0.7308    0.6444    0.6849      1032
          G2     0.2188    0.8750    0.3500         8
    Anaphase     0.1339    0.6164    0.2200        73
    Prophase     0.6223    0.4749    0.5387      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6968      3872
   macro avg     0.5759    0.7107    0.5911      3872
weighted avg     0.7317    0.6968    0.7073      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch96
INFO:root:[97,    50] training loss: 0.01347015
INFO:root:[97,   100] training loss: 0.01511236
INFO:root:[97,   150] training loss: 0.01795797
INFO:root:[97,   200] training loss: 0.01406229
INFO:root:[97,   250] training loss: 0.01302162
INFO:root:[97,   300] training loss: 0.01428792
INFO:root:[97,   350] training loss: 0.01067798
INFO:root:[97,   400] training loss: 0.00008306
INFO:root:[97,   450] training loss: 0.00028663
INFO:root:[97,   500] training loss: 0.00053320
INFO:root:[97,   550] training loss: 0.00046666
INFO:root:[97,   600] training loss: 0.00220340
INFO:root:[97,   650] training loss: 0.00052185
INFO:root:[97,   700] training loss: 0.00033103
INFO:root:[97,   750] training loss: 0.00074467
INFO:root:[97,   800] training loss: 0.00032010
INFO:root:[97,   850] training loss: 0.00019108
INFO:root:[97,   900] training loss: 0.02143202
INFO:root:[97,   950] training loss: 0.00344092
INFO:root:[97,  1000] training loss: 0.00003527
INFO:root:[97,  1050] training loss: 0.00003063
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8720    0.7919    0.8300      1720
   Telophase     0.6772    0.6628    0.6699      1032
          G2     0.1892    0.8750    0.3111         8
    Anaphase     0.1351    0.6438    0.2233        73
    Prophase     0.5622    0.4942    0.5260      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.6756      3872
   macro avg     0.5860    0.7811    0.6229      3872
weighted avg     0.7220    0.6756    0.6938      3872

INFO:root:Accuracy of the network on the 3872 validation images: 67 %
INFO:root:epoch97
INFO:root:[98,    50] training loss: 0.01289543
INFO:root:[98,   100] training loss: 0.01293657
INFO:root:[98,   150] training loss: 0.01255666
INFO:root:[98,   200] training loss: 0.01348556
INFO:root:[98,   250] training loss: 0.01232617
INFO:root:[98,   300] training loss: 0.01394215
INFO:root:[98,   350] training loss: 0.01091533
INFO:root:[98,   400] training loss: 0.00008867
INFO:root:[98,   450] training loss: 0.00003116
INFO:root:[98,   500] training loss: 0.00044809
INFO:root:[98,   550] training loss: 0.00034493
INFO:root:[98,   600] training loss: 0.00247311
INFO:root:[98,   650] training loss: 0.00050100
INFO:root:[98,   700] training loss: 0.00031221
INFO:root:[98,   750] training loss: 0.00075012
INFO:root:[98,   800] training loss: 0.00029796
INFO:root:[98,   850] training loss: 0.00018322
INFO:root:[98,   900] training loss: 0.01872003
INFO:root:[98,   950] training loss: 0.00434940
INFO:root:[98,  1000] training loss: 0.00004952
INFO:root:[98,  1050] training loss: 0.00002564
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
           S     0.8137    0.9215    0.8642      1720
   Telophase     0.7271    0.7616    0.7440      1032
          G2     0.2308    0.7500    0.3529         8
    Anaphase     0.1912    0.5342    0.2816        73
    Prophase     0.6810    0.3985    0.5027      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7317      3872
   macro avg     0.5777    0.7665    0.6167      3872
weighted avg     0.7422    0.7317    0.7236      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch98
INFO:root:[99,    50] training loss: 0.01284469
INFO:root:[99,   100] training loss: 0.01268215
INFO:root:[99,   150] training loss: 0.01443210
INFO:root:[99,   200] training loss: 0.01586153
INFO:root:[99,   250] training loss: 0.01375298
INFO:root:[99,   300] training loss: 0.01423172
INFO:root:[99,   350] training loss: 0.01140278
INFO:root:[99,   400] training loss: 0.00007137
INFO:root:[99,   450] training loss: 0.00004388
INFO:root:[99,   500] training loss: 0.00036863
INFO:root:[99,   550] training loss: 0.00043190
INFO:root:[99,   600] training loss: 0.00246781
INFO:root:[99,   650] training loss: 0.00054933
INFO:root:[99,   700] training loss: 0.00038720
INFO:root:[99,   750] training loss: 0.00079456
INFO:root:[99,   800] training loss: 0.00030706
INFO:root:[99,   850] training loss: 0.00018469
INFO:root:[99,   900] training loss: 0.01813284
INFO:root:[99,   950] training loss: 0.00356224
INFO:root:[99,  1000] training loss: 0.00006128
INFO:root:[99,  1050] training loss: 0.00003782
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8181    0.8837    0.8496      1720
   Telophase     0.7243    0.6977    0.7108      1032
          G2     0.2258    0.8750    0.3590         8
    Anaphase     0.1861    0.6986    0.2939        73
    Prophase     0.6389    0.4381    0.5198      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7118      3872
   macro avg     0.6086    0.7990    0.6476      3872
weighted avg     0.7322    0.7118    0.7131      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch99
INFO:root:[100,    50] training loss: 0.01303787
INFO:root:[100,   100] training loss: 0.01277626
INFO:root:[100,   150] training loss: 0.01368239
INFO:root:[100,   200] training loss: 0.01311504
INFO:root:[100,   250] training loss: 0.01293718
INFO:root:[100,   300] training loss: 0.01330550
INFO:root:[100,   350] training loss: 0.01056950
INFO:root:[100,   400] training loss: 0.00004596
INFO:root:[100,   450] training loss: 0.00004503
INFO:root:[100,   500] training loss: 0.00045908
INFO:root:[100,   550] training loss: 0.00036702
INFO:root:[100,   600] training loss: 0.00225181
INFO:root:[100,   650] training loss: 0.00050513
INFO:root:[100,   700] training loss: 0.00033741
INFO:root:[100,   750] training loss: 0.00082845
INFO:root:[100,   800] training loss: 0.00029104
INFO:root:[100,   850] training loss: 0.00017162
INFO:root:[100,   900] training loss: 0.01771372
INFO:root:[100,   950] training loss: 0.00374102
INFO:root:[100,  1000] training loss: 0.00008918
INFO:root:[100,  1050] training loss: 0.00003262
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    1.0000    0.5000         2
           S     0.8418    0.8663    0.8539      1720
   Telophase     0.7489    0.6734    0.7092      1032
          G2     0.2069    0.7500    0.3243         8
    Anaphase     0.1352    0.5890    0.2199        73
    Prophase     0.6186    0.4894    0.5464      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7089      3872
   macro avg     0.5550    0.7669    0.5934      3872
weighted avg     0.7427    0.7089    0.7201      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch100
INFO:root:[101,    50] training loss: 0.01209960
INFO:root:[101,   100] training loss: 0.01186578
INFO:root:[101,   150] training loss: 0.01328265
INFO:root:[101,   200] training loss: 0.01305764
INFO:root:[101,   250] training loss: 0.01339894
INFO:root:[101,   300] training loss: 0.01404024
INFO:root:[101,   350] training loss: 0.01114763
INFO:root:[101,   400] training loss: 0.00006159
INFO:root:[101,   450] training loss: 0.00015146
INFO:root:[101,   500] training loss: 0.00045779
INFO:root:[101,   550] training loss: 0.00041102
INFO:root:[101,   600] training loss: 0.00234226
INFO:root:[101,   650] training loss: 0.00050483
INFO:root:[101,   700] training loss: 0.00031878
INFO:root:[101,   750] training loss: 0.00082904
INFO:root:[101,   800] training loss: 0.00032086
INFO:root:[101,   850] training loss: 0.00018736
INFO:root:[101,   900] training loss: 0.01689293
INFO:root:[101,   950] training loss: 0.00309255
INFO:root:[101,  1000] training loss: 0.00005002
INFO:root:[101,  1050] training loss: 0.00002810
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8397    0.8953    0.8666      1720
   Telophase     0.7371    0.7035    0.7199      1032
          G2     0.3000    0.7500    0.4286         8
    Anaphase     0.1690    0.6712    0.2700        73
    Prophase     0.6662    0.4749    0.5545      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7275      3872
   macro avg     0.6255    0.7850    0.6628      3872
weighted avg     0.7523    0.7275    0.7321      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch101
INFO:root:[102,    50] training loss: 0.01210040
INFO:root:[102,   100] training loss: 0.01343788
INFO:root:[102,   150] training loss: 0.01392287
INFO:root:[102,   200] training loss: 0.01459798
INFO:root:[102,   250] training loss: 0.01397922
INFO:root:[102,   300] training loss: 0.01425134
INFO:root:[102,   350] training loss: 0.01265876
INFO:root:[102,   400] training loss: 0.00006625
INFO:root:[102,   450] training loss: 0.00004668
INFO:root:[102,   500] training loss: 0.00045233
INFO:root:[102,   550] training loss: 0.00040640
INFO:root:[102,   600] training loss: 0.00225819
INFO:root:[102,   650] training loss: 0.00046417
INFO:root:[102,   700] training loss: 0.00029598
INFO:root:[102,   750] training loss: 0.00073633
INFO:root:[102,   800] training loss: 0.00036445
INFO:root:[102,   850] training loss: 0.00018768
INFO:root:[102,   900] training loss: 0.01685537
INFO:root:[102,   950] training loss: 0.00396923
INFO:root:[102,  1000] training loss: 0.00005718
INFO:root:[102,  1050] training loss: 0.00002608
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8291    0.8802    0.8539      1720
   Telophase     0.7167    0.7306    0.7236      1032
          G2     0.1458    0.8750    0.2500         8
    Anaphase     0.1660    0.5342    0.2532        73
    Prophase     0.6369    0.4342    0.5164      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.7146      3872
   macro avg     0.5706    0.7316    0.5805      3872
weighted avg     0.7339    0.7146    0.7163      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch102
INFO:root:[103,    50] training loss: 0.01254196
INFO:root:[103,   100] training loss: 0.01314376
INFO:root:[103,   150] training loss: 0.01250919
INFO:root:[103,   200] training loss: 0.01229081
INFO:root:[103,   250] training loss: 0.01194621
INFO:root:[103,   300] training loss: 0.01476326
INFO:root:[103,   350] training loss: 0.01110893
INFO:root:[103,   400] training loss: 0.00008095
INFO:root:[103,   450] training loss: 0.00004292
INFO:root:[103,   500] training loss: 0.00031195
INFO:root:[103,   550] training loss: 0.00028574
INFO:root:[103,   600] training loss: 0.00204655
INFO:root:[103,   650] training loss: 0.00040592
INFO:root:[103,   700] training loss: 0.00029967
INFO:root:[103,   750] training loss: 0.00077921
INFO:root:[103,   800] training loss: 0.00033941
INFO:root:[103,   850] training loss: 0.00017924
INFO:root:[103,   900] training loss: 0.01584003
INFO:root:[103,   950] training loss: 0.00366683
INFO:root:[103,  1000] training loss: 0.00005062
INFO:root:[103,  1050] training loss: 0.00002356
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8744    0.8826    0.8785      1720
   Telophase     0.7410    0.7539    0.7474      1032
          G2     0.1167    0.8750    0.2059         8
    Anaphase     0.1790    0.5616    0.2715        73
    Prophase     0.6903    0.5280    0.5984      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7477      3872
   macro avg     0.6097    0.8002    0.6431      3872
weighted avg     0.7750    0.7477    0.7559      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch103
INFO:root:[104,    50] training loss: 0.01528346
INFO:root:[104,   100] training loss: 0.01529317
INFO:root:[104,   150] training loss: 0.01229153
INFO:root:[104,   200] training loss: 0.01225404
INFO:root:[104,   250] training loss: 0.01226122
INFO:root:[104,   300] training loss: 0.01238476
INFO:root:[104,   350] training loss: 0.00992502
INFO:root:[104,   400] training loss: 0.00009292
INFO:root:[104,   450] training loss: 0.00003879
INFO:root:[104,   500] training loss: 0.00026863
INFO:root:[104,   550] training loss: 0.00040691
INFO:root:[104,   600] training loss: 0.00185292
INFO:root:[104,   650] training loss: 0.00039242
INFO:root:[104,   700] training loss: 0.00022706
INFO:root:[104,   750] training loss: 0.00085235
INFO:root:[104,   800] training loss: 0.00031678
INFO:root:[104,   850] training loss: 0.00017361
INFO:root:[104,   900] training loss: 0.01573723
INFO:root:[104,   950] training loss: 0.00297404
INFO:root:[104,  1000] training loss: 0.00004076
INFO:root:[104,  1050] training loss: 0.00002318
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8741    0.8599    0.8669      1720
   Telophase     0.7136    0.7703    0.7409      1032
          G2     0.2593    0.8750    0.4000         8
    Anaphase     0.1719    0.6027    0.2675        73
    Prophase     0.6538    0.4913    0.5610      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7330      3872
   macro avg     0.6199    0.7999    0.6623      3872
weighted avg     0.7580    0.7330    0.7395      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch104
INFO:root:[105,    50] training loss: 0.01216474
INFO:root:[105,   100] training loss: 0.01187416
INFO:root:[105,   150] training loss: 0.01380206
INFO:root:[105,   200] training loss: 0.01336920
INFO:root:[105,   250] training loss: 0.01261692
INFO:root:[105,   300] training loss: 0.01284627
INFO:root:[105,   350] training loss: 0.01123039
INFO:root:[105,   400] training loss: 0.00005919
INFO:root:[105,   450] training loss: 0.00004144
INFO:root:[105,   500] training loss: 0.00044085
INFO:root:[105,   550] training loss: 0.00032095
INFO:root:[105,   600] training loss: 0.00176707
INFO:root:[105,   650] training loss: 0.00032927
INFO:root:[105,   700] training loss: 0.00024845
INFO:root:[105,   750] training loss: 0.00078943
INFO:root:[105,   800] training loss: 0.00030993
INFO:root:[105,   850] training loss: 0.00015927
INFO:root:[105,   900] training loss: 0.01525830
INFO:root:[105,   950] training loss: 0.00426736
INFO:root:[105,  1000] training loss: 0.00005141
INFO:root:[105,  1050] training loss: 0.00002842
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8437    0.8471    0.8454      1720
   Telophase     0.7606    0.6802    0.7182      1032
          G2     0.2414    0.8750    0.3784         8
    Anaphase     0.1606    0.6027    0.2536        73
    Prophase     0.6349    0.5600    0.5951      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7216      3872
   macro avg     0.5916    0.7950    0.6367      3872
weighted avg     0.7516    0.7216    0.7325      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch105
INFO:root:[106,    50] training loss: 0.01273340
INFO:root:[106,   100] training loss: 0.01188546
INFO:root:[106,   150] training loss: 0.01286705
INFO:root:[106,   200] training loss: 0.01213048
INFO:root:[106,   250] training loss: 0.01168879
INFO:root:[106,   300] training loss: 0.01189516
INFO:root:[106,   350] training loss: 0.00969008
INFO:root:[106,   400] training loss: 0.00004133
INFO:root:[106,   450] training loss: 0.00003466
INFO:root:[106,   500] training loss: 0.00041784
INFO:root:[106,   550] training loss: 0.00023330
INFO:root:[106,   600] training loss: 0.00163417
INFO:root:[106,   650] training loss: 0.00035222
INFO:root:[106,   700] training loss: 0.00022840
INFO:root:[106,   750] training loss: 0.00078601
INFO:root:[106,   800] training loss: 0.00030771
INFO:root:[106,   850] training loss: 0.00016376
INFO:root:[106,   900] training loss: 0.01586426
INFO:root:[106,   950] training loss: 0.00336187
INFO:root:[106,  1000] training loss: 0.00004802
INFO:root:[106,  1050] training loss: 0.00002254
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8570    0.8988    0.8774      1720
   Telophase     0.7467    0.6628    0.7023      1032
          G2     0.1842    0.8750    0.3043         8
    Anaphase     0.1442    0.6301    0.2347        73
    Prophase     0.6781    0.5174    0.5869      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7288      3872
   macro avg     0.5515    0.7263    0.5804      3872
weighted avg     0.7647    0.7288    0.7396      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch106
INFO:root:[107,    50] training loss: 0.01250949
INFO:root:[107,   100] training loss: 0.01237541
INFO:root:[107,   150] training loss: 0.01190757
INFO:root:[107,   200] training loss: 0.01197344
INFO:root:[107,   250] training loss: 0.01148405
INFO:root:[107,   300] training loss: 0.01286699
INFO:root:[107,   350] training loss: 0.00966990
INFO:root:[107,   400] training loss: 0.00004736
INFO:root:[107,   450] training loss: 0.00003644
INFO:root:[107,   500] training loss: 0.00019726
INFO:root:[107,   550] training loss: 0.00033518
INFO:root:[107,   600] training loss: 0.00159033
INFO:root:[107,   650] training loss: 0.00032228
INFO:root:[107,   700] training loss: 0.00021649
INFO:root:[107,   750] training loss: 0.00075550
INFO:root:[107,   800] training loss: 0.00029946
INFO:root:[107,   850] training loss: 0.00015454
INFO:root:[107,   900] training loss: 0.01612945
INFO:root:[107,   950] training loss: 0.00326692
INFO:root:[107,  1000] training loss: 0.00004348
INFO:root:[107,  1050] training loss: 0.00002021
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8202    0.9227    0.8684      1720
   Telophase     0.7814    0.6754    0.7245      1032
          G2     0.1591    0.8750    0.2692         8
    Anaphase     0.1743    0.5753    0.2675        73
    Prophase     0.6724    0.4903    0.5671      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7345      3872
   macro avg     0.5510    0.7198    0.5791      3872
weighted avg     0.7566    0.7345    0.7368      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch107
INFO:root:[108,    50] training loss: 0.01245020
INFO:root:[108,   100] training loss: 0.01282332
INFO:root:[108,   150] training loss: 0.01389285
INFO:root:[108,   200] training loss: 0.01201304
INFO:root:[108,   250] training loss: 0.01157574
INFO:root:[108,   300] training loss: 0.01210886
INFO:root:[108,   350] training loss: 0.01120461
INFO:root:[108,   400] training loss: 0.00002413
INFO:root:[108,   450] training loss: 0.00003319
INFO:root:[108,   500] training loss: 0.00025831
INFO:root:[108,   550] training loss: 0.00034103
INFO:root:[108,   600] training loss: 0.00151322
INFO:root:[108,   650] training loss: 0.00035228
INFO:root:[108,   700] training loss: 0.00021636
INFO:root:[108,   750] training loss: 0.00072769
INFO:root:[108,   800] training loss: 0.00031417
INFO:root:[108,   850] training loss: 0.00013980
INFO:root:[108,   900] training loss: 0.01616779
INFO:root:[108,   950] training loss: 0.00333518
INFO:root:[108,  1000] training loss: 0.00003365
INFO:root:[108,  1050] training loss: 0.00002283
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8426    0.9151    0.8774      1720
   Telophase     0.7786    0.6783    0.7250      1032
          G2     0.2143    0.7500    0.3333         8
    Anaphase     0.1789    0.6027    0.2759        73
    Prophase     0.6776    0.5406    0.6014      1034
   Metaphase     1.0000    0.6667    0.8000         3

    accuracy                         0.7456      3872
   macro avg     0.5989    0.7362    0.6114      3872
weighted avg     0.7676    0.7456    0.7504      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch108
INFO:root:[109,    50] training loss: 0.01375141
INFO:root:[109,   100] training loss: 0.01268186
INFO:root:[109,   150] training loss: 0.01210765
INFO:root:[109,   200] training loss: 0.01170748
INFO:root:[109,   250] training loss: 0.01160439
INFO:root:[109,   300] training loss: 0.01316340
INFO:root:[109,   350] training loss: 0.01056286
INFO:root:[109,   400] training loss: 0.00005801
INFO:root:[109,   450] training loss: 0.00004675
INFO:root:[109,   500] training loss: 0.00034026
INFO:root:[109,   550] training loss: 0.00030509
INFO:root:[109,   600] training loss: 0.00161705
INFO:root:[109,   650] training loss: 0.00033216
INFO:root:[109,   700] training loss: 0.00019350
INFO:root:[109,   750] training loss: 0.00083824
INFO:root:[109,   800] training loss: 0.00029002
INFO:root:[109,   850] training loss: 0.00013694
INFO:root:[109,   900] training loss: 0.01606987
INFO:root:[109,   950] training loss: 0.00292819
INFO:root:[109,  1000] training loss: 0.00003176
INFO:root:[109,  1050] training loss: 0.00001858
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8192    0.9244    0.8686      1720
   Telophase     0.7641    0.6938    0.7273      1032
          G2     0.3125    0.6250    0.4167         8
    Anaphase     0.2042    0.6712    0.3131        73
    Prophase     0.6776    0.4797    0.5617      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7386      3872
   macro avg     0.5754    0.6992    0.6064      3872
weighted avg     0.7538    0.7386    0.7374      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch109
INFO:root:[110,    50] training loss: 0.01102834
INFO:root:[110,   100] training loss: 0.01207118
INFO:root:[110,   150] training loss: 0.01292320
INFO:root:[110,   200] training loss: 0.01411442
INFO:root:[110,   250] training loss: 0.01227353
INFO:root:[110,   300] training loss: 0.01347566
INFO:root:[110,   350] training loss: 0.01125115
INFO:root:[110,   400] training loss: 0.00010822
INFO:root:[110,   450] training loss: 0.00004288
INFO:root:[110,   500] training loss: 0.00024635
INFO:root:[110,   550] training loss: 0.00035681
INFO:root:[110,   600] training loss: 0.00157346
INFO:root:[110,   650] training loss: 0.00031430
INFO:root:[110,   700] training loss: 0.00019767
INFO:root:[110,   750] training loss: 0.00076303
INFO:root:[110,   800] training loss: 0.00029448
INFO:root:[110,   850] training loss: 0.00014374
INFO:root:[110,   900] training loss: 0.01433913
INFO:root:[110,   950] training loss: 0.00276537
INFO:root:[110,  1000] training loss: 0.00003183
INFO:root:[110,  1050] training loss: 0.00001934
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8474    0.9169    0.8808      1720
   Telophase     0.7460    0.7742    0.7599      1032
          G2     0.3182    0.8750    0.4667         8
    Anaphase     0.2516    0.5342    0.3421        73
    Prophase     0.6843    0.5010    0.5784      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7606      3872
   macro avg     0.6449    0.8002    0.6897      3872
weighted avg     0.7645    0.7606    0.7568      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch110
INFO:root:[111,    50] training loss: 0.01207183
INFO:root:[111,   100] training loss: 0.01246136
INFO:root:[111,   150] training loss: 0.01164044
INFO:root:[111,   200] training loss: 0.01185579
INFO:root:[111,   250] training loss: 0.01091559
INFO:root:[111,   300] training loss: 0.01420564
INFO:root:[111,   350] training loss: 0.01028636
INFO:root:[111,   400] training loss: 0.00002788
INFO:root:[111,   450] training loss: 0.00004700
INFO:root:[111,   500] training loss: 0.00007701
INFO:root:[111,   550] training loss: 0.00072946
INFO:root:[111,   600] training loss: 0.00284654
INFO:root:[111,   650] training loss: 0.00184342
INFO:root:[111,   700] training loss: 0.00117091
INFO:root:[111,   750] training loss: 0.00436290
INFO:root:[111,   800] training loss: 0.00279508
INFO:root:[111,   850] training loss: 0.00166655
INFO:root:[111,   900] training loss: 0.01170508
INFO:root:[111,   950] training loss: 0.00388900
INFO:root:[111,  1000] training loss: 0.00003248
INFO:root:[111,  1050] training loss: 0.00002589
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8991    0.8599    0.8790      1720
   Telophase     0.7435    0.8818    0.8067      1032
          G2     0.3333    0.7500    0.4615         8
    Anaphase     0.4359    0.4658    0.4503        73
    Prophase     0.6711    0.5841    0.6246      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7846      3872
   macro avg     0.6547    0.7917    0.6984      3872
weighted avg     0.7867    0.7846    0.7829      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch111
INFO:root:[112,    50] training loss: 0.01138397
INFO:root:[112,   100] training loss: 0.01169971
INFO:root:[112,   150] training loss: 0.01123094
INFO:root:[112,   200] training loss: 0.01079203
INFO:root:[112,   250] training loss: 0.01087494
INFO:root:[112,   300] training loss: 0.01241915
INFO:root:[112,   350] training loss: 0.00942518
INFO:root:[112,   400] training loss: 0.00002316
INFO:root:[112,   450] training loss: 0.00002893
INFO:root:[112,   500] training loss: 0.00008477
INFO:root:[112,   550] training loss: 0.00058256
INFO:root:[112,   600] training loss: 0.00120566
INFO:root:[112,   650] training loss: 0.00092860
INFO:root:[112,   700] training loss: 0.00074062
INFO:root:[112,   750] training loss: 0.00327213
INFO:root:[112,   800] training loss: 0.00247807
INFO:root:[112,   850] training loss: 0.00138743
INFO:root:[112,   900] training loss: 0.01246681
INFO:root:[112,   950] training loss: 0.00347729
INFO:root:[112,  1000] training loss: 0.00002476
INFO:root:[112,  1050] training loss: 0.00001876
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8908    0.8826    0.8867      1720
   Telophase     0.7759    0.8285    0.8013      1032
          G2     0.3125    0.6250    0.4167         8
    Anaphase     0.3417    0.5616    0.4249        73
    Prophase     0.6905    0.6170    0.6517      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7908      3872
   macro avg     0.6683    0.7878    0.7116      3872
weighted avg     0.7951    0.7908    0.7915      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch112
INFO:root:[113,    50] training loss: 0.01039077
INFO:root:[113,   100] training loss: 0.01171413
INFO:root:[113,   150] training loss: 0.01261967
INFO:root:[113,   200] training loss: 0.01146289
INFO:root:[113,   250] training loss: 0.01063802
INFO:root:[113,   300] training loss: 0.01157882
INFO:root:[113,   350] training loss: 0.00973175
INFO:root:[113,   400] training loss: 0.00002106
INFO:root:[113,   450] training loss: 0.00003136
INFO:root:[113,   500] training loss: 0.00007528
INFO:root:[113,   550] training loss: 0.00061866
INFO:root:[113,   600] training loss: 0.00090114
INFO:root:[113,   650] training loss: 0.00063527
INFO:root:[113,   700] training loss: 0.00058868
INFO:root:[113,   750] training loss: 0.00285837
INFO:root:[113,   800] training loss: 0.00198804
INFO:root:[113,   850] training loss: 0.00135559
INFO:root:[113,   900] training loss: 0.01260065
INFO:root:[113,   950] training loss: 0.00335179
INFO:root:[113,  1000] training loss: 0.00002076
INFO:root:[113,  1050] training loss: 0.00001891
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8892    0.8959    0.8926      1720
   Telophase     0.7961    0.7984    0.7973      1032
          G2     0.3684    0.8750    0.5185         8
    Anaphase     0.3281    0.5753    0.4179        73
    Prophase     0.6940    0.6383    0.6650      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7949      3872
   macro avg     0.6180    0.7547    0.6641      3872
weighted avg     0.8003    0.7949    0.7964      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch113
INFO:root:[114,    50] training loss: 0.01119363
INFO:root:[114,   100] training loss: 0.01011583
INFO:root:[114,   150] training loss: 0.01091897
INFO:root:[114,   200] training loss: 0.01223092
INFO:root:[114,   250] training loss: 0.01048294
INFO:root:[114,   300] training loss: 0.01120179
INFO:root:[114,   350] training loss: 0.00928626
INFO:root:[114,   400] training loss: 0.00002030
INFO:root:[114,   450] training loss: 0.00002526
INFO:root:[114,   500] training loss: 0.00008905
INFO:root:[114,   550] training loss: 0.00056045
INFO:root:[114,   600] training loss: 0.00075815
INFO:root:[114,   650] training loss: 0.00052279
INFO:root:[114,   700] training loss: 0.00049777
INFO:root:[114,   750] training loss: 0.00282367
INFO:root:[114,   800] training loss: 0.00175230
INFO:root:[114,   850] training loss: 0.00110833
INFO:root:[114,   900] training loss: 0.01186406
INFO:root:[114,   950] training loss: 0.00333624
INFO:root:[114,  1000] training loss: 0.00002004
INFO:root:[114,  1050] training loss: 0.00001959
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
           S     0.8876    0.9000    0.8938      1720
   Telophase     0.8002    0.7878    0.7939      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.3037    0.5616    0.3942        73
    Prophase     0.7002    0.6460    0.6720      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7957      3872
   macro avg     0.6524    0.8065    0.7029      3872
weighted avg     0.8021    0.7957    0.7977      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch114
INFO:root:[115,    50] training loss: 0.01047031
INFO:root:[115,   100] training loss: 0.01045261
INFO:root:[115,   150] training loss: 0.01131522
INFO:root:[115,   200] training loss: 0.01106545
INFO:root:[115,   250] training loss: 0.01059719
INFO:root:[115,   300] training loss: 0.01080212
INFO:root:[115,   350] training loss: 0.00931681
INFO:root:[115,   400] training loss: 0.00001941
INFO:root:[115,   450] training loss: 0.00002606
INFO:root:[115,   500] training loss: 0.00005955
INFO:root:[115,   550] training loss: 0.00056891
INFO:root:[115,   600] training loss: 0.00063368
INFO:root:[115,   650] training loss: 0.00043022
INFO:root:[115,   700] training loss: 0.00042274
INFO:root:[115,   750] training loss: 0.00263876
INFO:root:[115,   800] training loss: 0.00169351
INFO:root:[115,   850] training loss: 0.00105835
INFO:root:[115,   900] training loss: 0.01249073
INFO:root:[115,   950] training loss: 0.00353612
INFO:root:[115,  1000] training loss: 0.00002621
INFO:root:[115,  1050] training loss: 0.00002103
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8950    0.8924    0.8937      1720
   Telophase     0.7916    0.8023    0.7969      1032
          G2     0.3529    0.7500    0.4800         8
    Anaphase     0.3116    0.5890    0.4076        73
    Prophase     0.7021    0.6451    0.6724      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7965      3872
   macro avg     0.6743    0.8113    0.7215      3872
weighted avg     0.8038    0.7965    0.7988      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch115
INFO:root:[116,    50] training loss: 0.01073329
INFO:root:[116,   100] training loss: 0.01101258
INFO:root:[116,   150] training loss: 0.01136596
INFO:root:[116,   200] training loss: 0.00993486
INFO:root:[116,   250] training loss: 0.01022026
INFO:root:[116,   300] training loss: 0.01279319
INFO:root:[116,   350] training loss: 0.00865384
INFO:root:[116,   400] training loss: 0.00001964
INFO:root:[116,   450] training loss: 0.00003163
INFO:root:[116,   500] training loss: 0.00005822
INFO:root:[116,   550] training loss: 0.00050877
INFO:root:[116,   600] training loss: 0.00066482
INFO:root:[116,   650] training loss: 0.00047643
INFO:root:[116,   700] training loss: 0.00044804
INFO:root:[116,   750] training loss: 0.00256476
INFO:root:[116,   800] training loss: 0.00163524
INFO:root:[116,   850] training loss: 0.00103599
INFO:root:[116,   900] training loss: 0.01217934
INFO:root:[116,   950] training loss: 0.00336854
INFO:root:[116,  1000] training loss: 0.00002262
INFO:root:[116,  1050] training loss: 0.00001752
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8910    0.8936    0.8923      1720
   Telophase     0.7942    0.7742    0.7841      1032
          G2     0.3684    0.8750    0.5185         8
    Anaphase     0.2763    0.5753    0.3733        73
    Prophase     0.6961    0.6489    0.6717      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6704    0.8239    0.7200      3872
weighted avg     0.8005    0.7905    0.7940      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch116
INFO:root:[117,    50] training loss: 0.01005655
INFO:root:[117,   100] training loss: 0.01072101
INFO:root:[117,   150] training loss: 0.01122099
INFO:root:[117,   200] training loss: 0.01062554
INFO:root:[117,   250] training loss: 0.01015348
INFO:root:[117,   300] training loss: 0.01278802
INFO:root:[117,   350] training loss: 0.00888192
INFO:root:[117,   400] training loss: 0.00002170
INFO:root:[117,   450] training loss: 0.00002784
INFO:root:[117,   500] training loss: 0.00007886
INFO:root:[117,   550] training loss: 0.00052724
INFO:root:[117,   600] training loss: 0.00069170
INFO:root:[117,   650] training loss: 0.00044773
INFO:root:[117,   700] training loss: 0.00040547
INFO:root:[117,   750] training loss: 0.00253909
INFO:root:[117,   800] training loss: 0.00168055
INFO:root:[117,   850] training loss: 0.00091420
INFO:root:[117,   900] training loss: 0.01104325
INFO:root:[117,   950] training loss: 0.00333143
INFO:root:[117,  1000] training loss: 0.00002315
INFO:root:[117,  1050] training loss: 0.00001931
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8958    0.8895    0.8926      1720
   Telophase     0.7912    0.7859    0.7885      1032
          G2     0.3889    0.8750    0.5385         8
    Anaphase     0.2745    0.5753    0.3717        73
    Prophase     0.6944    0.6460    0.6693      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7911      3872
   macro avg     0.6731    0.8245    0.7230      3872
weighted avg     0.8013    0.7911    0.7947      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch117
INFO:root:[118,    50] training loss: 0.00960789
INFO:root:[118,   100] training loss: 0.01066821
INFO:root:[118,   150] training loss: 0.01128103
INFO:root:[118,   200] training loss: 0.01074571
INFO:root:[118,   250] training loss: 0.01037332
INFO:root:[118,   300] training loss: 0.01065798
INFO:root:[118,   350] training loss: 0.00821014
INFO:root:[118,   400] training loss: 0.00001991
INFO:root:[118,   450] training loss: 0.00003187
INFO:root:[118,   500] training loss: 0.00008816
INFO:root:[118,   550] training loss: 0.00048630
INFO:root:[118,   600] training loss: 0.00055580
INFO:root:[118,   650] training loss: 0.00040443
INFO:root:[118,   700] training loss: 0.00036899
INFO:root:[118,   750] training loss: 0.00231037
INFO:root:[118,   800] training loss: 0.00158336
INFO:root:[118,   850] training loss: 0.00088093
INFO:root:[118,   900] training loss: 0.01039648
INFO:root:[118,   950] training loss: 0.00342060
INFO:root:[118,  1000] training loss: 0.00001710
INFO:root:[118,  1050] training loss: 0.00001632
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8856    0.9047    0.8950      1720
   Telophase     0.7914    0.7645    0.7777      1032
          G2     0.4286    0.7500    0.5455         8
    Anaphase     0.2771    0.6301    0.3849        73
    Prophase     0.6996    0.6306    0.6633      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7887      3872
   macro avg     0.6784    0.8114    0.7238      3872
weighted avg     0.7984    0.7887    0.7916      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch118
INFO:root:[119,    50] training loss: 0.01009057
INFO:root:[119,   100] training loss: 0.01136050
INFO:root:[119,   150] training loss: 0.01137902
INFO:root:[119,   200] training loss: 0.01054984
INFO:root:[119,   250] training loss: 0.01079666
INFO:root:[119,   300] training loss: 0.01210700
INFO:root:[119,   350] training loss: 0.00870703
INFO:root:[119,   400] training loss: 0.00002137
INFO:root:[119,   450] training loss: 0.00002598
INFO:root:[119,   500] training loss: 0.00011289
INFO:root:[119,   550] training loss: 0.00046348
INFO:root:[119,   600] training loss: 0.00048426
INFO:root:[119,   650] training loss: 0.00036057
INFO:root:[119,   700] training loss: 0.00033473
INFO:root:[119,   750] training loss: 0.00219130
INFO:root:[119,   800] training loss: 0.00144868
INFO:root:[119,   850] training loss: 0.00090045
INFO:root:[119,   900] training loss: 0.01121507
INFO:root:[119,   950] training loss: 0.00333403
INFO:root:[119,  1000] training loss: 0.00001768
INFO:root:[119,  1050] training loss: 0.00001574
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8910    0.8936    0.8923      1720
   Telophase     0.7943    0.7781    0.7861      1032
          G2     0.3529    0.7500    0.4800         8
    Anaphase     0.2710    0.5753    0.3684        73
    Prophase     0.6900    0.6393    0.6637      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7885      3872
   macro avg     0.6070    0.7338    0.6497      3872
weighted avg     0.7984    0.7885    0.7920      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch119
INFO:root:[120,    50] training loss: 0.01217980
INFO:root:[120,   100] training loss: 0.01042879
INFO:root:[120,   150] training loss: 0.01116362
INFO:root:[120,   200] training loss: 0.01067755
INFO:root:[120,   250] training loss: 0.00978325
INFO:root:[120,   300] training loss: 0.01205251
INFO:root:[120,   350] training loss: 0.00811417
INFO:root:[120,   400] training loss: 0.00002158
INFO:root:[120,   450] training loss: 0.00002610
INFO:root:[120,   500] training loss: 0.00006384
INFO:root:[120,   550] training loss: 0.00037819
INFO:root:[120,   600] training loss: 0.00047991
INFO:root:[120,   650] training loss: 0.00033089
INFO:root:[120,   700] training loss: 0.00035461
INFO:root:[120,   750] training loss: 0.00244246
INFO:root:[120,   800] training loss: 0.00143456
INFO:root:[120,   850] training loss: 0.00082983
INFO:root:[120,   900] training loss: 0.01048943
INFO:root:[120,   950] training loss: 0.00361650
INFO:root:[120,  1000] training loss: 0.00002007
INFO:root:[120,  1050] training loss: 0.00002373
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9016    0.8733    0.8872      1720
   Telophase     0.7875    0.7723    0.7798      1032
          G2     0.3500    0.8750    0.5000         8
    Anaphase     0.2561    0.5753    0.3544        73
    Prophase     0.6793    0.6596    0.6693      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7836      3872
   macro avg     0.6035    0.7508    0.6497      3872
weighted avg     0.7982    0.7836    0.7893      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch120
INFO:root:[121,    50] training loss: 0.01023897
INFO:root:[121,   100] training loss: 0.01072961
INFO:root:[121,   150] training loss: 0.01058175
INFO:root:[121,   200] training loss: 0.01001413
INFO:root:[121,   250] training loss: 0.01055164
INFO:root:[121,   300] training loss: 0.01260885
INFO:root:[121,   350] training loss: 0.00850052
INFO:root:[121,   400] training loss: 0.00001902
INFO:root:[121,   450] training loss: 0.00002811
INFO:root:[121,   500] training loss: 0.00007947
INFO:root:[121,   550] training loss: 0.00048309
INFO:root:[121,   600] training loss: 0.00049303
INFO:root:[121,   650] training loss: 0.00034968
INFO:root:[121,   700] training loss: 0.00033122
INFO:root:[121,   750] training loss: 0.00214430
INFO:root:[121,   800] training loss: 0.00139230
INFO:root:[121,   850] training loss: 0.00091700
INFO:root:[121,   900] training loss: 0.00966035
INFO:root:[121,   950] training loss: 0.00320577
INFO:root:[121,  1000] training loss: 0.00001998
INFO:root:[121,  1050] training loss: 0.00001502
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9038    0.8686    0.8859      1720
   Telophase     0.7877    0.7839    0.7858      1032
          G2     0.3684    0.8750    0.5185         8
    Anaphase     0.2622    0.5890    0.3629        73
    Prophase     0.6780    0.6576    0.6676      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7843      3872
   macro avg     0.6072    0.7535    0.6540      3872
weighted avg     0.7990    0.7843    0.7901      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch121
INFO:root:[122,    50] training loss: 0.01027177
INFO:root:[122,   100] training loss: 0.01005468
INFO:root:[122,   150] training loss: 0.01064788
INFO:root:[122,   200] training loss: 0.00999855
INFO:root:[122,   250] training loss: 0.01000584
INFO:root:[122,   300] training loss: 0.01178909
INFO:root:[122,   350] training loss: 0.00864657
INFO:root:[122,   400] training loss: 0.00001973
INFO:root:[122,   450] training loss: 0.00002568
INFO:root:[122,   500] training loss: 0.00007227
INFO:root:[122,   550] training loss: 0.00044430
INFO:root:[122,   600] training loss: 0.00048200
INFO:root:[122,   650] training loss: 0.00027976
INFO:root:[122,   700] training loss: 0.00031972
INFO:root:[122,   750] training loss: 0.00213499
INFO:root:[122,   800] training loss: 0.00130758
INFO:root:[122,   850] training loss: 0.00079748
INFO:root:[122,   900] training loss: 0.01132295
INFO:root:[122,   950] training loss: 0.00333470
INFO:root:[122,  1000] training loss: 0.00001922
INFO:root:[122,  1050] training loss: 0.00001468
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8969    0.8901    0.8935      1720
   Telophase     0.7896    0.7636    0.7764      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2500    0.6027    0.3534        73
    Prophase     0.6956    0.6518    0.6730      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7869      3872
   macro avg     0.6081    0.7369    0.6505      3872
weighted avg     0.8009    0.7869    0.7922      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch122
INFO:root:[123,    50] training loss: 0.00962410
INFO:root:[123,   100] training loss: 0.01097683
INFO:root:[123,   150] training loss: 0.01139457
INFO:root:[123,   200] training loss: 0.01068633
INFO:root:[123,   250] training loss: 0.01032262
INFO:root:[123,   300] training loss: 0.01082815
INFO:root:[123,   350] training loss: 0.01031682
INFO:root:[123,   400] training loss: 0.00001886
INFO:root:[123,   450] training loss: 0.00002712
INFO:root:[123,   500] training loss: 0.00005760
INFO:root:[123,   550] training loss: 0.00046107
INFO:root:[123,   600] training loss: 0.00047929
INFO:root:[123,   650] training loss: 0.00028243
INFO:root:[123,   700] training loss: 0.00031006
INFO:root:[123,   750] training loss: 0.00212620
INFO:root:[123,   800] training loss: 0.00133815
INFO:root:[123,   850] training loss: 0.00083723
INFO:root:[123,   900] training loss: 0.01116304
INFO:root:[123,   950] training loss: 0.00305033
INFO:root:[123,  1000] training loss: 0.00001689
INFO:root:[123,  1050] training loss: 0.00001757
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8988    0.8727    0.8855      1720
   Telophase     0.7876    0.7762    0.7818      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2795    0.6164    0.3846        73
    Prophase     0.6760    0.6557    0.6657      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7838      3872
   macro avg     0.6131    0.7387    0.6567      3872
weighted avg     0.7966    0.7838    0.7888      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch123
INFO:root:[124,    50] training loss: 0.00953704
INFO:root:[124,   100] training loss: 0.01072203
INFO:root:[124,   150] training loss: 0.01058033
INFO:root:[124,   200] training loss: 0.00971312
INFO:root:[124,   250] training loss: 0.00956984
INFO:root:[124,   300] training loss: 0.01091111
INFO:root:[124,   350] training loss: 0.00887242
INFO:root:[124,   400] training loss: 0.00001981
INFO:root:[124,   450] training loss: 0.00002891
INFO:root:[124,   500] training loss: 0.00005405
INFO:root:[124,   550] training loss: 0.00057627
INFO:root:[124,   600] training loss: 0.00047849
INFO:root:[124,   650] training loss: 0.00028639
INFO:root:[124,   700] training loss: 0.00031163
INFO:root:[124,   750] training loss: 0.00217478
INFO:root:[124,   800] training loss: 0.00137172
INFO:root:[124,   850] training loss: 0.00080381
INFO:root:[124,   900] training loss: 0.00994671
INFO:root:[124,   950] training loss: 0.00274709
INFO:root:[124,  1000] training loss: 0.00001892
INFO:root:[124,  1050] training loss: 0.00002086
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8924    0.8971    0.8948      1720
   Telophase     0.7902    0.7810    0.7856      1032
          G2     0.3158    0.7500    0.4444         8
    Anaphase     0.2697    0.5616    0.3644        73
    Prophase     0.6998    0.6402    0.6687      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7908      3872
   macro avg     0.6026    0.7329    0.6450      3872
weighted avg     0.8005    0.7908    0.7941      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch124
INFO:root:[125,    50] training loss: 0.00972091
INFO:root:[125,   100] training loss: 0.01018858
INFO:root:[125,   150] training loss: 0.01052688
INFO:root:[125,   200] training loss: 0.01110489
INFO:root:[125,   250] training loss: 0.01009423
INFO:root:[125,   300] training loss: 0.01074387
INFO:root:[125,   350] training loss: 0.00889726
INFO:root:[125,   400] training loss: 0.00001804
INFO:root:[125,   450] training loss: 0.00002453
INFO:root:[125,   500] training loss: 0.00005018
INFO:root:[125,   550] training loss: 0.00041259
INFO:root:[125,   600] training loss: 0.00055173
INFO:root:[125,   650] training loss: 0.00027060
INFO:root:[125,   700] training loss: 0.00027124
INFO:root:[125,   750] training loss: 0.00211704
INFO:root:[125,   800] training loss: 0.00125699
INFO:root:[125,   850] training loss: 0.00079018
INFO:root:[125,   900] training loss: 0.00989485
INFO:root:[125,   950] training loss: 0.00295426
INFO:root:[125,  1000] training loss: 0.00001700
INFO:root:[125,  1050] training loss: 0.00001649
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8976    0.8767    0.8871      1720
   Telophase     0.7890    0.7897    0.7893      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2953    0.6027    0.3964        73
    Prophase     0.6781    0.6480    0.6627      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7869      3872
   macro avg     0.6121    0.7382    0.6561      3872
weighted avg     0.7973    0.7869    0.7908      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch125
INFO:root:[126,    50] training loss: 0.01028903
INFO:root:[126,   100] training loss: 0.00984951
INFO:root:[126,   150] training loss: 0.01092684
INFO:root:[126,   200] training loss: 0.00994759
INFO:root:[126,   250] training loss: 0.01013873
INFO:root:[126,   300] training loss: 0.01097756
INFO:root:[126,   350] training loss: 0.00856484
INFO:root:[126,   400] training loss: 0.00001918
INFO:root:[126,   450] training loss: 0.00002770
INFO:root:[126,   500] training loss: 0.00007154
INFO:root:[126,   550] training loss: 0.00047637
INFO:root:[126,   600] training loss: 0.00045240
INFO:root:[126,   650] training loss: 0.00025874
INFO:root:[126,   700] training loss: 0.00022748
INFO:root:[126,   750] training loss: 0.00207159
INFO:root:[126,   800] training loss: 0.00120668
INFO:root:[126,   850] training loss: 0.00065659
INFO:root:[126,   900] training loss: 0.01059123
INFO:root:[126,   950] training loss: 0.00325066
INFO:root:[126,  1000] training loss: 0.00002399
INFO:root:[126,  1050] training loss: 0.00001754
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.8925    0.8930    0.8928      1720
   Telophase     0.7998    0.7665    0.7828      1032
          G2     0.3529    0.7500    0.4800         8
    Anaphase     0.2622    0.5890    0.3629        73
    Prophase     0.6944    0.6547    0.6740      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7895      3872
   macro avg     0.6074    0.7362    0.6499      3872
weighted avg     0.8016    0.7895    0.7939      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch126
INFO:root:[127,    50] training loss: 0.00977234
INFO:root:[127,   100] training loss: 0.01119729
INFO:root:[127,   150] training loss: 0.01025025
INFO:root:[127,   200] training loss: 0.01049075
INFO:root:[127,   250] training loss: 0.01005852
INFO:root:[127,   300] training loss: 0.01070399
INFO:root:[127,   350] training loss: 0.00883302
INFO:root:[127,   400] training loss: 0.00001731
INFO:root:[127,   450] training loss: 0.00004538
INFO:root:[127,   500] training loss: 0.00008234
INFO:root:[127,   550] training loss: 0.00045326
INFO:root:[127,   600] training loss: 0.00041031
INFO:root:[127,   650] training loss: 0.00027842
INFO:root:[127,   700] training loss: 0.00027172
INFO:root:[127,   750] training loss: 0.00213674
INFO:root:[127,   800] training loss: 0.00128570
INFO:root:[127,   850] training loss: 0.00072543
INFO:root:[127,   900] training loss: 0.01032768
INFO:root:[127,   950] training loss: 0.00284288
INFO:root:[127,  1000] training loss: 0.00001651
INFO:root:[127,  1050] training loss: 0.00001648
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8922    0.8901    0.8912      1720
   Telophase     0.7931    0.7800    0.7865      1032
          G2     0.4286    0.7500    0.5455         8
    Anaphase     0.2866    0.6164    0.3913        73
    Prophase     0.6909    0.6441    0.6667      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7898      3872
   macro avg     0.6797    0.8115    0.7259      3872
weighted avg     0.7996    0.7898    0.7932      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch127
INFO:root:[128,    50] training loss: 0.00994124
INFO:root:[128,   100] training loss: 0.01033904
INFO:root:[128,   150] training loss: 0.01074309
INFO:root:[128,   200] training loss: 0.01007031
INFO:root:[128,   250] training loss: 0.01022717
INFO:root:[128,   300] training loss: 0.01062437
INFO:root:[128,   350] training loss: 0.00865851
INFO:root:[128,   400] training loss: 0.00001827
INFO:root:[128,   450] training loss: 0.00002334
INFO:root:[128,   500] training loss: 0.00006786
INFO:root:[128,   550] training loss: 0.00043465
INFO:root:[128,   600] training loss: 0.00036510
INFO:root:[128,   650] training loss: 0.00023433
INFO:root:[128,   700] training loss: 0.00023667
INFO:root:[128,   750] training loss: 0.00212857
INFO:root:[128,   800] training loss: 0.00119219
INFO:root:[128,   850] training loss: 0.00075047
INFO:root:[128,   900] training loss: 0.01023999
INFO:root:[128,   950] training loss: 0.00257062
INFO:root:[128,  1000] training loss: 0.00001719
INFO:root:[128,  1050] training loss: 0.00001592
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.8930    0.8977    0.8953      1720
   Telophase     0.7945    0.7829    0.7887      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2848    0.6164    0.3896        73
    Prophase     0.6987    0.6393    0.6677      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7926      3872
   macro avg     0.6732    0.8123    0.7202      3872
weighted avg     0.8023    0.7926    0.7958      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch128
INFO:root:[129,    50] training loss: 0.01031285
INFO:root:[129,   100] training loss: 0.01039512
INFO:root:[129,   150] training loss: 0.01031881
INFO:root:[129,   200] training loss: 0.01102855
INFO:root:[129,   250] training loss: 0.00996181
INFO:root:[129,   300] training loss: 0.01069190
INFO:root:[129,   350] training loss: 0.00813493
INFO:root:[129,   400] training loss: 0.00001859
INFO:root:[129,   450] training loss: 0.00003155
INFO:root:[129,   500] training loss: 0.00008691
INFO:root:[129,   550] training loss: 0.00031865
INFO:root:[129,   600] training loss: 0.00042500
INFO:root:[129,   650] training loss: 0.00028376
INFO:root:[129,   700] training loss: 0.00034688
INFO:root:[129,   750] training loss: 0.00306324
INFO:root:[129,   800] training loss: 0.00326201
INFO:root:[129,   850] training loss: 0.00270022
INFO:root:[129,   900] training loss: 0.00747275
INFO:root:[129,   950] training loss: 0.00284784
INFO:root:[129,  1000] training loss: 0.00001851
INFO:root:[129,  1050] training loss: 0.00003746
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9198    0.8337    0.8747      1720
   Telophase     0.7707    0.8110    0.7904      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2774    0.5890    0.3772        73
    Prophase     0.6533    0.6634    0.6583      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7776      3872
   macro avg     0.6661    0.8068    0.7144      3872
weighted avg     0.7956    0.7776    0.7843      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch129
INFO:root:[130,    50] training loss: 0.00976357
INFO:root:[130,   100] training loss: 0.00992646
INFO:root:[130,   150] training loss: 0.01031183
INFO:root:[130,   200] training loss: 0.00983459
INFO:root:[130,   250] training loss: 0.01024887
INFO:root:[130,   300] training loss: 0.01056974
INFO:root:[130,   350] training loss: 0.00800923
INFO:root:[130,   400] training loss: 0.00002081
INFO:root:[130,   450] training loss: 0.00002684
INFO:root:[130,   500] training loss: 0.00004707
INFO:root:[130,   550] training loss: 0.00036736
INFO:root:[130,   600] training loss: 0.00033877
INFO:root:[130,   650] training loss: 0.00025407
INFO:root:[130,   700] training loss: 0.00020711
INFO:root:[130,   750] training loss: 0.00255656
INFO:root:[130,   800] training loss: 0.00279772
INFO:root:[130,   850] training loss: 0.00220603
INFO:root:[130,   900] training loss: 0.00872489
INFO:root:[130,   950] training loss: 0.00345311
INFO:root:[130,  1000] training loss: 0.00001924
INFO:root:[130,  1050] training loss: 0.00002097
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9244    0.8244    0.8715      1720
   Telophase     0.7735    0.8207    0.7964      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2877    0.5753    0.3836        73
    Prophase     0.6484    0.6741    0.6610      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7787      3872
   macro avg     0.6679    0.8064    0.7161      3872
weighted avg     0.7973    0.7787    0.7854      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch130
INFO:root:[131,    50] training loss: 0.00951923
INFO:root:[131,   100] training loss: 0.01017133
INFO:root:[131,   150] training loss: 0.01078523
INFO:root:[131,   200] training loss: 0.00979658
INFO:root:[131,   250] training loss: 0.01009779
INFO:root:[131,   300] training loss: 0.01074123
INFO:root:[131,   350] training loss: 0.00924228
INFO:root:[131,   400] training loss: 0.00002107
INFO:root:[131,   450] training loss: 0.00003383
INFO:root:[131,   500] training loss: 0.00005743
INFO:root:[131,   550] training loss: 0.00038139
INFO:root:[131,   600] training loss: 0.00033930
INFO:root:[131,   650] training loss: 0.00017300
INFO:root:[131,   700] training loss: 0.00019939
INFO:root:[131,   750] training loss: 0.00217877
INFO:root:[131,   800] training loss: 0.00230212
INFO:root:[131,   850] training loss: 0.00204043
INFO:root:[131,   900] training loss: 0.00847076
INFO:root:[131,   950] training loss: 0.00323939
INFO:root:[131,  1000] training loss: 0.00003856
INFO:root:[131,  1050] training loss: 0.00002105
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9266    0.8215    0.8709      1720
   Telophase     0.7751    0.8217    0.7977      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2966    0.5890    0.3945        73
    Prophase     0.6473    0.6799    0.6632      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7794      3872
   macro avg     0.6696    0.8089    0.7180      3872
weighted avg     0.7985    0.7794    0.7862      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch131
INFO:root:[132,    50] training loss: 0.00928441
INFO:root:[132,   100] training loss: 0.01021093
INFO:root:[132,   150] training loss: 0.01017184
INFO:root:[132,   200] training loss: 0.01052801
INFO:root:[132,   250] training loss: 0.00945863
INFO:root:[132,   300] training loss: 0.01144783
INFO:root:[132,   350] training loss: 0.00873330
INFO:root:[132,   400] training loss: 0.00001873
INFO:root:[132,   450] training loss: 0.00002922
INFO:root:[132,   500] training loss: 0.00007950
INFO:root:[132,   550] training loss: 0.00038191
INFO:root:[132,   600] training loss: 0.00031639
INFO:root:[132,   650] training loss: 0.00017772
INFO:root:[132,   700] training loss: 0.00018391
INFO:root:[132,   750] training loss: 0.00210476
INFO:root:[132,   800] training loss: 0.00218369
INFO:root:[132,   850] training loss: 0.00182386
INFO:root:[132,   900] training loss: 0.00778684
INFO:root:[132,   950] training loss: 0.00275477
INFO:root:[132,  1000] training loss: 0.00015116
INFO:root:[132,  1050] training loss: 0.00002132
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9258    0.8192    0.8692      1720
   Telophase     0.7744    0.8217    0.7974      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2966    0.5890    0.3945        73
    Prophase     0.6443    0.6779    0.6607      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7779      3872
   macro avg     0.6690    0.8083    0.7174      3872
weighted avg     0.7972    0.7779    0.7847      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch132
INFO:root:[133,    50] training loss: 0.00983081
INFO:root:[133,   100] training loss: 0.00956755
INFO:root:[133,   150] training loss: 0.01042014
INFO:root:[133,   200] training loss: 0.01020093
INFO:root:[133,   250] training loss: 0.00972905
INFO:root:[133,   300] training loss: 0.01242170
INFO:root:[133,   350] training loss: 0.00814180
INFO:root:[133,   400] training loss: 0.00001905
INFO:root:[133,   450] training loss: 0.00002936
INFO:root:[133,   500] training loss: 0.00006317
INFO:root:[133,   550] training loss: 0.00034832
INFO:root:[133,   600] training loss: 0.00029702
INFO:root:[133,   650] training loss: 0.00017501
INFO:root:[133,   700] training loss: 0.00016389
INFO:root:[133,   750] training loss: 0.00178424
INFO:root:[133,   800] training loss: 0.00192945
INFO:root:[133,   850] training loss: 0.00176941
INFO:root:[133,   900] training loss: 0.00883069
INFO:root:[133,   950] training loss: 0.00331512
INFO:root:[133,  1000] training loss: 0.00002515
INFO:root:[133,  1050] training loss: 0.00002356
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9255    0.8238    0.8717      1720
   Telophase     0.7779    0.8178    0.7974      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.2986    0.5890    0.3963        73
    Prophase     0.6486    0.6838    0.6657      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7802      3872
   macro avg     0.6108    0.7378    0.6555      3872
weighted avg     0.7989    0.7802    0.7870      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch133
INFO:root:[134,    50] training loss: 0.00970899
INFO:root:[134,   100] training loss: 0.00980810
INFO:root:[134,   150] training loss: 0.01013769
INFO:root:[134,   200] training loss: 0.00957287
INFO:root:[134,   250] training loss: 0.00930824
INFO:root:[134,   300] training loss: 0.01037924
INFO:root:[134,   350] training loss: 0.00856168
INFO:root:[134,   400] training loss: 0.00002155
INFO:root:[134,   450] training loss: 0.00002689
INFO:root:[134,   500] training loss: 0.00004930
INFO:root:[134,   550] training loss: 0.00040883
INFO:root:[134,   600] training loss: 0.00027172
INFO:root:[134,   650] training loss: 0.00017074
INFO:root:[134,   700] training loss: 0.00016504
INFO:root:[134,   750] training loss: 0.00178121
INFO:root:[134,   800] training loss: 0.00192280
INFO:root:[134,   850] training loss: 0.00164955
INFO:root:[134,   900] training loss: 0.01144278
INFO:root:[134,   950] training loss: 0.00283719
INFO:root:[134,  1000] training loss: 0.00002159
INFO:root:[134,  1050] training loss: 0.00002539
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9242    0.8297    0.8744      1720
   Telophase     0.7806    0.8101    0.7951      1032
          G2     0.3750    0.7500    0.5000         8
    Anaphase     0.3007    0.5890    0.3981        73
    Prophase     0.6502    0.6867    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7815      3872
   macro avg     0.6115    0.7379    0.6561      3872
weighted avg     0.7995    0.7815    0.7881      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch134
INFO:root:[135,    50] training loss: 0.00950088
INFO:root:[135,   100] training loss: 0.00974741
INFO:root:[135,   150] training loss: 0.01087128
INFO:root:[135,   200] training loss: 0.01030135
INFO:root:[135,   250] training loss: 0.00996158
INFO:root:[135,   300] training loss: 0.01039450
INFO:root:[135,   350] training loss: 0.00830122
INFO:root:[135,   400] training loss: 0.00002437
INFO:root:[135,   450] training loss: 0.00003371
INFO:root:[135,   500] training loss: 0.00008773
INFO:root:[135,   550] training loss: 0.00039389
INFO:root:[135,   600] training loss: 0.00026576
INFO:root:[135,   650] training loss: 0.00015530
INFO:root:[135,   700] training loss: 0.00018514
INFO:root:[135,   750] training loss: 0.00177543
INFO:root:[135,   800] training loss: 0.00184970
INFO:root:[135,   850] training loss: 0.00156851
INFO:root:[135,   900] training loss: 0.00730892
INFO:root:[135,   950] training loss: 0.00334633
INFO:root:[135,  1000] training loss: 0.00002395
INFO:root:[135,  1050] training loss: 0.00002046
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
           S     0.9255    0.8233    0.8714      1720
   Telophase     0.7780    0.8081    0.7928      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2973    0.6027    0.3982        73
    Prophase     0.6449    0.6867    0.6651      1034
   Metaphase     1.0000    1.0000    1.0000         3

    accuracy                         0.7787      3872
   macro avg     0.6732    0.8101    0.7213      3872
weighted avg     0.7982    0.7787    0.7858      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch135
INFO:root:[136,    50] training loss: 0.00945819
INFO:root:[136,   100] training loss: 0.00967961
INFO:root:[136,   150] training loss: 0.01014433
INFO:root:[136,   200] training loss: 0.00982630
INFO:root:[136,   250] training loss: 0.01143907
INFO:root:[136,   300] training loss: 0.01117616
INFO:root:[136,   350] training loss: 0.00819443
INFO:root:[136,   400] training loss: 0.00001795
INFO:root:[136,   450] training loss: 0.00002902
INFO:root:[136,   500] training loss: 0.00004849
INFO:root:[136,   550] training loss: 0.00037562
INFO:root:[136,   600] training loss: 0.00023681
INFO:root:[136,   650] training loss: 0.00014112
INFO:root:[136,   700] training loss: 0.00016921
INFO:root:[136,   750] training loss: 0.00167483
INFO:root:[136,   800] training loss: 0.00182941
INFO:root:[136,   850] training loss: 0.00163741
INFO:root:[136,   900] training loss: 0.00755343
INFO:root:[136,   950] training loss: 0.00317978
INFO:root:[136,  1000] training loss: 0.00002782
INFO:root:[136,  1050] training loss: 0.00003570
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9260    0.8221    0.8710      1720
   Telophase     0.7775    0.8091    0.7930      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2857    0.6027    0.3877        73
    Prophase     0.6460    0.6847    0.6648      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6122    0.7384    0.6565      3872
weighted avg     0.7981    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch136
INFO:root:[137,    50] training loss: 0.00930141
INFO:root:[137,   100] training loss: 0.01045192
INFO:root:[137,   150] training loss: 0.01022531
INFO:root:[137,   200] training loss: 0.00956099
INFO:root:[137,   250] training loss: 0.00925820
INFO:root:[137,   300] training loss: 0.01041659
INFO:root:[137,   350] training loss: 0.00839172
INFO:root:[137,   400] training loss: 0.00001818
INFO:root:[137,   450] training loss: 0.00003428
INFO:root:[137,   500] training loss: 0.00007512
INFO:root:[137,   550] training loss: 0.00040765
INFO:root:[137,   600] training loss: 0.00028505
INFO:root:[137,   650] training loss: 0.00012875
INFO:root:[137,   700] training loss: 0.00018485
INFO:root:[137,   750] training loss: 0.00163246
INFO:root:[137,   800] training loss: 0.00183038
INFO:root:[137,   850] training loss: 0.00144529
INFO:root:[137,   900] training loss: 0.00885101
INFO:root:[137,   950] training loss: 0.00286862
INFO:root:[137,  1000] training loss: 0.00002299
INFO:root:[137,  1050] training loss: 0.00004590
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9246    0.8273    0.8733      1720
   Telophase     0.7817    0.8014    0.7914      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6479    0.6905    0.6685      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7794      3872
   macro avg     0.6134    0.7388    0.6576      3872
weighted avg     0.7992    0.7794    0.7868      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch137
INFO:root:[138,    50] training loss: 0.00971912
INFO:root:[138,   100] training loss: 0.00965192
INFO:root:[138,   150] training loss: 0.00993213
INFO:root:[138,   200] training loss: 0.01032446
INFO:root:[138,   250] training loss: 0.00985892
INFO:root:[138,   300] training loss: 0.01110058
INFO:root:[138,   350] training loss: 0.00794122
INFO:root:[138,   400] training loss: 0.00001818
INFO:root:[138,   450] training loss: 0.00002961
INFO:root:[138,   500] training loss: 0.00006933
INFO:root:[138,   550] training loss: 0.00041482
INFO:root:[138,   600] training loss: 0.00025181
INFO:root:[138,   650] training loss: 0.00014605
INFO:root:[138,   700] training loss: 0.00016177
INFO:root:[138,   750] training loss: 0.00145819
INFO:root:[138,   800] training loss: 0.00174585
INFO:root:[138,   850] training loss: 0.00144487
INFO:root:[138,   900] training loss: 0.00917679
INFO:root:[138,   950] training loss: 0.00303519
INFO:root:[138,  1000] training loss: 0.00002702
INFO:root:[138,  1050] training loss: 0.00002111
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9235    0.8285    0.8734      1720
   Telophase     0.7836    0.8033    0.7933      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2953    0.6027    0.3964        73
    Prophase     0.6476    0.6896    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7802      3872
   macro avg     0.6143    0.7392    0.6586      3872
weighted avg     0.7993    0.7802    0.7873      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch138
INFO:root:[139,    50] training loss: 0.00915190
INFO:root:[139,   100] training loss: 0.00966143
INFO:root:[139,   150] training loss: 0.01121275
INFO:root:[139,   200] training loss: 0.00974054
INFO:root:[139,   250] training loss: 0.01027709
INFO:root:[139,   300] training loss: 0.01031331
INFO:root:[139,   350] training loss: 0.00846651
INFO:root:[139,   400] training loss: 0.00001753
INFO:root:[139,   450] training loss: 0.00003773
INFO:root:[139,   500] training loss: 0.00009076
INFO:root:[139,   550] training loss: 0.00041866
INFO:root:[139,   600] training loss: 0.00025948
INFO:root:[139,   650] training loss: 0.00013561
INFO:root:[139,   700] training loss: 0.00013897
INFO:root:[139,   750] training loss: 0.00158836
INFO:root:[139,   800] training loss: 0.00170897
INFO:root:[139,   850] training loss: 0.00142583
INFO:root:[139,   900] training loss: 0.00758299
INFO:root:[139,   950] training loss: 0.00338480
INFO:root:[139,  1000] training loss: 0.00002112
INFO:root:[139,  1050] training loss: 0.00001991
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9246    0.8267    0.8729      1720
   Telophase     0.7820    0.7994    0.7906      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6471    0.6915    0.6685      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7789      3872
   macro avg     0.6130    0.7386    0.6572      3872
weighted avg     0.7990    0.7789    0.7864      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch139
INFO:root:[140,    50] training loss: 0.00967740
INFO:root:[140,   100] training loss: 0.00960353
INFO:root:[140,   150] training loss: 0.01008805
INFO:root:[140,   200] training loss: 0.00914263
INFO:root:[140,   250] training loss: 0.01095262
INFO:root:[140,   300] training loss: 0.01056956
INFO:root:[140,   350] training loss: 0.00805572
INFO:root:[140,   400] training loss: 0.00001948
INFO:root:[140,   450] training loss: 0.00003055
INFO:root:[140,   500] training loss: 0.00006099
INFO:root:[140,   550] training loss: 0.00034557
INFO:root:[140,   600] training loss: 0.00023001
INFO:root:[140,   650] training loss: 0.00011303
INFO:root:[140,   700] training loss: 0.00017788
INFO:root:[140,   750] training loss: 0.00144837
INFO:root:[140,   800] training loss: 0.00186060
INFO:root:[140,   850] training loss: 0.00146925
INFO:root:[140,   900] training loss: 0.00804088
INFO:root:[140,   950] training loss: 0.00255274
INFO:root:[140,  1000] training loss: 0.00001950
INFO:root:[140,  1050] training loss: 0.00006332
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9246    0.8267    0.8729      1720
   Telophase     0.7815    0.8004    0.7908      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6467    0.6905    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7789      3872
   macro avg     0.6132    0.7386    0.6574      3872
weighted avg     0.7988    0.7789    0.7863      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch140
INFO:root:[141,    50] training loss: 0.00931143
INFO:root:[141,   100] training loss: 0.00995606
INFO:root:[141,   150] training loss: 0.01114021
INFO:root:[141,   200] training loss: 0.01066199
INFO:root:[141,   250] training loss: 0.00929650
INFO:root:[141,   300] training loss: 0.01133395
INFO:root:[141,   350] training loss: 0.00808263
INFO:root:[141,   400] training loss: 0.00001779
INFO:root:[141,   450] training loss: 0.00003727
INFO:root:[141,   500] training loss: 0.00008876
INFO:root:[141,   550] training loss: 0.00035170
INFO:root:[141,   600] training loss: 0.00027869
INFO:root:[141,   650] training loss: 0.00012049
INFO:root:[141,   700] training loss: 0.00014425
INFO:root:[141,   750] training loss: 0.00134212
INFO:root:[141,   800] training loss: 0.00170548
INFO:root:[141,   850] training loss: 0.00163645
INFO:root:[141,   900] training loss: 0.00828744
INFO:root:[141,   950] training loss: 0.00279270
INFO:root:[141,  1000] training loss: 0.00002185
INFO:root:[141,  1050] training loss: 0.00002378
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9246    0.8267    0.8729      1720
   Telophase     0.7829    0.8004    0.7916      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6465    0.6915    0.6682      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7792      3872
   macro avg     0.6134    0.7388    0.6575      3872
weighted avg     0.7991    0.7792    0.7866      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch141
INFO:root:[142,    50] training loss: 0.00936437
INFO:root:[142,   100] training loss: 0.01010443
INFO:root:[142,   150] training loss: 0.01040866
INFO:root:[142,   200] training loss: 0.00967343
INFO:root:[142,   250] training loss: 0.00972332
INFO:root:[142,   300] training loss: 0.01067227
INFO:root:[142,   350] training loss: 0.00849051
INFO:root:[142,   400] training loss: 0.00001910
INFO:root:[142,   450] training loss: 0.00002626
INFO:root:[142,   500] training loss: 0.00005776
INFO:root:[142,   550] training loss: 0.00038792
INFO:root:[142,   600] training loss: 0.00024805
INFO:root:[142,   650] training loss: 0.00014743
INFO:root:[142,   700] training loss: 0.00014256
INFO:root:[142,   750] training loss: 0.00142817
INFO:root:[142,   800] training loss: 0.00168109
INFO:root:[142,   850] training loss: 0.00166583
INFO:root:[142,   900] training loss: 0.00821855
INFO:root:[142,   950] training loss: 0.00283965
INFO:root:[142,  1000] training loss: 0.00002246
INFO:root:[142,  1050] training loss: 0.00001963
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9246    0.8267    0.8729      1720
   Telophase     0.7817    0.8014    0.7914      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6473    0.6905    0.6682      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7792      3872
   macro avg     0.6133    0.7388    0.6575      3872
weighted avg     0.7990    0.7792    0.7865      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch142
INFO:root:[143,    50] training loss: 0.00897645
INFO:root:[143,   100] training loss: 0.01033244
INFO:root:[143,   150] training loss: 0.01010513
INFO:root:[143,   200] training loss: 0.00985391
INFO:root:[143,   250] training loss: 0.00933783
INFO:root:[143,   300] training loss: 0.01063417
INFO:root:[143,   350] training loss: 0.00836855
INFO:root:[143,   400] training loss: 0.00001704
INFO:root:[143,   450] training loss: 0.00002510
INFO:root:[143,   500] training loss: 0.00004422
INFO:root:[143,   550] training loss: 0.00041486
INFO:root:[143,   600] training loss: 0.00022577
INFO:root:[143,   650] training loss: 0.00011739
INFO:root:[143,   700] training loss: 0.00013275
INFO:root:[143,   750] training loss: 0.00149855
INFO:root:[143,   800] training loss: 0.00185727
INFO:root:[143,   850] training loss: 0.00148880
INFO:root:[143,   900] training loss: 0.00772959
INFO:root:[143,   950] training loss: 0.00352155
INFO:root:[143,  1000] training loss: 0.00002294
INFO:root:[143,  1050] training loss: 0.00002338
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9246    0.8267    0.8729      1720
   Telophase     0.7826    0.8023    0.7923      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2914    0.6027    0.3929        73
    Prophase     0.6476    0.6915    0.6688      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7797      3872
   macro avg     0.6137    0.7390    0.6580      3872
weighted avg     0.7994    0.7797    0.7870      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch143
INFO:root:[144,    50] training loss: 0.00979759
INFO:root:[144,   100] training loss: 0.00979876
INFO:root:[144,   150] training loss: 0.01026291
INFO:root:[144,   200] training loss: 0.00996055
INFO:root:[144,   250] training loss: 0.01006263
INFO:root:[144,   300] training loss: 0.01065623
INFO:root:[144,   350] training loss: 0.00860536
INFO:root:[144,   400] training loss: 0.00002056
INFO:root:[144,   450] training loss: 0.00002404
INFO:root:[144,   500] training loss: 0.00005276
INFO:root:[144,   550] training loss: 0.00033170
INFO:root:[144,   600] training loss: 0.00025472
INFO:root:[144,   650] training loss: 0.00011683
INFO:root:[144,   700] training loss: 0.00015151
INFO:root:[144,   750] training loss: 0.00156752
INFO:root:[144,   800] training loss: 0.00177779
INFO:root:[144,   850] training loss: 0.00166240
INFO:root:[144,   900] training loss: 0.00930123
INFO:root:[144,   950] training loss: 0.00333003
INFO:root:[144,  1000] training loss: 0.00002575
INFO:root:[144,  1050] training loss: 0.00002098
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7817    0.8014    0.7914      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6467    0.6905    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7789      3872
   macro avg     0.6132    0.7387    0.6574      3872
weighted avg     0.7989    0.7789    0.7863      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch144
INFO:root:[145,    50] training loss: 0.00928277
INFO:root:[145,   100] training loss: 0.01048617
INFO:root:[145,   150] training loss: 0.01090713
INFO:root:[145,   200] training loss: 0.00927995
INFO:root:[145,   250] training loss: 0.01013227
INFO:root:[145,   300] training loss: 0.01162451
INFO:root:[145,   350] training loss: 0.00857963
INFO:root:[145,   400] training loss: 0.00002021
INFO:root:[145,   450] training loss: 0.00002436
INFO:root:[145,   500] training loss: 0.00004554
INFO:root:[145,   550] training loss: 0.00039685
INFO:root:[145,   600] training loss: 0.00025103
INFO:root:[145,   650] training loss: 0.00014891
INFO:root:[145,   700] training loss: 0.00013795
INFO:root:[145,   750] training loss: 0.00155276
INFO:root:[145,   800] training loss: 0.00189958
INFO:root:[145,   850] training loss: 0.00167740
INFO:root:[145,   900] training loss: 0.00791560
INFO:root:[145,   950] training loss: 0.00294919
INFO:root:[145,  1000] training loss: 0.00002740
INFO:root:[145,  1050] training loss: 0.00002693
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9251    0.8256    0.8725      1720
   Telophase     0.7809    0.8014    0.7910      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6462    0.6905    0.6676      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7787      3872
   macro avg     0.6131    0.7386    0.6573      3872
weighted avg     0.7987    0.7787    0.7861      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch145
INFO:root:[146,    50] training loss: 0.00943972
INFO:root:[146,   100] training loss: 0.00948348
INFO:root:[146,   150] training loss: 0.00999946
INFO:root:[146,   200] training loss: 0.01047520
INFO:root:[146,   250] training loss: 0.00949512
INFO:root:[146,   300] training loss: 0.01114617
INFO:root:[146,   350] training loss: 0.00826916
INFO:root:[146,   400] training loss: 0.00001714
INFO:root:[146,   450] training loss: 0.00002880
INFO:root:[146,   500] training loss: 0.00004783
INFO:root:[146,   550] training loss: 0.00036607
INFO:root:[146,   600] training loss: 0.00026040
INFO:root:[146,   650] training loss: 0.00016262
INFO:root:[146,   700] training loss: 0.00016304
INFO:root:[146,   750] training loss: 0.00151372
INFO:root:[146,   800] training loss: 0.00173093
INFO:root:[146,   850] training loss: 0.00164661
INFO:root:[146,   900] training loss: 0.00818574
INFO:root:[146,   950] training loss: 0.00343959
INFO:root:[146,  1000] training loss: 0.00002266
INFO:root:[146,  1050] training loss: 0.00002132
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9250    0.8250    0.8722      1720
   Telophase     0.7809    0.8014    0.7910      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6456    0.6905    0.6673      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7784      3872
   macro avg     0.6130    0.7385    0.6572      3872
weighted avg     0.7986    0.7784    0.7858      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch146
INFO:root:[147,    50] training loss: 0.00938603
INFO:root:[147,   100] training loss: 0.01178751
INFO:root:[147,   150] training loss: 0.01016127
INFO:root:[147,   200] training loss: 0.01046294
INFO:root:[147,   250] training loss: 0.00961747
INFO:root:[147,   300] training loss: 0.01021423
INFO:root:[147,   350] training loss: 0.00853552
INFO:root:[147,   400] training loss: 0.00002003
INFO:root:[147,   450] training loss: 0.00002551
INFO:root:[147,   500] training loss: 0.00004555
INFO:root:[147,   550] training loss: 0.00038266
INFO:root:[147,   600] training loss: 0.00027930
INFO:root:[147,   650] training loss: 0.00010773
INFO:root:[147,   700] training loss: 0.00015863
INFO:root:[147,   750] training loss: 0.00155327
INFO:root:[147,   800] training loss: 0.00174415
INFO:root:[147,   850] training loss: 0.00141021
INFO:root:[147,   900] training loss: 0.00754928
INFO:root:[147,   950] training loss: 0.00305413
INFO:root:[147,  1000] training loss: 0.00003013
INFO:root:[147,  1050] training loss: 0.00002377
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9251    0.8262    0.8729      1720
   Telophase     0.7807    0.8004    0.7904      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6467    0.6905    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7787      3872
   macro avg     0.6129    0.7385    0.6571      3872
weighted avg     0.7988    0.7787    0.7861      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch147
INFO:root:[148,    50] training loss: 0.00928667
INFO:root:[148,   100] training loss: 0.00957965
INFO:root:[148,   150] training loss: 0.01038378
INFO:root:[148,   200] training loss: 0.00938448
INFO:root:[148,   250] training loss: 0.00935571
INFO:root:[148,   300] training loss: 0.01050857
INFO:root:[148,   350] training loss: 0.00825963
INFO:root:[148,   400] training loss: 0.00001891
INFO:root:[148,   450] training loss: 0.00003308
INFO:root:[148,   500] training loss: 0.00004812
INFO:root:[148,   550] training loss: 0.00039699
INFO:root:[148,   600] training loss: 0.00024363
INFO:root:[148,   650] training loss: 0.00012261
INFO:root:[148,   700] training loss: 0.00015404
INFO:root:[148,   750] training loss: 0.00147993
INFO:root:[148,   800] training loss: 0.00198893
INFO:root:[148,   850] training loss: 0.00150564
INFO:root:[148,   900] training loss: 0.00791591
INFO:root:[148,   950] training loss: 0.00404812
INFO:root:[148,  1000] training loss: 0.00002459
INFO:root:[148,  1050] training loss: 0.00002249
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9251    0.8262    0.8729      1720
   Telophase     0.7809    0.8014    0.7910      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6467    0.6905    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7789      3872
   macro avg     0.6132    0.7387    0.6574      3872
weighted avg     0.7989    0.7789    0.7863      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch148
INFO:root:[149,    50] training loss: 0.00980619
INFO:root:[149,   100] training loss: 0.00944577
INFO:root:[149,   150] training loss: 0.01004109
INFO:root:[149,   200] training loss: 0.00970276
INFO:root:[149,   250] training loss: 0.00999244
INFO:root:[149,   300] training loss: 0.01014437
INFO:root:[149,   350] training loss: 0.00830414
INFO:root:[149,   400] training loss: 0.00001847
INFO:root:[149,   450] training loss: 0.00002517
INFO:root:[149,   500] training loss: 0.00007563
INFO:root:[149,   550] training loss: 0.00042804
INFO:root:[149,   600] training loss: 0.00025376
INFO:root:[149,   650] training loss: 0.00011852
INFO:root:[149,   700] training loss: 0.00014117
INFO:root:[149,   750] training loss: 0.00151806
INFO:root:[149,   800] training loss: 0.00174683
INFO:root:[149,   850] training loss: 0.00152850
INFO:root:[149,   900] training loss: 0.00782471
INFO:root:[149,   950] training loss: 0.00305006
INFO:root:[149,  1000] training loss: 0.00002214
INFO:root:[149,  1050] training loss: 0.00002361
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9251    0.8262    0.8729      1720
   Telophase     0.7807    0.8004    0.7904      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6467    0.6905    0.6679      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7787      3872
   macro avg     0.6129    0.7385    0.6571      3872
weighted avg     0.7988    0.7787    0.7861      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch149
INFO:root:[150,    50] training loss: 0.00978479
INFO:root:[150,   100] training loss: 0.01067123
INFO:root:[150,   150] training loss: 0.01092042
INFO:root:[150,   200] training loss: 0.01002764
INFO:root:[150,   250] training loss: 0.01045677
INFO:root:[150,   300] training loss: 0.00986681
INFO:root:[150,   350] training loss: 0.00783656
INFO:root:[150,   400] training loss: 0.00001916
INFO:root:[150,   450] training loss: 0.00002894
INFO:root:[150,   500] training loss: 0.00005056
INFO:root:[150,   550] training loss: 0.00037134
INFO:root:[150,   600] training loss: 0.00024957
INFO:root:[150,   650] training loss: 0.00010451
INFO:root:[150,   700] training loss: 0.00018165
INFO:root:[150,   750] training loss: 0.00145673
INFO:root:[150,   800] training loss: 0.00184430
INFO:root:[150,   850] training loss: 0.00150350
INFO:root:[150,   900] training loss: 0.00813356
INFO:root:[150,   950] training loss: 0.00341653
INFO:root:[150,  1000] training loss: 0.00002295
INFO:root:[150,  1050] training loss: 0.00002159
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch150
INFO:root:[151,    50] training loss: 0.00978082
INFO:root:[151,   100] training loss: 0.01000318
INFO:root:[151,   150] training loss: 0.01175094
INFO:root:[151,   200] training loss: 0.00926926
INFO:root:[151,   250] training loss: 0.00912311
INFO:root:[151,   300] training loss: 0.01002501
INFO:root:[151,   350] training loss: 0.00800825
INFO:root:[151,   400] training loss: 0.00001851
INFO:root:[151,   450] training loss: 0.00003059
INFO:root:[151,   500] training loss: 0.00004612
INFO:root:[151,   550] training loss: 0.00037095
INFO:root:[151,   600] training loss: 0.00024468
INFO:root:[151,   650] training loss: 0.00013127
INFO:root:[151,   700] training loss: 0.00014589
INFO:root:[151,   750] training loss: 0.00157305
INFO:root:[151,   800] training loss: 0.00166705
INFO:root:[151,   850] training loss: 0.00149479
INFO:root:[151,   900] training loss: 0.00864618
INFO:root:[151,   950] training loss: 0.00268998
INFO:root:[151,  1000] training loss: 0.00002482
INFO:root:[151,  1050] training loss: 0.00002030
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch151
INFO:root:[152,    50] training loss: 0.00975380
INFO:root:[152,   100] training loss: 0.01033455
INFO:root:[152,   150] training loss: 0.01031000
INFO:root:[152,   200] training loss: 0.00940363
INFO:root:[152,   250] training loss: 0.01004168
INFO:root:[152,   300] training loss: 0.01025410
INFO:root:[152,   350] training loss: 0.00877525
INFO:root:[152,   400] training loss: 0.00001848
INFO:root:[152,   450] training loss: 0.00002567
INFO:root:[152,   500] training loss: 0.00005179
INFO:root:[152,   550] training loss: 0.00039238
INFO:root:[152,   600] training loss: 0.00027445
INFO:root:[152,   650] training loss: 0.00010793
INFO:root:[152,   700] training loss: 0.00017271
INFO:root:[152,   750] training loss: 0.00159361
INFO:root:[152,   800] training loss: 0.00166922
INFO:root:[152,   850] training loss: 0.00172370
INFO:root:[152,   900] training loss: 0.00782573
INFO:root:[152,   950] training loss: 0.00303648
INFO:root:[152,  1000] training loss: 0.00002264
INFO:root:[152,  1050] training loss: 0.00002139
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch152
INFO:root:[153,    50] training loss: 0.00935366
INFO:root:[153,   100] training loss: 0.01017287
INFO:root:[153,   150] training loss: 0.01114812
INFO:root:[153,   200] training loss: 0.01092108
INFO:root:[153,   250] training loss: 0.00979500
INFO:root:[153,   300] training loss: 0.01074702
INFO:root:[153,   350] training loss: 0.00921287
INFO:root:[153,   400] training loss: 0.00001849
INFO:root:[153,   450] training loss: 0.00002523
INFO:root:[153,   500] training loss: 0.00004893
INFO:root:[153,   550] training loss: 0.00035471
INFO:root:[153,   600] training loss: 0.00023970
INFO:root:[153,   650] training loss: 0.00011566
INFO:root:[153,   700] training loss: 0.00017616
INFO:root:[153,   750] training loss: 0.00146383
INFO:root:[153,   800] training loss: 0.00176645
INFO:root:[153,   850] training loss: 0.00158915
INFO:root:[153,   900] training loss: 0.00740260
INFO:root:[153,   950] training loss: 0.00364157
INFO:root:[153,  1000] training loss: 0.00002228
INFO:root:[153,  1050] training loss: 0.00002480
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch153
INFO:root:[154,    50] training loss: 0.01012517
INFO:root:[154,   100] training loss: 0.01003261
INFO:root:[154,   150] training loss: 0.01109110
INFO:root:[154,   200] training loss: 0.00977019
INFO:root:[154,   250] training loss: 0.00996490
INFO:root:[154,   300] training loss: 0.01029429
INFO:root:[154,   350] training loss: 0.00807303
INFO:root:[154,   400] training loss: 0.00002021
INFO:root:[154,   450] training loss: 0.00002638
INFO:root:[154,   500] training loss: 0.00005858
INFO:root:[154,   550] training loss: 0.00036775
INFO:root:[154,   600] training loss: 0.00026545
INFO:root:[154,   650] training loss: 0.00012090
INFO:root:[154,   700] training loss: 0.00016938
INFO:root:[154,   750] training loss: 0.00151307
INFO:root:[154,   800] training loss: 0.00178641
INFO:root:[154,   850] training loss: 0.00152406
INFO:root:[154,   900] training loss: 0.00815720
INFO:root:[154,   950] training loss: 0.00296286
INFO:root:[154,  1000] training loss: 0.00002360
INFO:root:[154,  1050] training loss: 0.00002064
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch154
INFO:root:[155,    50] training loss: 0.01055825
INFO:root:[155,   100] training loss: 0.01041565
INFO:root:[155,   150] training loss: 0.01071618
INFO:root:[155,   200] training loss: 0.00977899
INFO:root:[155,   250] training loss: 0.00933632
INFO:root:[155,   300] training loss: 0.01085689
INFO:root:[155,   350] training loss: 0.00813126
INFO:root:[155,   400] training loss: 0.00001977
INFO:root:[155,   450] training loss: 0.00002600
INFO:root:[155,   500] training loss: 0.00005271
INFO:root:[155,   550] training loss: 0.00030661
INFO:root:[155,   600] training loss: 0.00026862
INFO:root:[155,   650] training loss: 0.00014732
INFO:root:[155,   700] training loss: 0.00014336
INFO:root:[155,   750] training loss: 0.00147134
INFO:root:[155,   800] training loss: 0.00172531
INFO:root:[155,   850] training loss: 0.00140247
INFO:root:[155,   900] training loss: 0.00816207
INFO:root:[155,   950] training loss: 0.00369433
INFO:root:[155,  1000] training loss: 0.00002230
INFO:root:[155,  1050] training loss: 0.00002110
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch155
INFO:root:[156,    50] training loss: 0.00910612
INFO:root:[156,   100] training loss: 0.01025919
INFO:root:[156,   150] training loss: 0.01005436
INFO:root:[156,   200] training loss: 0.01001572
INFO:root:[156,   250] training loss: 0.00943285
INFO:root:[156,   300] training loss: 0.01114359
INFO:root:[156,   350] training loss: 0.00834261
INFO:root:[156,   400] training loss: 0.00001931
INFO:root:[156,   450] training loss: 0.00006766
INFO:root:[156,   500] training loss: 0.00004754
INFO:root:[156,   550] training loss: 0.00033861
INFO:root:[156,   600] training loss: 0.00025012
INFO:root:[156,   650] training loss: 0.00014198
INFO:root:[156,   700] training loss: 0.00014138
INFO:root:[156,   750] training loss: 0.00139594
INFO:root:[156,   800] training loss: 0.00168491
INFO:root:[156,   850] training loss: 0.00156421
INFO:root:[156,   900] training loss: 0.00846285
INFO:root:[156,   950] training loss: 0.00309433
INFO:root:[156,  1000] training loss: 0.00003260
INFO:root:[156,  1050] training loss: 0.00002609
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch156
INFO:root:[157,    50] training loss: 0.00949986
INFO:root:[157,   100] training loss: 0.01004552
INFO:root:[157,   150] training loss: 0.01096545
INFO:root:[157,   200] training loss: 0.00986396
INFO:root:[157,   250] training loss: 0.00998045
INFO:root:[157,   300] training loss: 0.01000265
INFO:root:[157,   350] training loss: 0.00834487
INFO:root:[157,   400] training loss: 0.00001915
INFO:root:[157,   450] training loss: 0.00002821
INFO:root:[157,   500] training loss: 0.00007074
INFO:root:[157,   550] training loss: 0.00037777
INFO:root:[157,   600] training loss: 0.00026376
INFO:root:[157,   650] training loss: 0.00010298
INFO:root:[157,   700] training loss: 0.00015291
INFO:root:[157,   750] training loss: 0.00146620
INFO:root:[157,   800] training loss: 0.00164043
INFO:root:[157,   850] training loss: 0.00162192
INFO:root:[157,   900] training loss: 0.00793700
INFO:root:[157,   950] training loss: 0.00301790
INFO:root:[157,  1000] training loss: 0.00002160
INFO:root:[157,  1050] training loss: 0.00002517
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch157
INFO:root:[158,    50] training loss: 0.00960668
INFO:root:[158,   100] training loss: 0.00970846
INFO:root:[158,   150] training loss: 0.01027927
INFO:root:[158,   200] training loss: 0.01002922
INFO:root:[158,   250] training loss: 0.00979580
INFO:root:[158,   300] training loss: 0.01153246
INFO:root:[158,   350] training loss: 0.00800166
INFO:root:[158,   400] training loss: 0.00001692
INFO:root:[158,   450] training loss: 0.00002544
INFO:root:[158,   500] training loss: 0.00005124
INFO:root:[158,   550] training loss: 0.00036776
INFO:root:[158,   600] training loss: 0.00029310
INFO:root:[158,   650] training loss: 0.00011162
INFO:root:[158,   700] training loss: 0.00014213
INFO:root:[158,   750] training loss: 0.00157478
INFO:root:[158,   800] training loss: 0.00174316
INFO:root:[158,   850] training loss: 0.00159584
INFO:root:[158,   900] training loss: 0.00829972
INFO:root:[158,   950] training loss: 0.00318493
INFO:root:[158,  1000] training loss: 0.00002193
INFO:root:[158,  1050] training loss: 0.00001956
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch158
INFO:root:[159,    50] training loss: 0.00976731
INFO:root:[159,   100] training loss: 0.00979443
INFO:root:[159,   150] training loss: 0.01025565
INFO:root:[159,   200] training loss: 0.00972396
INFO:root:[159,   250] training loss: 0.01027937
INFO:root:[159,   300] training loss: 0.01089365
INFO:root:[159,   350] training loss: 0.00812628
INFO:root:[159,   400] training loss: 0.00001878
INFO:root:[159,   450] training loss: 0.00002435
INFO:root:[159,   500] training loss: 0.00004504
INFO:root:[159,   550] training loss: 0.00031158
INFO:root:[159,   600] training loss: 0.00023562
INFO:root:[159,   650] training loss: 0.00011389
INFO:root:[159,   700] training loss: 0.00014091
INFO:root:[159,   750] training loss: 0.00154198
INFO:root:[159,   800] training loss: 0.00195863
INFO:root:[159,   850] training loss: 0.00152179
INFO:root:[159,   900] training loss: 0.00811877
INFO:root:[159,   950] training loss: 0.00317687
INFO:root:[159,  1000] training loss: 0.00002235
INFO:root:[159,  1050] training loss: 0.00003040
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch159
INFO:root:[160,    50] training loss: 0.00947158
INFO:root:[160,   100] training loss: 0.00998659
INFO:root:[160,   150] training loss: 0.00970803
INFO:root:[160,   200] training loss: 0.00912590
INFO:root:[160,   250] training loss: 0.00973087
INFO:root:[160,   300] training loss: 0.01076820
INFO:root:[160,   350] training loss: 0.00876859
INFO:root:[160,   400] training loss: 0.00001652
INFO:root:[160,   450] training loss: 0.00003015
INFO:root:[160,   500] training loss: 0.00004060
INFO:root:[160,   550] training loss: 0.00036536
INFO:root:[160,   600] training loss: 0.00021009
INFO:root:[160,   650] training loss: 0.00011865
INFO:root:[160,   700] training loss: 0.00013180
INFO:root:[160,   750] training loss: 0.00154543
INFO:root:[160,   800] training loss: 0.00172883
INFO:root:[160,   850] training loss: 0.00166084
INFO:root:[160,   900] training loss: 0.00900044
INFO:root:[160,   950] training loss: 0.00325792
INFO:root:[160,  1000] training loss: 0.00002066
INFO:root:[160,  1050] training loss: 0.00002489
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch160
INFO:root:[161,    50] training loss: 0.00995510
INFO:root:[161,   100] training loss: 0.01018228
INFO:root:[161,   150] training loss: 0.01206608
INFO:root:[161,   200] training loss: 0.00978579
INFO:root:[161,   250] training loss: 0.01003450
INFO:root:[161,   300] training loss: 0.01030765
INFO:root:[161,   350] training loss: 0.00839438
INFO:root:[161,   400] training loss: 0.00001908
INFO:root:[161,   450] training loss: 0.00002512
INFO:root:[161,   500] training loss: 0.00006295
INFO:root:[161,   550] training loss: 0.00040251
INFO:root:[161,   600] training loss: 0.00024631
INFO:root:[161,   650] training loss: 0.00011402
INFO:root:[161,   700] training loss: 0.00015165
INFO:root:[161,   750] training loss: 0.00156500
INFO:root:[161,   800] training loss: 0.00173081
INFO:root:[161,   850] training loss: 0.00168389
INFO:root:[161,   900] training loss: 0.00866892
INFO:root:[161,   950] training loss: 0.00316267
INFO:root:[161,  1000] training loss: 0.00002510
INFO:root:[161,  1050] training loss: 0.00002208
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch161
INFO:root:[162,    50] training loss: 0.00939592
INFO:root:[162,   100] training loss: 0.00981828
INFO:root:[162,   150] training loss: 0.01035847
INFO:root:[162,   200] training loss: 0.00968821
INFO:root:[162,   250] training loss: 0.00946668
INFO:root:[162,   300] training loss: 0.01009436
INFO:root:[162,   350] training loss: 0.00817176
INFO:root:[162,   400] training loss: 0.00001801
INFO:root:[162,   450] training loss: 0.00002615
INFO:root:[162,   500] training loss: 0.00007386
INFO:root:[162,   550] training loss: 0.00038678
INFO:root:[162,   600] training loss: 0.00025871
INFO:root:[162,   650] training loss: 0.00012473
INFO:root:[162,   700] training loss: 0.00015767
INFO:root:[162,   750] training loss: 0.00153067
INFO:root:[162,   800] training loss: 0.00171161
INFO:root:[162,   850] training loss: 0.00161854
INFO:root:[162,   900] training loss: 0.00866839
INFO:root:[162,   950] training loss: 0.00318522
INFO:root:[162,  1000] training loss: 0.00002506
INFO:root:[162,  1050] training loss: 0.00002274
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch162
INFO:root:[163,    50] training loss: 0.00952510
INFO:root:[163,   100] training loss: 0.00970070
INFO:root:[163,   150] training loss: 0.00999558
INFO:root:[163,   200] training loss: 0.01010129
INFO:root:[163,   250] training loss: 0.00956773
INFO:root:[163,   300] training loss: 0.01081422
INFO:root:[163,   350] training loss: 0.00861973
INFO:root:[163,   400] training loss: 0.00001991
INFO:root:[163,   450] training loss: 0.00002792
INFO:root:[163,   500] training loss: 0.00005768
INFO:root:[163,   550] training loss: 0.00039456
INFO:root:[163,   600] training loss: 0.00026349
INFO:root:[163,   650] training loss: 0.00012568
INFO:root:[163,   700] training loss: 0.00016292
INFO:root:[163,   750] training loss: 0.00148725
INFO:root:[163,   800] training loss: 0.00151154
INFO:root:[163,   850] training loss: 0.00167159
INFO:root:[163,   900] training loss: 0.00819746
INFO:root:[163,   950] training loss: 0.00332062
INFO:root:[163,  1000] training loss: 0.00002498
INFO:root:[163,  1050] training loss: 0.00001947
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7800    0.8004    0.7901      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6455    0.6886    0.6664      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7782      3872
   macro avg     0.6128    0.7383    0.6570      3872
weighted avg     0.7981    0.7782    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch163
INFO:root:[164,    50] training loss: 0.00963259
INFO:root:[164,   100] training loss: 0.00981167
INFO:root:[164,   150] training loss: 0.01037663
INFO:root:[164,   200] training loss: 0.00992541
INFO:root:[164,   250] training loss: 0.00924819
INFO:root:[164,   300] training loss: 0.01111255
INFO:root:[164,   350] training loss: 0.00809095
INFO:root:[164,   400] training loss: 0.00001810
INFO:root:[164,   450] training loss: 0.00003097
INFO:root:[164,   500] training loss: 0.00006668
INFO:root:[164,   550] training loss: 0.00033446
INFO:root:[164,   600] training loss: 0.00026879
INFO:root:[164,   650] training loss: 0.00012942
INFO:root:[164,   700] training loss: 0.00014820
INFO:root:[164,   750] training loss: 0.00157066
INFO:root:[164,   800] training loss: 0.00185793
INFO:root:[164,   850] training loss: 0.00157514
INFO:root:[164,   900] training loss: 0.00819624
INFO:root:[164,   950] training loss: 0.00283746
INFO:root:[164,  1000] training loss: 0.00002314
INFO:root:[164,  1050] training loss: 0.00002465
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch164
INFO:root:[165,    50] training loss: 0.00911259
INFO:root:[165,   100] training loss: 0.00956813
INFO:root:[165,   150] training loss: 0.01020279
INFO:root:[165,   200] training loss: 0.01009529
INFO:root:[165,   250] training loss: 0.00962659
INFO:root:[165,   300] training loss: 0.01049617
INFO:root:[165,   350] training loss: 0.00887361
INFO:root:[165,   400] training loss: 0.00001880
INFO:root:[165,   450] training loss: 0.00003093
INFO:root:[165,   500] training loss: 0.00004464
INFO:root:[165,   550] training loss: 0.00031927
INFO:root:[165,   600] training loss: 0.00025325
INFO:root:[165,   650] training loss: 0.00012575
INFO:root:[165,   700] training loss: 0.00016954
INFO:root:[165,   750] training loss: 0.00147841
INFO:root:[165,   800] training loss: 0.00173759
INFO:root:[165,   850] training loss: 0.00162179
INFO:root:[165,   900] training loss: 0.00885044
INFO:root:[165,   950] training loss: 0.00327966
INFO:root:[165,  1000] training loss: 0.00002400
INFO:root:[165,  1050] training loss: 0.00002310
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch165
INFO:root:[166,    50] training loss: 0.00958057
INFO:root:[166,   100] training loss: 0.00962025
INFO:root:[166,   150] training loss: 0.01003588
INFO:root:[166,   200] training loss: 0.00945282
INFO:root:[166,   250] training loss: 0.01029144
INFO:root:[166,   300] training loss: 0.01145237
INFO:root:[166,   350] training loss: 0.00948037
INFO:root:[166,   400] training loss: 0.00001945
INFO:root:[166,   450] training loss: 0.00002673
INFO:root:[166,   500] training loss: 0.00008026
INFO:root:[166,   550] training loss: 0.00031847
INFO:root:[166,   600] training loss: 0.00027232
INFO:root:[166,   650] training loss: 0.00015786
INFO:root:[166,   700] training loss: 0.00014986
INFO:root:[166,   750] training loss: 0.00160610
INFO:root:[166,   800] training loss: 0.00161213
INFO:root:[166,   850] training loss: 0.00150063
INFO:root:[166,   900] training loss: 0.00789602
INFO:root:[166,   950] training loss: 0.00286296
INFO:root:[166,  1000] training loss: 0.00002363
INFO:root:[166,  1050] training loss: 0.00002486
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch166
INFO:root:[167,    50] training loss: 0.00936655
INFO:root:[167,   100] training loss: 0.00960158
INFO:root:[167,   150] training loss: 0.01007379
INFO:root:[167,   200] training loss: 0.01036799
INFO:root:[167,   250] training loss: 0.00968583
INFO:root:[167,   300] training loss: 0.01025438
INFO:root:[167,   350] training loss: 0.00832031
INFO:root:[167,   400] training loss: 0.00001921
INFO:root:[167,   450] training loss: 0.00002839
INFO:root:[167,   500] training loss: 0.00004786
INFO:root:[167,   550] training loss: 0.00033926
INFO:root:[167,   600] training loss: 0.00028370
INFO:root:[167,   650] training loss: 0.00011949
INFO:root:[167,   700] training loss: 0.00012342
INFO:root:[167,   750] training loss: 0.00146688
INFO:root:[167,   800] training loss: 0.00168952
INFO:root:[167,   850] training loss: 0.00160997
INFO:root:[167,   900] training loss: 0.00882409
INFO:root:[167,   950] training loss: 0.00266543
INFO:root:[167,  1000] training loss: 0.00002238
INFO:root:[167,  1050] training loss: 0.00002695
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch167
INFO:root:[168,    50] training loss: 0.00994277
INFO:root:[168,   100] training loss: 0.00981178
INFO:root:[168,   150] training loss: 0.01031237
INFO:root:[168,   200] training loss: 0.01006186
INFO:root:[168,   250] training loss: 0.00916579
INFO:root:[168,   300] training loss: 0.01062932
INFO:root:[168,   350] training loss: 0.00816360
INFO:root:[168,   400] training loss: 0.00002006
INFO:root:[168,   450] training loss: 0.00002688
INFO:root:[168,   500] training loss: 0.00005684
INFO:root:[168,   550] training loss: 0.00031974
INFO:root:[168,   600] training loss: 0.00026259
INFO:root:[168,   650] training loss: 0.00013211
INFO:root:[168,   700] training loss: 0.00014259
INFO:root:[168,   750] training loss: 0.00145021
INFO:root:[168,   800] training loss: 0.00175629
INFO:root:[168,   850] training loss: 0.00161137
INFO:root:[168,   900] training loss: 0.00870771
INFO:root:[168,   950] training loss: 0.00322865
INFO:root:[168,  1000] training loss: 0.00002716
INFO:root:[168,  1050] training loss: 0.00002137
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch168
INFO:root:[169,    50] training loss: 0.00964494
INFO:root:[169,   100] training loss: 0.00976140
INFO:root:[169,   150] training loss: 0.01020672
INFO:root:[169,   200] training loss: 0.00954560
INFO:root:[169,   250] training loss: 0.00939006
INFO:root:[169,   300] training loss: 0.01015471
INFO:root:[169,   350] training loss: 0.00794151
INFO:root:[169,   400] training loss: 0.00002028
INFO:root:[169,   450] training loss: 0.00002627
INFO:root:[169,   500] training loss: 0.00005069
INFO:root:[169,   550] training loss: 0.00040966
INFO:root:[169,   600] training loss: 0.00027765
INFO:root:[169,   650] training loss: 0.00012070
INFO:root:[169,   700] training loss: 0.00012702
INFO:root:[169,   750] training loss: 0.00170044
INFO:root:[169,   800] training loss: 0.00168128
INFO:root:[169,   850] training loss: 0.00160914
INFO:root:[169,   900] training loss: 0.00838859
INFO:root:[169,   950] training loss: 0.00284605
INFO:root:[169,  1000] training loss: 0.00002208
INFO:root:[169,  1050] training loss: 0.00002016
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch169
INFO:root:[170,    50] training loss: 0.00936703
INFO:root:[170,   100] training loss: 0.00984286
INFO:root:[170,   150] training loss: 0.00991151
INFO:root:[170,   200] training loss: 0.01016086
INFO:root:[170,   250] training loss: 0.00971265
INFO:root:[170,   300] training loss: 0.01025922
INFO:root:[170,   350] training loss: 0.00782430
INFO:root:[170,   400] training loss: 0.00001967
INFO:root:[170,   450] training loss: 0.00002681
INFO:root:[170,   500] training loss: 0.00005290
INFO:root:[170,   550] training loss: 0.00034882
INFO:root:[170,   600] training loss: 0.00024652
INFO:root:[170,   650] training loss: 0.00015026
INFO:root:[170,   700] training loss: 0.00015044
INFO:root:[170,   750] training loss: 0.00149199
INFO:root:[170,   800] training loss: 0.00164224
INFO:root:[170,   850] training loss: 0.00158111
INFO:root:[170,   900] training loss: 0.00774801
INFO:root:[170,   950] training loss: 0.00327541
INFO:root:[170,  1000] training loss: 0.00002403
INFO:root:[170,  1050] training loss: 0.00002613
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch170
INFO:root:[171,    50] training loss: 0.00919649
INFO:root:[171,   100] training loss: 0.01072866
INFO:root:[171,   150] training loss: 0.01012640
INFO:root:[171,   200] training loss: 0.01010857
INFO:root:[171,   250] training loss: 0.00925664
INFO:root:[171,   300] training loss: 0.01085891
INFO:root:[171,   350] training loss: 0.00812000
INFO:root:[171,   400] training loss: 0.00001973
INFO:root:[171,   450] training loss: 0.00002713
INFO:root:[171,   500] training loss: 0.00004760
INFO:root:[171,   550] training loss: 0.00042890
INFO:root:[171,   600] training loss: 0.00032642
INFO:root:[171,   650] training loss: 0.00011949
INFO:root:[171,   700] training loss: 0.00012280
INFO:root:[171,   750] training loss: 0.00151190
INFO:root:[171,   800] training loss: 0.00163832
INFO:root:[171,   850] training loss: 0.00169163
INFO:root:[171,   900] training loss: 0.00845439
INFO:root:[171,   950] training loss: 0.00289692
INFO:root:[171,  1000] training loss: 0.00002531
INFO:root:[171,  1050] training loss: 0.00002560
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch171
INFO:root:[172,    50] training loss: 0.00981004
INFO:root:[172,   100] training loss: 0.00997224
INFO:root:[172,   150] training loss: 0.01025528
INFO:root:[172,   200] training loss: 0.01156546
INFO:root:[172,   250] training loss: 0.00977000
INFO:root:[172,   300] training loss: 0.01019173
INFO:root:[172,   350] training loss: 0.00794770
INFO:root:[172,   400] training loss: 0.00001717
INFO:root:[172,   450] training loss: 0.00003427
INFO:root:[172,   500] training loss: 0.00004653
INFO:root:[172,   550] training loss: 0.00040390
INFO:root:[172,   600] training loss: 0.00024636
INFO:root:[172,   650] training loss: 0.00012129
INFO:root:[172,   700] training loss: 0.00014331
INFO:root:[172,   750] training loss: 0.00143785
INFO:root:[172,   800] training loss: 0.00177534
INFO:root:[172,   850] training loss: 0.00145275
INFO:root:[172,   900] training loss: 0.00833322
INFO:root:[172,   950] training loss: 0.00265934
INFO:root:[172,  1000] training loss: 0.00002799
INFO:root:[172,  1050] training loss: 0.00002014
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch172
INFO:root:[173,    50] training loss: 0.00992525
INFO:root:[173,   100] training loss: 0.01015653
INFO:root:[173,   150] training loss: 0.00980658
INFO:root:[173,   200] training loss: 0.01018094
INFO:root:[173,   250] training loss: 0.00990688
INFO:root:[173,   300] training loss: 0.01073114
INFO:root:[173,   350] training loss: 0.00802692
INFO:root:[173,   400] training loss: 0.00001832
INFO:root:[173,   450] training loss: 0.00002550
INFO:root:[173,   500] training loss: 0.00007939
INFO:root:[173,   550] training loss: 0.00037275
INFO:root:[173,   600] training loss: 0.00026411
INFO:root:[173,   650] training loss: 0.00012759
INFO:root:[173,   700] training loss: 0.00016488
INFO:root:[173,   750] training loss: 0.00141040
INFO:root:[173,   800] training loss: 0.00166354
INFO:root:[173,   850] training loss: 0.00149198
INFO:root:[173,   900] training loss: 0.00763244
INFO:root:[173,   950] training loss: 0.00320600
INFO:root:[173,  1000] training loss: 0.00002366
INFO:root:[173,  1050] training loss: 0.00002346
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch173
INFO:root:[174,    50] training loss: 0.00983615
INFO:root:[174,   100] training loss: 0.01051705
INFO:root:[174,   150] training loss: 0.01133375
INFO:root:[174,   200] training loss: 0.00976690
INFO:root:[174,   250] training loss: 0.00943089
INFO:root:[174,   300] training loss: 0.01040206
INFO:root:[174,   350] training loss: 0.00803471
INFO:root:[174,   400] training loss: 0.00001868
INFO:root:[174,   450] training loss: 0.00002902
INFO:root:[174,   500] training loss: 0.00006523
INFO:root:[174,   550] training loss: 0.00037878
INFO:root:[174,   600] training loss: 0.00022419
INFO:root:[174,   650] training loss: 0.00012610
INFO:root:[174,   700] training loss: 0.00014659
INFO:root:[174,   750] training loss: 0.00151501
INFO:root:[174,   800] training loss: 0.00166567
INFO:root:[174,   850] training loss: 0.00156139
INFO:root:[174,   900] training loss: 0.00809528
INFO:root:[174,   950] training loss: 0.00335065
INFO:root:[174,  1000] training loss: 0.00002005
INFO:root:[174,  1050] training loss: 0.00002190
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch174
INFO:root:[175,    50] training loss: 0.00966980
INFO:root:[175,   100] training loss: 0.00972317
INFO:root:[175,   150] training loss: 0.01036462
INFO:root:[175,   200] training loss: 0.00975926
INFO:root:[175,   250] training loss: 0.00945211
INFO:root:[175,   300] training loss: 0.01168548
INFO:root:[175,   350] training loss: 0.00820970
INFO:root:[175,   400] training loss: 0.00001942
INFO:root:[175,   450] training loss: 0.00003025
INFO:root:[175,   500] training loss: 0.00005784
INFO:root:[175,   550] training loss: 0.00040084
INFO:root:[175,   600] training loss: 0.00023376
INFO:root:[175,   650] training loss: 0.00013597
INFO:root:[175,   700] training loss: 0.00016345
INFO:root:[175,   750] training loss: 0.00136142
INFO:root:[175,   800] training loss: 0.00181921
INFO:root:[175,   850] training loss: 0.00150802
INFO:root:[175,   900] training loss: 0.00840125
INFO:root:[175,   950] training loss: 0.00322570
INFO:root:[175,  1000] training loss: 0.00001997
INFO:root:[175,  1050] training loss: 0.00002500
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch175
INFO:root:[176,    50] training loss: 0.00947809
INFO:root:[176,   100] training loss: 0.01038433
INFO:root:[176,   150] training loss: 0.00970033
INFO:root:[176,   200] training loss: 0.00927489
INFO:root:[176,   250] training loss: 0.00967054
INFO:root:[176,   300] training loss: 0.01063845
INFO:root:[176,   350] training loss: 0.00832316
INFO:root:[176,   400] training loss: 0.00001823
INFO:root:[176,   450] training loss: 0.00002387
INFO:root:[176,   500] training loss: 0.00009168
INFO:root:[176,   550] training loss: 0.00037619
INFO:root:[176,   600] training loss: 0.00023528
INFO:root:[176,   650] training loss: 0.00012161
INFO:root:[176,   700] training loss: 0.00014892
INFO:root:[176,   750] training loss: 0.00137824
INFO:root:[176,   800] training loss: 0.00188489
INFO:root:[176,   850] training loss: 0.00141785
INFO:root:[176,   900] training loss: 0.00755597
INFO:root:[176,   950] training loss: 0.00388734
INFO:root:[176,  1000] training loss: 0.00003344
INFO:root:[176,  1050] training loss: 0.00001742
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch176
INFO:root:[177,    50] training loss: 0.00931143
INFO:root:[177,   100] training loss: 0.00985685
INFO:root:[177,   150] training loss: 0.01033170
INFO:root:[177,   200] training loss: 0.01010752
INFO:root:[177,   250] training loss: 0.00902484
INFO:root:[177,   300] training loss: 0.01045230
INFO:root:[177,   350] training loss: 0.00826240
INFO:root:[177,   400] training loss: 0.00001837
INFO:root:[177,   450] training loss: 0.00002805
INFO:root:[177,   500] training loss: 0.00004435
INFO:root:[177,   550] training loss: 0.00039712
INFO:root:[177,   600] training loss: 0.00028047
INFO:root:[177,   650] training loss: 0.00013253
INFO:root:[177,   700] training loss: 0.00014160
INFO:root:[177,   750] training loss: 0.00154432
INFO:root:[177,   800] training loss: 0.00168802
INFO:root:[177,   850] training loss: 0.00157149
INFO:root:[177,   900] training loss: 0.00806385
INFO:root:[177,   950] training loss: 0.00289061
INFO:root:[177,  1000] training loss: 0.00002076
INFO:root:[177,  1050] training loss: 0.00002485
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch177
INFO:root:[178,    50] training loss: 0.00963791
INFO:root:[178,   100] training loss: 0.01049028
INFO:root:[178,   150] training loss: 0.01017041
INFO:root:[178,   200] training loss: 0.00973999
INFO:root:[178,   250] training loss: 0.00949626
INFO:root:[178,   300] training loss: 0.01063905
INFO:root:[178,   350] training loss: 0.00834110
INFO:root:[178,   400] training loss: 0.00001872
INFO:root:[178,   450] training loss: 0.00002813
INFO:root:[178,   500] training loss: 0.00012058
INFO:root:[178,   550] training loss: 0.00036361
INFO:root:[178,   600] training loss: 0.00023417
INFO:root:[178,   650] training loss: 0.00012970
INFO:root:[178,   700] training loss: 0.00013667
INFO:root:[178,   750] training loss: 0.00155826
INFO:root:[178,   800] training loss: 0.00174903
INFO:root:[178,   850] training loss: 0.00157290
INFO:root:[178,   900] training loss: 0.00767355
INFO:root:[178,   950] training loss: 0.00338390
INFO:root:[178,  1000] training loss: 0.00002513
INFO:root:[178,  1050] training loss: 0.00002273
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch178
INFO:root:[179,    50] training loss: 0.00919820
INFO:root:[179,   100] training loss: 0.01063154
INFO:root:[179,   150] training loss: 0.01046049
INFO:root:[179,   200] training loss: 0.00960525
INFO:root:[179,   250] training loss: 0.00945116
INFO:root:[179,   300] training loss: 0.01050187
INFO:root:[179,   350] training loss: 0.00808019
INFO:root:[179,   400] training loss: 0.00001912
INFO:root:[179,   450] training loss: 0.00002797
INFO:root:[179,   500] training loss: 0.00004659
INFO:root:[179,   550] training loss: 0.00042207
INFO:root:[179,   600] training loss: 0.00023077
INFO:root:[179,   650] training loss: 0.00015087
INFO:root:[179,   700] training loss: 0.00013664
INFO:root:[179,   750] training loss: 0.00146462
INFO:root:[179,   800] training loss: 0.00165093
INFO:root:[179,   850] training loss: 0.00164745
INFO:root:[179,   900] training loss: 0.00783282
INFO:root:[179,   950] training loss: 0.00298019
INFO:root:[179,  1000] training loss: 0.00002145
INFO:root:[179,  1050] training loss: 0.00002174
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch179
INFO:root:[180,    50] training loss: 0.00937746
INFO:root:[180,   100] training loss: 0.00960380
INFO:root:[180,   150] training loss: 0.00974767
INFO:root:[180,   200] training loss: 0.00968218
INFO:root:[180,   250] training loss: 0.00973378
INFO:root:[180,   300] training loss: 0.01038797
INFO:root:[180,   350] training loss: 0.00813924
INFO:root:[180,   400] training loss: 0.00002013
INFO:root:[180,   450] training loss: 0.00002766
INFO:root:[180,   500] training loss: 0.00005020
INFO:root:[180,   550] training loss: 0.00039266
INFO:root:[180,   600] training loss: 0.00023385
INFO:root:[180,   650] training loss: 0.00012552
INFO:root:[180,   700] training loss: 0.00014117
INFO:root:[180,   750] training loss: 0.00149646
INFO:root:[180,   800] training loss: 0.00169088
INFO:root:[180,   850] training loss: 0.00150389
INFO:root:[180,   900] training loss: 0.00773094
INFO:root:[180,   950] training loss: 0.00338030
INFO:root:[180,  1000] training loss: 0.00002335
INFO:root:[180,  1050] training loss: 0.00002639
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch180
INFO:root:[181,    50] training loss: 0.00914587
INFO:root:[181,   100] training loss: 0.00988185
INFO:root:[181,   150] training loss: 0.01025715
INFO:root:[181,   200] training loss: 0.01025922
INFO:root:[181,   250] training loss: 0.00953274
INFO:root:[181,   300] training loss: 0.01069196
INFO:root:[181,   350] training loss: 0.00838322
INFO:root:[181,   400] training loss: 0.00001774
INFO:root:[181,   450] training loss: 0.00002543
INFO:root:[181,   500] training loss: 0.00008887
INFO:root:[181,   550] training loss: 0.00034872
INFO:root:[181,   600] training loss: 0.00022780
INFO:root:[181,   650] training loss: 0.00011319
INFO:root:[181,   700] training loss: 0.00014615
INFO:root:[181,   750] training loss: 0.00145621
INFO:root:[181,   800] training loss: 0.00185694
INFO:root:[181,   850] training loss: 0.00153912
INFO:root:[181,   900] training loss: 0.00777157
INFO:root:[181,   950] training loss: 0.00285209
INFO:root:[181,  1000] training loss: 0.00003013
INFO:root:[181,  1050] training loss: 0.00002060
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch181
INFO:root:[182,    50] training loss: 0.00953515
INFO:root:[182,   100] training loss: 0.01015882
INFO:root:[182,   150] training loss: 0.01016500
INFO:root:[182,   200] training loss: 0.00964596
INFO:root:[182,   250] training loss: 0.00990381
INFO:root:[182,   300] training loss: 0.01090271
INFO:root:[182,   350] training loss: 0.00824397
INFO:root:[182,   400] training loss: 0.00001972
INFO:root:[182,   450] training loss: 0.00003169
INFO:root:[182,   500] training loss: 0.00005000
INFO:root:[182,   550] training loss: 0.00039684
INFO:root:[182,   600] training loss: 0.00022877
INFO:root:[182,   650] training loss: 0.00010982
INFO:root:[182,   700] training loss: 0.00016920
INFO:root:[182,   750] training loss: 0.00151182
INFO:root:[182,   800] training loss: 0.00169670
INFO:root:[182,   850] training loss: 0.00148588
INFO:root:[182,   900] training loss: 0.00801281
INFO:root:[182,   950] training loss: 0.00281169
INFO:root:[182,  1000] training loss: 0.00002394
INFO:root:[182,  1050] training loss: 0.00001870
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch182
INFO:root:[183,    50] training loss: 0.00953867
INFO:root:[183,   100] training loss: 0.01080287
INFO:root:[183,   150] training loss: 0.01051860
INFO:root:[183,   200] training loss: 0.00979918
INFO:root:[183,   250] training loss: 0.00914945
INFO:root:[183,   300] training loss: 0.01054457
INFO:root:[183,   350] training loss: 0.00838159
INFO:root:[183,   400] training loss: 0.00002101
INFO:root:[183,   450] training loss: 0.00002722
INFO:root:[183,   500] training loss: 0.00009725
INFO:root:[183,   550] training loss: 0.00042700
INFO:root:[183,   600] training loss: 0.00023240
INFO:root:[183,   650] training loss: 0.00013123
INFO:root:[183,   700] training loss: 0.00012904
INFO:root:[183,   750] training loss: 0.00149543
INFO:root:[183,   800] training loss: 0.00167322
INFO:root:[183,   850] training loss: 0.00154865
INFO:root:[183,   900] training loss: 0.00971359
INFO:root:[183,   950] training loss: 0.00352104
INFO:root:[183,  1000] training loss: 0.00002523
INFO:root:[183,  1050] training loss: 0.00001862
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch183
INFO:root:[184,    50] training loss: 0.00959219
INFO:root:[184,   100] training loss: 0.00989113
INFO:root:[184,   150] training loss: 0.00961201
INFO:root:[184,   200] training loss: 0.00975887
INFO:root:[184,   250] training loss: 0.00990532
INFO:root:[184,   300] training loss: 0.01052773
INFO:root:[184,   350] training loss: 0.00861667
INFO:root:[184,   400] training loss: 0.00001951
INFO:root:[184,   450] training loss: 0.00004120
INFO:root:[184,   500] training loss: 0.00006665
INFO:root:[184,   550] training loss: 0.00033550
INFO:root:[184,   600] training loss: 0.00022353
INFO:root:[184,   650] training loss: 0.00012042
INFO:root:[184,   700] training loss: 0.00012714
INFO:root:[184,   750] training loss: 0.00149562
INFO:root:[184,   800] training loss: 0.00180504
INFO:root:[184,   850] training loss: 0.00146541
INFO:root:[184,   900] training loss: 0.00720125
INFO:root:[184,   950] training loss: 0.00281268
INFO:root:[184,  1000] training loss: 0.00002488
INFO:root:[184,  1050] training loss: 0.00002358
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch184
INFO:root:[185,    50] training loss: 0.00971313
INFO:root:[185,   100] training loss: 0.00986613
INFO:root:[185,   150] training loss: 0.01061444
INFO:root:[185,   200] training loss: 0.01004364
INFO:root:[185,   250] training loss: 0.00929704
INFO:root:[185,   300] training loss: 0.01016830
INFO:root:[185,   350] training loss: 0.00821715
INFO:root:[185,   400] training loss: 0.00002348
INFO:root:[185,   450] training loss: 0.00002829
INFO:root:[185,   500] training loss: 0.00006339
INFO:root:[185,   550] training loss: 0.00034790
INFO:root:[185,   600] training loss: 0.00028457
INFO:root:[185,   650] training loss: 0.00010645
INFO:root:[185,   700] training loss: 0.00017317
INFO:root:[185,   750] training loss: 0.00147017
INFO:root:[185,   800] training loss: 0.00173607
INFO:root:[185,   850] training loss: 0.00160479
INFO:root:[185,   900] training loss: 0.00836866
INFO:root:[185,   950] training loss: 0.00303598
INFO:root:[185,  1000] training loss: 0.00002387
INFO:root:[185,  1050] training loss: 0.00001956
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch185
INFO:root:[186,    50] training loss: 0.01016044
INFO:root:[186,   100] training loss: 0.01020670
INFO:root:[186,   150] training loss: 0.01132977
INFO:root:[186,   200] training loss: 0.01010487
INFO:root:[186,   250] training loss: 0.01006229
INFO:root:[186,   300] training loss: 0.01023104
INFO:root:[186,   350] training loss: 0.00827048
INFO:root:[186,   400] training loss: 0.00001938
INFO:root:[186,   450] training loss: 0.00002840
INFO:root:[186,   500] training loss: 0.00004453
INFO:root:[186,   550] training loss: 0.00046593
INFO:root:[186,   600] training loss: 0.00026268
INFO:root:[186,   650] training loss: 0.00012293
INFO:root:[186,   700] training loss: 0.00014743
INFO:root:[186,   750] training loss: 0.00143842
INFO:root:[186,   800] training loss: 0.00178167
INFO:root:[186,   850] training loss: 0.00156684
INFO:root:[186,   900] training loss: 0.00781124
INFO:root:[186,   950] training loss: 0.00326352
INFO:root:[186,  1000] training loss: 0.00002389
INFO:root:[186,  1050] training loss: 0.00002056
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch186
INFO:root:[187,    50] training loss: 0.00963328
INFO:root:[187,   100] training loss: 0.00951877
INFO:root:[187,   150] training loss: 0.01028402
INFO:root:[187,   200] training loss: 0.00938756
INFO:root:[187,   250] training loss: 0.00930921
INFO:root:[187,   300] training loss: 0.01051725
INFO:root:[187,   350] training loss: 0.00809313
INFO:root:[187,   400] training loss: 0.00001891
INFO:root:[187,   450] training loss: 0.00002789
INFO:root:[187,   500] training loss: 0.00007612
INFO:root:[187,   550] training loss: 0.00032476
INFO:root:[187,   600] training loss: 0.00025988
INFO:root:[187,   650] training loss: 0.00012671
INFO:root:[187,   700] training loss: 0.00012862
INFO:root:[187,   750] training loss: 0.00137544
INFO:root:[187,   800] training loss: 0.00174986
INFO:root:[187,   850] training loss: 0.00172016
INFO:root:[187,   900] training loss: 0.00772725
INFO:root:[187,   950] training loss: 0.00328759
INFO:root:[187,  1000] training loss: 0.00002333
INFO:root:[187,  1050] training loss: 0.00002612
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch187
INFO:root:[188,    50] training loss: 0.00954531
INFO:root:[188,   100] training loss: 0.01003911
INFO:root:[188,   150] training loss: 0.01033438
INFO:root:[188,   200] training loss: 0.00977071
INFO:root:[188,   250] training loss: 0.01048269
INFO:root:[188,   300] training loss: 0.01093725
INFO:root:[188,   350] training loss: 0.00861332
INFO:root:[188,   400] training loss: 0.00002142
INFO:root:[188,   450] training loss: 0.00003179
INFO:root:[188,   500] training loss: 0.00005193
INFO:root:[188,   550] training loss: 0.00033819
INFO:root:[188,   600] training loss: 0.00025160
INFO:root:[188,   650] training loss: 0.00012289
INFO:root:[188,   700] training loss: 0.00017667
INFO:root:[188,   750] training loss: 0.00149679
INFO:root:[188,   800] training loss: 0.00177674
INFO:root:[188,   850] training loss: 0.00181107
INFO:root:[188,   900] training loss: 0.00794667
INFO:root:[188,   950] training loss: 0.00339137
INFO:root:[188,  1000] training loss: 0.00002361
INFO:root:[188,  1050] training loss: 0.00002075
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch188
INFO:root:[189,    50] training loss: 0.00949359
INFO:root:[189,   100] training loss: 0.01030936
INFO:root:[189,   150] training loss: 0.01034994
INFO:root:[189,   200] training loss: 0.00996760
INFO:root:[189,   250] training loss: 0.00934592
INFO:root:[189,   300] training loss: 0.01058384
INFO:root:[189,   350] training loss: 0.00856136
INFO:root:[189,   400] training loss: 0.00001675
INFO:root:[189,   450] training loss: 0.00002467
INFO:root:[189,   500] training loss: 0.00005895
INFO:root:[189,   550] training loss: 0.00037395
INFO:root:[189,   600] training loss: 0.00026364
INFO:root:[189,   650] training loss: 0.00015745
INFO:root:[189,   700] training loss: 0.00016256
INFO:root:[189,   750] training loss: 0.00154777
INFO:root:[189,   800] training loss: 0.00173020
INFO:root:[189,   850] training loss: 0.00159957
INFO:root:[189,   900] training loss: 0.00912900
INFO:root:[189,   950] training loss: 0.00342663
INFO:root:[189,  1000] training loss: 0.00002084
INFO:root:[189,  1050] training loss: 0.00002823
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch189
INFO:root:[190,    50] training loss: 0.00950796
INFO:root:[190,   100] training loss: 0.00967120
INFO:root:[190,   150] training loss: 0.01012406
INFO:root:[190,   200] training loss: 0.00994994
INFO:root:[190,   250] training loss: 0.00918446
INFO:root:[190,   300] training loss: 0.01020055
INFO:root:[190,   350] training loss: 0.00834256
INFO:root:[190,   400] training loss: 0.00001904
INFO:root:[190,   450] training loss: 0.00002948
INFO:root:[190,   500] training loss: 0.00006948
INFO:root:[190,   550] training loss: 0.00040009
INFO:root:[190,   600] training loss: 0.00024445
INFO:root:[190,   650] training loss: 0.00013065
INFO:root:[190,   700] training loss: 0.00012817
INFO:root:[190,   750] training loss: 0.00150188
INFO:root:[190,   800] training loss: 0.00172945
INFO:root:[190,   850] training loss: 0.00162969
INFO:root:[190,   900] training loss: 0.00752845
INFO:root:[190,   950] training loss: 0.00314839
INFO:root:[190,  1000] training loss: 0.00002305
INFO:root:[190,  1050] training loss: 0.00002007
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch190
INFO:root:[191,    50] training loss: 0.01012358
INFO:root:[191,   100] training loss: 0.00999357
INFO:root:[191,   150] training loss: 0.01064946
INFO:root:[191,   200] training loss: 0.00979267
INFO:root:[191,   250] training loss: 0.00941940
INFO:root:[191,   300] training loss: 0.01071666
INFO:root:[191,   350] training loss: 0.00871274
INFO:root:[191,   400] training loss: 0.00001952
INFO:root:[191,   450] training loss: 0.00002538
INFO:root:[191,   500] training loss: 0.00004006
INFO:root:[191,   550] training loss: 0.00037707
INFO:root:[191,   600] training loss: 0.00024850
INFO:root:[191,   650] training loss: 0.00010752
INFO:root:[191,   700] training loss: 0.00013894
INFO:root:[191,   750] training loss: 0.00149593
INFO:root:[191,   800] training loss: 0.00176164
INFO:root:[191,   850] training loss: 0.00166689
INFO:root:[191,   900] training loss: 0.00731565
INFO:root:[191,   950] training loss: 0.00309684
INFO:root:[191,  1000] training loss: 0.00002470
INFO:root:[191,  1050] training loss: 0.00004005
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch191
INFO:root:[192,    50] training loss: 0.01001188
INFO:root:[192,   100] training loss: 0.01132926
INFO:root:[192,   150] training loss: 0.01001612
INFO:root:[192,   200] training loss: 0.00994427
INFO:root:[192,   250] training loss: 0.01016790
INFO:root:[192,   300] training loss: 0.01067878
INFO:root:[192,   350] training loss: 0.00850266
INFO:root:[192,   400] training loss: 0.00001892
INFO:root:[192,   450] training loss: 0.00003067
INFO:root:[192,   500] training loss: 0.00004277
INFO:root:[192,   550] training loss: 0.00032982
INFO:root:[192,   600] training loss: 0.00024906
INFO:root:[192,   650] training loss: 0.00012077
INFO:root:[192,   700] training loss: 0.00015771
INFO:root:[192,   750] training loss: 0.00155331
INFO:root:[192,   800] training loss: 0.00166624
INFO:root:[192,   850] training loss: 0.00154790
INFO:root:[192,   900] training loss: 0.00853492
INFO:root:[192,   950] training loss: 0.00308645
INFO:root:[192,  1000] training loss: 0.00002371
INFO:root:[192,  1050] training loss: 0.00002297
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch192
INFO:root:[193,    50] training loss: 0.01013794
INFO:root:[193,   100] training loss: 0.01103653
INFO:root:[193,   150] training loss: 0.01022362
INFO:root:[193,   200] training loss: 0.00953150
INFO:root:[193,   250] training loss: 0.00945219
INFO:root:[193,   300] training loss: 0.01140216
INFO:root:[193,   350] training loss: 0.00832548
INFO:root:[193,   400] training loss: 0.00001903
INFO:root:[193,   450] training loss: 0.00002741
INFO:root:[193,   500] training loss: 0.00006468
INFO:root:[193,   550] training loss: 0.00035643
INFO:root:[193,   600] training loss: 0.00025588
INFO:root:[193,   650] training loss: 0.00010150
INFO:root:[193,   700] training loss: 0.00016306
INFO:root:[193,   750] training loss: 0.00152128
INFO:root:[193,   800] training loss: 0.00176600
INFO:root:[193,   850] training loss: 0.00148922
INFO:root:[193,   900] training loss: 0.00845843
INFO:root:[193,   950] training loss: 0.00315842
INFO:root:[193,  1000] training loss: 0.00002449
INFO:root:[193,  1050] training loss: 0.00002325
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch193
INFO:root:[194,    50] training loss: 0.00937568
INFO:root:[194,   100] training loss: 0.01001817
INFO:root:[194,   150] training loss: 0.00994870
INFO:root:[194,   200] training loss: 0.01048660
INFO:root:[194,   250] training loss: 0.00966977
INFO:root:[194,   300] training loss: 0.01060373
INFO:root:[194,   350] training loss: 0.00841336
INFO:root:[194,   400] training loss: 0.00001988
INFO:root:[194,   450] training loss: 0.00002825
INFO:root:[194,   500] training loss: 0.00005235
INFO:root:[194,   550] training loss: 0.00038660
INFO:root:[194,   600] training loss: 0.00028953
INFO:root:[194,   650] training loss: 0.00010910
INFO:root:[194,   700] training loss: 0.00014490
INFO:root:[194,   750] training loss: 0.00148888
INFO:root:[194,   800] training loss: 0.00173725
INFO:root:[194,   850] training loss: 0.00151020
INFO:root:[194,   900] training loss: 0.00818689
INFO:root:[194,   950] training loss: 0.00289098
INFO:root:[194,  1000] training loss: 0.00002235
INFO:root:[194,  1050] training loss: 0.00003051
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch194
INFO:root:[195,    50] training loss: 0.00979891
INFO:root:[195,   100] training loss: 0.00986438
INFO:root:[195,   150] training loss: 0.01049672
INFO:root:[195,   200] training loss: 0.00987675
INFO:root:[195,   250] training loss: 0.00948446
INFO:root:[195,   300] training loss: 0.01038745
INFO:root:[195,   350] training loss: 0.00815204
INFO:root:[195,   400] training loss: 0.00001897
INFO:root:[195,   450] training loss: 0.00002843
INFO:root:[195,   500] training loss: 0.00006826
INFO:root:[195,   550] training loss: 0.00033202
INFO:root:[195,   600] training loss: 0.00026397
INFO:root:[195,   650] training loss: 0.00013945
INFO:root:[195,   700] training loss: 0.00014821
INFO:root:[195,   750] training loss: 0.00146252
INFO:root:[195,   800] training loss: 0.00158018
INFO:root:[195,   850] training loss: 0.00145386
INFO:root:[195,   900] training loss: 0.00830048
INFO:root:[195,   950] training loss: 0.00347384
INFO:root:[195,  1000] training loss: 0.00002332
INFO:root:[195,  1050] training loss: 0.00002080
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch195
INFO:root:[196,    50] training loss: 0.00976320
INFO:root:[196,   100] training loss: 0.01016817
INFO:root:[196,   150] training loss: 0.01105176
INFO:root:[196,   200] training loss: 0.00970217
INFO:root:[196,   250] training loss: 0.00970939
INFO:root:[196,   300] training loss: 0.01012272
INFO:root:[196,   350] training loss: 0.00846618
INFO:root:[196,   400] training loss: 0.00002534
INFO:root:[196,   450] training loss: 0.00002561
INFO:root:[196,   500] training loss: 0.00007530
INFO:root:[196,   550] training loss: 0.00033355
INFO:root:[196,   600] training loss: 0.00024080
INFO:root:[196,   650] training loss: 0.00011123
INFO:root:[196,   700] training loss: 0.00017178
INFO:root:[196,   750] training loss: 0.00151544
INFO:root:[196,   800] training loss: 0.00152961
INFO:root:[196,   850] training loss: 0.00164301
INFO:root:[196,   900] training loss: 0.00785248
INFO:root:[196,   950] training loss: 0.00319940
INFO:root:[196,  1000] training loss: 0.00002239
INFO:root:[196,  1050] training loss: 0.00002516
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch196
INFO:root:[197,    50] training loss: 0.00971700
INFO:root:[197,   100] training loss: 0.00977494
INFO:root:[197,   150] training loss: 0.00986096
INFO:root:[197,   200] training loss: 0.00906099
INFO:root:[197,   250] training loss: 0.00957529
INFO:root:[197,   300] training loss: 0.00997176
INFO:root:[197,   350] training loss: 0.00805435
INFO:root:[197,   400] training loss: 0.00001752
INFO:root:[197,   450] training loss: 0.00002861
INFO:root:[197,   500] training loss: 0.00005709
INFO:root:[197,   550] training loss: 0.00039634
INFO:root:[197,   600] training loss: 0.00024035
INFO:root:[197,   650] training loss: 0.00011007
INFO:root:[197,   700] training loss: 0.00012945
INFO:root:[197,   750] training loss: 0.00145201
INFO:root:[197,   800] training loss: 0.00175497
INFO:root:[197,   850] training loss: 0.00139734
INFO:root:[197,   900] training loss: 0.00819755
INFO:root:[197,   950] training loss: 0.00274044
INFO:root:[197,  1000] training loss: 0.00002331
INFO:root:[197,  1050] training loss: 0.00002225
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch197
INFO:root:[198,    50] training loss: 0.00941033
INFO:root:[198,   100] training loss: 0.00951383
INFO:root:[198,   150] training loss: 0.01028028
INFO:root:[198,   200] training loss: 0.00989295
INFO:root:[198,   250] training loss: 0.00974124
INFO:root:[198,   300] training loss: 0.01151182
INFO:root:[198,   350] training loss: 0.00970274
INFO:root:[198,   400] training loss: 0.00002369
INFO:root:[198,   450] training loss: 0.00002437
INFO:root:[198,   500] training loss: 0.00005189
INFO:root:[198,   550] training loss: 0.00034476
INFO:root:[198,   600] training loss: 0.00025353
INFO:root:[198,   650] training loss: 0.00011632
INFO:root:[198,   700] training loss: 0.00014553
INFO:root:[198,   750] training loss: 0.00151558
INFO:root:[198,   800] training loss: 0.00161187
INFO:root:[198,   850] training loss: 0.00163313
INFO:root:[198,   900] training loss: 0.00838734
INFO:root:[198,   950] training loss: 0.00338157
INFO:root:[198,  1000] training loss: 0.00002411
INFO:root:[198,  1050] training loss: 0.00002554
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch198
INFO:root:[199,    50] training loss: 0.01012759
INFO:root:[199,   100] training loss: 0.01011799
INFO:root:[199,   150] training loss: 0.01054738
INFO:root:[199,   200] training loss: 0.01035348
INFO:root:[199,   250] training loss: 0.00985555
INFO:root:[199,   300] training loss: 0.01062669
INFO:root:[199,   350] training loss: 0.00784549
INFO:root:[199,   400] training loss: 0.00002671
INFO:root:[199,   450] training loss: 0.00002625
INFO:root:[199,   500] training loss: 0.00003837
INFO:root:[199,   550] training loss: 0.00037688
INFO:root:[199,   600] training loss: 0.00023331
INFO:root:[199,   650] training loss: 0.00011602
INFO:root:[199,   700] training loss: 0.00013471
INFO:root:[199,   750] training loss: 0.00153208
INFO:root:[199,   800] training loss: 0.00164136
INFO:root:[199,   850] training loss: 0.00155310
INFO:root:[199,   900] training loss: 0.00763533
INFO:root:[199,   950] training loss: 0.00287899
INFO:root:[199,  1000] training loss: 0.00002416
INFO:root:[199,  1050] training loss: 0.00001845
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch199
INFO:root:[200,    50] training loss: 0.00988596
INFO:root:[200,   100] training loss: 0.01082606
INFO:root:[200,   150] training loss: 0.00995923
INFO:root:[200,   200] training loss: 0.00989283
INFO:root:[200,   250] training loss: 0.00938145
INFO:root:[200,   300] training loss: 0.01037622
INFO:root:[200,   350] training loss: 0.00975077
INFO:root:[200,   400] training loss: 0.00001765
INFO:root:[200,   450] training loss: 0.00002666
INFO:root:[200,   500] training loss: 0.00005069
INFO:root:[200,   550] training loss: 0.00031052
INFO:root:[200,   600] training loss: 0.00026817
INFO:root:[200,   650] training loss: 0.00014999
INFO:root:[200,   700] training loss: 0.00013739
INFO:root:[200,   750] training loss: 0.00141363
INFO:root:[200,   800] training loss: 0.00181421
INFO:root:[200,   850] training loss: 0.00157489
INFO:root:[200,   900] training loss: 0.00774807
INFO:root:[200,   950] training loss: 0.00260891
INFO:root:[200,  1000] training loss: 0.00002354
INFO:root:[200,  1050] training loss: 0.00001999
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch200
INFO:root:[201,    50] training loss: 0.00943738
INFO:root:[201,   100] training loss: 0.01007187
INFO:root:[201,   150] training loss: 0.01032689
INFO:root:[201,   200] training loss: 0.00972837
INFO:root:[201,   250] training loss: 0.01050765
INFO:root:[201,   300] training loss: 0.01028851
INFO:root:[201,   350] training loss: 0.00824454
INFO:root:[201,   400] training loss: 0.00001913
INFO:root:[201,   450] training loss: 0.00002656
INFO:root:[201,   500] training loss: 0.00004939
INFO:root:[201,   550] training loss: 0.00032906
INFO:root:[201,   600] training loss: 0.00022538
INFO:root:[201,   650] training loss: 0.00012233
INFO:root:[201,   700] training loss: 0.00014604
INFO:root:[201,   750] training loss: 0.00150065
INFO:root:[201,   800] training loss: 0.00163755
INFO:root:[201,   850] training loss: 0.00180104
INFO:root:[201,   900] training loss: 0.00791036
INFO:root:[201,   950] training loss: 0.00314265
INFO:root:[201,  1000] training loss: 0.00002546
INFO:root:[201,  1050] training loss: 0.00002425
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch201
INFO:root:[202,    50] training loss: 0.00936735
INFO:root:[202,   100] training loss: 0.01011202
INFO:root:[202,   150] training loss: 0.00985811
INFO:root:[202,   200] training loss: 0.01041435
INFO:root:[202,   250] training loss: 0.01145154
INFO:root:[202,   300] training loss: 0.01026074
INFO:root:[202,   350] training loss: 0.00775041
INFO:root:[202,   400] training loss: 0.00002037
INFO:root:[202,   450] training loss: 0.00002703
INFO:root:[202,   500] training loss: 0.00005236
INFO:root:[202,   550] training loss: 0.00039561
INFO:root:[202,   600] training loss: 0.00023475
INFO:root:[202,   650] training loss: 0.00013914
INFO:root:[202,   700] training loss: 0.00014368
INFO:root:[202,   750] training loss: 0.00152367
INFO:root:[202,   800] training loss: 0.00159424
INFO:root:[202,   850] training loss: 0.00158760
INFO:root:[202,   900] training loss: 0.00790648
INFO:root:[202,   950] training loss: 0.00286629
INFO:root:[202,  1000] training loss: 0.00002583
INFO:root:[202,  1050] training loss: 0.00002301
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch202
INFO:root:[203,    50] training loss: 0.00916986
INFO:root:[203,   100] training loss: 0.00975061
INFO:root:[203,   150] training loss: 0.01025268
INFO:root:[203,   200] training loss: 0.00980797
INFO:root:[203,   250] training loss: 0.01000278
INFO:root:[203,   300] training loss: 0.01041930
INFO:root:[203,   350] training loss: 0.00799947
INFO:root:[203,   400] training loss: 0.00001791
INFO:root:[203,   450] training loss: 0.00002590
INFO:root:[203,   500] training loss: 0.00008152
INFO:root:[203,   550] training loss: 0.00033530
INFO:root:[203,   600] training loss: 0.00027676
INFO:root:[203,   650] training loss: 0.00012161
INFO:root:[203,   700] training loss: 0.00015388
INFO:root:[203,   750] training loss: 0.00144885
INFO:root:[203,   800] training loss: 0.00164409
INFO:root:[203,   850] training loss: 0.00166284
INFO:root:[203,   900] training loss: 0.00806178
INFO:root:[203,   950] training loss: 0.00381277
INFO:root:[203,  1000] training loss: 0.00002351
INFO:root:[203,  1050] training loss: 0.00001911
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch203
INFO:root:[204,    50] training loss: 0.01076918
INFO:root:[204,   100] training loss: 0.00995757
INFO:root:[204,   150] training loss: 0.01156036
INFO:root:[204,   200] training loss: 0.00953962
INFO:root:[204,   250] training loss: 0.00931246
INFO:root:[204,   300] training loss: 0.00985693
INFO:root:[204,   350] training loss: 0.00788184
INFO:root:[204,   400] training loss: 0.00002322
INFO:root:[204,   450] training loss: 0.00002509
INFO:root:[204,   500] training loss: 0.00007818
INFO:root:[204,   550] training loss: 0.00037899
INFO:root:[204,   600] training loss: 0.00028361
INFO:root:[204,   650] training loss: 0.00011910
INFO:root:[204,   700] training loss: 0.00012159
INFO:root:[204,   750] training loss: 0.00144512
INFO:root:[204,   800] training loss: 0.00158442
INFO:root:[204,   850] training loss: 0.00162802
INFO:root:[204,   900] training loss: 0.00855700
INFO:root:[204,   950] training loss: 0.00468570
INFO:root:[204,  1000] training loss: 0.00002312
INFO:root:[204,  1050] training loss: 0.00002407
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch204
INFO:root:[205,    50] training loss: 0.00940570
INFO:root:[205,   100] training loss: 0.00998033
INFO:root:[205,   150] training loss: 0.01021350
INFO:root:[205,   200] training loss: 0.00993476
INFO:root:[205,   250] training loss: 0.01012676
INFO:root:[205,   300] training loss: 0.01049520
INFO:root:[205,   350] training loss: 0.00831942
INFO:root:[205,   400] training loss: 0.00002505
INFO:root:[205,   450] training loss: 0.00002827
INFO:root:[205,   500] training loss: 0.00005715
INFO:root:[205,   550] training loss: 0.00035923
INFO:root:[205,   600] training loss: 0.00024370
INFO:root:[205,   650] training loss: 0.00011278
INFO:root:[205,   700] training loss: 0.00017256
INFO:root:[205,   750] training loss: 0.00140966
INFO:root:[205,   800] training loss: 0.00170099
INFO:root:[205,   850] training loss: 0.00149136
INFO:root:[205,   900] training loss: 0.00842740
INFO:root:[205,   950] training loss: 0.00300412
INFO:root:[205,  1000] training loss: 0.00002279
INFO:root:[205,  1050] training loss: 0.00002511
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch205
INFO:root:[206,    50] training loss: 0.00969973
INFO:root:[206,   100] training loss: 0.00963746
INFO:root:[206,   150] training loss: 0.00994710
INFO:root:[206,   200] training loss: 0.00944664
INFO:root:[206,   250] training loss: 0.00996094
INFO:root:[206,   300] training loss: 0.01002249
INFO:root:[206,   350] training loss: 0.00837125
INFO:root:[206,   400] training loss: 0.00001812
INFO:root:[206,   450] training loss: 0.00002761
INFO:root:[206,   500] training loss: 0.00006401
INFO:root:[206,   550] training loss: 0.00045610
INFO:root:[206,   600] training loss: 0.00024563
INFO:root:[206,   650] training loss: 0.00011636
INFO:root:[206,   700] training loss: 0.00013312
INFO:root:[206,   750] training loss: 0.00146401
INFO:root:[206,   800] training loss: 0.00179641
INFO:root:[206,   850] training loss: 0.00145334
INFO:root:[206,   900] training loss: 0.00782592
INFO:root:[206,   950] training loss: 0.00344081
INFO:root:[206,  1000] training loss: 0.00002058
INFO:root:[206,  1050] training loss: 0.00002263
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch206
INFO:root:[207,    50] training loss: 0.00993833
INFO:root:[207,   100] training loss: 0.01046200
INFO:root:[207,   150] training loss: 0.01017006
INFO:root:[207,   200] training loss: 0.00990149
INFO:root:[207,   250] training loss: 0.00965119
INFO:root:[207,   300] training loss: 0.01098900
INFO:root:[207,   350] training loss: 0.00900809
INFO:root:[207,   400] training loss: 0.00001819
INFO:root:[207,   450] training loss: 0.00002475
INFO:root:[207,   500] training loss: 0.00004916
INFO:root:[207,   550] training loss: 0.00033812
INFO:root:[207,   600] training loss: 0.00023426
INFO:root:[207,   650] training loss: 0.00012732
INFO:root:[207,   700] training loss: 0.00014894
INFO:root:[207,   750] training loss: 0.00160290
INFO:root:[207,   800] training loss: 0.00181717
INFO:root:[207,   850] training loss: 0.00146619
INFO:root:[207,   900] training loss: 0.00711927
INFO:root:[207,   950] training loss: 0.00332959
INFO:root:[207,  1000] training loss: 0.00002082
INFO:root:[207,  1050] training loss: 0.00002290
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch207
INFO:root:[208,    50] training loss: 0.00961867
INFO:root:[208,   100] training loss: 0.00976389
INFO:root:[208,   150] training loss: 0.01004855
INFO:root:[208,   200] training loss: 0.00967472
INFO:root:[208,   250] training loss: 0.01092211
INFO:root:[208,   300] training loss: 0.01025938
INFO:root:[208,   350] training loss: 0.00783639
INFO:root:[208,   400] training loss: 0.00001859
INFO:root:[208,   450] training loss: 0.00002675
INFO:root:[208,   500] training loss: 0.00011194
INFO:root:[208,   550] training loss: 0.00044951
INFO:root:[208,   600] training loss: 0.00021884
INFO:root:[208,   650] training loss: 0.00011764
INFO:root:[208,   700] training loss: 0.00014141
INFO:root:[208,   750] training loss: 0.00155368
INFO:root:[208,   800] training loss: 0.00174319
INFO:root:[208,   850] training loss: 0.00145897
INFO:root:[208,   900] training loss: 0.00798554
INFO:root:[208,   950] training loss: 0.00294769
INFO:root:[208,  1000] training loss: 0.00002255
INFO:root:[208,  1050] training loss: 0.00003065
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch208
INFO:root:[209,    50] training loss: 0.00999934
INFO:root:[209,   100] training loss: 0.00965876
INFO:root:[209,   150] training loss: 0.01032760
INFO:root:[209,   200] training loss: 0.01068993
INFO:root:[209,   250] training loss: 0.00952235
INFO:root:[209,   300] training loss: 0.01090468
INFO:root:[209,   350] training loss: 0.00870563
INFO:root:[209,   400] training loss: 0.00001801
INFO:root:[209,   450] training loss: 0.00002597
INFO:root:[209,   500] training loss: 0.00004642
INFO:root:[209,   550] training loss: 0.00037726
INFO:root:[209,   600] training loss: 0.00026814
INFO:root:[209,   650] training loss: 0.00012223
INFO:root:[209,   700] training loss: 0.00015162
INFO:root:[209,   750] training loss: 0.00151107
INFO:root:[209,   800] training loss: 0.00170895
INFO:root:[209,   850] training loss: 0.00158968
INFO:root:[209,   900] training loss: 0.00896739
INFO:root:[209,   950] training loss: 0.00351524
INFO:root:[209,  1000] training loss: 0.00002206
INFO:root:[209,  1050] training loss: 0.00002034
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch209
INFO:root:[210,    50] training loss: 0.00958603
INFO:root:[210,   100] training loss: 0.00948559
INFO:root:[210,   150] training loss: 0.00939848
INFO:root:[210,   200] training loss: 0.00988338
INFO:root:[210,   250] training loss: 0.00978265
INFO:root:[210,   300] training loss: 0.01077173
INFO:root:[210,   350] training loss: 0.00837592
INFO:root:[210,   400] training loss: 0.00001791
INFO:root:[210,   450] training loss: 0.00002742
INFO:root:[210,   500] training loss: 0.00008256
INFO:root:[210,   550] training loss: 0.00033135
INFO:root:[210,   600] training loss: 0.00024128
INFO:root:[210,   650] training loss: 0.00011409
INFO:root:[210,   700] training loss: 0.00013937
INFO:root:[210,   750] training loss: 0.00147631
INFO:root:[210,   800] training loss: 0.00176029
INFO:root:[210,   850] training loss: 0.00142978
INFO:root:[210,   900] training loss: 0.00819204
INFO:root:[210,   950] training loss: 0.00304645
INFO:root:[210,  1000] training loss: 0.00002329
INFO:root:[210,  1050] training loss: 0.00002092
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch210
INFO:root:[211,    50] training loss: 0.00927146
INFO:root:[211,   100] training loss: 0.00967144
INFO:root:[211,   150] training loss: 0.01048992
INFO:root:[211,   200] training loss: 0.01013484
INFO:root:[211,   250] training loss: 0.00989723
INFO:root:[211,   300] training loss: 0.01023615
INFO:root:[211,   350] training loss: 0.00843708
INFO:root:[211,   400] training loss: 0.00001803
INFO:root:[211,   450] training loss: 0.00002623
INFO:root:[211,   500] training loss: 0.00004509
INFO:root:[211,   550] training loss: 0.00032145
INFO:root:[211,   600] training loss: 0.00025442
INFO:root:[211,   650] training loss: 0.00014337
INFO:root:[211,   700] training loss: 0.00016477
INFO:root:[211,   750] training loss: 0.00142055
INFO:root:[211,   800] training loss: 0.00177237
INFO:root:[211,   850] training loss: 0.00165610
INFO:root:[211,   900] training loss: 0.00786143
INFO:root:[211,   950] training loss: 0.00309565
INFO:root:[211,  1000] training loss: 0.00002932
INFO:root:[211,  1050] training loss: 0.00002146
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch211
INFO:root:[212,    50] training loss: 0.00923081
INFO:root:[212,   100] training loss: 0.00965875
INFO:root:[212,   150] training loss: 0.01207788
INFO:root:[212,   200] training loss: 0.00976463
INFO:root:[212,   250] training loss: 0.00997191
INFO:root:[212,   300] training loss: 0.01134260
INFO:root:[212,   350] training loss: 0.00812341
INFO:root:[212,   400] training loss: 0.00001848
INFO:root:[212,   450] training loss: 0.00003506
INFO:root:[212,   500] training loss: 0.00006909
INFO:root:[212,   550] training loss: 0.00033767
INFO:root:[212,   600] training loss: 0.00026474
INFO:root:[212,   650] training loss: 0.00010963
INFO:root:[212,   700] training loss: 0.00014393
INFO:root:[212,   750] training loss: 0.00147887
INFO:root:[212,   800] training loss: 0.00162160
INFO:root:[212,   850] training loss: 0.00167314
INFO:root:[212,   900] training loss: 0.00824061
INFO:root:[212,   950] training loss: 0.00399680
INFO:root:[212,  1000] training loss: 0.00002423
INFO:root:[212,  1050] training loss: 0.00001941
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch212
INFO:root:[213,    50] training loss: 0.00964782
INFO:root:[213,   100] training loss: 0.01025430
INFO:root:[213,   150] training loss: 0.00993974
INFO:root:[213,   200] training loss: 0.00945536
INFO:root:[213,   250] training loss: 0.00936698
INFO:root:[213,   300] training loss: 0.01017329
INFO:root:[213,   350] training loss: 0.00797008
INFO:root:[213,   400] training loss: 0.00001938
INFO:root:[213,   450] training loss: 0.00002696
INFO:root:[213,   500] training loss: 0.00003735
INFO:root:[213,   550] training loss: 0.00034723
INFO:root:[213,   600] training loss: 0.00026814
INFO:root:[213,   650] training loss: 0.00012619
INFO:root:[213,   700] training loss: 0.00015772
INFO:root:[213,   750] training loss: 0.00141542
INFO:root:[213,   800] training loss: 0.00168542
INFO:root:[213,   850] training loss: 0.00159642
INFO:root:[213,   900] training loss: 0.00909135
INFO:root:[213,   950] training loss: 0.00349997
INFO:root:[213,  1000] training loss: 0.00002418
INFO:root:[213,  1050] training loss: 0.00002158
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch213
INFO:root:[214,    50] training loss: 0.00959603
INFO:root:[214,   100] training loss: 0.00992420
INFO:root:[214,   150] training loss: 0.01007477
INFO:root:[214,   200] training loss: 0.00954468
INFO:root:[214,   250] training loss: 0.00948254
INFO:root:[214,   300] training loss: 0.01055759
INFO:root:[214,   350] training loss: 0.00927086
INFO:root:[214,   400] training loss: 0.00001948
INFO:root:[214,   450] training loss: 0.00003286
INFO:root:[214,   500] training loss: 0.00004274
INFO:root:[214,   550] training loss: 0.00033938
INFO:root:[214,   600] training loss: 0.00023016
INFO:root:[214,   650] training loss: 0.00014350
INFO:root:[214,   700] training loss: 0.00014533
INFO:root:[214,   750] training loss: 0.00143375
INFO:root:[214,   800] training loss: 0.00170917
INFO:root:[214,   850] training loss: 0.00163638
INFO:root:[214,   900] training loss: 0.00733331
INFO:root:[214,   950] training loss: 0.00296318
INFO:root:[214,  1000] training loss: 0.00002301
INFO:root:[214,  1050] training loss: 0.00002231
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch214
INFO:root:[215,    50] training loss: 0.00904576
INFO:root:[215,   100] training loss: 0.00930963
INFO:root:[215,   150] training loss: 0.01000620
INFO:root:[215,   200] training loss: 0.01045875
INFO:root:[215,   250] training loss: 0.00995453
INFO:root:[215,   300] training loss: 0.01047324
INFO:root:[215,   350] training loss: 0.00824282
INFO:root:[215,   400] training loss: 0.00002096
INFO:root:[215,   450] training loss: 0.00002587
INFO:root:[215,   500] training loss: 0.00006047
INFO:root:[215,   550] training loss: 0.00044120
INFO:root:[215,   600] training loss: 0.00026346
INFO:root:[215,   650] training loss: 0.00013601
INFO:root:[215,   700] training loss: 0.00015866
INFO:root:[215,   750] training loss: 0.00143602
INFO:root:[215,   800] training loss: 0.00183207
INFO:root:[215,   850] training loss: 0.00170200
INFO:root:[215,   900] training loss: 0.00806514
INFO:root:[215,   950] training loss: 0.00314951
INFO:root:[215,  1000] training loss: 0.00002206
INFO:root:[215,  1050] training loss: 0.00002925
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch215
INFO:root:[216,    50] training loss: 0.00926193
INFO:root:[216,   100] training loss: 0.01008798
INFO:root:[216,   150] training loss: 0.01035769
INFO:root:[216,   200] training loss: 0.00950073
INFO:root:[216,   250] training loss: 0.00965664
INFO:root:[216,   300] training loss: 0.01059962
INFO:root:[216,   350] training loss: 0.00797097
INFO:root:[216,   400] training loss: 0.00001733
INFO:root:[216,   450] training loss: 0.00002677
INFO:root:[216,   500] training loss: 0.00004421
INFO:root:[216,   550] training loss: 0.00038443
INFO:root:[216,   600] training loss: 0.00025811
INFO:root:[216,   650] training loss: 0.00012239
INFO:root:[216,   700] training loss: 0.00013529
INFO:root:[216,   750] training loss: 0.00152716
INFO:root:[216,   800] training loss: 0.00171578
INFO:root:[216,   850] training loss: 0.00150993
INFO:root:[216,   900] training loss: 0.00822488
INFO:root:[216,   950] training loss: 0.00323845
INFO:root:[216,  1000] training loss: 0.00002272
INFO:root:[216,  1050] training loss: 0.00002220
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch216
INFO:root:[217,    50] training loss: 0.00940979
INFO:root:[217,   100] training loss: 0.00985584
INFO:root:[217,   150] training loss: 0.01010094
INFO:root:[217,   200] training loss: 0.01042433
INFO:root:[217,   250] training loss: 0.00971968
INFO:root:[217,   300] training loss: 0.01019202
INFO:root:[217,   350] training loss: 0.00840399
INFO:root:[217,   400] training loss: 0.00001985
INFO:root:[217,   450] training loss: 0.00002627
INFO:root:[217,   500] training loss: 0.00004960
INFO:root:[217,   550] training loss: 0.00033556
INFO:root:[217,   600] training loss: 0.00024612
INFO:root:[217,   650] training loss: 0.00012500
INFO:root:[217,   700] training loss: 0.00012148
INFO:root:[217,   750] training loss: 0.00149555
INFO:root:[217,   800] training loss: 0.00176920
INFO:root:[217,   850] training loss: 0.00155739
INFO:root:[217,   900] training loss: 0.00850858
INFO:root:[217,   950] training loss: 0.00290584
INFO:root:[217,  1000] training loss: 0.00003118
INFO:root:[217,  1050] training loss: 0.00001810
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch217
INFO:root:[218,    50] training loss: 0.00924676
INFO:root:[218,   100] training loss: 0.00968712
INFO:root:[218,   150] training loss: 0.01023262
INFO:root:[218,   200] training loss: 0.00951798
INFO:root:[218,   250] training loss: 0.00989631
INFO:root:[218,   300] training loss: 0.01061588
INFO:root:[218,   350] training loss: 0.00807549
INFO:root:[218,   400] training loss: 0.00002037
INFO:root:[218,   450] training loss: 0.00002705
INFO:root:[218,   500] training loss: 0.00009173
INFO:root:[218,   550] training loss: 0.00037606
INFO:root:[218,   600] training loss: 0.00025029
INFO:root:[218,   650] training loss: 0.00012986
INFO:root:[218,   700] training loss: 0.00013607
INFO:root:[218,   750] training loss: 0.00151692
INFO:root:[218,   800] training loss: 0.00167959
INFO:root:[218,   850] training loss: 0.00174692
INFO:root:[218,   900] training loss: 0.00791448
INFO:root:[218,   950] training loss: 0.00335896
INFO:root:[218,  1000] training loss: 0.00002343
INFO:root:[218,  1050] training loss: 0.00002120
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch218
INFO:root:[219,    50] training loss: 0.00951516
INFO:root:[219,   100] training loss: 0.01024245
INFO:root:[219,   150] training loss: 0.01017655
INFO:root:[219,   200] training loss: 0.01000508
INFO:root:[219,   250] training loss: 0.00940745
INFO:root:[219,   300] training loss: 0.01091674
INFO:root:[219,   350] training loss: 0.00797168
INFO:root:[219,   400] training loss: 0.00001779
INFO:root:[219,   450] training loss: 0.00002490
INFO:root:[219,   500] training loss: 0.00007342
INFO:root:[219,   550] training loss: 0.00036119
INFO:root:[219,   600] training loss: 0.00025313
INFO:root:[219,   650] training loss: 0.00014115
INFO:root:[219,   700] training loss: 0.00013880
INFO:root:[219,   750] training loss: 0.00144241
INFO:root:[219,   800] training loss: 0.00173731
INFO:root:[219,   850] training loss: 0.00156278
INFO:root:[219,   900] training loss: 0.00821703
INFO:root:[219,   950] training loss: 0.00269763
INFO:root:[219,  1000] training loss: 0.00002278
INFO:root:[219,  1050] training loss: 0.00002011
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch219
INFO:root:[220,    50] training loss: 0.00931567
INFO:root:[220,   100] training loss: 0.00982865
INFO:root:[220,   150] training loss: 0.01062277
INFO:root:[220,   200] training loss: 0.01063700
INFO:root:[220,   250] training loss: 0.00959181
INFO:root:[220,   300] training loss: 0.01061918
INFO:root:[220,   350] training loss: 0.00824323
INFO:root:[220,   400] training loss: 0.00001874
INFO:root:[220,   450] training loss: 0.00002692
INFO:root:[220,   500] training loss: 0.00005398
INFO:root:[220,   550] training loss: 0.00036185
INFO:root:[220,   600] training loss: 0.00026258
INFO:root:[220,   650] training loss: 0.00011969
INFO:root:[220,   700] training loss: 0.00014279
INFO:root:[220,   750] training loss: 0.00159139
INFO:root:[220,   800] training loss: 0.00169977
INFO:root:[220,   850] training loss: 0.00159900
INFO:root:[220,   900] training loss: 0.00856349
INFO:root:[220,   950] training loss: 0.00299084
INFO:root:[220,  1000] training loss: 0.00002197
INFO:root:[220,  1050] training loss: 0.00002248
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch220
INFO:root:[221,    50] training loss: 0.00964302
INFO:root:[221,   100] training loss: 0.00993565
INFO:root:[221,   150] training loss: 0.01162049
INFO:root:[221,   200] training loss: 0.00975902
INFO:root:[221,   250] training loss: 0.00939537
INFO:root:[221,   300] training loss: 0.01163074
INFO:root:[221,   350] training loss: 0.00812540
INFO:root:[221,   400] training loss: 0.00001824
INFO:root:[221,   450] training loss: 0.00002513
INFO:root:[221,   500] training loss: 0.00004460
INFO:root:[221,   550] training loss: 0.00035996
INFO:root:[221,   600] training loss: 0.00024033
INFO:root:[221,   650] training loss: 0.00011860
INFO:root:[221,   700] training loss: 0.00013694
INFO:root:[221,   750] training loss: 0.00157004
INFO:root:[221,   800] training loss: 0.00160838
INFO:root:[221,   850] training loss: 0.00155701
INFO:root:[221,   900] training loss: 0.00894550
INFO:root:[221,   950] training loss: 0.00303653
INFO:root:[221,  1000] training loss: 0.00002232
INFO:root:[221,  1050] training loss: 0.00001969
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch221
INFO:root:[222,    50] training loss: 0.00969355
INFO:root:[222,   100] training loss: 0.00962229
INFO:root:[222,   150] training loss: 0.01038972
INFO:root:[222,   200] training loss: 0.00937488
INFO:root:[222,   250] training loss: 0.00972504
INFO:root:[222,   300] training loss: 0.01055684
INFO:root:[222,   350] training loss: 0.00833485
INFO:root:[222,   400] training loss: 0.00002037
INFO:root:[222,   450] training loss: 0.00003322
INFO:root:[222,   500] training loss: 0.00005422
INFO:root:[222,   550] training loss: 0.00044199
INFO:root:[222,   600] training loss: 0.00024639
INFO:root:[222,   650] training loss: 0.00011962
INFO:root:[222,   700] training loss: 0.00013376
INFO:root:[222,   750] training loss: 0.00158900
INFO:root:[222,   800] training loss: 0.00178187
INFO:root:[222,   850] training loss: 0.00163054
INFO:root:[222,   900] training loss: 0.00857971
INFO:root:[222,   950] training loss: 0.00306369
INFO:root:[222,  1000] training loss: 0.00001996
INFO:root:[222,  1050] training loss: 0.00002603
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch222
INFO:root:[223,    50] training loss: 0.00933569
INFO:root:[223,   100] training loss: 0.01039355
INFO:root:[223,   150] training loss: 0.01013893
INFO:root:[223,   200] training loss: 0.00957318
INFO:root:[223,   250] training loss: 0.00928841
INFO:root:[223,   300] training loss: 0.01020688
INFO:root:[223,   350] training loss: 0.00820644
INFO:root:[223,   400] training loss: 0.00001766
INFO:root:[223,   450] training loss: 0.00002546
INFO:root:[223,   500] training loss: 0.00005406
INFO:root:[223,   550] training loss: 0.00040094
INFO:root:[223,   600] training loss: 0.00024205
INFO:root:[223,   650] training loss: 0.00011959
INFO:root:[223,   700] training loss: 0.00016048
INFO:root:[223,   750] training loss: 0.00142384
INFO:root:[223,   800] training loss: 0.00174934
INFO:root:[223,   850] training loss: 0.00155643
INFO:root:[223,   900] training loss: 0.00818852
INFO:root:[223,   950] training loss: 0.00320493
INFO:root:[223,  1000] training loss: 0.00002152
INFO:root:[223,  1050] training loss: 0.00002282
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch223
INFO:root:[224,    50] training loss: 0.00957138
INFO:root:[224,   100] training loss: 0.01001359
INFO:root:[224,   150] training loss: 0.01039271
INFO:root:[224,   200] training loss: 0.00991740
INFO:root:[224,   250] training loss: 0.00932444
INFO:root:[224,   300] training loss: 0.01005854
INFO:root:[224,   350] training loss: 0.00780766
INFO:root:[224,   400] training loss: 0.00001714
INFO:root:[224,   450] training loss: 0.00002807
INFO:root:[224,   500] training loss: 0.00006076
INFO:root:[224,   550] training loss: 0.00039511
INFO:root:[224,   600] training loss: 0.00025556
INFO:root:[224,   650] training loss: 0.00012183
INFO:root:[224,   700] training loss: 0.00013349
INFO:root:[224,   750] training loss: 0.00161087
INFO:root:[224,   800] training loss: 0.00153860
INFO:root:[224,   850] training loss: 0.00166910
INFO:root:[224,   900] training loss: 0.00758180
INFO:root:[224,   950] training loss: 0.00332322
INFO:root:[224,  1000] training loss: 0.00002517
INFO:root:[224,  1050] training loss: 0.00002116
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch224
INFO:root:[225,    50] training loss: 0.00947499
INFO:root:[225,   100] training loss: 0.00946935
INFO:root:[225,   150] training loss: 0.01016738
INFO:root:[225,   200] training loss: 0.00930469
INFO:root:[225,   250] training loss: 0.00950033
INFO:root:[225,   300] training loss: 0.01004266
INFO:root:[225,   350] training loss: 0.00863675
INFO:root:[225,   400] training loss: 0.00001781
INFO:root:[225,   450] training loss: 0.00002814
INFO:root:[225,   500] training loss: 0.00005919
INFO:root:[225,   550] training loss: 0.00044912
INFO:root:[225,   600] training loss: 0.00023206
INFO:root:[225,   650] training loss: 0.00011967
INFO:root:[225,   700] training loss: 0.00014397
INFO:root:[225,   750] training loss: 0.00166231
INFO:root:[225,   800] training loss: 0.00182821
INFO:root:[225,   850] training loss: 0.00148088
INFO:root:[225,   900] training loss: 0.00920316
INFO:root:[225,   950] training loss: 0.00306253
INFO:root:[225,  1000] training loss: 0.00002617
INFO:root:[225,  1050] training loss: 0.00002336
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch225
INFO:root:[226,    50] training loss: 0.00943315
INFO:root:[226,   100] training loss: 0.00985287
INFO:root:[226,   150] training loss: 0.01025167
INFO:root:[226,   200] training loss: 0.01101683
INFO:root:[226,   250] training loss: 0.00978206
INFO:root:[226,   300] training loss: 0.01081323
INFO:root:[226,   350] training loss: 0.00933025
INFO:root:[226,   400] training loss: 0.00001889
INFO:root:[226,   450] training loss: 0.00004792
INFO:root:[226,   500] training loss: 0.00006325
INFO:root:[226,   550] training loss: 0.00041236
INFO:root:[226,   600] training loss: 0.00023787
INFO:root:[226,   650] training loss: 0.00012719
INFO:root:[226,   700] training loss: 0.00015787
INFO:root:[226,   750] training loss: 0.00158354
INFO:root:[226,   800] training loss: 0.00174791
INFO:root:[226,   850] training loss: 0.00160096
INFO:root:[226,   900] training loss: 0.00879149
INFO:root:[226,   950] training loss: 0.00301093
INFO:root:[226,  1000] training loss: 0.00002128
INFO:root:[226,  1050] training loss: 0.00002134
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch226
INFO:root:[227,    50] training loss: 0.00980555
INFO:root:[227,   100] training loss: 0.00988211
INFO:root:[227,   150] training loss: 0.01023425
INFO:root:[227,   200] training loss: 0.00971720
INFO:root:[227,   250] training loss: 0.00957096
INFO:root:[227,   300] training loss: 0.01111067
INFO:root:[227,   350] training loss: 0.00788297
INFO:root:[227,   400] training loss: 0.00002098
INFO:root:[227,   450] training loss: 0.00004909
INFO:root:[227,   500] training loss: 0.00004461
INFO:root:[227,   550] training loss: 0.00038873
INFO:root:[227,   600] training loss: 0.00023087
INFO:root:[227,   650] training loss: 0.00013145
INFO:root:[227,   700] training loss: 0.00014487
INFO:root:[227,   750] training loss: 0.00146706
INFO:root:[227,   800] training loss: 0.00182342
INFO:root:[227,   850] training loss: 0.00161240
INFO:root:[227,   900] training loss: 0.00820334
INFO:root:[227,   950] training loss: 0.00275724
INFO:root:[227,  1000] training loss: 0.00002030
INFO:root:[227,  1050] training loss: 0.00002336
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch227
INFO:root:[228,    50] training loss: 0.00925025
INFO:root:[228,   100] training loss: 0.00995621
INFO:root:[228,   150] training loss: 0.01012730
INFO:root:[228,   200] training loss: 0.00958404
INFO:root:[228,   250] training loss: 0.01012837
INFO:root:[228,   300] training loss: 0.01037746
INFO:root:[228,   350] training loss: 0.00827618
INFO:root:[228,   400] training loss: 0.00001907
INFO:root:[228,   450] training loss: 0.00002667
INFO:root:[228,   500] training loss: 0.00005261
INFO:root:[228,   550] training loss: 0.00038084
INFO:root:[228,   600] training loss: 0.00030084
INFO:root:[228,   650] training loss: 0.00013884
INFO:root:[228,   700] training loss: 0.00017401
INFO:root:[228,   750] training loss: 0.00149280
INFO:root:[228,   800] training loss: 0.00177054
INFO:root:[228,   850] training loss: 0.00155392
INFO:root:[228,   900] training loss: 0.00839456
INFO:root:[228,   950] training loss: 0.00304536
INFO:root:[228,  1000] training loss: 0.00002380
INFO:root:[228,  1050] training loss: 0.00002310
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch228
INFO:root:[229,    50] training loss: 0.00910574
INFO:root:[229,   100] training loss: 0.01003631
INFO:root:[229,   150] training loss: 0.01051494
INFO:root:[229,   200] training loss: 0.00940272
INFO:root:[229,   250] training loss: 0.01041813
INFO:root:[229,   300] training loss: 0.01009275
INFO:root:[229,   350] training loss: 0.00903332
INFO:root:[229,   400] training loss: 0.00001812
INFO:root:[229,   450] training loss: 0.00002548
INFO:root:[229,   500] training loss: 0.00005285
INFO:root:[229,   550] training loss: 0.00033850
INFO:root:[229,   600] training loss: 0.00022502
INFO:root:[229,   650] training loss: 0.00010967
INFO:root:[229,   700] training loss: 0.00013539
INFO:root:[229,   750] training loss: 0.00164956
INFO:root:[229,   800] training loss: 0.00165987
INFO:root:[229,   850] training loss: 0.00161759
INFO:root:[229,   900] training loss: 0.00837952
INFO:root:[229,   950] training loss: 0.00294308
INFO:root:[229,  1000] training loss: 0.00002252
INFO:root:[229,  1050] training loss: 0.00002739
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch229
INFO:root:[230,    50] training loss: 0.00974885
INFO:root:[230,   100] training loss: 0.00995073
INFO:root:[230,   150] training loss: 0.01068428
INFO:root:[230,   200] training loss: 0.00986906
INFO:root:[230,   250] training loss: 0.00960874
INFO:root:[230,   300] training loss: 0.01166256
INFO:root:[230,   350] training loss: 0.00838573
INFO:root:[230,   400] training loss: 0.00001777
INFO:root:[230,   450] training loss: 0.00002773
INFO:root:[230,   500] training loss: 0.00005373
INFO:root:[230,   550] training loss: 0.00031397
INFO:root:[230,   600] training loss: 0.00027794
INFO:root:[230,   650] training loss: 0.00012216
INFO:root:[230,   700] training loss: 0.00016957
INFO:root:[230,   750] training loss: 0.00151956
INFO:root:[230,   800] training loss: 0.00186885
INFO:root:[230,   850] training loss: 0.00160564
INFO:root:[230,   900] training loss: 0.00844416
INFO:root:[230,   950] training loss: 0.00330402
INFO:root:[230,  1000] training loss: 0.00002268
INFO:root:[230,  1050] training loss: 0.00002476
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch230
INFO:root:[231,    50] training loss: 0.00953339
INFO:root:[231,   100] training loss: 0.00982459
INFO:root:[231,   150] training loss: 0.00996777
INFO:root:[231,   200] training loss: 0.01037782
INFO:root:[231,   250] training loss: 0.00965839
INFO:root:[231,   300] training loss: 0.01029670
INFO:root:[231,   350] training loss: 0.00842294
INFO:root:[231,   400] training loss: 0.00001744
INFO:root:[231,   450] training loss: 0.00002449
INFO:root:[231,   500] training loss: 0.00004466
INFO:root:[231,   550] training loss: 0.00045657
INFO:root:[231,   600] training loss: 0.00026621
INFO:root:[231,   650] training loss: 0.00012191
INFO:root:[231,   700] training loss: 0.00015021
INFO:root:[231,   750] training loss: 0.00159384
INFO:root:[231,   800] training loss: 0.00167853
INFO:root:[231,   850] training loss: 0.00152404
INFO:root:[231,   900] training loss: 0.00755222
INFO:root:[231,   950] training loss: 0.00337026
INFO:root:[231,  1000] training loss: 0.00002535
INFO:root:[231,  1050] training loss: 0.00003686
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch231
INFO:root:[232,    50] training loss: 0.00947648
INFO:root:[232,   100] training loss: 0.00964760
INFO:root:[232,   150] training loss: 0.01079025
INFO:root:[232,   200] training loss: 0.00982479
INFO:root:[232,   250] training loss: 0.00935762
INFO:root:[232,   300] training loss: 0.01146785
INFO:root:[232,   350] training loss: 0.00826257
INFO:root:[232,   400] training loss: 0.00001896
INFO:root:[232,   450] training loss: 0.00002777
INFO:root:[232,   500] training loss: 0.00004799
INFO:root:[232,   550] training loss: 0.00035114
INFO:root:[232,   600] training loss: 0.00021807
INFO:root:[232,   650] training loss: 0.00013954
INFO:root:[232,   700] training loss: 0.00014422
INFO:root:[232,   750] training loss: 0.00156143
INFO:root:[232,   800] training loss: 0.00162142
INFO:root:[232,   850] training loss: 0.00155497
INFO:root:[232,   900] training loss: 0.00781957
INFO:root:[232,   950] training loss: 0.00278285
INFO:root:[232,  1000] training loss: 0.00002360
INFO:root:[232,  1050] training loss: 0.00002227
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch232
INFO:root:[233,    50] training loss: 0.00960759
INFO:root:[233,   100] training loss: 0.01117815
INFO:root:[233,   150] training loss: 0.01083493
INFO:root:[233,   200] training loss: 0.00984459
INFO:root:[233,   250] training loss: 0.00968963
INFO:root:[233,   300] training loss: 0.01153727
INFO:root:[233,   350] training loss: 0.00878777
INFO:root:[233,   400] training loss: 0.00002001
INFO:root:[233,   450] training loss: 0.00002382
INFO:root:[233,   500] training loss: 0.00007677
INFO:root:[233,   550] training loss: 0.00032778
INFO:root:[233,   600] training loss: 0.00023666
INFO:root:[233,   650] training loss: 0.00013548
INFO:root:[233,   700] training loss: 0.00014975
INFO:root:[233,   750] training loss: 0.00155339
INFO:root:[233,   800] training loss: 0.00158307
INFO:root:[233,   850] training loss: 0.00156956
INFO:root:[233,   900] training loss: 0.00806397
INFO:root:[233,   950] training loss: 0.00310782
INFO:root:[233,  1000] training loss: 0.00001999
INFO:root:[233,  1050] training loss: 0.00002139
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch233
INFO:root:[234,    50] training loss: 0.00925692
INFO:root:[234,   100] training loss: 0.00982207
INFO:root:[234,   150] training loss: 0.01048378
INFO:root:[234,   200] training loss: 0.00965784
INFO:root:[234,   250] training loss: 0.00951345
INFO:root:[234,   300] training loss: 0.01211561
INFO:root:[234,   350] training loss: 0.00827914
INFO:root:[234,   400] training loss: 0.00001947
INFO:root:[234,   450] training loss: 0.00002588
INFO:root:[234,   500] training loss: 0.00009172
INFO:root:[234,   550] training loss: 0.00035124
INFO:root:[234,   600] training loss: 0.00024512
INFO:root:[234,   650] training loss: 0.00011881
INFO:root:[234,   700] training loss: 0.00017059
INFO:root:[234,   750] training loss: 0.00157596
INFO:root:[234,   800] training loss: 0.00177518
INFO:root:[234,   850] training loss: 0.00172055
INFO:root:[234,   900] training loss: 0.00900401
INFO:root:[234,   950] training loss: 0.00309569
INFO:root:[234,  1000] training loss: 0.00002458
INFO:root:[234,  1050] training loss: 0.00002212
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch234
INFO:root:[235,    50] training loss: 0.00920031
INFO:root:[235,   100] training loss: 0.00982362
INFO:root:[235,   150] training loss: 0.01020107
INFO:root:[235,   200] training loss: 0.01206721
INFO:root:[235,   250] training loss: 0.00941912
INFO:root:[235,   300] training loss: 0.01007925
INFO:root:[235,   350] training loss: 0.00833375
INFO:root:[235,   400] training loss: 0.00001792
INFO:root:[235,   450] training loss: 0.00002621
INFO:root:[235,   500] training loss: 0.00004308
INFO:root:[235,   550] training loss: 0.00040234
INFO:root:[235,   600] training loss: 0.00026643
INFO:root:[235,   650] training loss: 0.00012702
INFO:root:[235,   700] training loss: 0.00013241
INFO:root:[235,   750] training loss: 0.00143550
INFO:root:[235,   800] training loss: 0.00171664
INFO:root:[235,   850] training loss: 0.00153339
INFO:root:[235,   900] training loss: 0.00928553
INFO:root:[235,   950] training loss: 0.00304751
INFO:root:[235,  1000] training loss: 0.00002119
INFO:root:[235,  1050] training loss: 0.00002688
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7798    0.7994    0.7895      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2895    0.6027    0.3911        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7779      3872
   macro avg     0.6127    0.7381    0.6569      3872
weighted avg     0.7979    0.7779    0.7853      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch235
INFO:root:[236,    50] training loss: 0.01020744
INFO:root:[236,   100] training loss: 0.00965684
INFO:root:[236,   150] training loss: 0.01087393
INFO:root:[236,   200] training loss: 0.00947455
INFO:root:[236,   250] training loss: 0.01023783
INFO:root:[236,   300] training loss: 0.01027718
INFO:root:[236,   350] training loss: 0.00828241
INFO:root:[236,   400] training loss: 0.00001802
INFO:root:[236,   450] training loss: 0.00003114
INFO:root:[236,   500] training loss: 0.00005111
INFO:root:[236,   550] training loss: 0.00041871
INFO:root:[236,   600] training loss: 0.00026601
INFO:root:[236,   650] training loss: 0.00011843
INFO:root:[236,   700] training loss: 0.00016591
INFO:root:[236,   750] training loss: 0.00151881
INFO:root:[236,   800] training loss: 0.00185634
INFO:root:[236,   850] training loss: 0.00161843
INFO:root:[236,   900] training loss: 0.00813730
INFO:root:[236,   950] training loss: 0.00285228
INFO:root:[236,  1000] training loss: 0.00002592
INFO:root:[236,  1050] training loss: 0.00002068
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch236
INFO:root:[237,    50] training loss: 0.00956754
INFO:root:[237,   100] training loss: 0.00949556
INFO:root:[237,   150] training loss: 0.01011883
INFO:root:[237,   200] training loss: 0.00962902
INFO:root:[237,   250] training loss: 0.00966568
INFO:root:[237,   300] training loss: 0.01023776
INFO:root:[237,   350] training loss: 0.00830577
INFO:root:[237,   400] training loss: 0.00001865
INFO:root:[237,   450] training loss: 0.00002626
INFO:root:[237,   500] training loss: 0.00006162
INFO:root:[237,   550] training loss: 0.00039899
INFO:root:[237,   600] training loss: 0.00023632
INFO:root:[237,   650] training loss: 0.00011362
INFO:root:[237,   700] training loss: 0.00013924
INFO:root:[237,   750] training loss: 0.00137832
INFO:root:[237,   800] training loss: 0.00184639
INFO:root:[237,   850] training loss: 0.00166284
INFO:root:[237,   900] training loss: 0.00828211
INFO:root:[237,   950] training loss: 0.00286285
INFO:root:[237,  1000] training loss: 0.00002025
INFO:root:[237,  1050] training loss: 0.00002260
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch237
INFO:root:[238,    50] training loss: 0.00965327
INFO:root:[238,   100] training loss: 0.01016163
INFO:root:[238,   150] training loss: 0.01049779
INFO:root:[238,   200] training loss: 0.01124603
INFO:root:[238,   250] training loss: 0.00944060
INFO:root:[238,   300] training loss: 0.01180442
INFO:root:[238,   350] training loss: 0.00885437
INFO:root:[238,   400] training loss: 0.00001960
INFO:root:[238,   450] training loss: 0.00003357
INFO:root:[238,   500] training loss: 0.00006377
INFO:root:[238,   550] training loss: 0.00033970
INFO:root:[238,   600] training loss: 0.00027277
INFO:root:[238,   650] training loss: 0.00013661
INFO:root:[238,   700] training loss: 0.00014741
INFO:root:[238,   750] training loss: 0.00145791
INFO:root:[238,   800] training loss: 0.00176388
INFO:root:[238,   850] training loss: 0.00148224
INFO:root:[238,   900] training loss: 0.00830847
INFO:root:[238,   950] training loss: 0.00288084
INFO:root:[238,  1000] training loss: 0.00002204
INFO:root:[238,  1050] training loss: 0.00002876
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch238
INFO:root:[239,    50] training loss: 0.00896268
INFO:root:[239,   100] training loss: 0.00990296
INFO:root:[239,   150] training loss: 0.01111100
INFO:root:[239,   200] training loss: 0.00940830
INFO:root:[239,   250] training loss: 0.00963109
INFO:root:[239,   300] training loss: 0.01025527
INFO:root:[239,   350] training loss: 0.00782042
INFO:root:[239,   400] training loss: 0.00001901
INFO:root:[239,   450] training loss: 0.00002614
INFO:root:[239,   500] training loss: 0.00004499
INFO:root:[239,   550] training loss: 0.00034851
INFO:root:[239,   600] training loss: 0.00025173
INFO:root:[239,   650] training loss: 0.00013020
INFO:root:[239,   700] training loss: 0.00014739
INFO:root:[239,   750] training loss: 0.00147294
INFO:root:[239,   800] training loss: 0.00161520
INFO:root:[239,   850] training loss: 0.00155741
INFO:root:[239,   900] training loss: 0.00760429
INFO:root:[239,   950] training loss: 0.00332749
INFO:root:[239,  1000] training loss: 0.00002347
INFO:root:[239,  1050] training loss: 0.00002581
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch239
INFO:root:[240,    50] training loss: 0.00942467
INFO:root:[240,   100] training loss: 0.01023426
INFO:root:[240,   150] training loss: 0.00972938
INFO:root:[240,   200] training loss: 0.00966983
INFO:root:[240,   250] training loss: 0.00914500
INFO:root:[240,   300] training loss: 0.01040223
INFO:root:[240,   350] training loss: 0.00848369
INFO:root:[240,   400] training loss: 0.00001676
INFO:root:[240,   450] training loss: 0.00002821
INFO:root:[240,   500] training loss: 0.00011421
INFO:root:[240,   550] training loss: 0.00034017
INFO:root:[240,   600] training loss: 0.00023181
INFO:root:[240,   650] training loss: 0.00012064
INFO:root:[240,   700] training loss: 0.00013225
INFO:root:[240,   750] training loss: 0.00143717
INFO:root:[240,   800] training loss: 0.00178999
INFO:root:[240,   850] training loss: 0.00144006
INFO:root:[240,   900] training loss: 0.00851758
INFO:root:[240,   950] training loss: 0.00327264
INFO:root:[240,  1000] training loss: 0.00002455
INFO:root:[240,  1050] training loss: 0.00002158
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch240
INFO:root:[241,    50] training loss: 0.00905446
INFO:root:[241,   100] training loss: 0.01044882
INFO:root:[241,   150] training loss: 0.01061094
INFO:root:[241,   200] training loss: 0.00920559
INFO:root:[241,   250] training loss: 0.00954581
INFO:root:[241,   300] training loss: 0.01020029
INFO:root:[241,   350] training loss: 0.00835823
INFO:root:[241,   400] training loss: 0.00001868
INFO:root:[241,   450] training loss: 0.00002569
INFO:root:[241,   500] training loss: 0.00010215
INFO:root:[241,   550] training loss: 0.00031065
INFO:root:[241,   600] training loss: 0.00022934
INFO:root:[241,   650] training loss: 0.00011679
INFO:root:[241,   700] training loss: 0.00013602
INFO:root:[241,   750] training loss: 0.00155395
INFO:root:[241,   800] training loss: 0.00176356
INFO:root:[241,   850] training loss: 0.00138004
INFO:root:[241,   900] training loss: 0.00741520
INFO:root:[241,   950] training loss: 0.00284205
INFO:root:[241,  1000] training loss: 0.00002280
INFO:root:[241,  1050] training loss: 0.00002429
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch241
INFO:root:[242,    50] training loss: 0.00894188
INFO:root:[242,   100] training loss: 0.01007431
INFO:root:[242,   150] training loss: 0.01069084
INFO:root:[242,   200] training loss: 0.00979340
INFO:root:[242,   250] training loss: 0.01070114
INFO:root:[242,   300] training loss: 0.01125471
INFO:root:[242,   350] training loss: 0.00900558
INFO:root:[242,   400] training loss: 0.00001981
INFO:root:[242,   450] training loss: 0.00002423
INFO:root:[242,   500] training loss: 0.00006449
INFO:root:[242,   550] training loss: 0.00034257
INFO:root:[242,   600] training loss: 0.00023774
INFO:root:[242,   650] training loss: 0.00011396
INFO:root:[242,   700] training loss: 0.00011820
INFO:root:[242,   750] training loss: 0.00150473
INFO:root:[242,   800] training loss: 0.00172953
INFO:root:[242,   850] training loss: 0.00147988
INFO:root:[242,   900] training loss: 0.00827617
INFO:root:[242,   950] training loss: 0.00313241
INFO:root:[242,  1000] training loss: 0.00002275
INFO:root:[242,  1050] training loss: 0.00002551
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch242
INFO:root:[243,    50] training loss: 0.00934043
INFO:root:[243,   100] training loss: 0.01036341
INFO:root:[243,   150] training loss: 0.01005023
INFO:root:[243,   200] training loss: 0.00958350
INFO:root:[243,   250] training loss: 0.00979506
INFO:root:[243,   300] training loss: 0.01042930
INFO:root:[243,   350] training loss: 0.00837859
INFO:root:[243,   400] training loss: 0.00001818
INFO:root:[243,   450] training loss: 0.00002928
INFO:root:[243,   500] training loss: 0.00005505
INFO:root:[243,   550] training loss: 0.00041263
INFO:root:[243,   600] training loss: 0.00028066
INFO:root:[243,   650] training loss: 0.00011940
INFO:root:[243,   700] training loss: 0.00015623
INFO:root:[243,   750] training loss: 0.00147893
INFO:root:[243,   800] training loss: 0.00171763
INFO:root:[243,   850] training loss: 0.00159914
INFO:root:[243,   900] training loss: 0.00800842
INFO:root:[243,   950] training loss: 0.00272612
INFO:root:[243,  1000] training loss: 0.00002120
INFO:root:[243,  1050] training loss: 0.00002038
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch243
INFO:root:[244,    50] training loss: 0.01008841
INFO:root:[244,   100] training loss: 0.01008631
INFO:root:[244,   150] training loss: 0.01048806
INFO:root:[244,   200] training loss: 0.00979396
INFO:root:[244,   250] training loss: 0.00887807
INFO:root:[244,   300] training loss: 0.01183473
INFO:root:[244,   350] training loss: 0.00851291
INFO:root:[244,   400] training loss: 0.00002195
INFO:root:[244,   450] training loss: 0.00003054
INFO:root:[244,   500] training loss: 0.00006063
INFO:root:[244,   550] training loss: 0.00031675
INFO:root:[244,   600] training loss: 0.00027417
INFO:root:[244,   650] training loss: 0.00013514
INFO:root:[244,   700] training loss: 0.00015170
INFO:root:[244,   750] training loss: 0.00149249
INFO:root:[244,   800] training loss: 0.00198124
INFO:root:[244,   850] training loss: 0.00167443
INFO:root:[244,   900] training loss: 0.00794263
INFO:root:[244,   950] training loss: 0.00269841
INFO:root:[244,  1000] training loss: 0.00002151
INFO:root:[244,  1050] training loss: 0.00002645
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch244
INFO:root:[245,    50] training loss: 0.00994952
INFO:root:[245,   100] training loss: 0.00979242
INFO:root:[245,   150] training loss: 0.00998822
INFO:root:[245,   200] training loss: 0.00915396
INFO:root:[245,   250] training loss: 0.00969248
INFO:root:[245,   300] training loss: 0.01048717
INFO:root:[245,   350] training loss: 0.00804686
INFO:root:[245,   400] training loss: 0.00001816
INFO:root:[245,   450] training loss: 0.00002626
INFO:root:[245,   500] training loss: 0.00007501
INFO:root:[245,   550] training loss: 0.00039485
INFO:root:[245,   600] training loss: 0.00023563
INFO:root:[245,   650] training loss: 0.00012436
INFO:root:[245,   700] training loss: 0.00015399
INFO:root:[245,   750] training loss: 0.00139205
INFO:root:[245,   800] training loss: 0.00171453
INFO:root:[245,   850] training loss: 0.00137240
INFO:root:[245,   900] training loss: 0.00776737
INFO:root:[245,   950] training loss: 0.00274307
INFO:root:[245,  1000] training loss: 0.00002172
INFO:root:[245,  1050] training loss: 0.00002148
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch245
INFO:root:[246,    50] training loss: 0.00950394
INFO:root:[246,   100] training loss: 0.01052884
INFO:root:[246,   150] training loss: 0.01044732
INFO:root:[246,   200] training loss: 0.00987416
INFO:root:[246,   250] training loss: 0.00918224
INFO:root:[246,   300] training loss: 0.01033069
INFO:root:[246,   350] training loss: 0.00791968
INFO:root:[246,   400] training loss: 0.00001897
INFO:root:[246,   450] training loss: 0.00006303
INFO:root:[246,   500] training loss: 0.00009695
INFO:root:[246,   550] training loss: 0.00036967
INFO:root:[246,   600] training loss: 0.00023947
INFO:root:[246,   650] training loss: 0.00012682
INFO:root:[246,   700] training loss: 0.00012791
INFO:root:[246,   750] training loss: 0.00147687
INFO:root:[246,   800] training loss: 0.00168017
INFO:root:[246,   850] training loss: 0.00156663
INFO:root:[246,   900] training loss: 0.00759481
INFO:root:[246,   950] training loss: 0.00275367
INFO:root:[246,  1000] training loss: 0.00002107
INFO:root:[246,  1050] training loss: 0.00002489
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch246
INFO:root:[247,    50] training loss: 0.00980262
INFO:root:[247,   100] training loss: 0.01027327
INFO:root:[247,   150] training loss: 0.01237740
INFO:root:[247,   200] training loss: 0.00975840
INFO:root:[247,   250] training loss: 0.00920149
INFO:root:[247,   300] training loss: 0.01034185
INFO:root:[247,   350] training loss: 0.00822115
INFO:root:[247,   400] training loss: 0.00001721
INFO:root:[247,   450] training loss: 0.00003143
INFO:root:[247,   500] training loss: 0.00004781
INFO:root:[247,   550] training loss: 0.00035464
INFO:root:[247,   600] training loss: 0.00024980
INFO:root:[247,   650] training loss: 0.00011537
INFO:root:[247,   700] training loss: 0.00015660
INFO:root:[247,   750] training loss: 0.00154465
INFO:root:[247,   800] training loss: 0.00186001
INFO:root:[247,   850] training loss: 0.00146937
INFO:root:[247,   900] training loss: 0.00802500
INFO:root:[247,   950] training loss: 0.00279366
INFO:root:[247,  1000] training loss: 0.00002162
INFO:root:[247,  1050] training loss: 0.00002742
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch247
INFO:root:[248,    50] training loss: 0.00909876
INFO:root:[248,   100] training loss: 0.01091861
INFO:root:[248,   150] training loss: 0.01050107
INFO:root:[248,   200] training loss: 0.01190402
INFO:root:[248,   250] training loss: 0.00979175
INFO:root:[248,   300] training loss: 0.01058922
INFO:root:[248,   350] training loss: 0.00792640
INFO:root:[248,   400] training loss: 0.00002051
INFO:root:[248,   450] training loss: 0.00003107
INFO:root:[248,   500] training loss: 0.00010875
INFO:root:[248,   550] training loss: 0.00046652
INFO:root:[248,   600] training loss: 0.00026106
INFO:root:[248,   650] training loss: 0.00012222
INFO:root:[248,   700] training loss: 0.00015375
INFO:root:[248,   750] training loss: 0.00164084
INFO:root:[248,   800] training loss: 0.00155282
INFO:root:[248,   850] training loss: 0.00150636
INFO:root:[248,   900] training loss: 0.01007331
INFO:root:[248,   950] training loss: 0.00291391
INFO:root:[248,  1000] training loss: 0.00002336
INFO:root:[248,  1050] training loss: 0.00002200
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch248
INFO:root:[249,    50] training loss: 0.00944618
INFO:root:[249,   100] training loss: 0.01135934
INFO:root:[249,   150] training loss: 0.01014592
INFO:root:[249,   200] training loss: 0.00931699
INFO:root:[249,   250] training loss: 0.01000845
INFO:root:[249,   300] training loss: 0.01051114
INFO:root:[249,   350] training loss: 0.00825750
INFO:root:[249,   400] training loss: 0.00001628
INFO:root:[249,   450] training loss: 0.00002875
INFO:root:[249,   500] training loss: 0.00007844
INFO:root:[249,   550] training loss: 0.00047261
INFO:root:[249,   600] training loss: 0.00030745
INFO:root:[249,   650] training loss: 0.00012516
INFO:root:[249,   700] training loss: 0.00014092
INFO:root:[249,   750] training loss: 0.00143970
INFO:root:[249,   800] training loss: 0.00185852
INFO:root:[249,   850] training loss: 0.00148974
INFO:root:[249,   900] training loss: 0.00812557
INFO:root:[249,   950] training loss: 0.00343772
INFO:root:[249,  1000] training loss: 0.00002660
INFO:root:[249,  1050] training loss: 0.00002582
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch249
INFO:root:[250,    50] training loss: 0.01028880
INFO:root:[250,   100] training loss: 0.00926251
INFO:root:[250,   150] training loss: 0.01033206
INFO:root:[250,   200] training loss: 0.00959087
INFO:root:[250,   250] training loss: 0.00938590
INFO:root:[250,   300] training loss: 0.01093715
INFO:root:[250,   350] training loss: 0.00815351
INFO:root:[250,   400] training loss: 0.00001677
INFO:root:[250,   450] training loss: 0.00002666
INFO:root:[250,   500] training loss: 0.00006108
INFO:root:[250,   550] training loss: 0.00035287
INFO:root:[250,   600] training loss: 0.00028168
INFO:root:[250,   650] training loss: 0.00011521
INFO:root:[250,   700] training loss: 0.00014522
INFO:root:[250,   750] training loss: 0.00136774
INFO:root:[250,   800] training loss: 0.00161451
INFO:root:[250,   850] training loss: 0.00158775
INFO:root:[250,   900] training loss: 0.00798093
INFO:root:[250,   950] training loss: 0.00314647
INFO:root:[250,  1000] training loss: 0.00002156
INFO:root:[250,  1050] training loss: 0.00002226
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch250
INFO:root:[251,    50] training loss: 0.00993613
INFO:root:[251,   100] training loss: 0.00958424
INFO:root:[251,   150] training loss: 0.01017025
INFO:root:[251,   200] training loss: 0.01142511
INFO:root:[251,   250] training loss: 0.00947204
INFO:root:[251,   300] training loss: 0.01055419
INFO:root:[251,   350] training loss: 0.00810685
INFO:root:[251,   400] training loss: 0.00001820
INFO:root:[251,   450] training loss: 0.00002736
INFO:root:[251,   500] training loss: 0.00013965
INFO:root:[251,   550] training loss: 0.00035482
INFO:root:[251,   600] training loss: 0.00023335
INFO:root:[251,   650] training loss: 0.00011315
INFO:root:[251,   700] training loss: 0.00015430
INFO:root:[251,   750] training loss: 0.00154713
INFO:root:[251,   800] training loss: 0.00173238
INFO:root:[251,   850] training loss: 0.00156762
INFO:root:[251,   900] training loss: 0.00739054
INFO:root:[251,   950] training loss: 0.00368945
INFO:root:[251,  1000] training loss: 0.00002124
INFO:root:[251,  1050] training loss: 0.00002407
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch251
INFO:root:[252,    50] training loss: 0.00963042
INFO:root:[252,   100] training loss: 0.00999934
INFO:root:[252,   150] training loss: 0.01053007
INFO:root:[252,   200] training loss: 0.00954753
INFO:root:[252,   250] training loss: 0.00941762
INFO:root:[252,   300] training loss: 0.00990150
INFO:root:[252,   350] training loss: 0.00874405
INFO:root:[252,   400] training loss: 0.00001664
INFO:root:[252,   450] training loss: 0.00002620
INFO:root:[252,   500] training loss: 0.00005397
INFO:root:[252,   550] training loss: 0.00039882
INFO:root:[252,   600] training loss: 0.00025136
INFO:root:[252,   650] training loss: 0.00012216
INFO:root:[252,   700] training loss: 0.00014971
INFO:root:[252,   750] training loss: 0.00163149
INFO:root:[252,   800] training loss: 0.00170785
INFO:root:[252,   850] training loss: 0.00155915
INFO:root:[252,   900] training loss: 0.00891914
INFO:root:[252,   950] training loss: 0.00264031
INFO:root:[252,  1000] training loss: 0.00002309
INFO:root:[252,  1050] training loss: 0.00002339
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch252
INFO:root:[253,    50] training loss: 0.00955424
INFO:root:[253,   100] training loss: 0.00999032
INFO:root:[253,   150] training loss: 0.01093762
INFO:root:[253,   200] training loss: 0.00913251
INFO:root:[253,   250] training loss: 0.00986848
INFO:root:[253,   300] training loss: 0.01065280
INFO:root:[253,   350] training loss: 0.00820238
INFO:root:[253,   400] training loss: 0.00001793
INFO:root:[253,   450] training loss: 0.00002833
INFO:root:[253,   500] training loss: 0.00005662
INFO:root:[253,   550] training loss: 0.00032090
INFO:root:[253,   600] training loss: 0.00022223
INFO:root:[253,   650] training loss: 0.00011102
INFO:root:[253,   700] training loss: 0.00014223
INFO:root:[253,   750] training loss: 0.00158298
INFO:root:[253,   800] training loss: 0.00183523
INFO:root:[253,   850] training loss: 0.00147875
INFO:root:[253,   900] training loss: 0.00817795
INFO:root:[253,   950] training loss: 0.00318704
INFO:root:[253,  1000] training loss: 0.00002507
INFO:root:[253,  1050] training loss: 0.00002346
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch253
INFO:root:[254,    50] training loss: 0.00954294
INFO:root:[254,   100] training loss: 0.00989984
INFO:root:[254,   150] training loss: 0.01020468
INFO:root:[254,   200] training loss: 0.01082606
INFO:root:[254,   250] training loss: 0.01000864
INFO:root:[254,   300] training loss: 0.01110587
INFO:root:[254,   350] training loss: 0.00866626
INFO:root:[254,   400] training loss: 0.00002127
INFO:root:[254,   450] training loss: 0.00002713
INFO:root:[254,   500] training loss: 0.00005076
INFO:root:[254,   550] training loss: 0.00040127
INFO:root:[254,   600] training loss: 0.00027529
INFO:root:[254,   650] training loss: 0.00011935
INFO:root:[254,   700] training loss: 0.00014121
INFO:root:[254,   750] training loss: 0.00159145
INFO:root:[254,   800] training loss: 0.00175689
INFO:root:[254,   850] training loss: 0.00159732
INFO:root:[254,   900] training loss: 0.00858021
INFO:root:[254,   950] training loss: 0.00346335
INFO:root:[254,  1000] training loss: 0.00002012
INFO:root:[254,  1050] training loss: 0.00003229
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch254
INFO:root:[255,    50] training loss: 0.00992950
INFO:root:[255,   100] training loss: 0.00988049
INFO:root:[255,   150] training loss: 0.01069697
INFO:root:[255,   200] training loss: 0.00969101
INFO:root:[255,   250] training loss: 0.00957251
INFO:root:[255,   300] training loss: 0.01020354
INFO:root:[255,   350] training loss: 0.00888254
INFO:root:[255,   400] training loss: 0.00002051
INFO:root:[255,   450] training loss: 0.00002717
INFO:root:[255,   500] training loss: 0.00004815
INFO:root:[255,   550] training loss: 0.00035646
INFO:root:[255,   600] training loss: 0.00023227
INFO:root:[255,   650] training loss: 0.00012208
INFO:root:[255,   700] training loss: 0.00017025
INFO:root:[255,   750] training loss: 0.00172941
INFO:root:[255,   800] training loss: 0.00174112
INFO:root:[255,   850] training loss: 0.00156296
INFO:root:[255,   900] training loss: 0.00768093
INFO:root:[255,   950] training loss: 0.00309416
INFO:root:[255,  1000] training loss: 0.00002250
INFO:root:[255,  1050] training loss: 0.00002193
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch255
INFO:root:[256,    50] training loss: 0.00916591
INFO:root:[256,   100] training loss: 0.01041213
INFO:root:[256,   150] training loss: 0.01010016
INFO:root:[256,   200] training loss: 0.00965404
INFO:root:[256,   250] training loss: 0.01026881
INFO:root:[256,   300] training loss: 0.01250989
INFO:root:[256,   350] training loss: 0.00920095
INFO:root:[256,   400] training loss: 0.00001852
INFO:root:[256,   450] training loss: 0.00002756
INFO:root:[256,   500] training loss: 0.00005505
INFO:root:[256,   550] training loss: 0.00040895
INFO:root:[256,   600] training loss: 0.00025160
INFO:root:[256,   650] training loss: 0.00013521
INFO:root:[256,   700] training loss: 0.00015758
INFO:root:[256,   750] training loss: 0.00158699
INFO:root:[256,   800] training loss: 0.00169463
INFO:root:[256,   850] training loss: 0.00149726
INFO:root:[256,   900] training loss: 0.00761036
INFO:root:[256,   950] training loss: 0.00311389
INFO:root:[256,  1000] training loss: 0.00002689
INFO:root:[256,  1050] training loss: 0.00002261
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch256
INFO:root:[257,    50] training loss: 0.00949403
INFO:root:[257,   100] training loss: 0.01026033
INFO:root:[257,   150] training loss: 0.01072431
INFO:root:[257,   200] training loss: 0.00933884
INFO:root:[257,   250] training loss: 0.00943186
INFO:root:[257,   300] training loss: 0.00996760
INFO:root:[257,   350] training loss: 0.00804718
INFO:root:[257,   400] training loss: 0.00001866
INFO:root:[257,   450] training loss: 0.00002682
INFO:root:[257,   500] training loss: 0.00006532
INFO:root:[257,   550] training loss: 0.00036527
INFO:root:[257,   600] training loss: 0.00023860
INFO:root:[257,   650] training loss: 0.00011292
INFO:root:[257,   700] training loss: 0.00016395
INFO:root:[257,   750] training loss: 0.00139347
INFO:root:[257,   800] training loss: 0.00169949
INFO:root:[257,   850] training loss: 0.00159780
INFO:root:[257,   900] training loss: 0.00835593
INFO:root:[257,   950] training loss: 0.00314496
INFO:root:[257,  1000] training loss: 0.00002615
INFO:root:[257,  1050] training loss: 0.00001968
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch257
INFO:root:[258,    50] training loss: 0.00929356
INFO:root:[258,   100] training loss: 0.00954245
INFO:root:[258,   150] training loss: 0.01288643
INFO:root:[258,   200] training loss: 0.00954403
INFO:root:[258,   250] training loss: 0.00909915
INFO:root:[258,   300] training loss: 0.01048937
INFO:root:[258,   350] training loss: 0.00816145
INFO:root:[258,   400] training loss: 0.00001879
INFO:root:[258,   450] training loss: 0.00002859
INFO:root:[258,   500] training loss: 0.00005261
INFO:root:[258,   550] training loss: 0.00035597
INFO:root:[258,   600] training loss: 0.00024367
INFO:root:[258,   650] training loss: 0.00014066
INFO:root:[258,   700] training loss: 0.00015699
INFO:root:[258,   750] training loss: 0.00146091
INFO:root:[258,   800] training loss: 0.00170388
INFO:root:[258,   850] training loss: 0.00141483
INFO:root:[258,   900] training loss: 0.00794456
INFO:root:[258,   950] training loss: 0.00318488
INFO:root:[258,  1000] training loss: 0.00002352
INFO:root:[258,  1050] training loss: 0.00004122
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch258
INFO:root:[259,    50] training loss: 0.00967346
INFO:root:[259,   100] training loss: 0.00981903
INFO:root:[259,   150] training loss: 0.01032776
INFO:root:[259,   200] training loss: 0.00973703
INFO:root:[259,   250] training loss: 0.00960582
INFO:root:[259,   300] training loss: 0.01046383
INFO:root:[259,   350] training loss: 0.00833312
INFO:root:[259,   400] training loss: 0.00001814
INFO:root:[259,   450] training loss: 0.00002745
INFO:root:[259,   500] training loss: 0.00006529
INFO:root:[259,   550] training loss: 0.00036532
INFO:root:[259,   600] training loss: 0.00024540
INFO:root:[259,   650] training loss: 0.00012643
INFO:root:[259,   700] training loss: 0.00014687
INFO:root:[259,   750] training loss: 0.00141816
INFO:root:[259,   800] training loss: 0.00169850
INFO:root:[259,   850] training loss: 0.00171100
INFO:root:[259,   900] training loss: 0.00798842
INFO:root:[259,   950] training loss: 0.00302181
INFO:root:[259,  1000] training loss: 0.00002101
INFO:root:[259,  1050] training loss: 0.00001891
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch259
INFO:root:[260,    50] training loss: 0.00915798
INFO:root:[260,   100] training loss: 0.00981838
INFO:root:[260,   150] training loss: 0.01127530
INFO:root:[260,   200] training loss: 0.00971111
INFO:root:[260,   250] training loss: 0.00931532
INFO:root:[260,   300] training loss: 0.01074208
INFO:root:[260,   350] training loss: 0.00836444
INFO:root:[260,   400] training loss: 0.00001707
INFO:root:[260,   450] training loss: 0.00002634
INFO:root:[260,   500] training loss: 0.00006191
INFO:root:[260,   550] training loss: 0.00035074
INFO:root:[260,   600] training loss: 0.00023499
INFO:root:[260,   650] training loss: 0.00011924
INFO:root:[260,   700] training loss: 0.00013753
INFO:root:[260,   750] training loss: 0.00149301
INFO:root:[260,   800] training loss: 0.00183354
INFO:root:[260,   850] training loss: 0.00150383
INFO:root:[260,   900] training loss: 0.00845485
INFO:root:[260,   950] training loss: 0.00313444
INFO:root:[260,  1000] training loss: 0.00002116
INFO:root:[260,  1050] training loss: 0.00002480
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch260
INFO:root:[261,    50] training loss: 0.00906166
INFO:root:[261,   100] training loss: 0.01016681
INFO:root:[261,   150] training loss: 0.01049143
INFO:root:[261,   200] training loss: 0.00953986
INFO:root:[261,   250] training loss: 0.01000136
INFO:root:[261,   300] training loss: 0.01168634
INFO:root:[261,   350] training loss: 0.00818590
INFO:root:[261,   400] training loss: 0.00001592
INFO:root:[261,   450] training loss: 0.00002881
INFO:root:[261,   500] training loss: 0.00008197
INFO:root:[261,   550] training loss: 0.00034680
INFO:root:[261,   600] training loss: 0.00020692
INFO:root:[261,   650] training loss: 0.00013703
INFO:root:[261,   700] training loss: 0.00013692
INFO:root:[261,   750] training loss: 0.00151346
INFO:root:[261,   800] training loss: 0.00159058
INFO:root:[261,   850] training loss: 0.00145689
INFO:root:[261,   900] training loss: 0.00842848
INFO:root:[261,   950] training loss: 0.00357795
INFO:root:[261,  1000] training loss: 0.00002183
INFO:root:[261,  1050] training loss: 0.00001961
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch261
INFO:root:[262,    50] training loss: 0.00919982
INFO:root:[262,   100] training loss: 0.01078591
INFO:root:[262,   150] training loss: 0.01420468
INFO:root:[262,   200] training loss: 0.00978380
INFO:root:[262,   250] training loss: 0.00958369
INFO:root:[262,   300] training loss: 0.01070870
INFO:root:[262,   350] training loss: 0.00786945
INFO:root:[262,   400] training loss: 0.00001925
INFO:root:[262,   450] training loss: 0.00003045
INFO:root:[262,   500] training loss: 0.00007003
INFO:root:[262,   550] training loss: 0.00038684
INFO:root:[262,   600] training loss: 0.00025163
INFO:root:[262,   650] training loss: 0.00012391
INFO:root:[262,   700] training loss: 0.00015555
INFO:root:[262,   750] training loss: 0.00152859
INFO:root:[262,   800] training loss: 0.00173733
INFO:root:[262,   850] training loss: 0.00178671
INFO:root:[262,   900] training loss: 0.00772382
INFO:root:[262,   950] training loss: 0.00590195
INFO:root:[262,  1000] training loss: 0.00002262
INFO:root:[262,  1050] training loss: 0.00002705
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch262
INFO:root:[263,    50] training loss: 0.00938012
INFO:root:[263,   100] training loss: 0.01008377
INFO:root:[263,   150] training loss: 0.01027306
INFO:root:[263,   200] training loss: 0.00941237
INFO:root:[263,   250] training loss: 0.00952480
INFO:root:[263,   300] training loss: 0.01063990
INFO:root:[263,   350] training loss: 0.00859997
INFO:root:[263,   400] training loss: 0.00001780
INFO:root:[263,   450] training loss: 0.00002825
INFO:root:[263,   500] training loss: 0.00006680
INFO:root:[263,   550] training loss: 0.00033006
INFO:root:[263,   600] training loss: 0.00024946
INFO:root:[263,   650] training loss: 0.00015100
INFO:root:[263,   700] training loss: 0.00021322
INFO:root:[263,   750] training loss: 0.00152043
INFO:root:[263,   800] training loss: 0.00164302
INFO:root:[263,   850] training loss: 0.00159248
INFO:root:[263,   900] training loss: 0.00956169
INFO:root:[263,   950] training loss: 0.00294225
INFO:root:[263,  1000] training loss: 0.00002945
INFO:root:[263,  1050] training loss: 0.00002019
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch263
INFO:root:[264,    50] training loss: 0.00944359
INFO:root:[264,   100] training loss: 0.00992760
INFO:root:[264,   150] training loss: 0.01030543
INFO:root:[264,   200] training loss: 0.00943032
INFO:root:[264,   250] training loss: 0.00986890
INFO:root:[264,   300] training loss: 0.01091647
INFO:root:[264,   350] training loss: 0.00815384
INFO:root:[264,   400] training loss: 0.00001953
INFO:root:[264,   450] training loss: 0.00004312
INFO:root:[264,   500] training loss: 0.00006047
INFO:root:[264,   550] training loss: 0.00042124
INFO:root:[264,   600] training loss: 0.00022980
INFO:root:[264,   650] training loss: 0.00012047
INFO:root:[264,   700] training loss: 0.00013557
INFO:root:[264,   750] training loss: 0.00146389
INFO:root:[264,   800] training loss: 0.00182707
INFO:root:[264,   850] training loss: 0.00149411
INFO:root:[264,   900] training loss: 0.00906788
INFO:root:[264,   950] training loss: 0.00296915
INFO:root:[264,  1000] training loss: 0.00002233
INFO:root:[264,  1050] training loss: 0.00002424
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch264
INFO:root:[265,    50] training loss: 0.00921873
INFO:root:[265,   100] training loss: 0.00993005
INFO:root:[265,   150] training loss: 0.00976714
INFO:root:[265,   200] training loss: 0.01009761
INFO:root:[265,   250] training loss: 0.00948276
INFO:root:[265,   300] training loss: 0.01115216
INFO:root:[265,   350] training loss: 0.00791953
INFO:root:[265,   400] training loss: 0.00001742
INFO:root:[265,   450] training loss: 0.00002750
INFO:root:[265,   500] training loss: 0.00005521
INFO:root:[265,   550] training loss: 0.00037728
INFO:root:[265,   600] training loss: 0.00025198
INFO:root:[265,   650] training loss: 0.00012769
INFO:root:[265,   700] training loss: 0.00015090
INFO:root:[265,   750] training loss: 0.00155726
INFO:root:[265,   800] training loss: 0.00174444
INFO:root:[265,   850] training loss: 0.00148049
INFO:root:[265,   900] training loss: 0.00790666
INFO:root:[265,   950] training loss: 0.00298923
INFO:root:[265,  1000] training loss: 0.00002370
INFO:root:[265,  1050] training loss: 0.00002341
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch265
INFO:root:[266,    50] training loss: 0.00916458
INFO:root:[266,   100] training loss: 0.01126576
INFO:root:[266,   150] training loss: 0.01007948
INFO:root:[266,   200] training loss: 0.00906858
INFO:root:[266,   250] training loss: 0.00987789
INFO:root:[266,   300] training loss: 0.01154505
INFO:root:[266,   350] training loss: 0.00790602
INFO:root:[266,   400] training loss: 0.00001902
INFO:root:[266,   450] training loss: 0.00002618
INFO:root:[266,   500] training loss: 0.00004455
INFO:root:[266,   550] training loss: 0.00034213
INFO:root:[266,   600] training loss: 0.00032409
INFO:root:[266,   650] training loss: 0.00012043
INFO:root:[266,   700] training loss: 0.00015181
INFO:root:[266,   750] training loss: 0.00155059
INFO:root:[266,   800] training loss: 0.00166048
INFO:root:[266,   850] training loss: 0.00145526
INFO:root:[266,   900] training loss: 0.00790906
INFO:root:[266,   950] training loss: 0.00298705
INFO:root:[266,  1000] training loss: 0.00002324
INFO:root:[266,  1050] training loss: 0.00002027
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch266
INFO:root:[267,    50] training loss: 0.00922282
INFO:root:[267,   100] training loss: 0.00975862
INFO:root:[267,   150] training loss: 0.00977102
INFO:root:[267,   200] training loss: 0.00939311
INFO:root:[267,   250] training loss: 0.00940984
INFO:root:[267,   300] training loss: 0.01081395
INFO:root:[267,   350] training loss: 0.00946930
INFO:root:[267,   400] training loss: 0.00001702
INFO:root:[267,   450] training loss: 0.00003137
INFO:root:[267,   500] training loss: 0.00013078
INFO:root:[267,   550] training loss: 0.00037895
INFO:root:[267,   600] training loss: 0.00022196
INFO:root:[267,   650] training loss: 0.00011965
INFO:root:[267,   700] training loss: 0.00013657
INFO:root:[267,   750] training loss: 0.00143155
INFO:root:[267,   800] training loss: 0.00159036
INFO:root:[267,   850] training loss: 0.00159666
INFO:root:[267,   900] training loss: 0.00836146
INFO:root:[267,   950] training loss: 0.00386454
INFO:root:[267,  1000] training loss: 0.00002500
INFO:root:[267,  1050] training loss: 0.00002251
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch267
INFO:root:[268,    50] training loss: 0.00929717
INFO:root:[268,   100] training loss: 0.01055451
INFO:root:[268,   150] training loss: 0.01023778
INFO:root:[268,   200] training loss: 0.00960889
INFO:root:[268,   250] training loss: 0.00937157
INFO:root:[268,   300] training loss: 0.01127208
INFO:root:[268,   350] training loss: 0.00890342
INFO:root:[268,   400] training loss: 0.00001793
INFO:root:[268,   450] training loss: 0.00002626
INFO:root:[268,   500] training loss: 0.00004199
INFO:root:[268,   550] training loss: 0.00040762
INFO:root:[268,   600] training loss: 0.00022568
INFO:root:[268,   650] training loss: 0.00011998
INFO:root:[268,   700] training loss: 0.00013416
INFO:root:[268,   750] training loss: 0.00143558
INFO:root:[268,   800] training loss: 0.00160429
INFO:root:[268,   850] training loss: 0.00156166
INFO:root:[268,   900] training loss: 0.00783780
INFO:root:[268,   950] training loss: 0.00292792
INFO:root:[268,  1000] training loss: 0.00002271
INFO:root:[268,  1050] training loss: 0.00002287
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch268
INFO:root:[269,    50] training loss: 0.00980246
INFO:root:[269,   100] training loss: 0.00932379
INFO:root:[269,   150] training loss: 0.01038868
INFO:root:[269,   200] training loss: 0.00978346
INFO:root:[269,   250] training loss: 0.01146878
INFO:root:[269,   300] training loss: 0.01081994
INFO:root:[269,   350] training loss: 0.00895365
INFO:root:[269,   400] training loss: 0.00001757
INFO:root:[269,   450] training loss: 0.00002494
INFO:root:[269,   500] training loss: 0.00006969
INFO:root:[269,   550] training loss: 0.00037125
INFO:root:[269,   600] training loss: 0.00024297
INFO:root:[269,   650] training loss: 0.00012858
INFO:root:[269,   700] training loss: 0.00015160
INFO:root:[269,   750] training loss: 0.00159494
INFO:root:[269,   800] training loss: 0.00171027
INFO:root:[269,   850] training loss: 0.00157394
INFO:root:[269,   900] training loss: 0.00822681
INFO:root:[269,   950] training loss: 0.00328090
INFO:root:[269,  1000] training loss: 0.00002030
INFO:root:[269,  1050] training loss: 0.00002530
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch269
INFO:root:[270,    50] training loss: 0.00974567
INFO:root:[270,   100] training loss: 0.01047282
INFO:root:[270,   150] training loss: 0.00989789
INFO:root:[270,   200] training loss: 0.00989294
INFO:root:[270,   250] training loss: 0.00965515
INFO:root:[270,   300] training loss: 0.01047373
INFO:root:[270,   350] training loss: 0.00792513
INFO:root:[270,   400] training loss: 0.00001852
INFO:root:[270,   450] training loss: 0.00003195
INFO:root:[270,   500] training loss: 0.00010091
INFO:root:[270,   550] training loss: 0.00039823
INFO:root:[270,   600] training loss: 0.00024402
INFO:root:[270,   650] training loss: 0.00013711
INFO:root:[270,   700] training loss: 0.00014185
INFO:root:[270,   750] training loss: 0.00148627
INFO:root:[270,   800] training loss: 0.00175532
INFO:root:[270,   850] training loss: 0.00159052
INFO:root:[270,   900] training loss: 0.00752676
INFO:root:[270,   950] training loss: 0.00303571
INFO:root:[270,  1000] training loss: 0.00002332
INFO:root:[270,  1050] training loss: 0.00002406
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch270
INFO:root:[271,    50] training loss: 0.00956079
INFO:root:[271,   100] training loss: 0.01100936
INFO:root:[271,   150] training loss: 0.01055040
INFO:root:[271,   200] training loss: 0.00975720
INFO:root:[271,   250] training loss: 0.00978690
INFO:root:[271,   300] training loss: 0.01033304
INFO:root:[271,   350] training loss: 0.00844303
INFO:root:[271,   400] training loss: 0.00001905
INFO:root:[271,   450] training loss: 0.00002844
INFO:root:[271,   500] training loss: 0.00005321
INFO:root:[271,   550] training loss: 0.00040939
INFO:root:[271,   600] training loss: 0.00031841
INFO:root:[271,   650] training loss: 0.00012332
INFO:root:[271,   700] training loss: 0.00013788
INFO:root:[271,   750] training loss: 0.00154863
INFO:root:[271,   800] training loss: 0.00178762
INFO:root:[271,   850] training loss: 0.00161585
INFO:root:[271,   900] training loss: 0.00799087
INFO:root:[271,   950] training loss: 0.00342579
INFO:root:[271,  1000] training loss: 0.00002332
INFO:root:[271,  1050] training loss: 0.00002001
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch271
INFO:root:[272,    50] training loss: 0.00965300
INFO:root:[272,   100] training loss: 0.01052734
INFO:root:[272,   150] training loss: 0.00988857
INFO:root:[272,   200] training loss: 0.00977591
INFO:root:[272,   250] training loss: 0.00933211
INFO:root:[272,   300] training loss: 0.01045657
INFO:root:[272,   350] training loss: 0.00825501
INFO:root:[272,   400] training loss: 0.00001954
INFO:root:[272,   450] training loss: 0.00002560
INFO:root:[272,   500] training loss: 0.00006654
INFO:root:[272,   550] training loss: 0.00037758
INFO:root:[272,   600] training loss: 0.00024517
INFO:root:[272,   650] training loss: 0.00015081
INFO:root:[272,   700] training loss: 0.00015607
INFO:root:[272,   750] training loss: 0.00157013
INFO:root:[272,   800] training loss: 0.00164778
INFO:root:[272,   850] training loss: 0.00156173
INFO:root:[272,   900] training loss: 0.00722576
INFO:root:[272,   950] training loss: 0.00382583
INFO:root:[272,  1000] training loss: 0.00002283
INFO:root:[272,  1050] training loss: 0.00002274
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch272
INFO:root:[273,    50] training loss: 0.00919649
INFO:root:[273,   100] training loss: 0.00970867
INFO:root:[273,   150] training loss: 0.01029876
INFO:root:[273,   200] training loss: 0.01023562
INFO:root:[273,   250] training loss: 0.00944956
INFO:root:[273,   300] training loss: 0.01120070
INFO:root:[273,   350] training loss: 0.00812395
INFO:root:[273,   400] training loss: 0.00001998
INFO:root:[273,   450] training loss: 0.00002950
INFO:root:[273,   500] training loss: 0.00004414
INFO:root:[273,   550] training loss: 0.00037461
INFO:root:[273,   600] training loss: 0.00024755
INFO:root:[273,   650] training loss: 0.00010917
INFO:root:[273,   700] training loss: 0.00015959
INFO:root:[273,   750] training loss: 0.00159012
INFO:root:[273,   800] training loss: 0.00170251
INFO:root:[273,   850] training loss: 0.00165431
INFO:root:[273,   900] training loss: 0.00892307
INFO:root:[273,   950] training loss: 0.00324055
INFO:root:[273,  1000] training loss: 0.00001967
INFO:root:[273,  1050] training loss: 0.00002210
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch273
INFO:root:[274,    50] training loss: 0.00986693
INFO:root:[274,   100] training loss: 0.01031298
INFO:root:[274,   150] training loss: 0.01043345
INFO:root:[274,   200] training loss: 0.00960767
INFO:root:[274,   250] training loss: 0.00992115
INFO:root:[274,   300] training loss: 0.00977274
INFO:root:[274,   350] training loss: 0.00859824
INFO:root:[274,   400] training loss: 0.00001837
INFO:root:[274,   450] training loss: 0.00004400
INFO:root:[274,   500] training loss: 0.00004692
INFO:root:[274,   550] training loss: 0.00031581
INFO:root:[274,   600] training loss: 0.00025793
INFO:root:[274,   650] training loss: 0.00015749
INFO:root:[274,   700] training loss: 0.00014365
INFO:root:[274,   750] training loss: 0.00142848
INFO:root:[274,   800] training loss: 0.00173825
INFO:root:[274,   850] training loss: 0.00152155
INFO:root:[274,   900] training loss: 0.00766985
INFO:root:[274,   950] training loss: 0.00310491
INFO:root:[274,  1000] training loss: 0.00003085
INFO:root:[274,  1050] training loss: 0.00002384
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch274
INFO:root:[275,    50] training loss: 0.00910804
INFO:root:[275,   100] training loss: 0.01057161
INFO:root:[275,   150] training loss: 0.00973362
INFO:root:[275,   200] training loss: 0.01002734
INFO:root:[275,   250] training loss: 0.00947229
INFO:root:[275,   300] training loss: 0.01073762
INFO:root:[275,   350] training loss: 0.00851452
INFO:root:[275,   400] training loss: 0.00001961
INFO:root:[275,   450] training loss: 0.00002671
INFO:root:[275,   500] training loss: 0.00006032
INFO:root:[275,   550] training loss: 0.00036519
INFO:root:[275,   600] training loss: 0.00025281
INFO:root:[275,   650] training loss: 0.00012202
INFO:root:[275,   700] training loss: 0.00012059
INFO:root:[275,   750] training loss: 0.00147443
INFO:root:[275,   800] training loss: 0.00161787
INFO:root:[275,   850] training loss: 0.00147489
INFO:root:[275,   900] training loss: 0.00777793
INFO:root:[275,   950] training loss: 0.00367428
INFO:root:[275,  1000] training loss: 0.00002161
INFO:root:[275,  1050] training loss: 0.00002112
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch275
INFO:root:[276,    50] training loss: 0.00939890
INFO:root:[276,   100] training loss: 0.01047322
INFO:root:[276,   150] training loss: 0.01079902
INFO:root:[276,   200] training loss: 0.00980248
INFO:root:[276,   250] training loss: 0.00968234
INFO:root:[276,   300] training loss: 0.01016445
INFO:root:[276,   350] training loss: 0.00838768
INFO:root:[276,   400] training loss: 0.00001760
INFO:root:[276,   450] training loss: 0.00002537
INFO:root:[276,   500] training loss: 0.00007425
INFO:root:[276,   550] training loss: 0.00036847
INFO:root:[276,   600] training loss: 0.00026216
INFO:root:[276,   650] training loss: 0.00012833
INFO:root:[276,   700] training loss: 0.00013914
INFO:root:[276,   750] training loss: 0.00151296
INFO:root:[276,   800] training loss: 0.00173991
INFO:root:[276,   850] training loss: 0.00159156
INFO:root:[276,   900] training loss: 0.00800691
INFO:root:[276,   950] training loss: 0.00348305
INFO:root:[276,  1000] training loss: 0.00002540
INFO:root:[276,  1050] training loss: 0.00002121
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch276
INFO:root:[277,    50] training loss: 0.00971475
INFO:root:[277,   100] training loss: 0.00971214
INFO:root:[277,   150] training loss: 0.01047489
INFO:root:[277,   200] training loss: 0.01020673
INFO:root:[277,   250] training loss: 0.00979150
INFO:root:[277,   300] training loss: 0.01064355
INFO:root:[277,   350] training loss: 0.00820577
INFO:root:[277,   400] training loss: 0.00001890
INFO:root:[277,   450] training loss: 0.00002752
INFO:root:[277,   500] training loss: 0.00006067
INFO:root:[277,   550] training loss: 0.00033977
INFO:root:[277,   600] training loss: 0.00023678
INFO:root:[277,   650] training loss: 0.00013925
INFO:root:[277,   700] training loss: 0.00015094
INFO:root:[277,   750] training loss: 0.00150859
INFO:root:[277,   800] training loss: 0.00161047
INFO:root:[277,   850] training loss: 0.00144874
INFO:root:[277,   900] training loss: 0.00760696
INFO:root:[277,   950] training loss: 0.00338433
INFO:root:[277,  1000] training loss: 0.00002301
INFO:root:[277,  1050] training loss: 0.00002085
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch277
INFO:root:[278,    50] training loss: 0.00918942
INFO:root:[278,   100] training loss: 0.00983771
INFO:root:[278,   150] training loss: 0.01043644
INFO:root:[278,   200] training loss: 0.00961280
INFO:root:[278,   250] training loss: 0.00951146
INFO:root:[278,   300] training loss: 0.01008743
INFO:root:[278,   350] training loss: 0.00815709
INFO:root:[278,   400] training loss: 0.00001757
INFO:root:[278,   450] training loss: 0.00002484
INFO:root:[278,   500] training loss: 0.00006624
INFO:root:[278,   550] training loss: 0.00034674
INFO:root:[278,   600] training loss: 0.00028044
INFO:root:[278,   650] training loss: 0.00013925
INFO:root:[278,   700] training loss: 0.00014478
INFO:root:[278,   750] training loss: 0.00147434
INFO:root:[278,   800] training loss: 0.00172372
INFO:root:[278,   850] training loss: 0.00151654
INFO:root:[278,   900] training loss: 0.00856021
INFO:root:[278,   950] training loss: 0.00300061
INFO:root:[278,  1000] training loss: 0.00003303
INFO:root:[278,  1050] training loss: 0.00002214
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch278
INFO:root:[279,    50] training loss: 0.00980974
INFO:root:[279,   100] training loss: 0.00954814
INFO:root:[279,   150] training loss: 0.01024979
INFO:root:[279,   200] training loss: 0.00961679
INFO:root:[279,   250] training loss: 0.00985616
INFO:root:[279,   300] training loss: 0.01061422
INFO:root:[279,   350] training loss: 0.00821384
INFO:root:[279,   400] training loss: 0.00001771
INFO:root:[279,   450] training loss: 0.00002665
INFO:root:[279,   500] training loss: 0.00005797
INFO:root:[279,   550] training loss: 0.00038471
INFO:root:[279,   600] training loss: 0.00023566
INFO:root:[279,   650] training loss: 0.00012972
INFO:root:[279,   700] training loss: 0.00013494
INFO:root:[279,   750] training loss: 0.00162047
INFO:root:[279,   800] training loss: 0.00189418
INFO:root:[279,   850] training loss: 0.00159178
INFO:root:[279,   900] training loss: 0.00892982
INFO:root:[279,   950] training loss: 0.00297122
INFO:root:[279,  1000] training loss: 0.00002635
INFO:root:[279,  1050] training loss: 0.00001902
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch279
INFO:root:[280,    50] training loss: 0.00933875
INFO:root:[280,   100] training loss: 0.01026518
INFO:root:[280,   150] training loss: 0.01008403
INFO:root:[280,   200] training loss: 0.01056509
INFO:root:[280,   250] training loss: 0.00972958
INFO:root:[280,   300] training loss: 0.01028386
INFO:root:[280,   350] training loss: 0.00903756
INFO:root:[280,   400] training loss: 0.00001813
INFO:root:[280,   450] training loss: 0.00002937
INFO:root:[280,   500] training loss: 0.00004664
INFO:root:[280,   550] training loss: 0.00033366
INFO:root:[280,   600] training loss: 0.00025173
INFO:root:[280,   650] training loss: 0.00015910
INFO:root:[280,   700] training loss: 0.00013279
INFO:root:[280,   750] training loss: 0.00157465
INFO:root:[280,   800] training loss: 0.00179228
INFO:root:[280,   850] training loss: 0.00162861
INFO:root:[280,   900] training loss: 0.00794644
INFO:root:[280,   950] training loss: 0.00343752
INFO:root:[280,  1000] training loss: 0.00002178
INFO:root:[280,  1050] training loss: 0.00002983
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch280
INFO:root:[281,    50] training loss: 0.00946056
INFO:root:[281,   100] training loss: 0.00931297
INFO:root:[281,   150] training loss: 0.01092900
INFO:root:[281,   200] training loss: 0.00959954
INFO:root:[281,   250] training loss: 0.00959653
INFO:root:[281,   300] training loss: 0.01008211
INFO:root:[281,   350] training loss: 0.00843111
INFO:root:[281,   400] training loss: 0.00001640
INFO:root:[281,   450] training loss: 0.00002713
INFO:root:[281,   500] training loss: 0.00008659
INFO:root:[281,   550] training loss: 0.00037960
INFO:root:[281,   600] training loss: 0.00020610
INFO:root:[281,   650] training loss: 0.00013085
INFO:root:[281,   700] training loss: 0.00018454
INFO:root:[281,   750] training loss: 0.00148066
INFO:root:[281,   800] training loss: 0.00175435
INFO:root:[281,   850] training loss: 0.00150652
INFO:root:[281,   900] training loss: 0.00756583
INFO:root:[281,   950] training loss: 0.00341286
INFO:root:[281,  1000] training loss: 0.00002664
INFO:root:[281,  1050] training loss: 0.00002153
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch281
INFO:root:[282,    50] training loss: 0.00914770
INFO:root:[282,   100] training loss: 0.00979286
INFO:root:[282,   150] training loss: 0.01048990
INFO:root:[282,   200] training loss: 0.00942365
INFO:root:[282,   250] training loss: 0.00949731
INFO:root:[282,   300] training loss: 0.01166275
INFO:root:[282,   350] training loss: 0.00852858
INFO:root:[282,   400] training loss: 0.00002010
INFO:root:[282,   450] training loss: 0.00002729
INFO:root:[282,   500] training loss: 0.00004954
INFO:root:[282,   550] training loss: 0.00033007
INFO:root:[282,   600] training loss: 0.00024049
INFO:root:[282,   650] training loss: 0.00012583
INFO:root:[282,   700] training loss: 0.00017958
INFO:root:[282,   750] training loss: 0.00157062
INFO:root:[282,   800] training loss: 0.00165907
INFO:root:[282,   850] training loss: 0.00160397
INFO:root:[282,   900] training loss: 0.00820879
INFO:root:[282,   950] training loss: 0.00271693
INFO:root:[282,  1000] training loss: 0.00002207
INFO:root:[282,  1050] training loss: 0.00001744
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch282
INFO:root:[283,    50] training loss: 0.00939310
INFO:root:[283,   100] training loss: 0.01010196
INFO:root:[283,   150] training loss: 0.01022892
INFO:root:[283,   200] training loss: 0.01119297
INFO:root:[283,   250] training loss: 0.00906695
INFO:root:[283,   300] training loss: 0.00998495
INFO:root:[283,   350] training loss: 0.00810032
INFO:root:[283,   400] training loss: 0.00001795
INFO:root:[283,   450] training loss: 0.00002423
INFO:root:[283,   500] training loss: 0.00004532
INFO:root:[283,   550] training loss: 0.00035063
INFO:root:[283,   600] training loss: 0.00026939
INFO:root:[283,   650] training loss: 0.00011571
INFO:root:[283,   700] training loss: 0.00016482
INFO:root:[283,   750] training loss: 0.00148897
INFO:root:[283,   800] training loss: 0.00161338
INFO:root:[283,   850] training loss: 0.00146723
INFO:root:[283,   900] training loss: 0.00876622
INFO:root:[283,   950] training loss: 0.00300721
INFO:root:[283,  1000] training loss: 0.00002178
INFO:root:[283,  1050] training loss: 0.00002268
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch283
INFO:root:[284,    50] training loss: 0.00932151
INFO:root:[284,   100] training loss: 0.00972334
INFO:root:[284,   150] training loss: 0.00946092
INFO:root:[284,   200] training loss: 0.00977590
INFO:root:[284,   250] training loss: 0.00971509
INFO:root:[284,   300] training loss: 0.01263786
INFO:root:[284,   350] training loss: 0.00933035
INFO:root:[284,   400] training loss: 0.00001956
INFO:root:[284,   450] training loss: 0.00002631
INFO:root:[284,   500] training loss: 0.00006976
INFO:root:[284,   550] training loss: 0.00032747
INFO:root:[284,   600] training loss: 0.00024459
INFO:root:[284,   650] training loss: 0.00010446
INFO:root:[284,   700] training loss: 0.00017240
INFO:root:[284,   750] training loss: 0.00152624
INFO:root:[284,   800] training loss: 0.00168567
INFO:root:[284,   850] training loss: 0.00155598
INFO:root:[284,   900] training loss: 0.00861919
INFO:root:[284,   950] training loss: 0.00295944
INFO:root:[284,  1000] training loss: 0.00002801
INFO:root:[284,  1050] training loss: 0.00002204
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch284
INFO:root:[285,    50] training loss: 0.00956778
INFO:root:[285,   100] training loss: 0.00985216
INFO:root:[285,   150] training loss: 0.01018714
INFO:root:[285,   200] training loss: 0.00998232
INFO:root:[285,   250] training loss: 0.01001638
INFO:root:[285,   300] training loss: 0.01156923
INFO:root:[285,   350] training loss: 0.00959222
INFO:root:[285,   400] training loss: 0.00001843
INFO:root:[285,   450] training loss: 0.00002903
INFO:root:[285,   500] training loss: 0.00004589
INFO:root:[285,   550] training loss: 0.00039619
INFO:root:[285,   600] training loss: 0.00030242
INFO:root:[285,   650] training loss: 0.00011757
INFO:root:[285,   700] training loss: 0.00015556
INFO:root:[285,   750] training loss: 0.00145867
INFO:root:[285,   800] training loss: 0.00168831
INFO:root:[285,   850] training loss: 0.00166773
INFO:root:[285,   900] training loss: 0.00786210
INFO:root:[285,   950] training loss: 0.00303430
INFO:root:[285,  1000] training loss: 0.00002767
INFO:root:[285,  1050] training loss: 0.00002382
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch285
INFO:root:[286,    50] training loss: 0.00930680
INFO:root:[286,   100] training loss: 0.00992173
INFO:root:[286,   150] training loss: 0.01038285
INFO:root:[286,   200] training loss: 0.01016173
INFO:root:[286,   250] training loss: 0.00941580
INFO:root:[286,   300] training loss: 0.01041647
INFO:root:[286,   350] training loss: 0.00785841
INFO:root:[286,   400] training loss: 0.00002363
INFO:root:[286,   450] training loss: 0.00002507
INFO:root:[286,   500] training loss: 0.00004662
INFO:root:[286,   550] training loss: 0.00034661
INFO:root:[286,   600] training loss: 0.00026407
INFO:root:[286,   650] training loss: 0.00012665
INFO:root:[286,   700] training loss: 0.00015063
INFO:root:[286,   750] training loss: 0.00163093
INFO:root:[286,   800] training loss: 0.00167277
INFO:root:[286,   850] training loss: 0.00165440
INFO:root:[286,   900] training loss: 0.00828858
INFO:root:[286,   950] training loss: 0.00295993
INFO:root:[286,  1000] training loss: 0.00002231
INFO:root:[286,  1050] training loss: 0.00002222
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch286
INFO:root:[287,    50] training loss: 0.00940492
INFO:root:[287,   100] training loss: 0.01027006
INFO:root:[287,   150] training loss: 0.01014024
INFO:root:[287,   200] training loss: 0.01008973
INFO:root:[287,   250] training loss: 0.00984090
INFO:root:[287,   300] training loss: 0.01048703
INFO:root:[287,   350] training loss: 0.00805336
INFO:root:[287,   400] training loss: 0.00001904
INFO:root:[287,   450] training loss: 0.00002818
INFO:root:[287,   500] training loss: 0.00006330
INFO:root:[287,   550] training loss: 0.00035414
INFO:root:[287,   600] training loss: 0.00025527
INFO:root:[287,   650] training loss: 0.00011312
INFO:root:[287,   700] training loss: 0.00013102
INFO:root:[287,   750] training loss: 0.00139710
INFO:root:[287,   800] training loss: 0.00177077
INFO:root:[287,   850] training loss: 0.00165941
INFO:root:[287,   900] training loss: 0.00831652
INFO:root:[287,   950] training loss: 0.00328507
INFO:root:[287,  1000] training loss: 0.00002690
INFO:root:[287,  1050] training loss: 0.00002220
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch287
INFO:root:[288,    50] training loss: 0.00996347
INFO:root:[288,   100] training loss: 0.00958776
INFO:root:[288,   150] training loss: 0.01023429
INFO:root:[288,   200] training loss: 0.01048796
INFO:root:[288,   250] training loss: 0.00924568
INFO:root:[288,   300] training loss: 0.01134908
INFO:root:[288,   350] training loss: 0.00996637
INFO:root:[288,   400] training loss: 0.00001981
INFO:root:[288,   450] training loss: 0.00002660
INFO:root:[288,   500] training loss: 0.00008012
INFO:root:[288,   550] training loss: 0.00035283
INFO:root:[288,   600] training loss: 0.00024501
INFO:root:[288,   650] training loss: 0.00011701
INFO:root:[288,   700] training loss: 0.00014463
INFO:root:[288,   750] training loss: 0.00150928
INFO:root:[288,   800] training loss: 0.00174916
INFO:root:[288,   850] training loss: 0.00154874
INFO:root:[288,   900] training loss: 0.00793564
INFO:root:[288,   950] training loss: 0.00295453
INFO:root:[288,  1000] training loss: 0.00002221
INFO:root:[288,  1050] training loss: 0.00001913
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch288
INFO:root:[289,    50] training loss: 0.00925717
INFO:root:[289,   100] training loss: 0.00951495
INFO:root:[289,   150] training loss: 0.01013063
INFO:root:[289,   200] training loss: 0.00994440
INFO:root:[289,   250] training loss: 0.00911090
INFO:root:[289,   300] training loss: 0.01028397
INFO:root:[289,   350] training loss: 0.00809413
INFO:root:[289,   400] training loss: 0.00001888
INFO:root:[289,   450] training loss: 0.00002517
INFO:root:[289,   500] training loss: 0.00008506
INFO:root:[289,   550] training loss: 0.00035585
INFO:root:[289,   600] training loss: 0.00023250
INFO:root:[289,   650] training loss: 0.00012015
INFO:root:[289,   700] training loss: 0.00015571
INFO:root:[289,   750] training loss: 0.00155342
INFO:root:[289,   800] training loss: 0.00159808
INFO:root:[289,   850] training loss: 0.00152578
INFO:root:[289,   900] training loss: 0.00871749
INFO:root:[289,   950] training loss: 0.00301472
INFO:root:[289,  1000] training loss: 0.00002573
INFO:root:[289,  1050] training loss: 0.00002114
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch289
INFO:root:[290,    50] training loss: 0.00951167
INFO:root:[290,   100] training loss: 0.00980084
INFO:root:[290,   150] training loss: 0.01072606
INFO:root:[290,   200] training loss: 0.00969783
INFO:root:[290,   250] training loss: 0.00954242
INFO:root:[290,   300] training loss: 0.01016841
INFO:root:[290,   350] training loss: 0.00866933
INFO:root:[290,   400] training loss: 0.00001984
INFO:root:[290,   450] training loss: 0.00003057
INFO:root:[290,   500] training loss: 0.00004822
INFO:root:[290,   550] training loss: 0.00038162
INFO:root:[290,   600] training loss: 0.00027055
INFO:root:[290,   650] training loss: 0.00011792
INFO:root:[290,   700] training loss: 0.00013413
INFO:root:[290,   750] training loss: 0.00155830
INFO:root:[290,   800] training loss: 0.00160569
INFO:root:[290,   850] training loss: 0.00149688
INFO:root:[290,   900] training loss: 0.00799513
INFO:root:[290,   950] training loss: 0.00315256
INFO:root:[290,  1000] training loss: 0.00002536
INFO:root:[290,  1050] training loss: 0.00002229
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch290
INFO:root:[291,    50] training loss: 0.00936704
INFO:root:[291,   100] training loss: 0.00946889
INFO:root:[291,   150] training loss: 0.01011385
INFO:root:[291,   200] training loss: 0.01027058
INFO:root:[291,   250] training loss: 0.00956447
INFO:root:[291,   300] training loss: 0.01052985
INFO:root:[291,   350] training loss: 0.00835470
INFO:root:[291,   400] training loss: 0.00002085
INFO:root:[291,   450] training loss: 0.00002635
INFO:root:[291,   500] training loss: 0.00006672
INFO:root:[291,   550] training loss: 0.00036696
INFO:root:[291,   600] training loss: 0.00025566
INFO:root:[291,   650] training loss: 0.00014149
INFO:root:[291,   700] training loss: 0.00016044
INFO:root:[291,   750] training loss: 0.00159402
INFO:root:[291,   800] training loss: 0.00168602
INFO:root:[291,   850] training loss: 0.00145120
INFO:root:[291,   900] training loss: 0.00863322
INFO:root:[291,   950] training loss: 0.00288588
INFO:root:[291,  1000] training loss: 0.00002344
INFO:root:[291,  1050] training loss: 0.00002178
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch291
INFO:root:[292,    50] training loss: 0.00921905
INFO:root:[292,   100] training loss: 0.00963497
INFO:root:[292,   150] training loss: 0.00969135
INFO:root:[292,   200] training loss: 0.01030178
INFO:root:[292,   250] training loss: 0.00959863
INFO:root:[292,   300] training loss: 0.01027588
INFO:root:[292,   350] training loss: 0.00865482
INFO:root:[292,   400] training loss: 0.00001951
INFO:root:[292,   450] training loss: 0.00002516
INFO:root:[292,   500] training loss: 0.00005792
INFO:root:[292,   550] training loss: 0.00043738
INFO:root:[292,   600] training loss: 0.00025682
INFO:root:[292,   650] training loss: 0.00013466
INFO:root:[292,   700] training loss: 0.00012288
INFO:root:[292,   750] training loss: 0.00152983
INFO:root:[292,   800] training loss: 0.00179493
INFO:root:[292,   850] training loss: 0.00143679
INFO:root:[292,   900] training loss: 0.00768449
INFO:root:[292,   950] training loss: 0.00384015
INFO:root:[292,  1000] training loss: 0.00002876
INFO:root:[292,  1050] training loss: 0.00002323
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch292
INFO:root:[293,    50] training loss: 0.00940662
INFO:root:[293,   100] training loss: 0.00980790
INFO:root:[293,   150] training loss: 0.01029744
INFO:root:[293,   200] training loss: 0.00992700
INFO:root:[293,   250] training loss: 0.00947796
INFO:root:[293,   300] training loss: 0.01119552
INFO:root:[293,   350] training loss: 0.00845797
INFO:root:[293,   400] training loss: 0.00002048
INFO:root:[293,   450] training loss: 0.00003349
INFO:root:[293,   500] training loss: 0.00004506
INFO:root:[293,   550] training loss: 0.00033676
INFO:root:[293,   600] training loss: 0.00025082
INFO:root:[293,   650] training loss: 0.00011963
INFO:root:[293,   700] training loss: 0.00012804
INFO:root:[293,   750] training loss: 0.00158800
INFO:root:[293,   800] training loss: 0.00164220
INFO:root:[293,   850] training loss: 0.00156136
INFO:root:[293,   900] training loss: 0.00741944
INFO:root:[293,   950] training loss: 0.00305157
INFO:root:[293,  1000] training loss: 0.00002271
INFO:root:[293,  1050] training loss: 0.00002498
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch293
INFO:root:[294,    50] training loss: 0.00906006
INFO:root:[294,   100] training loss: 0.01089375
INFO:root:[294,   150] training loss: 0.01081876
INFO:root:[294,   200] training loss: 0.00977227
INFO:root:[294,   250] training loss: 0.00967149
INFO:root:[294,   300] training loss: 0.01127525
INFO:root:[294,   350] training loss: 0.00848083
INFO:root:[294,   400] training loss: 0.00002060
INFO:root:[294,   450] training loss: 0.00002635
INFO:root:[294,   500] training loss: 0.00011948
INFO:root:[294,   550] training loss: 0.00038443
INFO:root:[294,   600] training loss: 0.00023958
INFO:root:[294,   650] training loss: 0.00012623
INFO:root:[294,   700] training loss: 0.00013732
INFO:root:[294,   750] training loss: 0.00151516
INFO:root:[294,   800] training loss: 0.00170859
INFO:root:[294,   850] training loss: 0.00161525
INFO:root:[294,   900] training loss: 0.00789666
INFO:root:[294,   950] training loss: 0.00271736
INFO:root:[294,  1000] training loss: 0.00002777
INFO:root:[294,  1050] training loss: 0.00002713
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch294
INFO:root:[295,    50] training loss: 0.00972780
INFO:root:[295,   100] training loss: 0.01168038
INFO:root:[295,   150] training loss: 0.00965251
INFO:root:[295,   200] training loss: 0.00951891
INFO:root:[295,   250] training loss: 0.00955920
INFO:root:[295,   300] training loss: 0.01005572
INFO:root:[295,   350] training loss: 0.00807696
INFO:root:[295,   400] training loss: 0.00001995
INFO:root:[295,   450] training loss: 0.00002843
INFO:root:[295,   500] training loss: 0.00005758
INFO:root:[295,   550] training loss: 0.00036598
INFO:root:[295,   600] training loss: 0.00024102
INFO:root:[295,   650] training loss: 0.00011583
INFO:root:[295,   700] training loss: 0.00015075
INFO:root:[295,   750] training loss: 0.00145238
INFO:root:[295,   800] training loss: 0.00179771
INFO:root:[295,   850] training loss: 0.00166611
INFO:root:[295,   900] training loss: 0.00746324
INFO:root:[295,   950] training loss: 0.00368196
INFO:root:[295,  1000] training loss: 0.00002633
INFO:root:[295,  1050] training loss: 0.00001875
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch295
INFO:root:[296,    50] training loss: 0.00955224
INFO:root:[296,   100] training loss: 0.01031479
INFO:root:[296,   150] training loss: 0.01012968
INFO:root:[296,   200] training loss: 0.01017648
INFO:root:[296,   250] training loss: 0.00994205
INFO:root:[296,   300] training loss: 0.01041177
INFO:root:[296,   350] training loss: 0.00780236
INFO:root:[296,   400] training loss: 0.00001818
INFO:root:[296,   450] training loss: 0.00002696
INFO:root:[296,   500] training loss: 0.00003915
INFO:root:[296,   550] training loss: 0.00036183
INFO:root:[296,   600] training loss: 0.00033796
INFO:root:[296,   650] training loss: 0.00011571
INFO:root:[296,   700] training loss: 0.00014885
INFO:root:[296,   750] training loss: 0.00153789
INFO:root:[296,   800] training loss: 0.00164122
INFO:root:[296,   850] training loss: 0.00177391
INFO:root:[296,   900] training loss: 0.00824290
INFO:root:[296,   950] training loss: 0.00347359
INFO:root:[296,  1000] training loss: 0.00002367
INFO:root:[296,  1050] training loss: 0.00002419
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch296
INFO:root:[297,    50] training loss: 0.00959497
INFO:root:[297,   100] training loss: 0.01032033
INFO:root:[297,   150] training loss: 0.01010901
INFO:root:[297,   200] training loss: 0.00994767
INFO:root:[297,   250] training loss: 0.00989742
INFO:root:[297,   300] training loss: 0.01098811
INFO:root:[297,   350] training loss: 0.00829090
INFO:root:[297,   400] training loss: 0.00001753
INFO:root:[297,   450] training loss: 0.00002677
INFO:root:[297,   500] training loss: 0.00004545
INFO:root:[297,   550] training loss: 0.00032144
INFO:root:[297,   600] training loss: 0.00024136
INFO:root:[297,   650] training loss: 0.00013014
INFO:root:[297,   700] training loss: 0.00013365
INFO:root:[297,   750] training loss: 0.00144425
INFO:root:[297,   800] training loss: 0.00180141
INFO:root:[297,   850] training loss: 0.00157721
INFO:root:[297,   900] training loss: 0.00783454
INFO:root:[297,   950] training loss: 0.00286300
INFO:root:[297,  1000] training loss: 0.00002506
INFO:root:[297,  1050] training loss: 0.00002564
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch297
INFO:root:[298,    50] training loss: 0.00926820
INFO:root:[298,   100] training loss: 0.00995377
INFO:root:[298,   150] training loss: 0.01043356
INFO:root:[298,   200] training loss: 0.00982220
INFO:root:[298,   250] training loss: 0.00921479
INFO:root:[298,   300] training loss: 0.01156051
INFO:root:[298,   350] training loss: 0.00807199
INFO:root:[298,   400] training loss: 0.00001939
INFO:root:[298,   450] training loss: 0.00002463
INFO:root:[298,   500] training loss: 0.00004557
INFO:root:[298,   550] training loss: 0.00034053
INFO:root:[298,   600] training loss: 0.00027134
INFO:root:[298,   650] training loss: 0.00012414
INFO:root:[298,   700] training loss: 0.00015269
INFO:root:[298,   750] training loss: 0.00150982
INFO:root:[298,   800] training loss: 0.00176161
INFO:root:[298,   850] training loss: 0.00153341
INFO:root:[298,   900] training loss: 0.00736151
INFO:root:[298,   950] training loss: 0.00291811
INFO:root:[298,  1000] training loss: 0.00002268
INFO:root:[298,  1050] training loss: 0.00002422
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch298
INFO:root:[299,    50] training loss: 0.00957305
INFO:root:[299,   100] training loss: 0.01018221
INFO:root:[299,   150] training loss: 0.01050381
INFO:root:[299,   200] training loss: 0.01018798
INFO:root:[299,   250] training loss: 0.00954637
INFO:root:[299,   300] training loss: 0.01051743
INFO:root:[299,   350] training loss: 0.00799221
INFO:root:[299,   400] training loss: 0.00001988
INFO:root:[299,   450] training loss: 0.00002542
INFO:root:[299,   500] training loss: 0.00005942
INFO:root:[299,   550] training loss: 0.00038078
INFO:root:[299,   600] training loss: 0.00025588
INFO:root:[299,   650] training loss: 0.00013976
INFO:root:[299,   700] training loss: 0.00014461
INFO:root:[299,   750] training loss: 0.00146549
INFO:root:[299,   800] training loss: 0.00167645
INFO:root:[299,   850] training loss: 0.00155261
INFO:root:[299,   900] training loss: 0.00752930
INFO:root:[299,   950] training loss: 0.00299441
INFO:root:[299,  1000] training loss: 0.00002178
INFO:root:[299,  1050] training loss: 0.00002175
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch299
INFO:root:[300,    50] training loss: 0.01025222
INFO:root:[300,   100] training loss: 0.00969176
INFO:root:[300,   150] training loss: 0.01041234
INFO:root:[300,   200] training loss: 0.00991086
INFO:root:[300,   250] training loss: 0.00983642
INFO:root:[300,   300] training loss: 0.01104959
INFO:root:[300,   350] training loss: 0.00919094
INFO:root:[300,   400] training loss: 0.00001924
INFO:root:[300,   450] training loss: 0.00002718
INFO:root:[300,   500] training loss: 0.00004817
INFO:root:[300,   550] training loss: 0.00037987
INFO:root:[300,   600] training loss: 0.00024455
INFO:root:[300,   650] training loss: 0.00011468
INFO:root:[300,   700] training loss: 0.00014525
INFO:root:[300,   750] training loss: 0.00142757
INFO:root:[300,   800] training loss: 0.00162126
INFO:root:[300,   850] training loss: 0.00163798
INFO:root:[300,   900] training loss: 0.00850478
INFO:root:[300,   950] training loss: 0.00313100
INFO:root:[300,  1000] training loss: 0.00002333
INFO:root:[300,  1050] training loss: 0.00002437
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
           S     0.9245    0.8262    0.8726      1720
   Telophase     0.7796    0.7984    0.7889      1032
          G2     0.4000    0.7500    0.5217         8
    Anaphase     0.2876    0.6027    0.3894        73
    Prophase     0.6449    0.6886    0.6660      1034
   Metaphase     0.7500    1.0000    0.8571         3

    accuracy                         0.7776      3872
   macro avg     0.6124    0.7380    0.6565      3872
weighted avg     0.7978    0.7776    0.7851      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6454 test images: 78 %
INFO:root:The model saved: final_model_dict_jcd_h5_wo_0_2.pth
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.6667    0.5714         3
           S     0.9387    0.8068    0.8678      2867
   Telophase     0.7836    0.8314    0.8068      1720
          G2     0.4138    0.8571    0.5581        14
    Anaphase     0.3249    0.6364    0.4302       121
    Prophase     0.6376    0.6990    0.6669      1724
   Metaphase     1.0000    1.0000    1.0000         5

    accuracy                         0.7815      6454
   macro avg     0.6569    0.7853    0.7002      6454
weighted avg     0.8041    0.7815    0.7889      6454

INFO:root:         G1         S  Telophase       G2  Anaphase  Prophase  Metaphase
0  0.571429  0.867755    0.80677  0.55814  0.430168  0.666851        1.0
