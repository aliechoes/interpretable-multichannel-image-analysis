INFO:root:the deviced being used is cuda:0
INFO:root:statistics used: {'mean': tensor([0.3082, 0.0616]), 'std': tensor([0.1656, 0.1627])}
INFO:root:test_indx used: 8237, 3382, 2361, 23748, 26770, 23949, 26217, 2657, 12907, 12557, 9901, 28753, 26388, 18315, 9953, 1279, 483, 29762, 10375, 15787, 19051, 2360, 15455, 3587, 18292, 15161, 23610, 3242, 14355, 6639, 26804, 8859, 23863, 8840, 14873, 7827, 20791, 4885, 26928, 3376, 13621, 29907, 25215, 22651, 14878, 23525, 26595, 3688, 17113, 26824, 25818, 5062, 30105, 24690, 3709, 28211, 21721, 2321, 25599, 29410, 21245, 31452, 4282, 29187, 24573, 9878, 8000, 3446, 644, 22650, 1335, 13040, 19767, 26185, 16244, 31665, 21214, 13237, 3835, 11641, 4531, 24304, 184, 32152, 2830, 3798, 2016, 5724, 14967, 23031, 4668, 19491, 8718, 24518, 18181, 24615, 24372, 6955, 25187, 19658, 14280, 11520, 7434, 23161, 18419, 9989, 7944, 1516, 13962, 25255, 494, 26071, 15251, 26837, 28784, 9727, 17183, 9126, 18414, 4571, 17614, 3525, 28278, 25052, 1204, 18733, 4201, 22394, 18005, 19869, 4714, 374, 10896, 13991, 20660, 22152, 18343, 5290, 16743, 8031, 16729, 3130, 821, 19211, 17013, 21072, 7150, 7269, 31594, 26072, 21791, 27380, 28244, 3787, 19620, 9722, 14850, 27137, 13317, 5825, 31670, 2478, 12442, 12667, 26485, 605, 15491, 28725, 10831, 22164, 4042, 31518, 20299, 10842, 20721, 23386, 24865, 29958, 6284, 16696, 7578, 7340, 15998, 3155, 281, 2502, 11972, 25068, 18715, 17557, 4092, 27294, 29398, 8727, 24955, 23843, 19948, 25833, 11, 7339, 6752, 26351, 7581, 28703, 22672, 16917, 23766, 10170, 21968, 14618, 23652, 30304, 19502, 6349, 9981, 6105, 29284, 31383, 11484, 723, 17148, 22157, 20793, 30586, 26887, 30567, 16194, 9103, 22575, 31661, 8018, 17678, 31432, 12527, 3405, 17967, 23714, 15446, 11855, 27814, 3005, 29645, 15198, 20116, 13329, 31738, 5200, 14352, 28782, 26009, 32106, 23850, 31657, 21179, 1524, 8133, 8033, 6404, 21969, 21166, 9264, 7751, 17431, 20037, 4184, 27590, 1097, 10211, 18290, 19859, 4984, 18502, 31241, 18262, 9229, 27825, 27387, 7263, 4955, 870, 21805, 15786, 30979, 20794, 639, 26601, 5265, 26069, 2545, 21116, 21041, 25149, 5844, 17633, 31103, 3494, 28466, 27043, 23506, 28407, 17139, 24015, 7542, 10597, 18466, 22357, 2967, 25492, 18219, 27109, 10483, 11859, 14654, 17022, 13340, 31428, 27430, 25244, 5593, 28534, 7121, 4296, 15091, 16119, 3550, 8274, 26397, 11655, 1666, 31688, 18596, 2524, 2381, 719, 26498, 9079, 9534, 28754, 22026, 16144, 11773, 17925, 24116, 1760, 25519, 12858, 29525, 8790, 2742, 19270, 8262, 6767, 2069, 15253, 22758, 11963, 19194, 24101, 1978, 3412, 15526, 14121, 7466, 31993, 16457, 26057, 28962, 20946, 27213, 137, 17838, 12030, 28502, 2225, 1183, 14440, 17182, 19985, 30974, 11158, 16765, 1567, 400, 25547, 7360, 14374, 5812, 2914, 21588, 16245, 12471, 4755, 6323, 2215, 7327, 29560, 17720, 16609, 19360, 11207, 5681, 20109, 5744, 140, 11868, 26510, 27553, 7433, 16271, 2243, 26212, 10574, 22537, 26935, 3485, 18131, 21135, 25744, 3613, 26242, 26295, 31987, 10943, 25884, 22205, 18910, 29941, 28069, 15292, 8037, 26146, 23384, 31834, 20731, 24913, 23944, 5049, 9159, 19341, 23958, 9661, 16330, 26324, 9548, 31580, 12232, 30522, 18473, 17061, 3048, 16233, 28617, 7647, 28866, 10111, 10229, 2701, 18109, 21319, 30064, 12051, 20733, 23915, 22478, 4290, 28408, 21310, 31275, 21329, 13159, 949, 8121, 29711, 10956, 9731, 19449, 12187, 27901, 28046, 3592, 3398, 29417, 956, 29536, 13459, 16834, 30927, 31161, 7440, 27701, 921, 10698, 9701, 8993, 20956, 6401, 30697, 30630, 24897, 11140, 25766, 25677, 18729, 677, 21785, 13228, 5650, 28779, 7529, 19577, 23857, 20048, 9699, 30863, 27881, 7276, 14153, 3045, 21274, 9030, 13789, 8633, 249, 30386, 29530, 4514, 13983, 5277, 29137, 25569, 22050, 25111, 4339, 20419, 2300, 671, 18565, 25020, 23791, 7428, 25437, 15064, 24799, 17860, 24662, 2986, 18849, 27083, 26632, 1184, 28469, 24777, 2955, 22692, 22281, 867, 9221, 9632, 12412, 30733, 14329, 21675, 20750, 8844, 11846, 7220, 30377, 24577, 10747, 23580, 27095, 12135, 27930, 24611, 28134, 22044, 20504, 17339, 12550, 28666, 10789, 25877, 31154, 19596, 6028, 3673, 9118, 23556, 14409, 26784, 24588, 1220, 28837, 10825, 29245, 10296, 9582, 8637, 31477, 9086, 28078, 31469, 2155, 4761, 18816, 28522, 30278, 18710, 975, 30354, 31948, 9149, 5293, 4789, 23950, 4827, 24961, 19281, 30465, 20730, 13300, 2601, 7379, 6820, 10741, 20136, 20663, 9184, 16769, 26328, 13772, 21302, 17365, 1342, 787, 29776, 27359, 31698, 7566, 4660, 4143, 19973, 17155, 6005, 24427, 16474, 1120, 764, 8480, 11008, 30742, 27745, 25212, 29715, 7783, 23804, 4864, 25556, 31339, 208, 21824, 9427, 4309, 521, 20044, 11974, 25074, 1339, 31437, 18033, 30773, 26059, 10655, 447, 18990, 9821, 28070, 28906, 29330, 24968, 7414, 9370, 31829, 25936, 6731, 14539, 13844, 9339, 27196, 16191, 19071, 10363, 10476, 19754, 15283, 14337, 10766, 339, 21477, 21173, 2448, 18339, 11244, 308, 15766, 765, 29901, 28077, 3535, 15338, 22828, 15578, 4500, 819, 18276, 3019, 19510, 26974, 7424, 19996, 19450, 672, 43, 2737, 13853, 13794, 31351, 9165, 9501, 20557, 18040, 1084, 2471, 19255, 22919, 23694, 13367, 8028, 3433, 30088, 26780, 15956, 21210, 21690, 12875, 31730, 10692, 5842, 9594, 12091, 25118, 18204, 28857, 30861, 21221, 11149, 26854, 21416, 28891, 25001, 31601, 31468, 25887, 26342, 25473, 6595, 7842, 3034, 26959, 17427, 8593, 11847, 19756, 24988, 4284, 16031, 8924, 17569, 31732, 10249, 14877, 29777, 17200, 31147, 22507, 15475, 9526, 24957, 3564, 26544, 31188, 12189, 21055, 2085, 14158, 7153, 22049, 6400, 15041, 4344, 6385, 16910, 25777, 25726, 890, 17541, 6539, 30984, 20756, 10749, 9016, 11511, 6930, 2572, 1062, 20790, 1246, 29106, 24920, 15457, 19599, 8776, 31516, 11902, 2124, 445, 8252, 4793, 16407, 32115, 15101, 7224, 14800, 2912, 14378, 25256, 11796, 31839, 3286, 29651, 26856, 21578, 20385, 11181, 14950, 23877, 18848, 17325, 11587, 27987, 17948, 12919, 9040, 21627, 1331, 10316, 11463, 1125, 8886, 10965, 29236, 16358, 26629, 12859, 30481, 26951, 20352, 7585, 23876, 6920, 29743, 7889, 28882, 14080, 6220, 2439, 24463, 30356, 13277, 24309, 23426, 11199, 19674, 21593, 1509, 10940, 19872, 14853, 16858, 7138, 11500, 11470, 26023, 18250, 18548, 18159, 25402, 14600, 29494, 22365, 12826, 12340, 29976, 14112, 19002, 31907, 16441, 23639, 1213, 12305, 7, 20588, 18855, 25038, 15940, 26752, 12096, 15716, 31376, 1648, 6844, 14495, 593, 15031, 12624, 264, 11085, 6709, 10009, 9651, 9122, 6317, 9643, 5309, 2858, 15148, 17961, 14855, 25309, 26257, 31964, 9074, 15236, 11635, 20994, 25121, 25448, 21684, 8631, 32221, 11789, 24459, 1405, 942, 12807, 31060, 16963, 26043, 30780, 30213, 25060, 1186, 15430, 1685, 29815, 5695, 27595, 4028, 11905, 27846, 16273, 26769, 9000, 14923, 5110, 17501, 4614, 30559, 5982, 17597, 10867, 28260, 15895, 26628, 26588, 15006, 4432, 280, 22748, 23038, 16655, 19538, 31861, 4118, 21664, 1455, 19048, 25137, 24894, 17897, 14266, 8191, 6086, 12903, 6366, 27914, 13223, 17081, 32233, 907, 28094, 2581, 15816, 22680, 22372, 10644, 24371, 876, 1529, 8873, 30242, 2077, 19889, 1259, 14545, 5499, 22765, 25642, 15702, 14433, 24972, 31041, 23218, 25082, 3506, 18869, 15137, 20966, 24675, 21209, 54, 18568, 25465, 8431, 6802, 10470, 15193, 30211, 25036, 2630, 7222, 12861, 5763, 9703, 25208, 1274, 882, 3324, 13022, 17172, 7164, 17128, 12687, 30678, 20257, 20881, 15808, 25580, 13952, 7331, 20182, 24107, 1114, 20957, 23824, 14647, 13805, 6109, 12976, 22501, 19992, 30887, 4037, 1140, 1308, 22894, 12148, 16016, 7574, 30023, 21162, 17184, 16651, 15051, 31527, 14714, 27288, 14784, 9589, 16579, 25911, 20414, 30367, 21013, 2740, 7501, 5371, 16490, 5440, 21841, 27838, 26325, 5250, 327, 6413, 7090, 29058, 24303, 3609, 14001, 21340, 32265, 25370, 19466, 24180, 29851, 4406, 6837, 24986, 10973, 16978, 20206, 14854, 13087, 20183, 4751, 15713, 20685, 22504, 13162, 226, 2262, 4404, 7296, 18388, 16644, 7936, 31369, 9573, 2627, 14429, 6344, 26129, 26656, 26038, 22103, 24625, 4508, 10138, 19991, 19402, 24815, 13118, 3760, 14096, 30541, 30017, 888, 2101, 31710, 23882, 32005, 5785, 22821, 29946, 884, 6883, 13857, 2506, 16062, 7375, 24457, 3674, 20917, 30384, 11830, 10693, 26688, 18089, 31439, 10742, 14649, 18612, 13615, 5319, 23928, 24438, 25451, 11072, 24395, 29881, 1719, 16738, 12439, 11049, 29027, 19633, 10953, 16930, 11423, 23983, 8719, 30056, 3336, 1245, 8452, 6535, 17655, 12229, 12584, 22363, 21265, 3911, 5624, 16276, 28825, 8444, 12566, 2008, 8657, 197, 21843, 17639, 23679, 17358, 9207, 6970, 8984, 10804, 1287, 3069, 1494, 15431, 29493, 18481, 22342, 12587, 22341, 11792, 12245, 22291, 14679, 7877, 6341, 4157, 1268, 19277, 31529, 6775, 19657, 19989, 30880, 27847, 1263, 4684, 7354, 15520, 23816, 19803, 22654, 25950, 13597, 10502, 3151, 31989, 6097, 4491, 14972, 11981, 3900, 20458, 7839, 18335, 21827, 11039, 2417, 15752, 15289, 15428, 2172, 26019, 9022, 16209, 29981, 23711, 29471, 32196, 7003, 4357, 23878, 9629, 28272, 23110, 14331, 9687, 23226, 8964, 6586, 16589, 11033, 2213, 4695, 22708, 16692, 15021, 16602, 10411, 11857, 1008, 20482, 169, 4079, 17645, 11130, 22697, 10936, 15233, 17438, 29473, 19417, 15931, 6974, 10270, 2982, 1452, 9474, 2276, 23343, 3620, 25913, 25819, 26457, 5980, 28201, 11376, 9174, 17464, 23196, 31930, 22732, 11209, 4504, 31209, 2120, 23137, 9900, 10208, 22448, 22881, 9347, 18141, 15473, 19815, 13992, 27280, 9434, 16952, 10186, 7870, 13734, 17849, 4393, 21718, 32133, 31471, 20122, 11840, 15648, 22845, 30126, 1537, 12603, 17770, 9664, 20736, 20275, 6650, 2419, 30285, 29721, 15103, 30123, 15965, 15901, 26934, 14777, 13780, 7111, 4685, 15708, 15217, 8130, 21409, 14081, 5345, 28328, 28307, 8740, 22611, 19490, 10365, 305, 18645, 19679, 1278, 8559, 17670, 31783, 23591, 2455, 17802, 27609, 17637, 14265, 13347, 2096, 12298, 19501, 15652, 1054, 13099, 21366, 9626, 27611, 14049, 27500, 24592, 23054, 5334, 27247, 29616, 7069, 1736, 8223, 11255, 14821, 23939, 27517, 6303, 17079, 10271, 8538, 10877, 30461, 27376, 15144, 9862, 20173, 16161, 28308, 26625, 27061, 20523, 18628, 21301, 16976, 23817, 30051, 4166, 23124, 2499, 899, 8503, 26910, 14024, 1089, 5075, 11050, 16518, 15516, 1823, 24143, 17932, 23311, 19800, 12682, 16059, 17271, 6636, 29948, 8685, 29865, 11147, 6507, 18340, 8699, 27835, 3191, 28654, 24357, 29565, 29729, 32173, 26381, 4259, 859, 21410, 4099, 27666, 4008, 8640, 6438, 17987, 19616, 25823, 26298, 1497, 27134, 5936, 18460, 10954, 10460, 5818, 8507, 1726, 32066, 3676, 7490, 8188, 20311, 25115, 31049, 22149, 21529, 7278, 14496, 3645, 1686, 14341, 31828, 5352, 31123, 22588, 1320, 28323, 1700, 9817, 18075, 30782, 24622, 20478, 22780, 31666, 21983, 21206, 3519, 28888, 12729, 25419, 19977, 28277, 29546, 26539, 5356, 23285, 4346, 15392, 16827, 20008, 19126, 26925, 511, 9223, 1348, 11251, 3213, 999, 31089, 25459, 10408, 18149, 8598, 6926, 6651, 16691, 16224, 15098, 20397, 4197, 21960, 18237, 27002, 12373, 12537, 23756, 20188, 6672, 28671, 10453, 29824, 23155, 10472, 5539, 10533, 16403, 2573, 20989, 18479, 1875, 6420, 31838, 5940, 14893, 6403, 4093, 15821, 13207, 18859, 8902, 21138, 25938, 11178, 6122, 13320, 31567, 3219, 18974, 12586, 29304, 15179, 12672, 10769, 22840, 30225, 15026, 30776, 31944, 21513, 29327, 30163, 21596, 10473, 17761, 29773, 26953, 14187, 16114, 18240, 2659, 14567, 15932, 18078, 23515, 26036, 2280, 19670, 20518, 31108, 11668, 23029, 12706, 22295, 31322, 216, 21984, 8330, 2888, 15948, 12509, 29692, 6626, 5688, 22477, 15048, 12287, 22570, 5311, 17419, 11022, 31733, 23337, 1495, 13333, 15227, 14446, 23961, 2458, 8627, 13895, 29778, 23096, 27863, 18238, 17455, 11913, 18213, 31668, 6255, 3729, 22045, 18947, 9237, 25326, 74, 16735, 30467, 32147, 12502, 29900, 27250, 630, 4526, 2513, 15728, 10521, 5141, 9255, 13619, 25487, 18592, 9317, 14479, 570, 31227, 22239, 11617, 11229, 23920, 17587, 17654, 13883, 12786, 19779, 30961, 7240, 10711, 27574, 3892, 3375, 17319, 7972, 11414, 28404, 7037, 31232, 26134, 13975, 7910, 14792, 3970, 29375, 18403, 18377, 15631, 9536, 16344, 26710, 15657, 15499, 15010, 8717, 3093, 27776, 22585, 21090, 12061, 19858, 28165, 21580, 23034, 4276, 10146, 959, 8187, 16082, 15335, 52, 29420, 26015, 30615, 20082, 1007, 24331, 10740, 3995, 27084, 30700, 31765, 25724, 6218, 14881, 18360, 19865, 17240, 30856, 28342, 778, 3431, 18563, 28532, 18202, 9825, 8663, 26386, 28836, 13463, 31412, 28509, 20761, 23237, 6083, 10761, 28817, 4240, 6503, 21736, 5943, 21819, 15037, 7230, 8417, 1908, 13707, 15605, 29001, 23051, 21204, 15426, 8609, 29975, 28313, 15921, 529, 28647, 17248, 25706, 31346, 26054, 21818, 23326, 30632, 27608, 16616, 12261, 3834, 21811, 3499, 30068, 1749, 7767, 798, 31750, 3419, 19110, 23405, 6804, 19293, 11097, 15421, 22126, 13033, 8275, 29730, 16645, 20374, 16552, 7097, 19615, 19956, 18172, 19480, 15820, 28928, 3921, 3393, 12169, 28974, 13750, 25701, 4196, 27099, 28935, 3300, 23310, 26265, 6197, 4502, 27026, 17680, 15237, 4999, 2870, 24077, 6684, 21018, 31082, 20462, 4341, 25312, 25509, 17432, 31484, 11738, 18654, 22921, 12464, 25254, 12474, 9697, 15302, 12841, 12408, 9719, 7306, 6725, 8085, 550, 27644, 10350, 25219, 15372, 9013, 8005, 28748, 3094, 2151, 3972, 8548, 24153, 1459, 8635, 21532, 18690, 13535, 16865, 16256, 27893, 10959, 27045, 10593, 19980, 14196, 23830, 5958, 27642, 3157, 24734, 15724, 5872, 22658, 26139, 15171, 18092, 30082, 5007, 20833, 15680, 27174, 18080, 27675, 7322, 27929, 27576, 18731, 30790, 11896, 24486, 6302, 5879, 24651, 19953, 18173, 343, 142, 27055, 3651, 18662, 10925, 15662, 17762, 23242, 19376, 26878, 9425, 6575, 22897, 18585, 858, 6965, 20555, 15813, 21283, 12777, 10200, 23754, 8746, 7163, 22936, 24339, 14097, 18137, 10580, 6673, 14680, 30237, 13020, 11524, 25644, 20824, 20466, 21577, 15867, 10094, 4046, 6838, 30542, 12529, 2979, 30346, 17605, 7503, 22211, 1340, 15564, 9782, 26300, 615, 646, 13927, 27248, 26542, 5231, 19418, 6191, 32071, 22717, 830, 918, 24052, 26533, 31873, 2854, 22767, 15399, 2777, 148, 18318, 14753, 2780, 12467, 21950, 30715, 22310, 13762, 23450, 14559, 13310, 1271, 20239, 12146, 4174, 25835, 12762, 750, 29217, 8378, 7682, 25695, 12226, 194, 19845, 31924, 21854, 1166, 6299, 357, 10116, 18933, 20914, 28757, 5283, 13722, 5279, 4004, 17449, 10503, 7038, 19287, 13471, 19247, 5153, 19649, 3531, 23581, 5511, 10003, 6616, 8695, 20408, 30628, 9974, 13997, 15740, 12863, 21999, 1221, 5662, 396, 1804, 2765, 24728, 26705, 3206, 15401, 29225, 19410, 26446, 13731, 8329, 27799, 12775, 20403, 5991, 10439, 8132, 21202, 9295, 22313, 10191, 27472, 24824, 16981, 748, 12748, 11875, 14973, 28439, 23333, 20106, 30335, 17276, 29850, 19612, 17429, 4712, 19748, 28246, 26560, 16685, 8875, 30477, 25563, 16639, 6777, 18441, 29594, 25144, 27433, 9604, 15109, 5995, 21348, 25453, 22012, 11481, 7730, 22877, 6409, 22700, 15733, 27076, 32042, 23803, 3714, 19580, 15477, 16225, 11082, 12739, 10485, 199, 16372, 29335, 28301, 11248, 14817, 9571, 23062, 13130, 10517, 8603, 31449, 3772, 190, 769, 30720, 17719, 30592, 31228, 32215, 14750, 3560, 5015, 31127, 11735, 23647, 3032, 7869, 27904, 2135, 18070, 11746, 25117, 26763, 20603, 4723, 1267, 10809, 31448, 12497, 27398, 30, 9084, 6139, 4264, 16318, 8567, 10760, 2984, 13760, 7216, 15699, 20906, 29866, 6776, 28058, 20715, 923, 8166, 15944, 6226, 4401, 7351, 12120, 26402, 40, 16666, 6842, 27710, 6206, 7016, 28724, 29596, 23348, 16763, 5180, 24, 118, 14452, 19877, 2148, 21153, 25817, 13149, 25456, 31669, 8457, 1751, 3041, 3091, 31012, 20795, 26106, 20317, 18935, 25405, 20604, 24784, 27983, 9806, 24912, 11518, 1446, 5391, 5273, 12158, 31336, 4939, 2815, 1565, 17090, 13242, 210, 23924, 26942, 16681, 19663, 27792, 21097, 17250, 20704, 20406, 19597, 1202, 12145, 2309, 2037, 594, 18437, 4302, 9218, 27241, 30124, 27848, 20404, 4692, 24991, 23838, 26263, 25838, 7248, 22246, 12734, 1261, 20639, 24355, 9653, 22679, 4878, 22252, 1444, 26756, 31910, 14305, 31796, 24204, 29591, 22506, 1761, 13925, 29099, 10241, 7894, 2767, 19757, 3180, 6015, 25653, 13044, 16730, 19512, 14652, 31584, 2980, 17865, 14309, 19622, 18490, 7557, 31005, 2074, 3708, 3218, 30328, 16453, 19613, 27720, 13945, 7820, 31848, 25645, 18815, 23345, 2704, 17471, 146, 2523, 28075, 18424, 17750, 17234, 24629, 16961, 25942, 16551, 7718, 21630, 26440, 15674, 6612, 24149, 18411, 30624, 9702, 23859, 16385, 21401, 25789, 13522, 16207, 19061, 28495, 13108, 30330, 31068, 14, 23043, 10122, 19887, 2269, 21461, 12248, 5145, 14050, 11562, 5292, 26535, 25989, 6452, 9847, 28065, 17843, 11865, 22104, 17370, 11151, 8094, 21010, 7745, 27916, 13143, 5834, 3566, 25890, 11477, 9923, 7076, 17992, 14614, 22480, 1750, 27667, 14333, 28412, 30310, 21536, 15106, 11897, 12493, 27053, 1240, 21350, 16949, 29441, 23757, 12462, 11739, 18409, 19155, 13811, 31318, 2103, 5126, 9794, 26151, 11314, 7811, 8721, 15968, 2597, 30371, 1779, 2526, 7661, 23484, 29402, 17033, 31895, 6863, 18436, 16915, 26897, 29713, 713, 1596, 12855, 3472, 185, 29397, 1309, 16994, 13995, 1995, 19310, 1661, 1924, 13376, 5165, 611, 6262, 31920, 1559, 11984, 3529, 13600, 15057, 2709, 5142, 12791, 12278, 1086, 6319, 11123, 15452, 31712, 12447, 3297, 6223, 29138, 2395, 30638, 14682, 9770, 29325, 31289, 29653, 1892, 4863, 26860, 32199, 16847, 16140, 7382, 30301, 1807, 50, 2610, 20889, 18902, 1463, 20595, 25691, 2019, 14262, 14686, 21043, 9954, 9251, 14302, 21782, 2390, 5326, 21894, 9959, 17623, 24800, 4176, 23126, 22125, 7497, 28011, 7632, 23462, 23774, 30654, 18429, 4926, 20574, 31559, 15329, 28222, 15258, 8492, 27682, 9105, 29745, 27290, 8095, 701, 5888, 23200, 19, 2050, 20270, 28911, 247, 29323, 15938, 24742, 8159, 365, 10595, 26020, 10345, 25012, 19018, 23283, 23763, 15332, 3000, 3655, 4209, 32256, 17157, 25486, 3424, 7132, 8110, 26290, 9637, 19550, 27686, 9739, 16132, 29884, 4142, 22178, 20249, 7071, 3008, 19204, 27344, 20203, 30291, 26492, 6482, 19629, 2466, 9771, 14515, 23175, 27781, 22961, 15991, 11825, 21189, 4888, 18919, 1448, 30999, 9222, 6331, 15519, 3953, 29443, 13049, 24082, 4877, 26987, 20307, 19294, 16436, 26364, 17629, 8244, 21831, 6058, 31966, 9217, 25601, 30871, 30257, 7707, 13054, 8212, 9160, 25986, 2757, 252, 24346, 17447, 31957, 20240, 3040, 24731, 11117, 19714, 5118, 5014, 5981, 31176, 7615, 27601, 19695, 31430, 16154, 5000, 20990, 26166, 15243, 11783, 2643, 28321, 8885, 28862, 31453, 30169, 26818, 22208, 2073, 4615, 7875, 22714, 14628, 20411, 12468, 31680, 23159, 3362, 21885, 7741, 10524, 8338, 24410, 1713, 5930, 17789, 1927, 11387, 11499, 18918, 22251, 29472, 14588, 27200, 7044, 24378, 8733, 4770, 3912, 10462, 3347, 26611, 20378, 11297, 19132, 26733, 22716, 29780, 2931, 5904, 26808, 20103, 30032, 30594, 23122, 7425, 11539, 9757, 31248, 26279, 8210, 14536, 13095, 32012, 16761, 11716, 985, 30004, 29332, 19879, 30235, 17586, 28961, 14691, 19994, 6877, 29016, 3601, 17377, 12705, 14052, 21272, 5649, 29334, 31748, 29404, 9422, 21865, 13953, 11582, 24112, 19130, 27797, 11372, 16954, 297, 14413, 16020, 8354, 15515, 6081, 23179, 13873, 27393, 28056, 4254, 678, 13127, 16373, 30719, 8176, 11586, 19473, 23374, 23017, 18800, 4333, 22218, 1354, 6908, 23511, 25314, 11765, 25893, 22174, 17894, 3195, 7668, 24758, 3497, 14580, 1464, 5295, 19906, 17044, 6379, 872, 9483, 29654, 17170, 26280, 2287, 26040, 9864, 3580, 31496, 27158, 8517, 5252, 10141, 15447, 11447, 6129, 9288, 16007, 19974, 16678, 7732, 23006, 8910, 26981, 11242, 27680, 11740, 15339, 24637, 4701, 19979, 2154, 6760, 16890, 5177, 2751, 18155, 18829, 5146, 30143, 20228, 11517, 22999, 23614, 24283, 30040, 2948, 364, 26427, 26035, 10451, 128, 27034, 8554, 5312, 31658, 7109, 22321, 12974, 22820, 20107, 28375, 21311, 22349, 14312, 7300, 22655, 13003, 9206, 25697, 6959, 26074, 8209, 17565, 25367, 24587, 4648, 28645, 7198, 27157, 4168, 25325, 30793, 28596, 30881, 5436, 25424, 19978, 25418, 19229, 1413, 18586, 28670, 24607, 10325, 21849, 17353, 21762, 10768, 27336, 17580, 28976, 10185, 13344, 19687, 24335, 26392, 23111, 31967, 22, 3307, 15984, 24943, 27022, 2181, 26285, 19691, 10103, 31380, 6417, 24614, 3367, 8907, 26990, 26975, 29867, 20015, 31314, 10275, 29366, 2182, 2505, 14250, 17300, 28304, 8380, 15538, 9982, 4441, 13684, 2747, 26453, 4239, 2987, 29078, 24760, 13080, 16236, 528, 9097, 13666, 17209, 6020, 22934, 6451, 29788, 12180, 20108, 6098, 17579, 4433, 13512, 17123, 8951, 602, 6562, 29083, 3552, 8313, 18527, 13343, 7711, 17064, 4158, 30976, 16795, 7527, 30593, 117, 29456, 9131, 19721, 28677, 350, 3853, 22324, 30308, 2748, 19241, 29025, 14075, 27480, 24061, 31931, 8622, 13039, 31479, 10628, 7962, 20431, 2336, 13468, 29833, 6254, 4833, 16054, 24092, 23297, 1178, 16878, 8039, 2079, 15493, 28903, 17813, 31233, 21386, 16267, 2916, 10305, 6954, 28942, 20931, 28319, 3397, 6696, 25343, 22933, 32183, 13433, 20297, 22707, 4036, 31189, 22860, 24964, 21954, 16266, 7495, 27015, 5975, 1013, 11161, 4835, 9373, 9278, 4687, 25286, 138, 17165, 9990, 11460, 24464, 14918, 10690, 1384, 6305, 30455, 29967, 14288, 20569, 11844, 20325, 26545, 22460, 29313, 21109, 24382, 30402, 18027, 25662, 8160, 4644, 352, 13700, 12813, 24044, 11941, 7564, 391, 13328, 24638, 27259, 16135, 9249, 5832, 19645, 21769, 26832, 10713, 27232, 3220, 29483, 16001, 20762, 8677, 23491, 22811, 28390, 1959, 19045, 1791, 25799, 13917, 17690, 6770, 1638, 7526, 4679, 6405, 27509, 14834, 29983, 12466, 727, 4855, 31778, 25288, 3198, 12286, 14945, 15803, 427, 28166, 30573, 7856, 21691, 14743, 26494, 2618, 16780, 27180, 18246, 5769, 13234, 2245, 13435, 22240, 2720, 4551, 15634, 18461, 27181, 19013, 17908, 15141, 21938, 25875, 30406, 17194, 1821, 10882, 12519, 8596, 23825, 24099, 23898, 4476, 15700, 31673, 5680, 1050, 6394, 27672, 29468, 4330, 15444, 30246, 7422, 24316, 9939, 22207, 26169, 14314, 18892, 6960, 30309, 21917, 3503, 10256, 18108, 30274, 19514, 5799, 20702, 4804, 8174, 6702, 28496, 30576, 17029, 18885, 29705, 13012, 11476, 22487, 11263, 24795, 7334, 21545, 24809, 31531, 14386, 15923, 28180, 16354, 29376, 8242, 25796, 5555, 1083, 10725, 8799, 248, 30067, 29545, 21962, 12312, 17945, 16987, 17242, 25004, 17672, 30820, 18726, 30202, 21468, 25031, 8773, 21563, 25661, 9835, 24858, 8250, 29899, 13291, 16049, 22074, 13813, 1314, 13161, 4492, 3150, 618, 17168, 11269, 1351, 19527, 4485, 8236, 7452, 21346, 14047, 27491, 26076, 31031, 21738, 17793, 23451, 10235, 18750, 11292, 27626, 14538, 17189, 15800, 7313, 26529, 27593, 31292, 31744, 28380, 31813, 10552, 22041, 4894, 31208, 26830, 26802, 23202, 932, 29119, 25017, 27841, 14172, 3701, 21369, 13674, 9958, 4415, 10137, 7544, 1952, 15594, 1866, 7486, 27834, 13928, 7131, 17917, 19311, 21944, 19626, 30434, 28437, 24903, 10053, 15412, 13658, 2032, 9018, 12653, 30933, 10049, 14092, 28786, 26606, 14846, 27912, 797, 5884, 4389, 26371, 17514, 20321, 9543, 19397, 22947, 9542, 1972, 15448, 17530, 12902, 29289, 11985, 32065, 9996, 26210, 28706, 26586, 21485, 7207, 4851, 2450, 26884, 29672, 18410, 26754, 21081, 106, 1987, 13282, 4620, 6145, 23373, 17944, 4010, 31976, 26228, 25257, 30326, 18307, 10223, 16703, 6367, 10636, 30440, 7963, 9488, 18773, 18201, 8710, 12581, 2446, 25462, 23976, 27448, 25227, 11249, 9468, 1090, 3748, 25120, 21082, 5464, 12941, 1311, 4821, 17485, 5488, 12443, 24697, 32021, 11658, 25452, 31092, 9520, 23759, 561, 31061, 20265, 19102, 25925, 14353, 2494, 22325, 30109, 18334, 15112, 3906, 3299, 31804, 14976, 180, 30862, 20722, 31406, 30053, 24019, 3342, 10516, 14400, 17369, 3885, 29156, 742, 5191, 3211, 31849, 13914, 30336, 1321, 8731, 1702, 9885, 20255, 20631, 16025, 20130, 29682, 6995, 29746, 10013, 29014, 6568, 8061, 28150, 10952, 21543, 430, 25204, 11872, 13202, 31358, 12461, 13213, 25279, 3224, 20101, 16237, 5589, 3186, 27124, 10088, 30468, 18907, 3699, 13372, 10433, 7113, 10264, 29748, 7627, 12664, 19261, 11722, 1805, 5109, 19267, 30315, 13402, 7367, 18299, 17930, 4831, 22599, 5028, 9714, 2921, 24882, 13969, 13057, 22112, 5073, 11619, 15545, 5272, 32254, 13240, 18044, 24627, 11510, 2641, 23888, 20613, 9054, 5508, 11924, 3126, 22215, 10617, 9749, 7595, 19609, 30251, 27277, 4808, 13103, 15717, 21759, 8564, 13356, 31356, 6119, 21882, 7396, 7474, 8126, 3851, 5781, 23776, 22411, 3828, 31144, 24177, 2408, 3166, 3073, 22959, 2706, 7699, 16122, 17034, 10132, 23014, 24792, 25171, 1168, 27419, 24055, 30232, 26489, 30572, 23627, 26999, 2415, 589, 22514, 9133, 25959, 28627, 10957, 28865, 8493, 20217, 11923, 5032, 16536, 6412, 361, 17884, 12909, 14593, 20312, 1879, 6088, 22525, 21498, 31674, 22533, 15424, 7350, 12434, 17445, 17403, 8170, 21644, 31, 18009, 12241, 18936, 23956, 19430, 10860, 15574, 16657, 31528, 15296, 12621, 10482, 20692, 24978, 22139, 29244, 10571, 31950, 14678, 20820, 22607, 6806, 28875, 2220, 30292, 6596, 20515, 26180, 27573, 6131, 26943, 22344, 23271, 10856, 5406, 28995, 14206, 21900, 7782, 18677, 23078, 14695, 18753, 16105, 14454, 8700, 1096, 11404, 9734, 27252, 7750, 15513, 9050, 15877, 25974, 3929, 18646, 18597, 29181, 25043, 12972, 30819, 14328, 1667, 10064, 10057, 29868, 4934, 30807, 7932, 25987, 29065, 23726, 27251, 11824, 8514, 4581, 28626, 16611, 19356, 23589, 685, 17293, 23113, 28858, 16659, 27994, 14327, 5382, 3833, 16781, 6705, 24141, 24334, 9401, 21361, 28760, 30777, 25643, 22786, 3830, 21168, 29864, 12479, 4289, 920, 23678, 29566, 25745, 27347, 298, 19181, 29671, 5122, 5735, 3979, 14162, 6011, 20195, 2461, 25100, 18618, 13503, 24387, 19854, 21328, 17159, 9308, 28577, 3824, 24640, 24804, 21773, 2029, 18963, 28127, 31971, 3141, 6689, 9212, 7187, 29998, 7120, 909, 24379, 8053, 23583, 24084, 1670, 17450, 22572, 24572, 27765, 16922, 4451, 28462, 7778, 30297, 3083, 15961, 10010, 29128, 11646, 30483, 4958, 23885, 28363, 9435, 4170, 22376, 9353, 6386, 5204, 3182, 31617, 22114, 9331, 30850, 23305, 9557, 30084, 20649, 22461, 22932, 3724, 13270, 288, 4018, 18637, 27309, 699, 7029, 23762, 3156, 19162, 20640, 31763, 29714, 16199, 18041, 16439, 4464, 9685, 2750, 14557, 30534, 6578, 7508, 27390, 10377, 7543, 722, 17740, 1945, 3735, 7622, 28861, 18650, 26343, 5517, 9480, 30012, 25590, 29753, 30229, 23986, 26089, 26883, 16313, 25855, 12926, 5615, 9121, 19098, 16622, 17251, 24170, 151, 4587, 23742, 9117, 13078, 6246, 5784, 12472, 22806, 24008, 16252, 14042, 1815, 253, 29147, 20204, 7249, 25006, 26487, 3337, 2184, 20087, 18175, 25594, 18926, 3444, 21859, 832, 11427, 27895, 681, 21459, 14948, 12917, 663, 14069, 23430, 17538, 5780, 18996, 19732, 1800, 21165, 17018, 26996, 3994, 5894, 10513, 7223, 29673, 7621, 19342, 9950, 25587, 29790, 21199, 15946, 7705, 5474, 9521, 25973, 12427, 24472, 12441, 9859, 14664, 15909, 15122, 23605, 7127, 22248, 16286, 9290, 9929, 31386, 2758, 9495, 24540, 31025, 14926, 14359, 24660, 737, 25104, 20461, 15206, 31579, 32239, 16523, 2375, 13038, 1944, 5765, 21457, 19063, 7516, 26709, 17267, 9227, 913, 13551, 18115, 29979, 27193, 24451, 27059, 29652, 21923, 20671, 13867, 18471, 310, 32181, 26437, 16939, 6056, 17266, 22419, 29219, 16635, 27255, 31328, 6280, 9019, 12561, 24698, 428, 26924, 31421, 7801, 30387, 14787, 31589, 4686, 28710, 15090, 24058, 1426, 10653, 6907, 28153, 20643, 15027, 21467, 11458, 6583, 22415, 13239, 26661, 22193, 14029, 17299, 4997, 24212, 29797, 15633, 5490, 2723, 19160, 5716, 23340, 7966, 7245, 5776, 26058, 30277, 9020, 30920, 17904, 6012, 8182, 881, 1167, 18688, 27207, 17259, 30028, 30395, 8777, 23145, 32052, 18701, 17619, 28275, 1264, 16073, 23076, 5881, 9779, 11706, 10144, 9781, 18779, 16264, 28483, 13275, 24095, 18737, 2250, 9726, 1617, 10303, 5910, 5690, 2296, 5577, 32014, 17069, 17487, 20158, 30250, 23241, 6318, 24041, 13821, 23981, 25122, 17292, 9992, 10511, 70, 18971, 17533, 14879, 10855, 26992, 21198, 10888, 14362, 12752, 22953, 16193, 31224, 29183, 30935, 5048, 31047, 7210, 22347, 26775, 3899, 3275, 17411, 19035, 17156, 12839, 8438, 26892, 6092, 27844, 16188, 17546, 10723, 20153, 8158, 15197, 8302, 16755, 19448, 27940, 738, 20904, 9355, 14046, 11975, 16770, 237, 19921, 17389, 6360, 7982, 19839, 6667, 30173, 16149, 11669, 32143, 17878, 26357, 4017, 15104, 4574, 25514, 21466, 1017, 18129, 17382, 30735, 20575, 17140, 22323, 31048, 601, 20180, 23633, 12632, 3496, 1272, 9554, 28735, 18474, 3395, 10629, 12115, 11012, 27883, 11250, 22849, 14865, 22261, 28081, 31002, 14176, 18493, 929, 5696, 27031, 28564, 18320, 21288, 16229, 3043, 30646, 9350, 31629, 10002, 6296, 15407, 15649, 3082, 18874, 19809, 23190, 20837, 7573, 23630, 26707, 14236, 7832, 22909, 3335, 27041, 1619, 1401, 22459, 31401, 31566, 14736, 3309, 3632, 6112, 21549, 17428, 11682, 6570, 6831, 17110, 21780, 18642, 5987, 21481, 11697, 21528, 17400, 30763, 8605, 20991, 6906, 13010, 26984, 1442, 695, 377, 28880, 31459, 7630, 4801, 18986, 344, 9475, 25758, 23854, 30831, 19008, 12449, 1211, 16901, 25670, 25152, 16841, 15727, 30110, 31856, 2308, 13461, 19208, 22184, 16838, 6969, 12834, 7404, 17863, 17824, 9127, 31623, 18054, 31694, 15586, 11845, 7380, 14875, 8485, 18349, 19966, 15751, 6046, 2968, 24851, 3481, 11622, 28358, 24677, 614, 14505, 15154, 31979, 29478, 28410, 5117, 7421, 2698, 19675, 6748, 30986, 9352, 20911, 8062, 5717, 6301, 13279, 3484, 21540, 20006, 31628, 19576, 22022, 28149, 26655, 12831, 20254, 27977, 18842, 7618, 4826, 14181, 17795, 24591, 17065, 20608, 21734, 4430, 9066, 23760, 24215, 24887, 4288, 25376, 7292, 16120, 7032, 1171, 1996, 28557, 15868, 15152, 19955, 37, 19056, 26360, 25461, 11432, 11395, 9587, 25180, 16178, 24460, 6304, 29287, 14561, 768, 2212, 14499, 9240, 23475, 20202, 30648, 26571, 5294, 25605, 27246, 20806, 12332, 19268, 16548, 23463, 29427, 10603, 19886, 19218, 13411, 30494, 29229, 1163, 10567, 31575, 17942, 3586, 6533, 9431, 7841, 19773, 17175, 3072, 18722, 9828, 31393, 14009, 16324, 9389, 941, 9665, 31447, 10632, 17352, 11116, 13863, 23811, 4930, 30527, 23716, 24152, 7110, 6740, 4151, 13395, 24120, 27004, 30463, 7341, 29980, 18176, 18598, 21429, 16029, 6259, 24632, 7301, 15298, 25336, 13807, 31199, 11333, 9819, 17379, 27542, 5360, 3761, 3183, 13197, 22756, 31833, 6864, 19265, 11373, 10355, 11171, 23066, 866, 20250, 31781, 24441, 2293, 19777, 22854, 2894, 28512, 25272, 2823, 2444, 4465, 2413, 28173, 29015, 23007, 12680, 17361, 25525, 31495, 23082, 19452, 11170, 1031, 5552, 9635, 13439, 31784, 8874, 4117, 10913, 15238, 23441, 457, 10828, 12253, 11350, 16338, 2267, 12531, 26562, 28337, 17499, 24779, 21874, 25185, 19870, 5854, 14577, 12401, 15190, 9116, 1349, 27733, 14783, 15834, 7887, 2826, 12065, 7169, 14003, 29112, 7174, 26969, 28112, 28573, 22766, 21713, 29584, 12657, 15914, 267, 2509, 26762, 4119, 29667, 15380, 18128, 23046, 4906, 30992, 24220, 25975, 19572, 3855, 13560, 12768, 13860, 1292, 31505, 6983, 11174, 10336, 30374, 28292, 4599, 10962, 15216, 928, 23980, 5493, 19107, 16418, 23385, 7882, 25982, 1106, 5002, 15370, 10691, 23146, 10181, 26012, 6320, 8327, 14525, 17286, 27104, 8857, 19436, 23442, 28230, 21196, 20581, 31297, 22918, 13491, 17435, 15825, 13602, 7643, 24926, 2566, 10790, 5595, 10125, 7748, 22308, 19444, 444, 468, 19070, 5495, 4849, 26753, 26363, 11336, 1855, 10210, 11909, 19363, 31259, 11799, 4769, 18943, 29926, 15123, 24258, 7664, 5563, 20209, 31253, 11726, 14859, 26296, 30418, 13757, 2303, 13383, 19788, 1087, 12223, 25879, 19925, 13168, 16411, 28711, 23787, 29135, 20176, 21904, 19394, 16581, 163, 25495, 22545, 29863, 7083, 10066, 26284, 1818, 21685, 24293, 14026, 5813, 1889, 18209, 4011, 8064, 28797, 30816, 31212, 5811, 3867, 30604, 17684, 12897, 21208, 4102, 19292, 15052, 14142, 5603, 26461, 11537, 13632, 4469, 19710, 20454, 27917, 25686, 12796, 26734, 13790, 12543, 13730, 4647, 30128, 2562, 2481, 13993, 4242, 14653, 26486, 25347, 5210, 29947, 8989, 8919, 16103, 25978, 17949, 30248, 24879, 26760, 23820, 9192, 8977, 4278, 24930, 9439, 22887, 19587, 23395, 16640, 19787, 8458, 1137, 27417, 5380, 31506, 11176, 23818, 24620, 31943, 1668, 7441, 2171, 26954, 12303, 29522, 19290, 27164, 30394, 20848, 23460, 19062, 1641, 1902, 29069, 27817, 5974, 20095, 31544, 8760, 18229, 28020, 19148, 5237, 9767, 24578, 9497, 883, 359, 2936, 8055, 6519, 15415, 28448, 6966, 9196, 21660, 3417, 12738, 6726, 22510, 10990, 17952, 30692, 6228, 30946, 10328, 22879, 6265, 28082, 25360, 31715, 25910, 3540, 19536, 6384, 8811, 27239, 18730, 6410, 24568, 18983, 2290, 21778, 631, 12579, 460, 13636, 23534, 17295, 31801, 3416, 5909, 26569, 19548, 15280, 11127, 19761, 11139, 29874, 25390, 6008, 8778, 20669, 16786, 2787, 8192, 11299, 12556, 2756, 3690, 25366, 4876, 20737, 25408, 6486, 24593, 19273, 15366, 11541, 25480, 149, 15753, 1485, 289, 26173, 2080, 18802, 13180, 20635, 22624, 28804, 22200, 31338, 566, 6830, 31585, 25848, 10801, 24096, 11230, 31095, 14527, 26553, 19214, 31532, 501, 31882, 29943, 6240, 14712, 11346, 18486, 20134, 20559, 30317, 24506, 1605, 12425, 23622, 5164, 17668, 21876, 588, 9300, 28803, 12302, 27299, 4842, 17994, 31357, 15270, 22542, 8526, 8035, 16960, 22058, 10569, 8269, 28982, 2683, 8201, 26055, 17270, 3287, 14439, 23847, 27702, 1657, 24716, 9924, 21977, 22623, 20624, 9418, 29241, 27110, 14734, 12246, 10490, 13884, 2402, 8802, 25947, 4138, 12414, 14519, 16746, 23093, 15769, 2398, 8001, 14668, 28416, 13827, 22356, 9948, 22117, 8550, 21356, 12948, 22132, 5381, 24308, 6961, 18060, 7218, 25625, 9944, 1318, 11498, 23540, 21303, 20785, 10889, 26132, 19355, 648, 5664, 22118, 624, 27341, 18804, 19813, 12023, 32023, 11774, 30305, 25960, 22973, 12103, 15772, 25246, 662, 28472, 13753, 5941, 27395, 31880, 5206, 13536, 2663, 9195, 31347, 10243, 20666, 24059, 30561, 10370, 20524, 5379, 4207, 13838, 5129, 17899, 1992, 4813, 20086, 16873, 27700, 20873, 8151, 23538, 879, 4204, 19655, 707, 22982, 491, 13269, 10351, 12370, 1711, 31274, 7915, 23042, 21394, 2382, 27742, 24270, 14531, 14267, 19221, 3501, 7052, 16412, 96, 11514, 8309, 26786, 11588, 15312, 18647, 27685, 8585, 30482, 5375, 24719, 13770, 27622, 10849, 11561, 3117, 22036, 15139, 13109, 1843, 17424, 20369, 9691, 3516, 11560, 11379, 13448, 32013, 29008, 13392, 4816, 4413, 30484, 25687, 26765, 8996, 1862, 22329, 15517, 3067, 1510, 27, 11624, 25968, 24458, 19993, 23987, 21435, 12124, 19935, 15175, 30115, 8664, 15709, 17716, 15667, 5667, 13591, 22105, 19715, 25920, 14586, 18587, 28377, 8077, 14115, 334, 22466, 29460, 27128, 2385, 12052, 22923, 21943, 12186, 14154, 25700, 7589, 3598, 18718, 22336, 27541, 28868, 15533, 14644, 4165, 4140, 27971, 20912, 5332, 4582, 24598, 29606, 30750, 28575, 24938, 2703, 6251, 8083, 11733, 23797, 2734, 18552, 16914, 965, 763, 14045, 12942, 31955, 5358, 16826, 7749, 25737, 3223, 15295, 10557, 27507, 7462, 30853, 25565, 5051, 22285, 7409, 21987, 30814, 2118, 26604, 8319, 23129, 23219, 17344, 2273, 23624, 24407, 762, 11576, 3443, 3910, 9659, 5330, 24271, 29755, 14136, 4275, 30410, 9676, 15262, 15892, 5476, 21628, 12382, 13738, 29760, 12674, 24069, 19133, 25631, 24822, 10914, 28896, 15646, 29122, 8195, 5133, 1573, 9822, 28831, 3504, 9262, 32184, 10104, 3860, 16998, 24706, 21681, 13091, 8097, 10119, 12155, 4973, 20525, 16406, 8181, 5713, 32041, 10732, 22014, 16129, 19517, 7143, 23319, 10018, 10069, 1965, 18015, 3746, 30408, 22454, 4610, 3449, 20489, 7549, 17198, 32208, 10835, 26407, 10177, 10432, 14285, 258, 4050, 12335, 28747, 20207, 31899, 17691, 11106, 9809, 12829, 1393, 15458, 4054, 31745, 14958, 30579, 21729, 16311, 22703, 29759, 10233, 14183, 24848, 8821, 29836, 6504, 157, 26243, 21661, 31888, 28199, 1857, 22928, 25430, 19307, 895, 9934, 13158, 21538, 27332, 4794, 30789, 24453, 12121, 25280, 5183, 23366, 25161, 27757, 3838, 16700, 21637, 26472, 20434, 23084, 21584, 7376, 4328, 5185, 19780, 3554, 8042, 14448, 14729, 676, 32046, 25648, 19096, 24650, 1193, 3770, 15880, 3455, 15941, 27898, 23777, 16821, 20971, 30382, 26739, 30228, 10906, 24242, 32171, 18387, 27878, 16819, 27176, 7597, 25772, 21052, 29050, 24740, 23120, 32085, 15675, 25218, 10645, 16417, 5486, 27423, 790, 25490, 32182, 10570, 24225, 28236, 23892, 26376, 8027, 22762, 12967, 25813, 13121, 4449, 20169, 27729, 15780, 19336, 6327, 30754, 15718, 27038, 3744, 9673, 14964, 8108, 24664, 2699, 17488, 11926, 586, 4322, 5613, 5264, 1936, 18337, 10285, 25449, 13251, 16159, 22950, 18475, 23413, 25166, 20822, 9253, 21453, 966, 30378, 8381, 17326, 9881, 10919, 31709, 1652, 24429, 19141, 28785, 14321, 15933, 5885, 17525, 2965, 1358, 3047, 27442, 26757, 21044, 17796, 22130, 20144, 22150, 10545, 26989, 24137, 5587, 25650, 21503, 27127, 7570, 13387, 25533, 22362, 14210, 23500, 16542, 17951, 11501, 28270, 25566, 13217, 597, 28682, 32192, 2903, 17378, 2928, 23004, 4747, 22052, 11718, 4499, 2517, 14177, 31084, 9695, 17588, 15855, 3357, 25088, 26896, 20360, 26662, 28460, 28039, 7010, 11185, 13345, 4774, 20335, 21752, 13990, 7975, 11218, 6560, 31215, 22315, 4584, 27525, 1390, 26862, 10705, 25189, 20802, 24768, 24935, 19933, 8148, 11986, 28353, 4218, 26509, 31954, 24494, 29570, 23590, 1997, 21003, 15024, 14737, 28543, 3464, 3366, 24693, 5621, 398, 29929, 20805, 21505, 8891, 17839, 31906, 25196, 12505, 19406, 10007, 8498, 8399, 9837, 24227, 657, 22098, 2864, 24793, 10497, 20626, 3064, 7817, 30025, 32130, 29044, 917, 5441, 536, 6823, 9999, 12508, 21598, 7273, 11689, 13355, 22954, 29655, 690, 1983, 31055, 14048, 30967, 628, 9152, 29796, 29696, 10084, 15182, 25832, 21881, 4267, 11584, 24884, 28676, 17608, 5905, 14962, 20251, 2790, 28241, 20609, 23547, 23058, 6611, 30182, 16512, 27042, 29728, 5105, 18959, 32158, 25553, 26633, 10777, 9873, 3795, 3298, 11843, 18381, 11569, 20975, 6925, 18435, 22747, 5638, 32150, 3949, 9951, 13782, 28352, 29712, 12220, 45, 12191, 6230, 28106, 8128, 10033, 24016, 22647, 15859, 8652, 10886, 31787, 29438, 1301, 27713, 4152, 28826, 1074, 29352, 20544, 18755, 17071, 11928, 21525, 21297, 12750, 20054, 22617, 27936, 7196, 8193, 4634, 4429, 22875, 19656, 21989, 98, 14789, 6461, 14776, 13635, 30922, 13803, 16003, 5162, 562, 4867, 26609, 25714, 1562, 6890, 24148, 1752, 5341, 30205, 32072, 9890, 28877, 15848, 4076, 21974, 11124, 19567, 599, 6138, 21755, 13146, 20825, 9226, 28133, 11445, 18594, 326, 4722, 15543, 2849, 21421, 4719, 7639, 31125, 984, 2774, 18077, 8051, 3296, 20792, 29170, 25069, 8946, 20030, 1504, 1696, 28183, 19726, 7183, 1132, 25688, 32026, 16606, 31009, 7498, 13923, 6337, 10858, 5796, 18803, 9426, 7017, 3101, 25902, 20668, 5654, 28434, 25548, 15007, 20442, 11079, 1198, 1000, 6248, 16283, 3819, 2072, 5308, 21100, 31142, 31729, 22653, 18783, 21758, 25593, 15436, 7935, 25399, 7530, 27274, 11644, 29639, 6252, 27671, 29567, 29450, 5895, 8826, 4366, 17766, 26493, 25895, 7033, 16628, 27559, 23490, 17304, 3898, 12692, 15593, 6094, 20542, 9937, 12874, 29415, 3753, 31863, 4380, 32209, 16158, 28668, 160, 7787, 13225, 19919, 13986, 16549, 20538, 2109, 19275, 14093, 3579, 28400, 19659, 3757, 17681, 2829, 22530, 30536, 23569, 4498, 2291, 20426, 18660, 2128, 10684, 6756, 17815, 30266, 7694, 7823, 11755, 11482, 29139, 4298, 10863, 18862, 19816, 13578, 4410, 11800, 16235, 3328, 5278, 24319, 7999, 27177, 23702, 18636, 21756, 552, 5507, 18311, 23831, 29210, 3608, 6497, 31652, 30027, 9575, 1477, 19740, 29484, 16437, 11115, 25972, 30127, 24240, 13786, 23585, 31592, 3517, 18453, 3279, 23520, 6075, 17152, 9988, 6921, 13764, 10201, 5157, 2933, 3341, 1070, 5261, 18255, 31130, 29917, 1682, 5396, 19497, 2012, 22551, 15916, 23260, 19124, 20861, 28498, 21309, 12727, 27968, 27085, 17205, 24417, 17166, 5839, 12279, 28811, 27997, 1853, 752, 14809, 31222, 12235, 9539, 15334, 13870, 25195, 15263, 23422, 9750, 15528, 30841, 29341, 436, 28594, 30141, 25611, 20127, 24526, 20928, 3505, 11167, 5100, 23660, 10859, 8772, 27087, 11475, 18941, 807, 3985, 21533, 25516, 12592, 14209, 2233, 10802, 12406, 26706, 4044, 1871, 21883, 11093, 28840, 12345, 17036, 29457, 8583, 9360, 11208, 30198, 12243, 30118, 5652, 7202, 2539, 16450, 12569, 1704, 13052, 3777, 11066, 11389, 25203, 15364, 29605, 14277, 13101, 16647, 28912, 5316, 24269, 5131, 14888, 6778, 24688, 26473, 19828, 3687, 16911, 31097, 1633, 9909, 26903, 20184, 29703, 9993, 23165, 4125, 17511, 12255, 29508, 2812, 2275, 18121, 25667, 3192, 30385, 4890, 30283, 12997, 5531, 9713, 29075, 29153, 12904, 7104, 18830, 21820, 29904, 26644, 27708, 21338, 32113, 13783, 8986, 7776, 6607, 29196, 11444, 18656, 14788, 28461, 16408, 30740, 25222, 4974, 20913, 14592, 23698, 10252, 18426, 28357, 4287, 19431, 23725, 1904, 31021, 4680, 2312, 18839, 12608, 12119, 16138, 23554, 31513, 23769, 10306, 20278, 27372, 26067, 21215, 27483, 31014, 17804, 18438, 28834, 19135, 3775, 17147, 28129, 1755, 31757, 23699, 3380, 10945, 30422, 23177, 15187, 16303, 2902, 18814, 3318, 18305, 9320, 17974, 13272, 19428, 18448, 27204, 19999, 6336, 7681, 13714, 7478, 28714, 9547, 5791, 731, 29102, 12164, 30039, 27627, 3401, 8716, 9949, 11595, 12289, 21585, 11851, 24261, 11035, 17869, 27907, 20422, 2196, 25928, 3802, 13112, 8339, 8476, 23187, 18399, 22675, 14796, 22696, 1473, 4935, 30575, 4929, 22151, 22038, 3893, 9428, 1860, 14021, 31017, 6593, 31502, 10989, 1101, 2534, 11061, 8847, 8292, 21760, 6841, 6511, 6932, 26985, 26895, 13820, 13364, 27122, 5021, 21548, 26598, 27149, 8871, 22316, 10352, 17832, 8117, 17063, 26374, 12534, 29333, 23116, 29593, 17638, 16707, 6860, 8533, 28656, 2149, 29216, 130, 6018, 14913, 22018, 25205, 28331, 31422, 17882, 12512, 31051, 3200, 188, 8078, 25575, 23052, 24366, 4104, 8036, 5597, 4583, 1778, 11764, 6828, 27357, 31295, 27638, 13832, 24554, 18522, 28642, 20485, 5339, 30666, 7606, 8131, 5962, 10048, 15573, 8179, 10327, 728, 13836, 7092, 10910, 1337, 21959, 7080, 27656, 9569, 4596, 22902, 31633, 17364, 15945, 3468, 16147, 23609, 10131, 22757, 30414, 2728, 24344, 4368, 10566, 25234, 17706, 21669, 27240, 24105, 20073, 5263, 28655, 15629, 3142, 6426, 18324, 6660, 5887, 23304, 9356, 23369, 28174, 22690, 11192, 4177, 8087, 20860, 12352, 30710, 25084, 26528, 12317, 5648, 12767, 31603, 3882, 31510, 5590, 16213, 5232, 30370, 31679, 20242, 6669, 13431, 29528, 28540, 13705, 23248, 6679, 4897, 26001, 15614, 18252, 25676, 6997, 2647, 26639, 17323, 31283, 3750, 28743, 11613, 8010, 7483, 17947, 19874, 1746, 14322, 16799, 22986, 17127, 13307, 23474, 7106, 28403, 31099, 11947, 15569, 16725, 27762, 9443, 6620, 25431, 12965, 5860, 20145, 8745, 2658, 20779, 14356, 25116, 12843, 892, 24192, 11162, 2482, 30340, 13763, 24599, 7330, 24739, 9151, 24583, 17188, 12132, 19057, 17554, 22274, 20071, 28314, 20695, 19981, 25849, 12862, 7461, 25298, 323, 8098, 12946, 22189, 6724, 15665, 29130, 31000, 18203, 25534, 14916, 11999, 1542, 25864, 31146, 1774, 3977, 28368, 30452, 19082, 1695, 26480, 18178, 29658, 9507, 24221, 8704, 19837, 21175, 17493, 20528, 28640, 15864, 10871, 15146, 12981, 1942, 6832, 11519, 4481, 21414, 3295, 7938, 15130, 32243, 2614, 5090, 3559, 16301, 25146, 19631, 22269, 23930, 4916, 10112, 7743, 20799, 13793, 5644, 15987, 1060, 10826, 13267, 14102, 22338, 18732, 17143, 31706, 13389, 31631, 10744, 14782, 27046, 28055, 31303, 27718, 31362, 28338, 28111, 875, 13745, 26144, 1637, 20113, 29744, 16594, 31904, 9700, 15611, 8521, 16282, 12179, 7518, 181, 9274, 10619, 21570, 9636, 14368, 26045, 17214, 20985, 1540, 9161, 27160, 23485, 29809, 11534, 20932, 23593, 7231, 15588, 7275, 23010, 15271, 17497, 27340, 31264, 16041, 23592, 20698, 25374, 30311, 14406, 3311, 19798, 14319, 26482, 9032, 25892, 16111, 2584, 38, 25432, 14036, 14896, 3658, 9065, 15632, 3968, 7493, 12964, 15729, 12994, 3400, 29115, 27633, 15854, 25540, 27445, 20959, 20843, 11473, 13524, 8122, 14523, 29060, 15554, 4486, 20857, 19316, 1439, 3482, 9324, 23640, 26267, 17898, 6277, 24222, 8189, 28429, 21112, 28958, 8205, 6526, 16015, 14665, 14524, 16985, 3021, 8681, 2131, 22158, 27691, 30872, 19603, 18029, 15488, 22608, 27897, 20798, 4746
INFO:root:train dataset: 68117, validation dataset: 3872, test dataset: 6454
INFO:root:used only channels: [0, 1]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.04976940
INFO:root:[1,   100] training loss: 0.05372814
INFO:root:[1,   150] training loss: 0.04376466
INFO:root:[1,   200] training loss: 0.03748410
INFO:root:[1,   250] training loss: 0.03211496
INFO:root:[1,   300] training loss: 0.03147750
INFO:root:[1,   350] training loss: 0.03372590
INFO:root:[1,   400] training loss: 0.00103995
INFO:root:[1,   450] training loss: 0.00026953
INFO:root:[1,   500] training loss: 0.00791889
INFO:root:[1,   550] training loss: 0.00712126
INFO:root:[1,   600] training loss: 0.02549872
INFO:root:[1,   650] training loss: 0.00002508
INFO:root:[1,   700] training loss: 0.00001258
INFO:root:[1,   750] training loss: 0.00001619
INFO:root:[1,   800] training loss: 0.00001179
INFO:root:[1,   850] training loss: 0.00000868
INFO:root:[1,   900] training loss: 0.08756286
INFO:root:[1,   950] training loss: 0.02382126
INFO:root:[1,  1000] training loss: 0.00015342
INFO:root:[1,  1050] training loss: 0.00007504
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.09356887
INFO:root:[2,   100] training loss: 0.03991728
INFO:root:[2,   150] training loss: 0.03468468
INFO:root:[2,   200] training loss: 0.03573775
INFO:root:[2,   250] training loss: 0.03149975
INFO:root:[2,   300] training loss: 0.02793348
INFO:root:[2,   350] training loss: 0.03214218
INFO:root:[2,   400] training loss: 0.00115444
INFO:root:[2,   450] training loss: 0.00024378
INFO:root:[2,   500] training loss: 0.00762416
INFO:root:[2,   550] training loss: 0.00736695
INFO:root:[2,   600] training loss: 0.02483866
INFO:root:[2,   650] training loss: 0.00013692
INFO:root:[2,   700] training loss: 0.00009338
INFO:root:[2,   750] training loss: 0.00006355
INFO:root:[2,   800] training loss: 0.00006112
INFO:root:[2,   850] training loss: 0.00004747
INFO:root:[2,   900] training loss: 0.06105948
INFO:root:[2,   950] training loss: 0.02138647
INFO:root:[2,  1000] training loss: 0.00032807
INFO:root:[2,  1050] training loss: 0.00017216
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.06726765
INFO:root:[3,   100] training loss: 0.03361583
INFO:root:[3,   150] training loss: 0.03670715
INFO:root:[3,   200] training loss: 0.03456867
INFO:root:[3,   250] training loss: 0.02983445
INFO:root:[3,   300] training loss: 0.02736363
INFO:root:[3,   350] training loss: 0.03158439
INFO:root:[3,   400] training loss: 0.00210078
INFO:root:[3,   450] training loss: 0.00018763
INFO:root:[3,   500] training loss: 0.00805378
INFO:root:[3,   550] training loss: 0.00848678
INFO:root:[3,   600] training loss: 0.02549927
INFO:root:[3,   650] training loss: 0.00008466
INFO:root:[3,   700] training loss: 0.00006645
INFO:root:[3,   750] training loss: 0.00004961
INFO:root:[3,   800] training loss: 0.00004523
INFO:root:[3,   850] training loss: 0.00003639
INFO:root:[3,   900] training loss: 0.06472865
INFO:root:[3,   950] training loss: 0.02445998
INFO:root:[3,  1000] training loss: 0.00032158
INFO:root:[3,  1050] training loss: 0.00016862
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.07578715
INFO:root:[4,   100] training loss: 0.03103731
INFO:root:[4,   150] training loss: 0.02841636
INFO:root:[4,   200] training loss: 0.02422277
INFO:root:[4,   250] training loss: 0.02741605
INFO:root:[4,   300] training loss: 0.02765163
INFO:root:[4,   350] training loss: 0.02809580
INFO:root:[4,   400] training loss: 0.00111562
INFO:root:[4,   450] training loss: 0.00017735
INFO:root:[4,   500] training loss: 0.00716806
INFO:root:[4,   550] training loss: 0.00848455
INFO:root:[4,   600] training loss: 0.02588923
INFO:root:[4,   650] training loss: 0.00025284
INFO:root:[4,   700] training loss: 0.00017599
INFO:root:[4,   750] training loss: 0.00013186
INFO:root:[4,   800] training loss: 0.00010818
INFO:root:[4,   850] training loss: 0.00009551
INFO:root:[4,   900] training loss: 0.05829695
INFO:root:[4,   950] training loss: 0.02337774
INFO:root:[4,  1000] training loss: 0.00061243
INFO:root:[4,  1050] training loss: 0.00029457
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.06658763
INFO:root:[5,   100] training loss: 0.02903187
INFO:root:[5,   150] training loss: 0.02929119
INFO:root:[5,   200] training loss: 0.02691058
INFO:root:[5,   250] training loss: 0.02476901
INFO:root:[5,   300] training loss: 0.02497718
INFO:root:[5,   350] training loss: 0.02788166
INFO:root:[5,   400] training loss: 0.00166076
INFO:root:[5,   450] training loss: 0.00014906
INFO:root:[5,   500] training loss: 0.00722578
INFO:root:[5,   550] training loss: 0.00690602
INFO:root:[5,   600] training loss: 0.02655859
INFO:root:[5,   650] training loss: 0.00012860
INFO:root:[5,   700] training loss: 0.00008993
INFO:root:[5,   750] training loss: 0.00008275
INFO:root:[5,   800] training loss: 0.00007886
INFO:root:[5,   850] training loss: 0.00005530
INFO:root:[5,   900] training loss: 0.07078829
INFO:root:[5,   950] training loss: 0.02339607
INFO:root:[5,  1000] training loss: 0.00050198
INFO:root:[5,  1050] training loss: 0.00027231
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.19137483
INFO:root:[6,   100] training loss: 0.06208872
INFO:root:[6,   150] training loss: 0.05140847
INFO:root:[6,   200] training loss: 0.05525964
INFO:root:[6,   250] training loss: 0.03951169
INFO:root:[6,   300] training loss: 0.03894555
INFO:root:[6,   350] training loss: 0.04091647
INFO:root:[6,   400] training loss: 0.00044722
INFO:root:[6,   450] training loss: 0.00037416
INFO:root:[6,   500] training loss: 0.00925429
INFO:root:[6,   550] training loss: 0.00347872
INFO:root:[6,   600] training loss: 0.02809129
INFO:root:[6,   650] training loss: 0.00000053
INFO:root:[6,   700] training loss: 0.00000025
INFO:root:[6,   750] training loss: 0.00000130
INFO:root:[6,   800] training loss: 0.00000035
INFO:root:[6,   850] training loss: 0.00000054
INFO:root:[6,   900] training loss: 0.08583326
INFO:root:[6,   950] training loss: 0.01747575
INFO:root:[6,  1000] training loss: 0.00001730
INFO:root:[6,  1050] training loss: 0.00001106
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.08725939
INFO:root:[7,   100] training loss: 0.03769884
INFO:root:[7,   150] training loss: 0.03694726
INFO:root:[7,   200] training loss: 0.03533932
INFO:root:[7,   250] training loss: 0.03045684
INFO:root:[7,   300] training loss: 0.03021458
INFO:root:[7,   350] training loss: 0.03341762
INFO:root:[7,   400] training loss: 0.00110638
INFO:root:[7,   450] training loss: 0.00025840
INFO:root:[7,   500] training loss: 0.00647092
INFO:root:[7,   550] training loss: 0.00555174
INFO:root:[7,   600] training loss: 0.01990852
INFO:root:[7,   650] training loss: 0.00002932
INFO:root:[7,   700] training loss: 0.00001360
INFO:root:[7,   750] training loss: 0.00002107
INFO:root:[7,   800] training loss: 0.00002029
INFO:root:[7,   850] training loss: 0.00001431
INFO:root:[7,   900] training loss: 0.05336699
INFO:root:[7,   950] training loss: 0.02155987
INFO:root:[7,  1000] training loss: 0.00004555
INFO:root:[7,  1050] training loss: 0.00003517
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.07121328
INFO:root:[8,   100] training loss: 0.03582943
INFO:root:[8,   150] training loss: 0.04049062
INFO:root:[8,   200] training loss: 0.03239669
INFO:root:[8,   250] training loss: 0.02791028
INFO:root:[8,   300] training loss: 0.02940479
INFO:root:[8,   350] training loss: 0.03329581
INFO:root:[8,   400] training loss: 0.00061305
INFO:root:[8,   450] training loss: 0.00021170
INFO:root:[8,   500] training loss: 0.00561711
INFO:root:[8,   550] training loss: 0.00757401
INFO:root:[8,   600] training loss: 0.02117728
INFO:root:[8,   650] training loss: 0.00001418
INFO:root:[8,   700] training loss: 0.00001330
INFO:root:[8,   750] training loss: 0.00001677
INFO:root:[8,   800] training loss: 0.00001649
INFO:root:[8,   850] training loss: 0.00001493
INFO:root:[8,   900] training loss: 0.05599584
INFO:root:[8,   950] training loss: 0.02178478
INFO:root:[8,  1000] training loss: 0.00005574
INFO:root:[8,  1050] training loss: 0.00004561
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.07440457
INFO:root:[9,   100] training loss: 0.03058766
INFO:root:[9,   150] training loss: 0.03516370
INFO:root:[9,   200] training loss: 0.03194485
INFO:root:[9,   250] training loss: 0.02659727
INFO:root:[9,   300] training loss: 0.02927243
INFO:root:[9,   350] training loss: 0.03139895
INFO:root:[9,   400] training loss: 0.00064047
INFO:root:[9,   450] training loss: 0.00018313
INFO:root:[9,   500] training loss: 0.00526689
INFO:root:[9,   550] training loss: 0.00821589
INFO:root:[9,   600] training loss: 0.02262082
INFO:root:[9,   650] training loss: 0.00002819
INFO:root:[9,   700] training loss: 0.00002372
INFO:root:[9,   750] training loss: 0.00003488
INFO:root:[9,   800] training loss: 0.00002930
INFO:root:[9,   850] training loss: 0.00002871
INFO:root:[9,   900] training loss: 0.04734241
INFO:root:[9,   950] training loss: 0.01970949
INFO:root:[9,  1000] training loss: 0.00015954
INFO:root:[9,  1050] training loss: 0.00010322
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.05889543
INFO:root:[10,   100] training loss: 0.02758787
INFO:root:[10,   150] training loss: 0.02779685
INFO:root:[10,   200] training loss: 0.02872104
INFO:root:[10,   250] training loss: 0.02595657
INFO:root:[10,   300] training loss: 0.02921181
INFO:root:[10,   350] training loss: 0.02782066
INFO:root:[10,   400] training loss: 0.00057909
INFO:root:[10,   450] training loss: 0.00019700
INFO:root:[10,   500] training loss: 0.00489700
INFO:root:[10,   550] training loss: 0.00789823
INFO:root:[10,   600] training loss: 0.02528849
INFO:root:[10,   650] training loss: 0.00003952
INFO:root:[10,   700] training loss: 0.00003428
INFO:root:[10,   750] training loss: 0.00004175
INFO:root:[10,   800] training loss: 0.00003879
INFO:root:[10,   850] training loss: 0.00003638
INFO:root:[10,   900] training loss: 0.05033867
INFO:root:[10,   950] training loss: 0.02011529
INFO:root:[10,  1000] training loss: 0.00016800
INFO:root:[10,  1050] training loss: 0.00009086
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.05578000
INFO:root:[11,   100] training loss: 0.02759024
INFO:root:[11,   150] training loss: 0.02949333
INFO:root:[11,   200] training loss: 0.02449477
INFO:root:[11,   250] training loss: 0.02431990
INFO:root:[11,   300] training loss: 0.02667925
INFO:root:[11,   350] training loss: 0.02591330
INFO:root:[11,   400] training loss: 0.00027760
INFO:root:[11,   450] training loss: 0.00017662
INFO:root:[11,   500] training loss: 0.00654196
INFO:root:[11,   550] training loss: 0.00503419
INFO:root:[11,   600] training loss: 0.02560641
INFO:root:[11,   650] training loss: 0.00003074
INFO:root:[11,   700] training loss: 0.00002806
INFO:root:[11,   750] training loss: 0.00002961
INFO:root:[11,   800] training loss: 0.00002753
INFO:root:[11,   850] training loss: 0.00002583
INFO:root:[11,   900] training loss: 0.05118097
INFO:root:[11,   950] training loss: 0.01970479
INFO:root:[11,  1000] training loss: 0.00030279
INFO:root:[11,  1050] training loss: 0.00015894
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.05531743
INFO:root:[12,   100] training loss: 0.02618488
INFO:root:[12,   150] training loss: 0.02797984
INFO:root:[12,   200] training loss: 0.02386350
INFO:root:[12,   250] training loss: 0.02377537
INFO:root:[12,   300] training loss: 0.02575726
INFO:root:[12,   350] training loss: 0.02443295
INFO:root:[12,   400] training loss: 0.00124206
INFO:root:[12,   450] training loss: 0.00019962
INFO:root:[12,   500] training loss: 0.00718705
INFO:root:[12,   550] training loss: 0.00837335
INFO:root:[12,   600] training loss: 0.02643417
INFO:root:[12,   650] training loss: 0.00012911
INFO:root:[12,   700] training loss: 0.00007727
INFO:root:[12,   750] training loss: 0.00007581
INFO:root:[12,   800] training loss: 0.00005921
INFO:root:[12,   850] training loss: 0.00004949
INFO:root:[12,   900] training loss: 0.04994298
INFO:root:[12,   950] training loss: 0.02245742
INFO:root:[12,  1000] training loss: 0.00037406
INFO:root:[12,  1050] training loss: 0.00021207
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2671    1.0000    0.4216      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.05943521
INFO:root:[13,   100] training loss: 0.02778299
INFO:root:[13,   150] training loss: 0.02732628
INFO:root:[13,   200] training loss: 0.02763563
INFO:root:[13,   250] training loss: 0.02366483
INFO:root:[13,   300] training loss: 0.02743029
INFO:root:[13,   350] training loss: 0.02281110
INFO:root:[13,   400] training loss: 0.00159134
INFO:root:[13,   450] training loss: 0.00028079
INFO:root:[13,   500] training loss: 0.00626791
INFO:root:[13,   550] training loss: 0.00917254
INFO:root:[13,   600] training loss: 0.02565753
INFO:root:[13,   650] training loss: 0.00013784
INFO:root:[13,   700] training loss: 0.00010245
INFO:root:[13,   750] training loss: 0.00009578
INFO:root:[13,   800] training loss: 0.00008140
INFO:root:[13,   850] training loss: 0.00007219
INFO:root:[13,   900] training loss: 0.05189292
INFO:root:[13,   950] training loss: 0.01845836
INFO:root:[13,  1000] training loss: 0.00039156
INFO:root:[13,  1050] training loss: 0.00021461
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2673    1.0000    0.4218      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0603      3872
weighted avg     0.0714    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.05015570
INFO:root:[14,   100] training loss: 0.02443216
INFO:root:[14,   150] training loss: 0.02739988
INFO:root:[14,   200] training loss: 0.02460919
INFO:root:[14,   250] training loss: 0.02257049
INFO:root:[14,   300] training loss: 0.02508243
INFO:root:[14,   350] training loss: 0.02250761
INFO:root:[14,   400] training loss: 0.00112833
INFO:root:[14,   450] training loss: 0.00030756
INFO:root:[14,   500] training loss: 0.00553148
INFO:root:[14,   550] training loss: 0.00867136
INFO:root:[14,   600] training loss: 0.02700675
INFO:root:[14,   650] training loss: 0.00020793
INFO:root:[14,   700] training loss: 0.00014608
INFO:root:[14,   750] training loss: 0.00013223
INFO:root:[14,   800] training loss: 0.00009240
INFO:root:[14,   850] training loss: 0.00008212
INFO:root:[14,   900] training loss: 0.04524300
INFO:root:[14,   950] training loss: 0.02070893
INFO:root:[14,  1000] training loss: 0.00053297
INFO:root:[14,  1050] training loss: 0.00026258
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     1.0000    0.0137    0.0270        73
   Metaphase     0.2673    1.0000    0.4219      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.1810    0.1448    0.0641      3872
weighted avg     0.0902    0.2673    0.1132      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.05132605
INFO:root:[15,   100] training loss: 0.02308119
INFO:root:[15,   150] training loss: 0.02345828
INFO:root:[15,   200] training loss: 0.02273208
INFO:root:[15,   250] training loss: 0.02593130
INFO:root:[15,   300] training loss: 0.02204996
INFO:root:[15,   350] training loss: 0.02063028
INFO:root:[15,   400] training loss: 0.00071503
INFO:root:[15,   450] training loss: 0.00016769
INFO:root:[15,   500] training loss: 0.00488095
INFO:root:[15,   550] training loss: 0.00886218
INFO:root:[15,   600] training loss: 0.02662376
INFO:root:[15,   650] training loss: 0.00018610
INFO:root:[15,   700] training loss: 0.00014145
INFO:root:[15,   750] training loss: 0.00013376
INFO:root:[15,   800] training loss: 0.00009478
INFO:root:[15,   850] training loss: 0.00007970
INFO:root:[15,   900] training loss: 0.05586190
INFO:root:[15,   950] training loss: 0.02173234
INFO:root:[15,  1000] training loss: 0.00034330
INFO:root:[15,  1050] training loss: 0.00018225
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2670    1.0000    0.4215      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.06016284
INFO:root:[16,   100] training loss: 0.02696453
INFO:root:[16,   150] training loss: 0.02939361
INFO:root:[16,   200] training loss: 0.02835611
INFO:root:[16,   250] training loss: 0.02468047
INFO:root:[16,   300] training loss: 0.02433031
INFO:root:[16,   350] training loss: 0.02432995
INFO:root:[16,   400] training loss: 0.00097120
INFO:root:[16,   450] training loss: 0.00024586
INFO:root:[16,   500] training loss: 0.00529889
INFO:root:[16,   550] training loss: 0.00852721
INFO:root:[16,   600] training loss: 0.02607941
INFO:root:[16,   650] training loss: 0.00020148
INFO:root:[16,   700] training loss: 0.00017180
INFO:root:[16,   750] training loss: 0.00013734
INFO:root:[16,   800] training loss: 0.00013259
INFO:root:[16,   850] training loss: 0.00010795
INFO:root:[16,   900] training loss: 0.05836157
INFO:root:[16,   950] training loss: 0.01998755
INFO:root:[16,  1000] training loss: 0.00045216
INFO:root:[16,  1050] training loss: 0.00027072
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2671    1.0000    0.4216      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.04863822
INFO:root:[17,   100] training loss: 0.02297950
INFO:root:[17,   150] training loss: 0.02397546
INFO:root:[17,   200] training loss: 0.02453125
INFO:root:[17,   250] training loss: 0.02140881
INFO:root:[17,   300] training loss: 0.02213665
INFO:root:[17,   350] training loss: 0.02596513
INFO:root:[17,   400] training loss: 0.00104704
INFO:root:[17,   450] training loss: 0.00047666
INFO:root:[17,   500] training loss: 0.00742250
INFO:root:[17,   550] training loss: 0.00838306
INFO:root:[17,   600] training loss: 0.02924650
INFO:root:[17,   650] training loss: 0.00017470
INFO:root:[17,   700] training loss: 0.00012050
INFO:root:[17,   750] training loss: 0.00010964
INFO:root:[17,   800] training loss: 0.00009015
INFO:root:[17,   850] training loss: 0.00007937
INFO:root:[17,   900] training loss: 0.04673641
INFO:root:[17,   950] training loss: 0.02363099
INFO:root:[17,  1000] training loss: 0.00038390
INFO:root:[17,  1050] training loss: 0.00023633
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2674    1.0000    0.4220      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2678      3872
   macro avg     0.1811    0.2857    0.2031      3872
weighted avg     0.0722    0.2678    0.1135      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.04915456
INFO:root:[18,   100] training loss: 0.02282485
INFO:root:[18,   150] training loss: 0.02427231
INFO:root:[18,   200] training loss: 0.02315198
INFO:root:[18,   250] training loss: 0.02886800
INFO:root:[18,   300] training loss: 0.02504153
INFO:root:[18,   350] training loss: 0.02924469
INFO:root:[18,   400] training loss: 0.00084205
INFO:root:[18,   450] training loss: 0.00035929
INFO:root:[18,   500] training loss: 0.00803596
INFO:root:[18,   550] training loss: 0.00886403
INFO:root:[18,   600] training loss: 0.03118567
INFO:root:[18,   650] training loss: 0.00015600
INFO:root:[18,   700] training loss: 0.00012554
INFO:root:[18,   750] training loss: 0.00013397
INFO:root:[18,   800] training loss: 0.00009862
INFO:root:[18,   850] training loss: 0.00009606
INFO:root:[18,   900] training loss: 0.04772330
INFO:root:[18,   950] training loss: 0.01972463
INFO:root:[18,  1000] training loss: 0.00053323
INFO:root:[18,  1050] training loss: 0.00031619
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.5000    0.0274    0.0519        73
   Metaphase     0.2675    1.0000    0.4221      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2683      3872
   macro avg     0.2525    0.2896    0.2106      3872
weighted avg     0.0816    0.2683    0.1145      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.04946207
INFO:root:[19,   100] training loss: 0.02076114
INFO:root:[19,   150] training loss: 0.02234157
INFO:root:[19,   200] training loss: 0.01992871
INFO:root:[19,   250] training loss: 0.02266338
INFO:root:[19,   300] training loss: 0.02335020
INFO:root:[19,   350] training loss: 0.02344569
INFO:root:[19,   400] training loss: 0.00132135
INFO:root:[19,   450] training loss: 0.00028430
INFO:root:[19,   500] training loss: 0.00753019
INFO:root:[19,   550] training loss: 0.00920288
INFO:root:[19,   600] training loss: 0.03028207
INFO:root:[19,   650] training loss: 0.00026343
INFO:root:[19,   700] training loss: 0.00019100
INFO:root:[19,   750] training loss: 0.00016105
INFO:root:[19,   800] training loss: 0.00015495
INFO:root:[19,   850] training loss: 0.00012366
INFO:root:[19,   900] training loss: 0.04715283
INFO:root:[19,   950] training loss: 0.02070982
INFO:root:[19,  1000] training loss: 0.00069033
INFO:root:[19,  1050] training loss: 0.00037543
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    1.0000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.7143    0.0685    0.1250        73
   Metaphase     0.2689    1.0000    0.4239      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2696      3872
   macro avg     0.3309    0.4384    0.2927      3872
weighted avg     0.0862    0.2696    0.1166      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.04653447
INFO:root:[20,   100] training loss: 0.02065170
INFO:root:[20,   150] training loss: 0.02377988
INFO:root:[20,   200] training loss: 0.01978146
INFO:root:[20,   250] training loss: 0.02730686
INFO:root:[20,   300] training loss: 0.03137692
INFO:root:[20,   350] training loss: 0.02229298
INFO:root:[20,   400] training loss: 0.00120536
INFO:root:[20,   450] training loss: 0.00023195
INFO:root:[20,   500] training loss: 0.00502644
INFO:root:[20,   550] training loss: 0.00834592
INFO:root:[20,   600] training loss: 0.02734725
INFO:root:[20,   650] training loss: 0.00032606
INFO:root:[20,   700] training loss: 0.00023123
INFO:root:[20,   750] training loss: 0.00018401
INFO:root:[20,   800] training loss: 0.00014562
INFO:root:[20,   850] training loss: 0.00013622
INFO:root:[20,   900] training loss: 0.05332066
INFO:root:[20,   950] training loss: 0.01952445
INFO:root:[20,  1000] training loss: 0.00064947
INFO:root:[20,  1050] training loss: 0.00034230
INFO:root:              precision    recall  f1-score   support

          G1     0.1667    1.0000    0.2857         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1111    0.1250    0.1176         8
          G2     0.5000    0.0411    0.0759        73
   Metaphase     0.2689    1.0000    0.4239      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2686      3872
   macro avg     0.1495    0.3094    0.1290      3872
weighted avg     0.0816    0.2686    0.1150      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.04681114
INFO:root:[21,   100] training loss: 0.02127408
INFO:root:[21,   150] training loss: 0.02187681
INFO:root:[21,   200] training loss: 0.01848515
INFO:root:[21,   250] training loss: 0.02316381
INFO:root:[21,   300] training loss: 0.02237633
INFO:root:[21,   350] training loss: 0.02253804
INFO:root:[21,   400] training loss: 0.00071681
INFO:root:[21,   450] training loss: 0.00022028
INFO:root:[21,   500] training loss: 0.00649294
INFO:root:[21,   550] training loss: 0.00925085
INFO:root:[21,   600] training loss: 0.02913403
INFO:root:[21,   650] training loss: 0.00030407
INFO:root:[21,   700] training loss: 0.00023655
INFO:root:[21,   750] training loss: 0.00018826
INFO:root:[21,   800] training loss: 0.00015324
INFO:root:[21,   850] training loss: 0.00013135
INFO:root:[21,   900] training loss: 0.04765662
INFO:root:[21,   950] training loss: 0.02041603
INFO:root:[21,  1000] training loss: 0.00067262
INFO:root:[21,  1050] training loss: 0.00036690
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0909    0.1250    0.1053         8
          G2     0.5000    0.0274    0.0519        73
   Metaphase     0.2686    1.0000    0.4234      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2686      3872
   macro avg     0.2656    0.3075    0.2258      3872
weighted avg     0.0821    0.2686    0.1150      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.04517298
INFO:root:[22,   100] training loss: 0.02048572
INFO:root:[22,   150] training loss: 0.02065931
INFO:root:[22,   200] training loss: 0.01809537
INFO:root:[22,   250] training loss: 0.01845746
INFO:root:[22,   300] training loss: 0.01959892
INFO:root:[22,   350] training loss: 0.01728451
INFO:root:[22,   400] training loss: 0.00125269
INFO:root:[22,   450] training loss: 0.00022212
INFO:root:[22,   500] training loss: 0.00516456
INFO:root:[22,   550] training loss: 0.00894131
INFO:root:[22,   600] training loss: 0.02922517
INFO:root:[22,   650] training loss: 0.00030036
INFO:root:[22,   700] training loss: 0.00022311
INFO:root:[22,   750] training loss: 0.00019581
INFO:root:[22,   800] training loss: 0.00014859
INFO:root:[22,   850] training loss: 0.00012376
INFO:root:[22,   900] training loss: 0.04369263
INFO:root:[22,   950] training loss: 0.02043589
INFO:root:[22,  1000] training loss: 0.00073878
INFO:root:[22,  1050] training loss: 0.00041237
INFO:root:              precision    recall  f1-score   support

          G1     0.1429    0.5000    0.2222         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0667    0.1250    0.0870         8
          G2     0.4000    0.1370    0.2041        73
   Metaphase     0.2705    1.0000    0.4259      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2709      3872
   macro avg     0.2686    0.3946    0.2770      3872
weighted avg     0.0808    0.2709    0.1186      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.04526538
INFO:root:[23,   100] training loss: 0.02122938
INFO:root:[23,   150] training loss: 0.02062166
INFO:root:[23,   200] training loss: 0.02310741
INFO:root:[23,   250] training loss: 0.03634053
INFO:root:[23,   300] training loss: 0.02343148
INFO:root:[23,   350] training loss: 0.01815071
INFO:root:[23,   400] training loss: 0.00108594
INFO:root:[23,   450] training loss: 0.00014914
INFO:root:[23,   500] training loss: 0.00579635
INFO:root:[23,   550] training loss: 0.00636748
INFO:root:[23,   600] training loss: 0.02851177
INFO:root:[23,   650] training loss: 0.00023941
INFO:root:[23,   700] training loss: 0.00019530
INFO:root:[23,   750] training loss: 0.00015545
INFO:root:[23,   800] training loss: 0.00014066
INFO:root:[23,   850] training loss: 0.00011055
INFO:root:[23,   900] training loss: 0.05329754
INFO:root:[23,   950] training loss: 0.01880868
INFO:root:[23,  1000] training loss: 0.00049160
INFO:root:[23,  1050] training loss: 0.00029134
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.7500    0.0411    0.0779        73
   Metaphase     0.2682    1.0000    0.4230      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2689      3872
   macro avg     0.3240    0.3630    0.2620      3872
weighted avg     0.0867    0.2689    0.1154      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.04360587
INFO:root:[24,   100] training loss: 0.01899031
INFO:root:[24,   150] training loss: 0.02039385
INFO:root:[24,   200] training loss: 0.01793250
INFO:root:[24,   250] training loss: 0.01787123
INFO:root:[24,   300] training loss: 0.01845585
INFO:root:[24,   350] training loss: 0.01637300
INFO:root:[24,   400] training loss: 0.00071248
INFO:root:[24,   450] training loss: 0.00045961
INFO:root:[24,   500] training loss: 0.00492659
INFO:root:[24,   550] training loss: 0.00782693
INFO:root:[24,   600] training loss: 0.02857666
INFO:root:[24,   650] training loss: 0.00036005
INFO:root:[24,   700] training loss: 0.00022886
INFO:root:[24,   750] training loss: 0.00017591
INFO:root:[24,   800] training loss: 0.00016349
INFO:root:[24,   850] training loss: 0.00012908
INFO:root:[24,   900] training loss: 0.04016443
INFO:root:[24,   950] training loss: 0.02028803
INFO:root:[24,  1000] training loss: 0.00067310
INFO:root:[24,  1050] training loss: 0.00036904
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1154    0.3750    0.1765         8
          G2     0.5588    0.2603    0.3551        73
   Metaphase     0.2716    1.0000    0.4272      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2738      3872
   macro avg     0.3494    0.4479    0.3513      3872
weighted avg     0.0843    0.2738    0.1222      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.04375002
INFO:root:[25,   100] training loss: 0.01896860
INFO:root:[25,   150] training loss: 0.02106005
INFO:root:[25,   200] training loss: 0.01925513
INFO:root:[25,   250] training loss: 0.02033266
INFO:root:[25,   300] training loss: 0.01893505
INFO:root:[25,   350] training loss: 0.01605187
INFO:root:[25,   400] training loss: 0.00035284
INFO:root:[25,   450] training loss: 0.00014813
INFO:root:[25,   500] training loss: 0.00476382
INFO:root:[25,   550] training loss: 0.00929992
INFO:root:[25,   600] training loss: 0.02913846
INFO:root:[25,   650] training loss: 0.00048549
INFO:root:[25,   700] training loss: 0.00032007
INFO:root:[25,   750] training loss: 0.00022926
INFO:root:[25,   800] training loss: 0.00020410
INFO:root:[25,   850] training loss: 0.00017534
INFO:root:[25,   900] training loss: 0.04040678
INFO:root:[25,   950] training loss: 0.02049341
INFO:root:[25,  1000] training loss: 0.00073996
INFO:root:[25,  1050] training loss: 0.00042909
INFO:root:              precision    recall  f1-score   support

          G1     0.2857    1.0000    0.4444         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1176    0.5000    0.1905         8
          G2     0.4138    0.1644    0.2353        73
   Metaphase     0.2721    1.0000    0.4278      1034
    Prophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2722      3872
   macro avg     0.2985    0.4759    0.2997      3872
weighted avg     0.0816    0.2722    0.1199      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.04169087
INFO:root:[26,   100] training loss: 0.01872774
INFO:root:[26,   150] training loss: 0.01924636
INFO:root:[26,   200] training loss: 0.01814685
INFO:root:[26,   250] training loss: 0.01825555
INFO:root:[26,   300] training loss: 0.01969765
INFO:root:[26,   350] training loss: 0.01852218
INFO:root:[26,   400] training loss: 0.00117451
INFO:root:[26,   450] training loss: 0.00027331
INFO:root:[26,   500] training loss: 0.00498825
INFO:root:[26,   550] training loss: 0.01076065
INFO:root:[26,   600] training loss: 0.02984262
INFO:root:[26,   650] training loss: 0.00043727
INFO:root:[26,   700] training loss: 0.00024967
INFO:root:[26,   750] training loss: 0.00012428
INFO:root:[26,   800] training loss: 0.00015649
INFO:root:[26,   850] training loss: 0.00007786
INFO:root:[26,   900] training loss: 0.04440648
INFO:root:[26,   950] training loss: 0.01922130
INFO:root:[26,  1000] training loss: 0.00085600
INFO:root:[26,  1050] training loss: 0.00048824
INFO:root:              precision    recall  f1-score   support

          G1     0.2000    0.5000    0.2857         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0714    0.2500    0.1111         8
          G2     0.2667    0.1644    0.2034        73
   Metaphase     0.2725    1.0000    0.4283      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2709      3872
   macro avg     0.1158    0.2735    0.1469      3872
weighted avg     0.0781    0.2709    0.1186      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.04431047
INFO:root:[27,   100] training loss: 0.02010958
INFO:root:[27,   150] training loss: 0.01997735
INFO:root:[27,   200] training loss: 0.01984732
INFO:root:[27,   250] training loss: 0.01841644
INFO:root:[27,   300] training loss: 0.01966370
INFO:root:[27,   350] training loss: 0.01686614
INFO:root:[27,   400] training loss: 0.00086403
INFO:root:[27,   450] training loss: 0.00036483
INFO:root:[27,   500] training loss: 0.00539074
INFO:root:[27,   550] training loss: 0.00985255
INFO:root:[27,   600] training loss: 0.02988696
INFO:root:[27,   650] training loss: 0.00057489
INFO:root:[27,   700] training loss: 0.00032464
INFO:root:[27,   750] training loss: 0.00028597
INFO:root:[27,   800] training loss: 0.00020803
INFO:root:[27,   850] training loss: 0.00019053
INFO:root:[27,   900] training loss: 0.04460156
INFO:root:[27,   950] training loss: 0.02183922
INFO:root:[27,  1000] training loss: 0.00081361
INFO:root:[27,  1050] training loss: 0.00042900
INFO:root:              precision    recall  f1-score   support

          G1     0.2000    0.5000    0.2857         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0741    0.2500    0.1143         8
          G2     0.3696    0.2329    0.2857        73
   Metaphase     0.2725    1.0000    0.4283      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2722      3872
   macro avg     0.1309    0.2833    0.1591      3872
weighted avg     0.0800    0.2722    0.1202      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.04532516
INFO:root:[28,   100] training loss: 0.01912851
INFO:root:[28,   150] training loss: 0.02103460
INFO:root:[28,   200] training loss: 0.01735599
INFO:root:[28,   250] training loss: 0.01688902
INFO:root:[28,   300] training loss: 0.01798278
INFO:root:[28,   350] training loss: 0.01750412
INFO:root:[28,   400] training loss: 0.00050790
INFO:root:[28,   450] training loss: 0.00027539
INFO:root:[28,   500] training loss: 0.00500704
INFO:root:[28,   550] training loss: 0.01096880
INFO:root:[28,   600] training loss: 0.03129115
INFO:root:[28,   650] training loss: 0.00059415
INFO:root:[28,   700] training loss: 0.00036946
INFO:root:[28,   750] training loss: 0.00024897
INFO:root:[28,   800] training loss: 0.00023226
INFO:root:[28,   850] training loss: 0.00019222
INFO:root:[28,   900] training loss: 0.05847567
INFO:root:[28,   950] training loss: 0.02401891
INFO:root:[28,  1000] training loss: 0.00085899
INFO:root:[28,  1050] training loss: 0.00047487
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0400    0.1250    0.0606         8
          G2     0.4444    0.0548    0.0976        73
   Metaphase     0.2700    1.0000    0.4252      1034
    Prophase     1.0000    0.3333    0.5000         3

    accuracy                         0.2686      3872
   macro avg     0.2506    0.2162    0.1548      3872
weighted avg     0.0813    0.2686    0.1159      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.04921826
INFO:root:[29,   100] training loss: 0.02473457
INFO:root:[29,   150] training loss: 0.02711960
INFO:root:[29,   200] training loss: 0.02250853
INFO:root:[29,   250] training loss: 0.02128105
INFO:root:[29,   300] training loss: 0.02725252
INFO:root:[29,   350] training loss: 0.02943112
INFO:root:[29,   400] training loss: 0.00062924
INFO:root:[29,   450] training loss: 0.00024635
INFO:root:[29,   500] training loss: 0.00617275
INFO:root:[29,   550] training loss: 0.01014186
INFO:root:[29,   600] training loss: 0.03069513
INFO:root:[29,   650] training loss: 0.00058710
INFO:root:[29,   700] training loss: 0.00037145
INFO:root:[29,   750] training loss: 0.00029640
INFO:root:[29,   800] training loss: 0.00024082
INFO:root:[29,   850] training loss: 0.00021178
INFO:root:[29,   900] training loss: 0.05467256
INFO:root:[29,   950] training loss: 0.02616317
INFO:root:[29,  1000] training loss: 0.00106592
INFO:root:[29,  1050] training loss: 0.00052574
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0909    0.1250    0.1053         8
          G2     0.3333    0.0137    0.0263        73
   Metaphase     0.2682    1.0000    0.4230      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2683      3872
   macro avg     0.2418    0.3055    0.2221      3872
weighted avg     0.0789    0.2683    0.1144      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.04439048
INFO:root:[30,   100] training loss: 0.02351177
INFO:root:[30,   150] training loss: 0.02052375
INFO:root:[30,   200] training loss: 0.01896048
INFO:root:[30,   250] training loss: 0.02105042
INFO:root:[30,   300] training loss: 0.02486374
INFO:root:[30,   350] training loss: 0.03474196
INFO:root:[30,   400] training loss: 0.00046882
INFO:root:[30,   450] training loss: 0.00032064
INFO:root:[30,   500] training loss: 0.00633044
INFO:root:[30,   550] training loss: 0.01134490
INFO:root:[30,   600] training loss: 0.03251275
INFO:root:[30,   650] training loss: 0.00048445
INFO:root:[30,   700] training loss: 0.00033748
INFO:root:[30,   750] training loss: 0.00024506
INFO:root:[30,   800] training loss: 0.00019493
INFO:root:[30,   850] training loss: 0.00016394
INFO:root:[30,   900] training loss: 0.05954159
INFO:root:[30,   950] training loss: 0.02104084
INFO:root:[30,  1000] training loss: 0.00092918
INFO:root:[30,  1050] training loss: 0.00047726
INFO:root:              precision    recall  f1-score   support

          G1     0.2500    0.5000    0.3333         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.0000    0.0000    0.0000        73
   Metaphase     0.2677    1.0000    0.4224      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.0740    0.2143    0.1080      3872
weighted avg     0.0716    0.2673    0.1130      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.04832114
INFO:root:[31,   100] training loss: 0.02311276
INFO:root:[31,   150] training loss: 0.02562863
INFO:root:[31,   200] training loss: 0.02061119
INFO:root:[31,   250] training loss: 0.02110463
INFO:root:[31,   300] training loss: 0.02138077
INFO:root:[31,   350] training loss: 0.01991327
INFO:root:[31,   400] training loss: 0.00096258
INFO:root:[31,   450] training loss: 0.00028729
INFO:root:[31,   500] training loss: 0.00551137
INFO:root:[31,   550] training loss: 0.01102946
INFO:root:[31,   600] training loss: 0.03295760
INFO:root:[31,   650] training loss: 0.00078583
INFO:root:[31,   700] training loss: 0.00044427
INFO:root:[31,   750] training loss: 0.00031714
INFO:root:[31,   800] training loss: 0.00023703
INFO:root:[31,   850] training loss: 0.00021072
INFO:root:[31,   900] training loss: 0.04978500
INFO:root:[31,   950] training loss: 0.02311537
INFO:root:[31,  1000] training loss: 0.00114003
INFO:root:[31,  1050] training loss: 0.00052824
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1429    0.2500    0.1818         8
          G2     0.6667    0.0822    0.1463        73
   Metaphase     0.2689    1.0000    0.4238      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2691      3872
   macro avg     0.1541    0.1903    0.1074      3872
weighted avg     0.0847    0.2691    0.1163      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.04804143
INFO:root:[32,   100] training loss: 0.02815154
INFO:root:[32,   150] training loss: 0.03123769
INFO:root:[32,   200] training loss: 0.02148389
INFO:root:[32,   250] training loss: 0.02263479
INFO:root:[32,   300] training loss: 0.02594412
INFO:root:[32,   350] training loss: 0.02222571
INFO:root:[32,   400] training loss: 0.00094728
INFO:root:[32,   450] training loss: 0.00031658
INFO:root:[32,   500] training loss: 0.00627610
INFO:root:[32,   550] training loss: 0.01177053
INFO:root:[32,   600] training loss: 0.03123779
INFO:root:[32,   650] training loss: 0.00077504
INFO:root:[32,   700] training loss: 0.00046378
INFO:root:[32,   750] training loss: 0.00034254
INFO:root:[32,   800] training loss: 0.00026423
INFO:root:[32,   850] training loss: 0.00021729
INFO:root:[32,   900] training loss: 0.04922197
INFO:root:[32,   950] training loss: 0.02490014
INFO:root:[32,  1000] training loss: 0.00131395
INFO:root:[32,  1050] training loss: 0.00064168
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1176    0.2500    0.1600         8
          G2     0.4545    0.1370    0.2105        73
   Metaphase     0.2701    1.0000    0.4253      1034
    Prophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2709      3872
   macro avg     0.3108    0.3648    0.2851      3872
weighted avg     0.0819    0.2709    0.1187      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.04650940
INFO:root:[33,   100] training loss: 0.02246430
INFO:root:[33,   150] training loss: 0.02490317
INFO:root:[33,   200] training loss: 0.02051624
INFO:root:[33,   250] training loss: 0.03138491
INFO:root:[33,   300] training loss: 0.02466853
INFO:root:[33,   350] training loss: 0.02009094
INFO:root:[33,   400] training loss: 0.00103263
INFO:root:[33,   450] training loss: 0.00022283
INFO:root:[33,   500] training loss: 0.00558944
INFO:root:[33,   550] training loss: 0.01014381
INFO:root:[33,   600] training loss: 0.03180349
INFO:root:[33,   650] training loss: 0.00067165
INFO:root:[33,   700] training loss: 0.00045582
INFO:root:[33,   750] training loss: 0.00029148
INFO:root:[33,   800] training loss: 0.00023616
INFO:root:[33,   850] training loss: 0.00020226
INFO:root:[33,   900] training loss: 0.04353528
INFO:root:[33,   950] training loss: 0.02200089
INFO:root:[33,  1000] training loss: 0.00111316
INFO:root:[33,  1050] training loss: 0.00058037
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1250    0.3750    0.1875         8
          G2     0.3871    0.1644    0.2308        73
   Metaphase     0.2713    1.0000    0.4268      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2720      3872
   macro avg     0.2905    0.4342    0.3146      3872
weighted avg     0.0809    0.2720    0.1196      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.04365118
INFO:root:[34,   100] training loss: 0.02011977
INFO:root:[34,   150] training loss: 0.02144541
INFO:root:[34,   200] training loss: 0.02074423
INFO:root:[34,   250] training loss: 0.02384318
INFO:root:[34,   300] training loss: 0.02032291
INFO:root:[34,   350] training loss: 0.02407236
INFO:root:[34,   400] training loss: 0.00093891
INFO:root:[34,   450] training loss: 0.00020313
INFO:root:[34,   500] training loss: 0.00468211
INFO:root:[34,   550] training loss: 0.01066494
INFO:root:[34,   600] training loss: 0.02972196
INFO:root:[34,   650] training loss: 0.00067326
INFO:root:[34,   700] training loss: 0.00043651
INFO:root:[34,   750] training loss: 0.00031288
INFO:root:[34,   800] training loss: 0.00024348
INFO:root:[34,   850] training loss: 0.00019514
INFO:root:[34,   900] training loss: 0.04759196
INFO:root:[34,   950] training loss: 0.02057314
INFO:root:[34,  1000] training loss: 0.00086009
INFO:root:[34,  1050] training loss: 0.00036707
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.3333    0.2500    0.2857         8
          G2     0.5000    0.0822    0.1412        73
   Metaphase     0.2684    1.0000    0.4232      1034
    Prophase     1.0000    0.3333    0.5000         3

    accuracy                         0.2694      3872
   macro avg     0.3002    0.2379    0.1929      3872
weighted avg     0.0826    0.2694    0.1166      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.04324693
INFO:root:[35,   100] training loss: 0.02168596
INFO:root:[35,   150] training loss: 0.02219183
INFO:root:[35,   200] training loss: 0.02108384
INFO:root:[35,   250] training loss: 0.01944771
INFO:root:[35,   300] training loss: 0.02059123
INFO:root:[35,   350] training loss: 0.02271184
INFO:root:[35,   400] training loss: 0.00068130
INFO:root:[35,   450] training loss: 0.00020416
INFO:root:[35,   500] training loss: 0.00472593
INFO:root:[35,   550] training loss: 0.01215709
INFO:root:[35,   600] training loss: 0.03187817
INFO:root:[35,   650] training loss: 0.00080927
INFO:root:[35,   700] training loss: 0.00048670
INFO:root:[35,   750] training loss: 0.00033157
INFO:root:[35,   800] training loss: 0.00024689
INFO:root:[35,   850] training loss: 0.00021894
INFO:root:[35,   900] training loss: 0.04413611
INFO:root:[35,   950] training loss: 0.02210990
INFO:root:[35,  1000] training loss: 0.00145420
INFO:root:[35,  1050] training loss: 0.00072118
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0833    0.1250    0.1000         8
          G2     0.6000    0.1233    0.2045        73
   Metaphase     0.2692    1.0000    0.4242      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2707      3872
   macro avg     0.4218    0.3926    0.3422      3872
weighted avg     0.0847    0.2707    0.1185      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.04666300
INFO:root:[36,   100] training loss: 0.02014795
INFO:root:[36,   150] training loss: 0.02529608
INFO:root:[36,   200] training loss: 0.02019111
INFO:root:[36,   250] training loss: 0.01997986
INFO:root:[36,   300] training loss: 0.01950010
INFO:root:[36,   350] training loss: 0.01695377
INFO:root:[36,   400] training loss: 0.00068096
INFO:root:[36,   450] training loss: 0.00022986
INFO:root:[36,   500] training loss: 0.00484130
INFO:root:[36,   550] training loss: 0.01209424
INFO:root:[36,   600] training loss: 0.03124712
INFO:root:[36,   650] training loss: 0.00089769
INFO:root:[36,   700] training loss: 0.00050279
INFO:root:[36,   750] training loss: 0.00034904
INFO:root:[36,   800] training loss: 0.00025762
INFO:root:[36,   850] training loss: 0.00023134
INFO:root:[36,   900] training loss: 0.04433711
INFO:root:[36,   950] training loss: 0.02358043
INFO:root:[36,  1000] training loss: 0.00163663
INFO:root:[36,  1050] training loss: 0.00071368
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0909    0.1250    0.1053         8
          G2     0.5000    0.1507    0.2316        73
   Metaphase     0.2696    1.0000    0.4247      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2712      3872
   macro avg     0.4086    0.3965    0.3469      3872
weighted avg     0.0829    0.2712    0.1191      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.04505450
INFO:root:[37,   100] training loss: 0.02015546
INFO:root:[37,   150] training loss: 0.02174729
INFO:root:[37,   200] training loss: 0.01868086
INFO:root:[37,   250] training loss: 0.02260497
INFO:root:[37,   300] training loss: 0.02075032
INFO:root:[37,   350] training loss: 0.01866246
INFO:root:[37,   400] training loss: 0.00059109
INFO:root:[37,   450] training loss: 0.00027601
INFO:root:[37,   500] training loss: 0.00468921
INFO:root:[37,   550] training loss: 0.01284001
INFO:root:[37,   600] training loss: 0.03181547
INFO:root:[37,   650] training loss: 0.00102910
INFO:root:[37,   700] training loss: 0.00056730
INFO:root:[37,   750] training loss: 0.00035085
INFO:root:[37,   800] training loss: 0.00029271
INFO:root:[37,   850] training loss: 0.00023950
INFO:root:[37,   900] training loss: 0.04008851
INFO:root:[37,   950] training loss: 0.02404413
INFO:root:[37,  1000] training loss: 0.00135429
INFO:root:[37,  1050] training loss: 0.00068904
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    1.0000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1053    0.2500    0.1481         8
          G2     0.5600    0.1918    0.2857        73
   Metaphase     0.2705    1.0000    0.4259      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2717      3872
   macro avg     0.1813    0.3488    0.1942      3872
weighted avg     0.0832    0.2717    0.1197      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.04194427
INFO:root:[38,   100] training loss: 0.01993990
INFO:root:[38,   150] training loss: 0.02067386
INFO:root:[38,   200] training loss: 0.01905414
INFO:root:[38,   250] training loss: 0.02018538
INFO:root:[38,   300] training loss: 0.01906944
INFO:root:[38,   350] training loss: 0.01789922
INFO:root:[38,   400] training loss: 0.00076933
INFO:root:[38,   450] training loss: 0.00022333
INFO:root:[38,   500] training loss: 0.00496821
INFO:root:[38,   550] training loss: 0.01402154
INFO:root:[38,   600] training loss: 0.03413736
INFO:root:[38,   650] training loss: 0.00099914
INFO:root:[38,   700] training loss: 0.00053531
INFO:root:[38,   750] training loss: 0.00035823
INFO:root:[38,   800] training loss: 0.00026341
INFO:root:[38,   850] training loss: 0.00024596
INFO:root:[38,   900] training loss: 0.04410136
INFO:root:[38,   950] training loss: 0.02264111
INFO:root:[38,  1000] training loss: 0.00126073
INFO:root:[38,  1050] training loss: 0.00021172
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2500    0.5000    0.3333         8
          G2     0.2727    0.4521    0.3402        73
   Metaphase     0.2771    0.9990    0.4339      1034
    Prophase     0.6667    0.6667    0.6667         3

    accuracy                         0.2774      3872
   macro avg     0.2809    0.5168    0.3487      3872
weighted avg     0.0804    0.2774    0.1238      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.03972528
INFO:root:[39,   100] training loss: 0.02009162
INFO:root:[39,   150] training loss: 0.02104081
INFO:root:[39,   200] training loss: 0.02027994
INFO:root:[39,   250] training loss: 0.01829423
INFO:root:[39,   300] training loss: 0.01841202
INFO:root:[39,   350] training loss: 0.01692528
INFO:root:[39,   400] training loss: 0.00064307
INFO:root:[39,   450] training loss: 0.00019329
INFO:root:[39,   500] training loss: 0.00500655
INFO:root:[39,   550] training loss: 0.01369515
INFO:root:[39,   600] training loss: 0.03365359
INFO:root:[39,   650] training loss: 0.00099797
INFO:root:[39,   700] training loss: 0.00060395
INFO:root:[39,   750] training loss: 0.00041113
INFO:root:[39,   800] training loss: 0.00033513
INFO:root:[39,   850] training loss: 0.00024978
INFO:root:[39,   900] training loss: 0.03878318
INFO:root:[39,   950] training loss: 0.02412073
INFO:root:[39,  1000] training loss: 0.00135918
INFO:root:[39,  1050] training loss: 0.00063502
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2000    0.5000    0.2857         8
          G2     0.3902    0.2192    0.2807        73
   Metaphase     0.2715    1.0000    0.4270      1034
    Prophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2727      3872
   macro avg     0.2660    0.3408    0.2562      3872
weighted avg     0.0810    0.2727    0.1205      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.04113304
INFO:root:[40,   100] training loss: 0.01916656
INFO:root:[40,   150] training loss: 0.02047242
INFO:root:[40,   200] training loss: 0.01695422
INFO:root:[40,   250] training loss: 0.01811960
INFO:root:[40,   300] training loss: 0.01912794
INFO:root:[40,   350] training loss: 0.01504727
INFO:root:[40,   400] training loss: 0.00087194
INFO:root:[40,   450] training loss: 0.00023491
INFO:root:[40,   500] training loss: 0.00461393
INFO:root:[40,   550] training loss: 0.01381394
INFO:root:[40,   600] training loss: 0.03387599
INFO:root:[40,   650] training loss: 0.00149944
INFO:root:[40,   700] training loss: 0.00070532
INFO:root:[40,   750] training loss: 0.00043927
INFO:root:[40,   800] training loss: 0.00032200
INFO:root:[40,   850] training loss: 0.00029606
INFO:root:[40,   900] training loss: 0.03698539
INFO:root:[40,   950] training loss: 0.02450979
INFO:root:[40,  1000] training loss: 0.00153911
INFO:root:[40,  1050] training loss: 0.00075161
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2500    0.5000    0.3333         8
          G2     0.5556    0.2740    0.3670        73
   Metaphase     0.2709    1.0000    0.4263      1034
    Prophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2738      3872
   macro avg     0.2966    0.3487    0.2752      3872
weighted avg     0.0841    0.2738    0.1221      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.04203463
INFO:root:[41,   100] training loss: 0.02000408
INFO:root:[41,   150] training loss: 0.02165207
INFO:root:[41,   200] training loss: 0.01758054
INFO:root:[41,   250] training loss: 0.01775699
INFO:root:[41,   300] training loss: 0.01753176
INFO:root:[41,   350] training loss: 0.01529665
INFO:root:[41,   400] training loss: 0.00080382
INFO:root:[41,   450] training loss: 0.00022895
INFO:root:[41,   500] training loss: 0.00478302
INFO:root:[41,   550] training loss: 0.01294243
INFO:root:[41,   600] training loss: 0.03282221
INFO:root:[41,   650] training loss: 0.00153392
INFO:root:[41,   700] training loss: 0.00070523
INFO:root:[41,   750] training loss: 0.00046968
INFO:root:[41,   800] training loss: 0.00034888
INFO:root:[41,   850] training loss: 0.00027052
INFO:root:[41,   900] training loss: 0.03687618
INFO:root:[41,   950] training loss: 0.02322408
INFO:root:[41,  1000] training loss: 0.00157972
INFO:root:[41,  1050] training loss: 0.00070064
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2273    0.6250    0.3333         8
          G2     0.4242    0.3836    0.4029        73
   Metaphase     0.2737    1.0000    0.4298      1034
    Prophase     0.6667    0.6667    0.6667         3

    accuracy                         0.2763      3872
   macro avg     0.2750    0.4536    0.3189      3872
weighted avg     0.0822    0.2763    0.1238      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.03853859
INFO:root:[42,   100] training loss: 0.01821819
INFO:root:[42,   150] training loss: 0.01845560
INFO:root:[42,   200] training loss: 0.01616425
INFO:root:[42,   250] training loss: 0.01811900
INFO:root:[42,   300] training loss: 0.01782216
INFO:root:[42,   350] training loss: 0.01750207
INFO:root:[42,   400] training loss: 0.00040760
INFO:root:[42,   450] training loss: 0.00014664
INFO:root:[42,   500] training loss: 0.00461196
INFO:root:[42,   550] training loss: 0.01330103
INFO:root:[42,   600] training loss: 0.03315766
INFO:root:[42,   650] training loss: 0.00159730
INFO:root:[42,   700] training loss: 0.00074531
INFO:root:[42,   750] training loss: 0.00049919
INFO:root:[42,   800] training loss: 0.00036975
INFO:root:[42,   850] training loss: 0.00027230
INFO:root:[42,   900] training loss: 0.03682140
INFO:root:[42,   950] training loss: 0.02380288
INFO:root:[42,  1000] training loss: 0.00154756
INFO:root:[42,  1050] training loss: 0.00075625
INFO:root:              precision    recall  f1-score   support

          G1     0.1667    0.5000    0.2500         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.5806    0.2466    0.3462        73
   Metaphase     0.2701    1.0000    0.4253      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2720      3872
   macro avg     0.1453    0.2495    0.1459      3872
weighted avg     0.0832    0.2720    0.1202      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.03955713
INFO:root:[43,   100] training loss: 0.01942036
INFO:root:[43,   150] training loss: 0.02077573
INFO:root:[43,   200] training loss: 0.02037464
INFO:root:[43,   250] training loss: 0.01733922
INFO:root:[43,   300] training loss: 0.01806607
INFO:root:[43,   350] training loss: 0.01477142
INFO:root:[43,   400] training loss: 0.00054197
INFO:root:[43,   450] training loss: 0.00023883
INFO:root:[43,   500] training loss: 0.00433562
INFO:root:[43,   550] training loss: 0.01234570
INFO:root:[43,   600] training loss: 0.03259378
INFO:root:[43,   650] training loss: 0.00132533
INFO:root:[43,   700] training loss: 0.00064447
INFO:root:[43,   750] training loss: 0.00044580
INFO:root:[43,   800] training loss: 0.00030922
INFO:root:[43,   850] training loss: 0.00024406
INFO:root:[43,   900] training loss: 0.03830188
INFO:root:[43,   950] training loss: 0.02067609
INFO:root:[43,  1000] training loss: 0.00122516
INFO:root:[43,  1050] training loss: 0.00068836
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1935    0.7500    0.3077         8
          G2     0.2661    0.4521    0.3350        73
   Metaphase     0.2777    0.9971    0.4345      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2774      3872
   macro avg     0.3553    0.5285    0.3716      3872
weighted avg     0.0807    0.2774    0.1240      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.03791311
INFO:root:[44,   100] training loss: 0.02056432
INFO:root:[44,   150] training loss: 0.02125441
INFO:root:[44,   200] training loss: 0.01865755
INFO:root:[44,   250] training loss: 0.01701077
INFO:root:[44,   300] training loss: 0.01910978
INFO:root:[44,   350] training loss: 0.01746892
INFO:root:[44,   400] training loss: 0.00081465
INFO:root:[44,   450] training loss: 0.00026432
INFO:root:[44,   500] training loss: 0.00473510
INFO:root:[44,   550] training loss: 0.01077898
INFO:root:[44,   600] training loss: 0.03310451
INFO:root:[44,   650] training loss: 0.00139815
INFO:root:[44,   700] training loss: 0.00074414
INFO:root:[44,   750] training loss: 0.00050527
INFO:root:[44,   800] training loss: 0.00037289
INFO:root:[44,   850] training loss: 0.00031248
INFO:root:[44,   900] training loss: 0.04764306
INFO:root:[44,   950] training loss: 0.02425864
INFO:root:[44,  1000] training loss: 0.00166098
INFO:root:[44,  1050] training loss: 0.00081667
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.3548    0.1507    0.2115        73
   Metaphase     0.2699    0.9990    0.4249      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2707      3872
   macro avg     0.3750    0.3785    0.3290      3872
weighted avg     0.0800    0.2707    0.1186      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.03956094
INFO:root:[45,   100] training loss: 0.02157074
INFO:root:[45,   150] training loss: 0.02085846
INFO:root:[45,   200] training loss: 0.02176906
INFO:root:[45,   250] training loss: 0.01963249
INFO:root:[45,   300] training loss: 0.02103349
INFO:root:[45,   350] training loss: 0.01675420
INFO:root:[45,   400] training loss: 0.00062861
INFO:root:[45,   450] training loss: 0.00025595
INFO:root:[45,   500] training loss: 0.00502629
INFO:root:[45,   550] training loss: 0.01108191
INFO:root:[45,   600] training loss: 0.03234632
INFO:root:[45,   650] training loss: 0.00109063
INFO:root:[45,   700] training loss: 0.00058586
INFO:root:[45,   750] training loss: 0.00044605
INFO:root:[45,   800] training loss: 0.00031076
INFO:root:[45,   850] training loss: 0.00027598
INFO:root:[45,   900] training loss: 0.03967948
INFO:root:[45,   950] training loss: 0.02012591
INFO:root:[45,  1000] training loss: 0.00122608
INFO:root:[45,  1050] training loss: 0.00068853
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2500    0.6250    0.3571         8
          G2     0.2891    0.5068    0.3682        73
   Metaphase     0.2770    0.9961    0.4334      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2776      3872
   macro avg     0.2237    0.4469    0.2880      3872
weighted avg     0.0805    0.2776    0.1241      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.03625855
INFO:root:[46,   100] training loss: 0.01830702
INFO:root:[46,   150] training loss: 0.02055610
INFO:root:[46,   200] training loss: 0.01761327
INFO:root:[46,   250] training loss: 0.01584328
INFO:root:[46,   300] training loss: 0.01786885
INFO:root:[46,   350] training loss: 0.01607839
INFO:root:[46,   400] training loss: 0.00077009
INFO:root:[46,   450] training loss: 0.00025684
INFO:root:[46,   500] training loss: 0.00452181
INFO:root:[46,   550] training loss: 0.00985695
INFO:root:[46,   600] training loss: 0.03141448
INFO:root:[46,   650] training loss: 0.00121963
INFO:root:[46,   700] training loss: 0.00060933
INFO:root:[46,   750] training loss: 0.00039750
INFO:root:[46,   800] training loss: 0.00033126
INFO:root:[46,   850] training loss: 0.00024277
INFO:root:[46,   900] training loss: 0.03667539
INFO:root:[46,   950] training loss: 0.02238826
INFO:root:[46,  1000] training loss: 0.00128335
INFO:root:[46,  1050] training loss: 0.00071261
INFO:root:              precision    recall  f1-score   support

          G1     0.1667    0.5000    0.2500         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2632    0.6250    0.3704         8
          G2     0.5854    0.3288    0.4211        73
   Metaphase     0.2714    0.9990    0.4269      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2745      3872
   macro avg     0.1838    0.3504    0.2098      3872
weighted avg     0.0841    0.2745    0.1228      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.03687697
INFO:root:[47,   100] training loss: 0.01928858
INFO:root:[47,   150] training loss: 0.01851390
INFO:root:[47,   200] training loss: 0.01567212
INFO:root:[47,   250] training loss: 0.01724161
INFO:root:[47,   300] training loss: 0.01765780
INFO:root:[47,   350] training loss: 0.01409670
INFO:root:[47,   400] training loss: 0.00043871
INFO:root:[47,   450] training loss: 0.00017454
INFO:root:[47,   500] training loss: 0.00427490
INFO:root:[47,   550] training loss: 0.00874409
INFO:root:[47,   600] training loss: 0.03112072
INFO:root:[47,   650] training loss: 0.00157925
INFO:root:[47,   700] training loss: 0.00077704
INFO:root:[47,   750] training loss: 0.00050757
INFO:root:[47,   800] training loss: 0.00041106
INFO:root:[47,   850] training loss: 0.00029822
INFO:root:[47,   900] training loss: 0.03774322
INFO:root:[47,   950] training loss: 0.02218422
INFO:root:[47,  1000] training loss: 0.00137202
INFO:root:[47,  1050] training loss: 0.00071856
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2632    0.6250    0.3704         8
          G2     0.3269    0.4658    0.3842        73
   Metaphase     0.2756    0.9981    0.4320      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2774      3872
   macro avg     0.2308    0.4413    0.2920      3872
weighted avg     0.0809    0.2774    0.1240      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.03721873
INFO:root:[48,   100] training loss: 0.01748137
INFO:root:[48,   150] training loss: 0.01934534
INFO:root:[48,   200] training loss: 0.01528611
INFO:root:[48,   250] training loss: 0.01548645
INFO:root:[48,   300] training loss: 0.01595229
INFO:root:[48,   350] training loss: 0.01433280
INFO:root:[48,   400] training loss: 0.00025958
INFO:root:[48,   450] training loss: 0.00019643
INFO:root:[48,   500] training loss: 0.00425691
INFO:root:[48,   550] training loss: 0.00831717
INFO:root:[48,   600] training loss: 0.03054940
INFO:root:[48,   650] training loss: 0.00150461
INFO:root:[48,   700] training loss: 0.00070499
INFO:root:[48,   750] training loss: 0.00047879
INFO:root:[48,   800] training loss: 0.00031428
INFO:root:[48,   850] training loss: 0.00026670
INFO:root:[48,   900] training loss: 0.03468249
INFO:root:[48,   950] training loss: 0.02250985
INFO:root:[48,  1000] training loss: 0.00138593
INFO:root:[48,  1050] training loss: 0.00065640
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.3125    0.6250    0.4167         8
          G2     0.4615    0.3288    0.3840        73
   Metaphase     0.2712    0.9971    0.4265      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2745      3872
   macro avg     0.2922    0.4216    0.3182      3872
weighted avg     0.0826    0.2745    0.1228      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.03683301
INFO:root:[49,   100] training loss: 0.02072857
INFO:root:[49,   150] training loss: 0.01784327
INFO:root:[49,   200] training loss: 0.01570869
INFO:root:[49,   250] training loss: 0.01541673
INFO:root:[49,   300] training loss: 0.01738418
INFO:root:[49,   350] training loss: 0.01377006
INFO:root:[49,   400] training loss: 0.00038538
INFO:root:[49,   450] training loss: 0.00015348
INFO:root:[49,   500] training loss: 0.00431862
INFO:root:[49,   550] training loss: 0.00875851
INFO:root:[49,   600] training loss: 0.02916940
INFO:root:[49,   650] training loss: 0.00146707
INFO:root:[49,   700] training loss: 0.00066971
INFO:root:[49,   750] training loss: 0.00046040
INFO:root:[49,   800] training loss: 0.00032313
INFO:root:[49,   850] training loss: 0.00024304
INFO:root:[49,   900] training loss: 0.03487608
INFO:root:[49,   950] training loss: 0.02218310
INFO:root:[49,  1000] training loss: 0.00118092
INFO:root:[49,  1050] training loss: 0.00063692
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.3125    0.6250    0.4167         8
          G2     0.3306    0.5479    0.4124        73
   Metaphase     0.2755    0.9942    0.4314      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2779      3872
   macro avg     0.2741    0.4524    0.3229      3872
weighted avg     0.0812    0.2779    0.1246      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.03346501
INFO:root:[50,   100] training loss: 0.01704611
INFO:root:[50,   150] training loss: 0.01810921
INFO:root:[50,   200] training loss: 0.01632848
INFO:root:[50,   250] training loss: 0.01684590
INFO:root:[50,   300] training loss: 0.01661474
INFO:root:[50,   350] training loss: 0.01430991
INFO:root:[50,   400] training loss: 0.00047452
INFO:root:[50,   450] training loss: 0.00014653
INFO:root:[50,   500] training loss: 0.00406962
INFO:root:[50,   550] training loss: 0.00729005
INFO:root:[50,   600] training loss: 0.02783825
INFO:root:[50,   650] training loss: 0.00180229
INFO:root:[50,   700] training loss: 0.00086442
INFO:root:[50,   750] training loss: 0.00056893
INFO:root:[50,   800] training loss: 0.00036657
INFO:root:[50,   850] training loss: 0.00033440
INFO:root:[50,   900] training loss: 0.03034979
INFO:root:[50,   950] training loss: 0.02245838
INFO:root:[50,  1000] training loss: 0.00124154
INFO:root:[50,  1050] training loss: 0.00056372
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.3750    0.7500    0.5000         8
          G2     0.3077    0.5479    0.3941        73
   Metaphase     0.2750    0.9894    0.4304      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2771      3872
   macro avg     0.3154    0.5410    0.3831      3872
weighted avg     0.0809    0.2771    0.1243      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch50
INFO:root:[51,    50] training loss: 0.03253770
INFO:root:[51,   100] training loss: 0.01687402
INFO:root:[51,   150] training loss: 0.01685777
INFO:root:[51,   200] training loss: 0.01568995
INFO:root:[51,   250] training loss: 0.01598440
INFO:root:[51,   300] training loss: 0.01645173
INFO:root:[51,   350] training loss: 0.01553433
INFO:root:[51,   400] training loss: 0.00033215
INFO:root:[51,   450] training loss: 0.00016877
INFO:root:[51,   500] training loss: 0.00438804
INFO:root:[51,   550] training loss: 0.00867183
INFO:root:[51,   600] training loss: 0.02781035
INFO:root:[51,   650] training loss: 0.00163086
INFO:root:[51,   700] training loss: 0.00062876
INFO:root:[51,   750] training loss: 0.00033489
INFO:root:[51,   800] training loss: 0.00022805
INFO:root:[51,   850] training loss: 0.00013857
INFO:root:[51,   900] training loss: 0.03313914
INFO:root:[51,   950] training loss: 0.02011985
INFO:root:[51,  1000] training loss: 0.00112720
INFO:root:[51,  1050] training loss: 0.00057809
INFO:root:              precision    recall  f1-score   support

          G1     1.0000    0.5000    0.6667         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.3846    0.6250    0.4762         8
          G2     0.2238    0.6438    0.3322        73
   Metaphase     0.2788    0.9826    0.4344      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2769      3872
   macro avg     0.3767    0.5359    0.3952      3872
weighted avg     0.0806    0.2769    0.1243      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch51
INFO:root:[52,    50] training loss: 0.03073749
INFO:root:[52,   100] training loss: 0.01704004
INFO:root:[52,   150] training loss: 0.01731956
INFO:root:[52,   200] training loss: 0.01493359
INFO:root:[52,   250] training loss: 0.01672033
INFO:root:[52,   300] training loss: 0.01584489
INFO:root:[52,   350] training loss: 0.01469674
INFO:root:[52,   400] training loss: 0.00027044
INFO:root:[52,   450] training loss: 0.00032700
INFO:root:[52,   500] training loss: 0.00421192
INFO:root:[52,   550] training loss: 0.00744770
INFO:root:[52,   600] training loss: 0.02620091
INFO:root:[52,   650] training loss: 0.00161599
INFO:root:[52,   700] training loss: 0.00076976
INFO:root:[52,   750] training loss: 0.00050969
INFO:root:[52,   800] training loss: 0.00038956
INFO:root:[52,   850] training loss: 0.00027588
INFO:root:[52,   900] training loss: 0.02974399
INFO:root:[52,   950] training loss: 0.02093953
INFO:root:[52,  1000] training loss: 0.00099438
INFO:root:[52,  1050] training loss: 0.00051553
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.6667    0.0019    0.0039      1032
           S     0.4444    0.5000    0.4706         8
          G2     0.2249    0.6438    0.3333        73
   Metaphase     0.2807    0.9894    0.4373      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2789      3872
   macro avg     0.4095    0.5193    0.3717      3872
weighted avg     0.2586    0.2789    0.1260      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch52
INFO:root:[53,    50] training loss: 0.02986992
INFO:root:[53,   100] training loss: 0.01621725
INFO:root:[53,   150] training loss: 0.01577803
INFO:root:[53,   200] training loss: 0.01607500
INFO:root:[53,   250] training loss: 0.01493601
INFO:root:[53,   300] training loss: 0.01463644
INFO:root:[53,   350] training loss: 0.01411947
INFO:root:[53,   400] training loss: 0.00033588
INFO:root:[53,   450] training loss: 0.00012087
INFO:root:[53,   500] training loss: 0.00417153
INFO:root:[53,   550] training loss: 0.00648811
INFO:root:[53,   600] training loss: 0.02554124
INFO:root:[53,   650] training loss: 0.00157054
INFO:root:[53,   700] training loss: 0.00073479
INFO:root:[53,   750] training loss: 0.00054869
INFO:root:[53,   800] training loss: 0.00040848
INFO:root:[53,   850] training loss: 0.00034034
INFO:root:[53,   900] training loss: 0.02917982
INFO:root:[53,   950] training loss: 0.02123032
INFO:root:[53,  1000] training loss: 0.00095069
INFO:root:[53,  1050] training loss: 0.00048066
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.2500    0.5000    0.3333         8
          G2     0.2407    0.7123    0.3599        73
   Metaphase     0.2827    0.9932    0.4401      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2810      3872
   macro avg     0.3129    0.6008    0.3986      3872
weighted avg     0.0815    0.2810    0.1261      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch53
INFO:root:[54,    50] training loss: 0.02862498
INFO:root:[54,   100] training loss: 0.01497820
INFO:root:[54,   150] training loss: 0.01780782
INFO:root:[54,   200] training loss: 0.01752021
INFO:root:[54,   250] training loss: 0.01489135
INFO:root:[54,   300] training loss: 0.01617895
INFO:root:[54,   350] training loss: 0.01658511
INFO:root:[54,   400] training loss: 0.00035734
INFO:root:[54,   450] training loss: 0.00018541
INFO:root:[54,   500] training loss: 0.00366763
INFO:root:[54,   550] training loss: 0.00578442
INFO:root:[54,   600] training loss: 0.02381409
INFO:root:[54,   650] training loss: 0.00144279
INFO:root:[54,   700] training loss: 0.00070723
INFO:root:[54,   750] training loss: 0.00047722
INFO:root:[54,   800] training loss: 0.00033190
INFO:root:[54,   850] training loss: 0.00028717
INFO:root:[54,   900] training loss: 0.03036139
INFO:root:[54,   950] training loss: 0.02320477
INFO:root:[54,  1000] training loss: 0.00107904
INFO:root:[54,  1050] training loss: 0.00059979
INFO:root:              precision    recall  f1-score   support

          G1     0.0000    0.0000    0.0000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.0000    0.0000    0.0000      1032
           S     0.1562    0.6250    0.2500         8
          G2     0.4730    0.4795    0.4762        73
   Metaphase     0.2725    0.9913    0.4274      1034
    Prophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2751      3872
   macro avg     0.1288    0.2994    0.1648      3872
weighted avg     0.0820    0.2751    0.1236      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch54
INFO:root:[55,    50] training loss: 0.03584113
INFO:root:[55,   100] training loss: 0.01706012
INFO:root:[55,   150] training loss: 0.01710407
INFO:root:[55,   200] training loss: 0.01535054
INFO:root:[55,   250] training loss: 0.01568128
INFO:root:[55,   300] training loss: 0.01780794
INFO:root:[55,   350] training loss: 0.01415187
INFO:root:[55,   400] training loss: 0.00025278
INFO:root:[55,   450] training loss: 0.00013144
INFO:root:[55,   500] training loss: 0.00383853
INFO:root:[55,   550] training loss: 0.00526958
INFO:root:[55,   600] training loss: 0.02543233
INFO:root:[55,   650] training loss: 0.00152249
INFO:root:[55,   700] training loss: 0.00073033
INFO:root:[55,   750] training loss: 0.00054290
INFO:root:[55,   800] training loss: 0.00034233
INFO:root:[55,   850] training loss: 0.00029497
INFO:root:[55,   900] training loss: 0.02781052
INFO:root:[55,   950] training loss: 0.02173617
INFO:root:[55,  1000] training loss: 0.00093796
INFO:root:[55,  1050] training loss: 0.00049134
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0019    0.0039      1032
           S     0.3000    0.7500    0.4286         8
          G2     0.2033    0.6712    0.3121        73
   Metaphase     0.2817    0.9816    0.4378      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2779      3872
   macro avg     0.4336    0.5578    0.3628      3872
weighted avg     0.3471    0.2779    0.1256      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch55
INFO:root:[56,    50] training loss: 0.02817956
INFO:root:[56,   100] training loss: 0.01768755
INFO:root:[56,   150] training loss: 0.01619946
INFO:root:[56,   200] training loss: 0.01516257
INFO:root:[56,   250] training loss: 0.01505146
INFO:root:[56,   300] training loss: 0.01509439
INFO:root:[56,   350] training loss: 0.01739037
INFO:root:[56,   400] training loss: 0.00084087
INFO:root:[56,   450] training loss: 0.00016616
INFO:root:[56,   500] training loss: 0.00388894
INFO:root:[56,   550] training loss: 0.00482458
INFO:root:[56,   600] training loss: 0.02443211
INFO:root:[56,   650] training loss: 0.00164642
INFO:root:[56,   700] training loss: 0.00072818
INFO:root:[56,   750] training loss: 0.00056595
INFO:root:[56,   800] training loss: 0.00039075
INFO:root:[56,   850] training loss: 0.00030273
INFO:root:[56,   900] training loss: 0.02833517
INFO:root:[56,   950] training loss: 0.02106995
INFO:root:[56,  1000] training loss: 0.00080433
INFO:root:[56,  1050] training loss: 0.00037627
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0019    0.0039      1032
           S     0.1923    0.6250    0.2941         8
          G2     0.2463    0.6849    0.3623        73
   Metaphase     0.2803    0.9855    0.4365      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2789      3872
   macro avg     0.4241    0.5425    0.3506      3872
weighted avg     0.3473    0.2789    0.1260      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch56
INFO:root:[57,    50] training loss: 0.03044240
INFO:root:[57,   100] training loss: 0.01741295
INFO:root:[57,   150] training loss: 0.01603364
INFO:root:[57,   200] training loss: 0.01484989
INFO:root:[57,   250] training loss: 0.01411486
INFO:root:[57,   300] training loss: 0.01498083
INFO:root:[57,   350] training loss: 0.01338868
INFO:root:[57,   400] training loss: 0.00023853
INFO:root:[57,   450] training loss: 0.00012604
INFO:root:[57,   500] training loss: 0.00340946
INFO:root:[57,   550] training loss: 0.00370383
INFO:root:[57,   600] training loss: 0.02259886
INFO:root:[57,   650] training loss: 0.00141949
INFO:root:[57,   700] training loss: 0.00074672
INFO:root:[57,   750] training loss: 0.00057026
INFO:root:[57,   800] training loss: 0.00039254
INFO:root:[57,   850] training loss: 0.00034590
INFO:root:[57,   900] training loss: 0.02892721
INFO:root:[57,   950] training loss: 0.02017862
INFO:root:[57,  1000] training loss: 0.00072746
INFO:root:[57,  1050] training loss: 0.00034190
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0078    0.0154      1032
           S     0.3333    0.6250    0.4348         8
          G2     0.2722    0.5890    0.3723        73
   Metaphase     0.2757    0.9826    0.4306      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2779      3872
   macro avg     0.4473    0.5292    0.3729      3872
weighted avg     0.3468    0.2779    0.1279      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch57
INFO:root:[58,    50] training loss: 0.03194449
INFO:root:[58,   100] training loss: 0.01627459
INFO:root:[58,   150] training loss: 0.01790658
INFO:root:[58,   200] training loss: 0.01686936
INFO:root:[58,   250] training loss: 0.01548333
INFO:root:[58,   300] training loss: 0.01573929
INFO:root:[58,   350] training loss: 0.01324377
INFO:root:[58,   400] training loss: 0.00032037
INFO:root:[58,   450] training loss: 0.00016730
INFO:root:[58,   500] training loss: 0.00332075
INFO:root:[58,   550] training loss: 0.00353203
INFO:root:[58,   600] training loss: 0.02127452
INFO:root:[58,   650] training loss: 0.00142338
INFO:root:[58,   700] training loss: 0.00079689
INFO:root:[58,   750] training loss: 0.00062381
INFO:root:[58,   800] training loss: 0.00043129
INFO:root:[58,   850] training loss: 0.00030904
INFO:root:[58,   900] training loss: 0.02763812
INFO:root:[58,   950] training loss: 0.01952330
INFO:root:[58,  1000] training loss: 0.00063826
INFO:root:[58,  1050] training loss: 0.00032436
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0019    0.0039      1032
           S     0.1429    0.6250    0.2326         8
          G2     0.1694    0.6986    0.2727        73
   Metaphase     0.2804    0.9565    0.4337      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.2714      3872
   macro avg     0.3847    0.5403    0.3133      3872
weighted avg     0.3456    0.2714    0.1233      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch58
INFO:root:[59,    50] training loss: 0.02824230
INFO:root:[59,   100] training loss: 0.01615404
INFO:root:[59,   150] training loss: 0.01798893
INFO:root:[59,   200] training loss: 0.01485146
INFO:root:[59,   250] training loss: 0.01366111
INFO:root:[59,   300] training loss: 0.01493943
INFO:root:[59,   350] training loss: 0.01378492
INFO:root:[59,   400] training loss: 0.00036032
INFO:root:[59,   450] training loss: 0.00011138
INFO:root:[59,   500] training loss: 0.00311306
INFO:root:[59,   550] training loss: 0.00337214
INFO:root:[59,   600] training loss: 0.02023644
INFO:root:[59,   650] training loss: 0.00142030
INFO:root:[59,   700] training loss: 0.00079753
INFO:root:[59,   750] training loss: 0.00055872
INFO:root:[59,   800] training loss: 0.00037853
INFO:root:[59,   850] training loss: 0.00030187
INFO:root:[59,   900] training loss: 0.02727924
INFO:root:[59,   950] training loss: 0.01693300
INFO:root:[59,  1000] training loss: 0.00060958
INFO:root:[59,  1050] training loss: 0.00028868
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0126    0.0249      1032
           S     0.2941    0.6250    0.4000         8
          G2     0.1753    0.7397    0.2835        73
   Metaphase     0.2828    0.9652    0.4374      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2774      3872
   macro avg     0.4646    0.5489    0.3780      3872
weighted avg     0.3470    0.2774    0.1306      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch59
INFO:root:[60,    50] training loss: 0.02672008
INFO:root:[60,   100] training loss: 0.01561773
INFO:root:[60,   150] training loss: 0.01632774
INFO:root:[60,   200] training loss: 0.01489326
INFO:root:[60,   250] training loss: 0.01597183
INFO:root:[60,   300] training loss: 0.01571942
INFO:root:[60,   350] training loss: 0.01395762
INFO:root:[60,   400] training loss: 0.00023545
INFO:root:[60,   450] training loss: 0.00012000
INFO:root:[60,   500] training loss: 0.00305076
INFO:root:[60,   550] training loss: 0.00285310
INFO:root:[60,   600] training loss: 0.01793055
INFO:root:[60,   650] training loss: 0.00127320
INFO:root:[60,   700] training loss: 0.00067833
INFO:root:[60,   750] training loss: 0.00055890
INFO:root:[60,   800] training loss: 0.00038364
INFO:root:[60,   850] training loss: 0.00028247
INFO:root:[60,   900] training loss: 0.02986511
INFO:root:[60,   950] training loss: 0.02046474
INFO:root:[60,  1000] training loss: 0.00063195
INFO:root:[60,  1050] training loss: 0.00027299
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     1.0000    0.0029    0.0058      1032
           S     0.4000    0.5000    0.4444         8
          G2     0.2222    0.7123    0.3388        73
   Metaphase     0.2809    0.9836    0.4370      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2789      3872
   macro avg     0.4862    0.5284    0.3894      3872
weighted avg     0.3476    0.2789    0.1266      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch60
INFO:root:[61,    50] training loss: 0.02751416
INFO:root:[61,   100] training loss: 0.01608234
INFO:root:[61,   150] training loss: 0.01603808
INFO:root:[61,   200] training loss: 0.01343649
INFO:root:[61,   250] training loss: 0.01390263
INFO:root:[61,   300] training loss: 0.01614661
INFO:root:[61,   350] training loss: 0.01250652
INFO:root:[61,   400] training loss: 0.00021085
INFO:root:[61,   450] training loss: 0.00011227
INFO:root:[61,   500] training loss: 0.00270489
INFO:root:[61,   550] training loss: 0.00282579
INFO:root:[61,   600] training loss: 0.01673875
INFO:root:[61,   650] training loss: 0.00132319
INFO:root:[61,   700] training loss: 0.00073707
INFO:root:[61,   750] training loss: 0.00060816
INFO:root:[61,   800] training loss: 0.00040336
INFO:root:[61,   850] training loss: 0.00029365
INFO:root:[61,   900] training loss: 0.02720222
INFO:root:[61,   950] training loss: 0.01630959
INFO:root:[61,  1000] training loss: 0.00056588
INFO:root:[61,  1050] training loss: 0.00027522
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.9487    0.0359    0.0691      1032
           S     0.1786    0.6250    0.2778         8
          G2     0.1771    0.6986    0.2825        73
   Metaphase     0.2855    0.9691    0.4410      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.2838      3872
   macro avg     0.3843    0.5469    0.3315      3872
weighted avg     0.3335    0.2838    0.1429      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch61
INFO:root:[62,    50] training loss: 0.02502998
INFO:root:[62,   100] training loss: 0.01484714
INFO:root:[62,   150] training loss: 0.01627131
INFO:root:[62,   200] training loss: 0.01319704
INFO:root:[62,   250] training loss: 0.01356953
INFO:root:[62,   300] training loss: 0.01449876
INFO:root:[62,   350] training loss: 0.01294042
INFO:root:[62,   400] training loss: 0.00033791
INFO:root:[62,   450] training loss: 0.00012849
INFO:root:[62,   500] training loss: 0.00285243
INFO:root:[62,   550] training loss: 0.00231408
INFO:root:[62,   600] training loss: 0.01413349
INFO:root:[62,   650] training loss: 0.00132415
INFO:root:[62,   700] training loss: 0.00070210
INFO:root:[62,   750] training loss: 0.00060236
INFO:root:[62,   800] training loss: 0.00037864
INFO:root:[62,   850] training loss: 0.00032437
INFO:root:[62,   900] training loss: 0.02404947
INFO:root:[62,   950] training loss: 0.01539647
INFO:root:[62,  1000] training loss: 0.00047121
INFO:root:[62,  1050] training loss: 0.00022639
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.8932    0.0891    0.1621      1032
           S     0.1622    0.7500    0.2667         8
          G2     0.1564    0.6575    0.2526        73
   Metaphase     0.2877    0.9507    0.4417      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.2929      3872
   macro avg     0.3952    0.6353    0.3819      3872
weighted avg     0.3190    0.2929    0.1675      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch62
INFO:root:[63,    50] training loss: 0.02375083
INFO:root:[63,   100] training loss: 0.01505101
INFO:root:[63,   150] training loss: 0.01681458
INFO:root:[63,   200] training loss: 0.02032697
INFO:root:[63,   250] training loss: 0.01459777
INFO:root:[63,   300] training loss: 0.01514802
INFO:root:[63,   350] training loss: 0.01248931
INFO:root:[63,   400] training loss: 0.00025942
INFO:root:[63,   450] training loss: 0.00023305
INFO:root:[63,   500] training loss: 0.00265298
INFO:root:[63,   550] training loss: 0.00192724
INFO:root:[63,   600] training loss: 0.01392301
INFO:root:[63,   650] training loss: 0.00108210
INFO:root:[63,   700] training loss: 0.00061922
INFO:root:[63,   750] training loss: 0.00062988
INFO:root:[63,   800] training loss: 0.00037735
INFO:root:[63,   850] training loss: 0.00028830
INFO:root:[63,   900] training loss: 0.02486735
INFO:root:[63,   950] training loss: 0.01592179
INFO:root:[63,  1000] training loss: 0.00051335
INFO:root:[63,  1050] training loss: 0.00025115
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.9297    0.1153    0.2052      1032
           S     0.1579    0.3750    0.2222         8
          G2     0.2119    0.6849    0.3236        73
   Metaphase     0.2895    0.9749    0.4464      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3058      3872
   macro avg     0.3841    0.5214    0.3496      3872
weighted avg     0.3301    0.3058    0.1813      3872

INFO:root:Accuracy of the network on the 3872 validation images: 30 %
INFO:root:epoch63
INFO:root:[64,    50] training loss: 0.02231715
INFO:root:[64,   100] training loss: 0.01489357
INFO:root:[64,   150] training loss: 0.01538237
INFO:root:[64,   200] training loss: 0.01578155
INFO:root:[64,   250] training loss: 0.01420544
INFO:root:[64,   300] training loss: 0.01499964
INFO:root:[64,   350] training loss: 0.01466415
INFO:root:[64,   400] training loss: 0.00037860
INFO:root:[64,   450] training loss: 0.00017545
INFO:root:[64,   500] training loss: 0.00294107
INFO:root:[64,   550] training loss: 0.00211555
INFO:root:[64,   600] training loss: 0.01213588
INFO:root:[64,   650] training loss: 0.00110469
INFO:root:[64,   700] training loss: 0.00065631
INFO:root:[64,   750] training loss: 0.00061669
INFO:root:[64,   800] training loss: 0.00040992
INFO:root:[64,   850] training loss: 0.00030224
INFO:root:[64,   900] training loss: 0.02419204
INFO:root:[64,   950] training loss: 0.01524617
INFO:root:[64,  1000] training loss: 0.00036078
INFO:root:[64,  1050] training loss: 0.00018439
INFO:root:              precision    recall  f1-score   support

          G1     0.3333    0.5000    0.4000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.8909    0.0475    0.0902      1032
           S     0.2500    0.3750    0.3000         8
          G2     0.2402    0.6712    0.3538        73
   Metaphase     0.2807    0.9758    0.4360      1034
    Prophase     0.5000    0.6667    0.5714         3

    accuracy                         0.2874      3872
   macro avg     0.3565    0.4623    0.3073      3872
weighted avg     0.3180    0.2874    0.1484      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch64
INFO:root:[65,    50] training loss: 0.02304461
INFO:root:[65,   100] training loss: 0.01351885
INFO:root:[65,   150] training loss: 0.01631539
INFO:root:[65,   200] training loss: 0.01425295
INFO:root:[65,   250] training loss: 0.01495786
INFO:root:[65,   300] training loss: 0.01470601
INFO:root:[65,   350] training loss: 0.01175519
INFO:root:[65,   400] training loss: 0.00016894
INFO:root:[65,   450] training loss: 0.00011250
INFO:root:[65,   500] training loss: 0.00270683
INFO:root:[65,   550] training loss: 0.00169565
INFO:root:[65,   600] training loss: 0.01078736
INFO:root:[65,   650] training loss: 0.00105301
INFO:root:[65,   700] training loss: 0.00062457
INFO:root:[65,   750] training loss: 0.00065731
INFO:root:[65,   800] training loss: 0.00040162
INFO:root:[65,   850] training loss: 0.00027652
INFO:root:[65,   900] training loss: 0.02124208
INFO:root:[65,   950] training loss: 0.01330731
INFO:root:[65,  1000] training loss: 0.00035787
INFO:root:[65,  1050] training loss: 0.00020382
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.9103    0.1376    0.2391      1032
           S     0.2500    0.3750    0.3000         8
          G2     0.2186    0.7397    0.3375        73
   Metaphase     0.2882    0.9613    0.4435      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3094      3872
   macro avg     0.4191    0.6019    0.4100      3872
weighted avg     0.3250    0.3094    0.1901      3872

INFO:root:Accuracy of the network on the 3872 validation images: 30 %
INFO:root:epoch65
INFO:root:[66,    50] training loss: 0.02219524
INFO:root:[66,   100] training loss: 0.01490920
INFO:root:[66,   150] training loss: 0.01442146
INFO:root:[66,   200] training loss: 0.01305943
INFO:root:[66,   250] training loss: 0.01369731
INFO:root:[66,   300] training loss: 0.01483140
INFO:root:[66,   350] training loss: 0.01276369
INFO:root:[66,   400] training loss: 0.00017592
INFO:root:[66,   450] training loss: 0.00014018
INFO:root:[66,   500] training loss: 0.00240055
INFO:root:[66,   550] training loss: 0.00168507
INFO:root:[66,   600] training loss: 0.01002063
INFO:root:[66,   650] training loss: 0.00091414
INFO:root:[66,   700] training loss: 0.00055345
INFO:root:[66,   750] training loss: 0.00055933
INFO:root:[66,   800] training loss: 0.00038028
INFO:root:[66,   850] training loss: 0.00026745
INFO:root:[66,   900] training loss: 0.02206377
INFO:root:[66,   950] training loss: 0.01221439
INFO:root:[66,  1000] training loss: 0.00035711
INFO:root:[66,  1050] training loss: 0.00020823
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.8974    0.1017    0.1828      1032
           S     0.1429    0.3750    0.2069         8
          G2     0.2135    0.7808    0.3353        73
   Metaphase     0.2903    0.9710    0.4469      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3032      3872
   macro avg     0.4015    0.6041    0.3888      3872
weighted avg     0.3218    0.3032    0.1758      3872

INFO:root:Accuracy of the network on the 3872 validation images: 30 %
INFO:root:epoch66
INFO:root:[67,    50] training loss: 0.02236859
INFO:root:[67,   100] training loss: 0.01409164
INFO:root:[67,   150] training loss: 0.01410392
INFO:root:[67,   200] training loss: 0.01263433
INFO:root:[67,   250] training loss: 0.01361176
INFO:root:[67,   300] training loss: 0.01418260
INFO:root:[67,   350] training loss: 0.01394771
INFO:root:[67,   400] training loss: 0.00020678
INFO:root:[67,   450] training loss: 0.00009632
INFO:root:[67,   500] training loss: 0.00239889
INFO:root:[67,   550] training loss: 0.00157943
INFO:root:[67,   600] training loss: 0.00884474
INFO:root:[67,   650] training loss: 0.00082150
INFO:root:[67,   700] training loss: 0.00045433
INFO:root:[67,   750] training loss: 0.00057418
INFO:root:[67,   800] training loss: 0.00037274
INFO:root:[67,   850] training loss: 0.00025969
INFO:root:[67,   900] training loss: 0.02321633
INFO:root:[67,   950] training loss: 0.01040443
INFO:root:[67,  1000] training loss: 0.00034596
INFO:root:[67,  1050] training loss: 0.00016338
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.0000    0.0000    0.0000      1720
   Telophase     0.8815    0.1802    0.2993      1032
           S     0.1724    0.6250    0.2703         8
          G2     0.1910    0.6986    0.3000        73
   Metaphase     0.2955    0.9594    0.4518      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3200      3872
   macro avg     0.4010    0.6376    0.4102      3872
weighted avg     0.3186    0.3200    0.2076      3872

INFO:root:Accuracy of the network on the 3872 validation images: 31 %
INFO:root:epoch67
INFO:root:[68,    50] training loss: 0.01960589
INFO:root:[68,   100] training loss: 0.01541413
INFO:root:[68,   150] training loss: 0.01461415
INFO:root:[68,   200] training loss: 0.01604629
INFO:root:[68,   250] training loss: 0.01598475
INFO:root:[68,   300] training loss: 0.01579144
INFO:root:[68,   350] training loss: 0.01276169
INFO:root:[68,   400] training loss: 0.00016992
INFO:root:[68,   450] training loss: 0.00009603
INFO:root:[68,   500] training loss: 0.00251339
INFO:root:[68,   550] training loss: 0.00161132
INFO:root:[68,   600] training loss: 0.00902355
INFO:root:[68,   650] training loss: 0.00083722
INFO:root:[68,   700] training loss: 0.00043560
INFO:root:[68,   750] training loss: 0.00060835
INFO:root:[68,   800] training loss: 0.00038151
INFO:root:[68,   850] training loss: 0.00028589
INFO:root:[68,   900] training loss: 0.01937672
INFO:root:[68,   950] training loss: 0.01043290
INFO:root:[68,  1000] training loss: 0.00028733
INFO:root:[68,  1050] training loss: 0.00016007
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     1.0000    0.0012    0.0023      1720
   Telophase     0.8902    0.2277    0.3627      1032
           S     0.2500    0.3750    0.3000         8
          G2     0.2314    0.7671    0.3556        73
   Metaphase     0.2964    0.9584    0.4527      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3337      3872
   macro avg     0.5621    0.6185    0.4319      3872
weighted avg     0.7663    0.3337    0.2269      3872

INFO:root:Accuracy of the network on the 3872 validation images: 33 %
INFO:root:epoch68
INFO:root:[69,    50] training loss: 0.01899452
INFO:root:[69,   100] training loss: 0.01483540
INFO:root:[69,   150] training loss: 0.01518940
INFO:root:[69,   200] training loss: 0.01324018
INFO:root:[69,   250] training loss: 0.01325439
INFO:root:[69,   300] training loss: 0.01402587
INFO:root:[69,   350] training loss: 0.01231918
INFO:root:[69,   400] training loss: 0.00024590
INFO:root:[69,   450] training loss: 0.00008138
INFO:root:[69,   500] training loss: 0.00189429
INFO:root:[69,   550] training loss: 0.00125440
INFO:root:[69,   600] training loss: 0.00655578
INFO:root:[69,   650] training loss: 0.00071405
INFO:root:[69,   700] training loss: 0.00034953
INFO:root:[69,   750] training loss: 0.00067183
INFO:root:[69,   800] training loss: 0.00034894
INFO:root:[69,   850] training loss: 0.00025105
INFO:root:[69,   900] training loss: 0.02108644
INFO:root:[69,   950] training loss: 0.01056530
INFO:root:[69,  1000] training loss: 0.00026911
INFO:root:[69,  1050] training loss: 0.00014505
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     1.0000    0.0023    0.0046      1720
   Telophase     0.8520    0.2064    0.3323      1032
           S     0.2353    0.5000    0.3200         8
          G2     0.2042    0.7945    0.3249        73
   Metaphase     0.2942    0.9420    0.4483      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.3246      3872
   macro avg     0.5480    0.5636    0.3982      3872
weighted avg     0.7550    0.3246    0.2181      3872

INFO:root:Accuracy of the network on the 3872 validation images: 32 %
INFO:root:epoch69
INFO:root:[70,    50] training loss: 0.01849651
INFO:root:[70,   100] training loss: 0.01382067
INFO:root:[70,   150] training loss: 0.01302119
INFO:root:[70,   200] training loss: 0.01376538
INFO:root:[70,   250] training loss: 0.01328980
INFO:root:[70,   300] training loss: 0.01555304
INFO:root:[70,   350] training loss: 0.01544374
INFO:root:[70,   400] training loss: 0.00016238
INFO:root:[70,   450] training loss: 0.00011368
INFO:root:[70,   500] training loss: 0.00200226
INFO:root:[70,   550] training loss: 0.00127182
INFO:root:[70,   600] training loss: 0.00793601
INFO:root:[70,   650] training loss: 0.00069744
INFO:root:[70,   700] training loss: 0.00041923
INFO:root:[70,   750] training loss: 0.00050887
INFO:root:[70,   800] training loss: 0.00032934
INFO:root:[70,   850] training loss: 0.00023732
INFO:root:[70,   900] training loss: 0.01997862
INFO:root:[70,   950] training loss: 0.00951926
INFO:root:[70,  1000] training loss: 0.00040671
INFO:root:[70,  1050] training loss: 0.00013130
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     1.0000    0.0029    0.0058      1720
   Telophase     0.9091    0.1744    0.2927      1032
           S     0.3333    0.2500    0.2857         8
          G2     0.2107    0.8630    0.3387        73
   Metaphase     0.2981    0.9681    0.4558      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.3241      3872
   macro avg     0.5716    0.5369    0.3908      3872
weighted avg     0.7716    0.3241    0.2102      3872

INFO:root:Accuracy of the network on the 3872 validation images: 32 %
INFO:root:epoch70
INFO:root:[71,    50] training loss: 0.01844079
INFO:root:[71,   100] training loss: 0.01347910
INFO:root:[71,   150] training loss: 0.01373147
INFO:root:[71,   200] training loss: 0.01239278
INFO:root:[71,   250] training loss: 0.01235801
INFO:root:[71,   300] training loss: 0.01274215
INFO:root:[71,   350] training loss: 0.01249440
INFO:root:[71,   400] training loss: 0.00017829
INFO:root:[71,   450] training loss: 0.00008421
INFO:root:[71,   500] training loss: 0.00150322
INFO:root:[71,   550] training loss: 0.00089798
INFO:root:[71,   600] training loss: 0.00567117
INFO:root:[71,   650] training loss: 0.00074661
INFO:root:[71,   700] training loss: 0.00042662
INFO:root:[71,   750] training loss: 0.00063127
INFO:root:[71,   800] training loss: 0.00034514
INFO:root:[71,   850] training loss: 0.00022757
INFO:root:[71,   900] training loss: 0.02000879
INFO:root:[71,   950] training loss: 0.00848114
INFO:root:[71,  1000] training loss: 0.00025839
INFO:root:[71,  1050] training loss: 0.00012918
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     1.0000    0.0081    0.0161      1720
   Telophase     0.8595    0.2490    0.3862      1032
           S     0.3125    0.6250    0.4167         8
          G2     0.2013    0.8219    0.3235        73
   Metaphase     0.3018    0.9449    0.4575      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3404      3872
   macro avg     0.5631    0.6641    0.4500      3872
weighted avg     0.7592    0.3404    0.2402      3872

INFO:root:Accuracy of the network on the 3872 validation images: 34 %
INFO:root:epoch71
INFO:root:[72,    50] training loss: 0.01717322
INFO:root:[72,   100] training loss: 0.01358699
INFO:root:[72,   150] training loss: 0.01368710
INFO:root:[72,   200] training loss: 0.01290847
INFO:root:[72,   250] training loss: 0.01336498
INFO:root:[72,   300] training loss: 0.01386469
INFO:root:[72,   350] training loss: 0.01145038
INFO:root:[72,   400] training loss: 0.00017714
INFO:root:[72,   450] training loss: 0.00008587
INFO:root:[72,   500] training loss: 0.00127498
INFO:root:[72,   550] training loss: 0.00075296
INFO:root:[72,   600] training loss: 0.00502991
INFO:root:[72,   650] training loss: 0.00072215
INFO:root:[72,   700] training loss: 0.00035859
INFO:root:[72,   750] training loss: 0.00071963
INFO:root:[72,   800] training loss: 0.00034096
INFO:root:[72,   850] training loss: 0.00024170
INFO:root:[72,   900] training loss: 0.01728470
INFO:root:[72,   950] training loss: 0.00798758
INFO:root:[72,  1000] training loss: 0.00023321
INFO:root:[72,  1050] training loss: 0.00011918
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     1.0000    0.0012    0.0023      1720
   Telophase     0.8371    0.2539    0.3896      1032
           S     0.3000    0.3750    0.3333         8
          G2     0.2775    0.7945    0.4113        73
   Metaphase     0.2936    0.9458    0.4481      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3376      3872
   macro avg     0.5440    0.5529    0.4050      3872
weighted avg     0.7523    0.3376    0.2338      3872

INFO:root:Accuracy of the network on the 3872 validation images: 33 %
INFO:root:epoch72
INFO:root:[73,    50] training loss: 0.01884982
INFO:root:[73,   100] training loss: 0.01229090
INFO:root:[73,   150] training loss: 0.01326983
INFO:root:[73,   200] training loss: 0.01325150
INFO:root:[73,   250] training loss: 0.01248329
INFO:root:[73,   300] training loss: 0.01409959
INFO:root:[73,   350] training loss: 0.01324895
INFO:root:[73,   400] training loss: 0.00019335
INFO:root:[73,   450] training loss: 0.00010121
INFO:root:[73,   500] training loss: 0.00144801
INFO:root:[73,   550] training loss: 0.00081256
INFO:root:[73,   600] training loss: 0.00475766
INFO:root:[73,   650] training loss: 0.00063041
INFO:root:[73,   700] training loss: 0.00041070
INFO:root:[73,   750] training loss: 0.00062661
INFO:root:[73,   800] training loss: 0.00033174
INFO:root:[73,   850] training loss: 0.00022411
INFO:root:[73,   900] training loss: 0.01889079
INFO:root:[73,   950] training loss: 0.00723964
INFO:root:[73,  1000] training loss: 0.00025381
INFO:root:[73,  1050] training loss: 0.00010434
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     1.0000    0.0157    0.0309      1720
   Telophase     0.8647    0.3469    0.4952      1032
           S     0.3333    0.7500    0.4615         8
          G2     0.2197    0.7945    0.3442        73
   Metaphase     0.3090    0.9391    0.4650      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.3680      3872
   macro avg     0.5919    0.6923    0.4934      3872
weighted avg     0.7630    0.3680    0.2784      3872

INFO:root:Accuracy of the network on the 3872 validation images: 36 %
INFO:root:epoch73
INFO:root:[74,    50] training loss: 0.01655425
INFO:root:[74,   100] training loss: 0.01219701
INFO:root:[74,   150] training loss: 0.01470384
INFO:root:[74,   200] training loss: 0.01410308
INFO:root:[74,   250] training loss: 0.01477913
INFO:root:[74,   300] training loss: 0.01524501
INFO:root:[74,   350] training loss: 0.01356179
INFO:root:[74,   400] training loss: 0.00033569
INFO:root:[74,   450] training loss: 0.00010134
INFO:root:[74,   500] training loss: 0.00110004
INFO:root:[74,   550] training loss: 0.00065869
INFO:root:[74,   600] training loss: 0.00438584
INFO:root:[74,   650] training loss: 0.00062090
INFO:root:[74,   700] training loss: 0.00033889
INFO:root:[74,   750] training loss: 0.00063878
INFO:root:[74,   800] training loss: 0.00033007
INFO:root:[74,   850] training loss: 0.00020143
INFO:root:[74,   900] training loss: 0.01713149
INFO:root:[74,   950] training loss: 0.00823376
INFO:root:[74,  1000] training loss: 0.00021214
INFO:root:[74,  1050] training loss: 0.00008914
INFO:root:              precision    recall  f1-score   support

          G1     0.4000    1.0000    0.5714         2
    Anaphase     0.9875    0.0459    0.0878      1720
   Telophase     0.8246    0.3828    0.5228      1032
           S     0.1667    0.2500    0.2000         8
          G2     0.2828    0.7671    0.4133        73
   Metaphase     0.3092    0.9255    0.4636      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.3858      3872
   macro avg     0.5673    0.6245    0.4656      3872
weighted avg     0.7477    0.3858    0.3114      3872

INFO:root:Accuracy of the network on the 3872 validation images: 38 %
INFO:root:epoch74
INFO:root:[75,    50] training loss: 0.01586961
INFO:root:[75,   100] training loss: 0.01277827
INFO:root:[75,   150] training loss: 0.01404337
INFO:root:[75,   200] training loss: 0.01237114
INFO:root:[75,   250] training loss: 0.01360312
INFO:root:[75,   300] training loss: 0.01310412
INFO:root:[75,   350] training loss: 0.01223255
INFO:root:[75,   400] training loss: 0.00009893
INFO:root:[75,   450] training loss: 0.00009335
INFO:root:[75,   500] training loss: 0.00105320
INFO:root:[75,   550] training loss: 0.00068631
INFO:root:[75,   600] training loss: 0.00390503
INFO:root:[75,   650] training loss: 0.00056961
INFO:root:[75,   700] training loss: 0.00033848
INFO:root:[75,   750] training loss: 0.00069583
INFO:root:[75,   800] training loss: 0.00033068
INFO:root:[75,   850] training loss: 0.00021303
INFO:root:[75,   900] training loss: 0.01682983
INFO:root:[75,   950] training loss: 0.00641343
INFO:root:[75,  1000] training loss: 0.00025977
INFO:root:[75,  1050] training loss: 0.00010741
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
    Anaphase     0.9861    0.0413    0.0792      1720
   Telophase     0.8333    0.4506    0.5849      1032
           S     0.1818    0.2500    0.2105         8
          G2     0.1892    0.8630    0.3103        73
   Metaphase     0.3221    0.9004    0.4745      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.3970      3872
   macro avg     0.5375    0.6436    0.4548      3872
weighted avg     0.7510    0.3970    0.3251      3872

INFO:root:Accuracy of the network on the 3872 validation images: 39 %
INFO:root:epoch75
INFO:root:[76,    50] training loss: 0.01486320
INFO:root:[76,   100] training loss: 0.01221005
INFO:root:[76,   150] training loss: 0.01473348
INFO:root:[76,   200] training loss: 0.01449780
INFO:root:[76,   250] training loss: 0.01233770
INFO:root:[76,   300] training loss: 0.01458563
INFO:root:[76,   350] training loss: 0.01187789
INFO:root:[76,   400] training loss: 0.00009781
INFO:root:[76,   450] training loss: 0.00007676
INFO:root:[76,   500] training loss: 0.00096777
INFO:root:[76,   550] training loss: 0.00070183
INFO:root:[76,   600] training loss: 0.00349930
INFO:root:[76,   650] training loss: 0.00046781
INFO:root:[76,   700] training loss: 0.00030321
INFO:root:[76,   750] training loss: 0.00073454
INFO:root:[76,   800] training loss: 0.00030062
INFO:root:[76,   850] training loss: 0.00020100
INFO:root:[76,   900] training loss: 0.01748519
INFO:root:[76,   950] training loss: 0.00636256
INFO:root:[76,  1000] training loss: 0.00023808
INFO:root:[76,  1050] training loss: 0.00011005
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9750    0.0907    0.1660      1720
   Telophase     0.8339    0.5010    0.6259      1032
           S     0.2188    0.8750    0.3500         8
          G2     0.2179    0.7671    0.3394        73
   Metaphase     0.3332    0.9014    0.4866      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.4321      3872
   macro avg     0.6065    0.7336    0.5383      3872
weighted avg     0.7500    0.4321    0.3788      3872

INFO:root:Accuracy of the network on the 3872 validation images: 43 %
INFO:root:epoch76
INFO:root:[77,    50] training loss: 0.01458903
INFO:root:[77,   100] training loss: 0.01172464
INFO:root:[77,   150] training loss: 0.01177906
INFO:root:[77,   200] training loss: 0.01207887
INFO:root:[77,   250] training loss: 0.01282220
INFO:root:[77,   300] training loss: 0.01365204
INFO:root:[77,   350] training loss: 0.01068182
INFO:root:[77,   400] training loss: 0.00012534
INFO:root:[77,   450] training loss: 0.00008774
INFO:root:[77,   500] training loss: 0.00094376
INFO:root:[77,   550] training loss: 0.00059083
INFO:root:[77,   600] training loss: 0.00358054
INFO:root:[77,   650] training loss: 0.00054062
INFO:root:[77,   700] training loss: 0.00030988
INFO:root:[77,   750] training loss: 0.00070809
INFO:root:[77,   800] training loss: 0.00029356
INFO:root:[77,   850] training loss: 0.00021005
INFO:root:[77,   900] training loss: 0.01523586
INFO:root:[77,   950] training loss: 0.00556757
INFO:root:[77,  1000] training loss: 0.00029090
INFO:root:[77,  1050] training loss: 0.00009970
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9735    0.1070    0.1928      1720
   Telophase     0.8376    0.4147    0.5548      1032
           S     0.0000    0.0000    0.0000         8
          G2     0.1762    0.8904    0.2941        73
   Metaphase     0.3341    0.9014    0.4874      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.4168      3872
   macro avg     0.5697    0.6162    0.4756      3872
weighted avg     0.7493    0.4168    0.3704      3872

INFO:root:Accuracy of the network on the 3872 validation images: 41 %
INFO:root:epoch77
INFO:root:[78,    50] training loss: 0.01432305
INFO:root:[78,   100] training loss: 0.01352300
INFO:root:[78,   150] training loss: 0.01558547
INFO:root:[78,   200] training loss: 0.01168046
INFO:root:[78,   250] training loss: 0.01167891
INFO:root:[78,   300] training loss: 0.01171112
INFO:root:[78,   350] training loss: 0.01181068
INFO:root:[78,   400] training loss: 0.00011590
INFO:root:[78,   450] training loss: 0.00007747
INFO:root:[78,   500] training loss: 0.00059906
INFO:root:[78,   550] training loss: 0.00054446
INFO:root:[78,   600] training loss: 0.00291899
INFO:root:[78,   650] training loss: 0.00044924
INFO:root:[78,   700] training loss: 0.00023091
INFO:root:[78,   750] training loss: 0.00061834
INFO:root:[78,   800] training loss: 0.00027028
INFO:root:[78,   850] training loss: 0.00016436
INFO:root:[78,   900] training loss: 0.01588990
INFO:root:[78,   950] training loss: 0.00567771
INFO:root:[78,  1000] training loss: 0.00023021
INFO:root:[78,  1050] training loss: 0.00009402
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9790    0.1355    0.2380      1720
   Telophase     0.8330    0.4302    0.5674      1032
           S     0.2143    0.3750    0.2727         8
          G2     0.1958    0.8904    0.3210        73
   Metaphase     0.3405    0.9052    0.4948      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.4354      3872
   macro avg     0.6042    0.6766    0.5277      3872
weighted avg     0.7531    0.4354    0.3969      3872

INFO:root:Accuracy of the network on the 3872 validation images: 43 %
INFO:root:epoch78
INFO:root:[79,    50] training loss: 0.01290467
INFO:root:[79,   100] training loss: 0.01226718
INFO:root:[79,   150] training loss: 0.01213890
INFO:root:[79,   200] training loss: 0.01220513
INFO:root:[79,   250] training loss: 0.01220670
INFO:root:[79,   300] training loss: 0.01230427
INFO:root:[79,   350] training loss: 0.01054480
INFO:root:[79,   400] training loss: 0.00013522
INFO:root:[79,   450] training loss: 0.00005175
INFO:root:[79,   500] training loss: 0.00060717
INFO:root:[79,   550] training loss: 0.00048426
INFO:root:[79,   600] training loss: 0.00287491
INFO:root:[79,   650] training loss: 0.00043734
INFO:root:[79,   700] training loss: 0.00025981
INFO:root:[79,   750] training loss: 0.00069116
INFO:root:[79,   800] training loss: 0.00023776
INFO:root:[79,   850] training loss: 0.00014770
INFO:root:[79,   900] training loss: 0.01488315
INFO:root:[79,   950] training loss: 0.00649385
INFO:root:[79,  1000] training loss: 0.00029482
INFO:root:[79,  1050] training loss: 0.00008913
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9577    0.2767    0.4294      1720
   Telophase     0.8630    0.5310    0.6575      1032
           S     0.1613    0.6250    0.2564         8
          G2     0.2948    0.6986    0.4146        73
   Metaphase     0.3696    0.9043    0.5247      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.5217      3872
   macro avg     0.6162    0.7194    0.5832      3872
weighted avg     0.7612    0.5217    0.5156      3872

INFO:root:Accuracy of the network on the 3872 validation images: 52 %
INFO:root:epoch79
INFO:root:[80,    50] training loss: 0.01292302
INFO:root:[80,   100] training loss: 0.01289899
INFO:root:[80,   150] training loss: 0.01257053
INFO:root:[80,   200] training loss: 0.01483894
INFO:root:[80,   250] training loss: 0.01308333
INFO:root:[80,   300] training loss: 0.01390231
INFO:root:[80,   350] training loss: 0.01153372
INFO:root:[80,   400] training loss: 0.00006217
INFO:root:[80,   450] training loss: 0.00006105
INFO:root:[80,   500] training loss: 0.00059335
INFO:root:[80,   550] training loss: 0.00048048
INFO:root:[80,   600] training loss: 0.00280045
INFO:root:[80,   650] training loss: 0.00044450
INFO:root:[80,   700] training loss: 0.00025341
INFO:root:[80,   750] training loss: 0.00062321
INFO:root:[80,   800] training loss: 0.00026090
INFO:root:[80,   850] training loss: 0.00015794
INFO:root:[80,   900] training loss: 0.01464823
INFO:root:[80,   950] training loss: 0.00442602
INFO:root:[80,  1000] training loss: 0.00026313
INFO:root:[80,  1050] training loss: 0.00010237
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.9418    0.3483    0.5085      1720
   Telophase     0.8464    0.4806    0.6131      1032
           S     0.2222    0.2500    0.2353         8
          G2     0.1796    0.9178    0.3004        73
   Metaphase     0.3921    0.8578    0.5382      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.5307      3872
   macro avg     0.5475    0.6221    0.5075      3872
weighted avg     0.7534    0.5307    0.5401      3872

INFO:root:Accuracy of the network on the 3872 validation images: 53 %
INFO:root:epoch80
INFO:root:[81,    50] training loss: 0.01230100
INFO:root:[81,   100] training loss: 0.01098774
INFO:root:[81,   150] training loss: 0.01195465
INFO:root:[81,   200] training loss: 0.01132412
INFO:root:[81,   250] training loss: 0.01310759
INFO:root:[81,   300] training loss: 0.01320089
INFO:root:[81,   350] training loss: 0.01047727
INFO:root:[81,   400] training loss: 0.00005961
INFO:root:[81,   450] training loss: 0.00005746
INFO:root:[81,   500] training loss: 0.00043260
INFO:root:[81,   550] training loss: 0.00048960
INFO:root:[81,   600] training loss: 0.00239962
INFO:root:[81,   650] training loss: 0.00042503
INFO:root:[81,   700] training loss: 0.00025693
INFO:root:[81,   750] training loss: 0.00064666
INFO:root:[81,   800] training loss: 0.00026319
INFO:root:[81,   850] training loss: 0.00015216
INFO:root:[81,   900] training loss: 0.01392912
INFO:root:[81,   950] training loss: 0.00613190
INFO:root:[81,  1000] training loss: 0.00021885
INFO:root:[81,  1050] training loss: 0.00011078
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9517    0.3669    0.5296      1720
   Telophase     0.8706    0.5281    0.6574      1032
           S     0.4000    0.5000    0.4444         8
          G2     0.2611    0.8082    0.3946        73
   Metaphase     0.3956    0.8956    0.5487      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.5604      3872
   macro avg     0.6494    0.7284    0.6250      3872
weighted avg     0.7673    0.5604    0.5666      3872

INFO:root:Accuracy of the network on the 3872 validation images: 56 %
INFO:root:epoch81
INFO:root:[82,    50] training loss: 0.01295975
INFO:root:[82,   100] training loss: 0.01254624
INFO:root:[82,   150] training loss: 0.01649084
INFO:root:[82,   200] training loss: 0.01324896
INFO:root:[82,   250] training loss: 0.01213418
INFO:root:[82,   300] training loss: 0.01262619
INFO:root:[82,   350] training loss: 0.01037155
INFO:root:[82,   400] training loss: 0.00013937
INFO:root:[82,   450] training loss: 0.00008518
INFO:root:[82,   500] training loss: 0.00057007
INFO:root:[82,   550] training loss: 0.00037553
INFO:root:[82,   600] training loss: 0.00204664
INFO:root:[82,   650] training loss: 0.00032438
INFO:root:[82,   700] training loss: 0.00022971
INFO:root:[82,   750] training loss: 0.00060988
INFO:root:[82,   800] training loss: 0.00020433
INFO:root:[82,   850] training loss: 0.00012862
INFO:root:[82,   900] training loss: 0.01432987
INFO:root:[82,   950] training loss: 0.00438982
INFO:root:[82,  1000] training loss: 0.00026536
INFO:root:[82,  1050] training loss: 0.00008752
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.5000    0.5000         2
    Anaphase     0.8924    0.4436    0.5926      1720
   Telophase     0.8855    0.4196    0.5694      1032
           S     0.2727    0.3750    0.3158         8
          G2     0.2230    0.8219    0.3509        73
   Metaphase     0.4005    0.8685    0.5482      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.5581      3872
   macro avg     0.5606    0.6327    0.5334      3872
weighted avg     0.7450    0.5581    0.5696      3872

INFO:root:Accuracy of the network on the 3872 validation images: 55 %
INFO:root:epoch82
INFO:root:[83,    50] training loss: 0.01217987
INFO:root:[83,   100] training loss: 0.01163002
INFO:root:[83,   150] training loss: 0.01298832
INFO:root:[83,   200] training loss: 0.01250208
INFO:root:[83,   250] training loss: 0.01291263
INFO:root:[83,   300] training loss: 0.01233592
INFO:root:[83,   350] training loss: 0.01063345
INFO:root:[83,   400] training loss: 0.00004172
INFO:root:[83,   450] training loss: 0.00005048
INFO:root:[83,   500] training loss: 0.00031543
INFO:root:[83,   550] training loss: 0.00045038
INFO:root:[83,   600] training loss: 0.00192715
INFO:root:[83,   650] training loss: 0.00033518
INFO:root:[83,   700] training loss: 0.00019016
INFO:root:[83,   750] training loss: 0.00064921
INFO:root:[83,   800] training loss: 0.00022813
INFO:root:[83,   850] training loss: 0.00013935
INFO:root:[83,   900] training loss: 0.01348393
INFO:root:[83,   950] training loss: 0.00420856
INFO:root:[83,  1000] training loss: 0.00017348
INFO:root:[83,  1050] training loss: 0.00008610
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9130    0.4640    0.6153      1720
   Telophase     0.8585    0.5349    0.6591      1032
           S     0.1200    0.3750    0.1818         8
          G2     0.2523    0.7671    0.3797        73
   Metaphase     0.4184    0.8501    0.5608      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.5922      3872
   macro avg     0.5684    0.7130    0.5791      3872
weighted avg     0.7520    0.5922    0.6073      3872

INFO:root:Accuracy of the network on the 3872 validation images: 59 %
INFO:root:epoch83
INFO:root:[84,    50] training loss: 0.01203937
INFO:root:[84,   100] training loss: 0.01322501
INFO:root:[84,   150] training loss: 0.01208615
INFO:root:[84,   200] training loss: 0.01217650
INFO:root:[84,   250] training loss: 0.01104691
INFO:root:[84,   300] training loss: 0.01198179
INFO:root:[84,   350] training loss: 0.01091066
INFO:root:[84,   400] training loss: 0.00004949
INFO:root:[84,   450] training loss: 0.00004226
INFO:root:[84,   500] training loss: 0.00038706
INFO:root:[84,   550] training loss: 0.00044112
INFO:root:[84,   600] training loss: 0.00222349
INFO:root:[84,   650] training loss: 0.00037563
INFO:root:[84,   700] training loss: 0.00018684
INFO:root:[84,   750] training loss: 0.00066092
INFO:root:[84,   800] training loss: 0.00021778
INFO:root:[84,   850] training loss: 0.00013473
INFO:root:[84,   900] training loss: 0.01299453
INFO:root:[84,   950] training loss: 0.00381888
INFO:root:[84,  1000] training loss: 0.00020177
INFO:root:[84,  1050] training loss: 0.00008176
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
    Anaphase     0.9147    0.5547    0.6906      1720
   Telophase     0.8654    0.5107    0.6423      1032
           S     0.2381    0.6250    0.3448         8
          G2     0.2477    0.7534    0.3729        73
   Metaphase     0.4426    0.8433    0.5806      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6245      3872
   macro avg     0.6012    0.7553    0.6140      3872
weighted avg     0.7614    0.6245    0.6418      3872

INFO:root:Accuracy of the network on the 3872 validation images: 62 %
INFO:root:epoch84
INFO:root:[85,    50] training loss: 0.01240843
INFO:root:[85,   100] training loss: 0.01326773
INFO:root:[85,   150] training loss: 0.01378912
INFO:root:[85,   200] training loss: 0.01193603
INFO:root:[85,   250] training loss: 0.01210397
INFO:root:[85,   300] training loss: 0.01206734
INFO:root:[85,   350] training loss: 0.01104838
INFO:root:[85,   400] training loss: 0.00015934
INFO:root:[85,   450] training loss: 0.00006433
INFO:root:[85,   500] training loss: 0.00104883
INFO:root:[85,   550] training loss: 0.00037763
INFO:root:[85,   600] training loss: 0.00177832
INFO:root:[85,   650] training loss: 0.00028124
INFO:root:[85,   700] training loss: 0.00017184
INFO:root:[85,   750] training loss: 0.00067163
INFO:root:[85,   800] training loss: 0.00021069
INFO:root:[85,   850] training loss: 0.00014398
INFO:root:[85,   900] training loss: 0.01522758
INFO:root:[85,   950] training loss: 0.00457682
INFO:root:[85,  1000] training loss: 0.00023740
INFO:root:[85,  1050] training loss: 0.00010085
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9405    0.4506    0.6093      1720
   Telophase     0.8163    0.5339    0.6456      1032
           S     0.3125    0.6250    0.4167         8
          G2     0.2092    0.8767    0.3377        73
   Metaphase     0.4230    0.8366    0.5619      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.5850      3872
   macro avg     0.6240    0.7604    0.6244      3872
weighted avg     0.7540    0.5850    0.6012      3872

INFO:root:Accuracy of the network on the 3872 validation images: 58 %
INFO:root:epoch85
INFO:root:[86,    50] training loss: 0.01231343
INFO:root:[86,   100] training loss: 0.01094486
INFO:root:[86,   150] training loss: 0.01270624
INFO:root:[86,   200] training loss: 0.01196731
INFO:root:[86,   250] training loss: 0.01116083
INFO:root:[86,   300] training loss: 0.01168936
INFO:root:[86,   350] training loss: 0.01170919
INFO:root:[86,   400] training loss: 0.00019338
INFO:root:[86,   450] training loss: 0.00005265
INFO:root:[86,   500] training loss: 0.00041266
INFO:root:[86,   550] training loss: 0.00036305
INFO:root:[86,   600] training loss: 0.00181482
INFO:root:[86,   650] training loss: 0.00027883
INFO:root:[86,   700] training loss: 0.00017074
INFO:root:[86,   750] training loss: 0.00066609
INFO:root:[86,   800] training loss: 0.00019487
INFO:root:[86,   850] training loss: 0.00014348
INFO:root:[86,   900] training loss: 0.01449363
INFO:root:[86,   950] training loss: 0.00354502
INFO:root:[86,  1000] training loss: 0.00016471
INFO:root:[86,  1050] training loss: 0.00007850
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
    Anaphase     0.9006    0.5581    0.6892      1720
   Telophase     0.8313    0.5349    0.6509      1032
           S     0.1818    0.2500    0.2105         8
          G2     0.2542    0.8219    0.3883        73
   Metaphase     0.4438    0.8095    0.5733      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.6240      3872
   macro avg     0.5302    0.7106    0.5613      3872
weighted avg     0.7460    0.6240    0.6414      3872

INFO:root:Accuracy of the network on the 3872 validation images: 62 %
INFO:root:epoch86
INFO:root:[87,    50] training loss: 0.01100392
INFO:root:[87,   100] training loss: 0.01166556
INFO:root:[87,   150] training loss: 0.01261386
INFO:root:[87,   200] training loss: 0.01073236
INFO:root:[87,   250] training loss: 0.01304553
INFO:root:[87,   300] training loss: 0.01259057
INFO:root:[87,   350] training loss: 0.01077648
INFO:root:[87,   400] training loss: 0.00014104
INFO:root:[87,   450] training loss: 0.00006390
INFO:root:[87,   500] training loss: 0.00024562
INFO:root:[87,   550] training loss: 0.00038612
INFO:root:[87,   600] training loss: 0.00165866
INFO:root:[87,   650] training loss: 0.00027702
INFO:root:[87,   700] training loss: 0.00015544
INFO:root:[87,   750] training loss: 0.00067708
INFO:root:[87,   800] training loss: 0.00021110
INFO:root:[87,   850] training loss: 0.00013722
INFO:root:[87,   900] training loss: 0.01247994
INFO:root:[87,   950] training loss: 0.00338880
INFO:root:[87,  1000] training loss: 0.00023487
INFO:root:[87,  1050] training loss: 0.00009078
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8775    0.6831    0.7682      1720
   Telophase     0.8233    0.5194    0.6370      1032
           S     0.2308    0.3750    0.2857         8
          G2     0.2243    0.8356    0.3536        73
   Metaphase     0.4890    0.7524    0.5928      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6606      3872
   macro avg     0.6159    0.7379    0.6339      3872
weighted avg     0.7457    0.6606    0.6778      3872

INFO:root:Accuracy of the network on the 3872 validation images: 66 %
INFO:root:epoch87
INFO:root:[88,    50] training loss: 0.01117213
INFO:root:[88,   100] training loss: 0.01214466
INFO:root:[88,   150] training loss: 0.01120797
INFO:root:[88,   200] training loss: 0.01092968
INFO:root:[88,   250] training loss: 0.01132873
INFO:root:[88,   300] training loss: 0.01139079
INFO:root:[88,   350] training loss: 0.01026491
INFO:root:[88,   400] training loss: 0.00005846
INFO:root:[88,   450] training loss: 0.00007326
INFO:root:[88,   500] training loss: 0.00022729
INFO:root:[88,   550] training loss: 0.00035778
INFO:root:[88,   600] training loss: 0.00159727
INFO:root:[88,   650] training loss: 0.00027255
INFO:root:[88,   700] training loss: 0.00019968
INFO:root:[88,   750] training loss: 0.00065776
INFO:root:[88,   800] training loss: 0.00020109
INFO:root:[88,   850] training loss: 0.00011690
INFO:root:[88,   900] training loss: 0.01195435
INFO:root:[88,   950] training loss: 0.00339936
INFO:root:[88,  1000] training loss: 0.00031254
INFO:root:[88,  1050] training loss: 0.00007729
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8549    0.7744    0.8127      1720
   Telophase     0.8695    0.5165    0.6480      1032
           S     0.1818    0.2500    0.2105         8
          G2     0.2646    0.8082    0.3986        73
   Metaphase     0.5171    0.7302    0.6055      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6937      3872
   macro avg     0.5864    0.7256    0.6189      3872
weighted avg     0.7559    0.6937    0.7044      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch88
INFO:root:[89,    50] training loss: 0.01112140
INFO:root:[89,   100] training loss: 0.01481916
INFO:root:[89,   150] training loss: 0.01892072
INFO:root:[89,   200] training loss: 0.01359933
INFO:root:[89,   250] training loss: 0.01120056
INFO:root:[89,   300] training loss: 0.01154582
INFO:root:[89,   350] training loss: 0.01009271
INFO:root:[89,   400] training loss: 0.00009865
INFO:root:[89,   450] training loss: 0.00006181
INFO:root:[89,   500] training loss: 0.00050077
INFO:root:[89,   550] training loss: 0.00027960
INFO:root:[89,   600] training loss: 0.00149577
INFO:root:[89,   650] training loss: 0.00021458
INFO:root:[89,   700] training loss: 0.00014487
INFO:root:[89,   750] training loss: 0.00066491
INFO:root:[89,   800] training loss: 0.00019958
INFO:root:[89,   850] training loss: 0.00010131
INFO:root:[89,   900] training loss: 0.01275678
INFO:root:[89,   950] training loss: 0.00331650
INFO:root:[89,  1000] training loss: 0.00018989
INFO:root:[89,  1050] training loss: 0.00009169
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8560    0.7360    0.7915      1720
   Telophase     0.8611    0.6008    0.7078      1032
           S     0.3000    0.3750    0.3333         8
          G2     0.3029    0.7260    0.4274        73
   Metaphase     0.5098    0.7302    0.6004      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6978      3872
   macro avg     0.6066    0.7383    0.6454      3872
weighted avg     0.7531    0.6978    0.7104      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch89
INFO:root:[90,    50] training loss: 0.01115950
INFO:root:[90,   100] training loss: 0.01342747
INFO:root:[90,   150] training loss: 0.01249161
INFO:root:[90,   200] training loss: 0.01133124
INFO:root:[90,   250] training loss: 0.01106277
INFO:root:[90,   300] training loss: 0.01233116
INFO:root:[90,   350] training loss: 0.01024847
INFO:root:[90,   400] training loss: 0.00006400
INFO:root:[90,   450] training loss: 0.00009221
INFO:root:[90,   500] training loss: 0.00033407
INFO:root:[90,   550] training loss: 0.00027033
INFO:root:[90,   600] training loss: 0.00130770
INFO:root:[90,   650] training loss: 0.00021406
INFO:root:[90,   700] training loss: 0.00014552
INFO:root:[90,   750] training loss: 0.00067033
INFO:root:[90,   800] training loss: 0.00017323
INFO:root:[90,   850] training loss: 0.00011204
INFO:root:[90,   900] training loss: 0.01328962
INFO:root:[90,   950] training loss: 0.00299844
INFO:root:[90,  1000] training loss: 0.00019894
INFO:root:[90,  1050] training loss: 0.00007487
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8589    0.7506    0.8011      1720
   Telophase     0.8567    0.5504    0.6702      1032
           S     0.2667    0.5000    0.3478         8
          G2     0.2209    0.7808    0.3444        73
   Metaphase     0.5256    0.7253    0.6095      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6909      3872
   macro avg     0.6279    0.7582    0.6533      3872
weighted avg     0.7561    0.6909    0.7057      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch90
INFO:root:[91,    50] training loss: 0.01281844
INFO:root:[91,   100] training loss: 0.01432090
INFO:root:[91,   150] training loss: 0.01114108
INFO:root:[91,   200] training loss: 0.01177188
INFO:root:[91,   250] training loss: 0.01049513
INFO:root:[91,   300] training loss: 0.01171952
INFO:root:[91,   350] training loss: 0.00964499
INFO:root:[91,   400] training loss: 0.00004492
INFO:root:[91,   450] training loss: 0.00005593
INFO:root:[91,   500] training loss: 0.00025487
INFO:root:[91,   550] training loss: 0.00031841
INFO:root:[91,   600] training loss: 0.00151410
INFO:root:[91,   650] training loss: 0.00022207
INFO:root:[91,   700] training loss: 0.00011922
INFO:root:[91,   750] training loss: 0.00061411
INFO:root:[91,   800] training loss: 0.00017906
INFO:root:[91,   850] training loss: 0.00010939
INFO:root:[91,   900] training loss: 0.01080001
INFO:root:[91,   950] training loss: 0.00269658
INFO:root:[91,  1000] training loss: 0.00025326
INFO:root:[91,  1050] training loss: 0.00008468
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8214    0.8076    0.8144      1720
   Telophase     0.8312    0.5775    0.6815      1032
           S     0.2857    0.5000    0.3636         8
          G2     0.2759    0.6575    0.3887        73
   Metaphase     0.5225    0.6412    0.5758      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6986      3872
   macro avg     0.5933    0.7405    0.6402      3872
weighted avg     0.7327    0.6986    0.7063      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch91
INFO:root:[92,    50] training loss: 0.01087650
INFO:root:[92,   100] training loss: 0.01125117
INFO:root:[92,   150] training loss: 0.01085694
INFO:root:[92,   200] training loss: 0.01135383
INFO:root:[92,   250] training loss: 0.01051579
INFO:root:[92,   300] training loss: 0.01201945
INFO:root:[92,   350] training loss: 0.01042629
INFO:root:[92,   400] training loss: 0.00004564
INFO:root:[92,   450] training loss: 0.00004658
INFO:root:[92,   500] training loss: 0.00019779
INFO:root:[92,   550] training loss: 0.00036979
INFO:root:[92,   600] training loss: 0.00121854
INFO:root:[92,   650] training loss: 0.00017307
INFO:root:[92,   700] training loss: 0.00012868
INFO:root:[92,   750] training loss: 0.00063441
INFO:root:[92,   800] training loss: 0.00016940
INFO:root:[92,   850] training loss: 0.00010411
INFO:root:[92,   900] training loss: 0.01185678
INFO:root:[92,   950] training loss: 0.00318499
INFO:root:[92,  1000] training loss: 0.00022508
INFO:root:[92,  1050] training loss: 0.00008794
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8827    0.7087    0.7862      1720
   Telophase     0.8452    0.6192    0.7148      1032
           S     0.3333    0.2500    0.2857         8
          G2     0.2775    0.7945    0.4113        73
   Metaphase     0.5102    0.7466    0.6062      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6960      3872
   macro avg     0.6094    0.7313    0.6373      3872
weighted avg     0.7605    0.6960    0.7111      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch92
INFO:root:[93,    50] training loss: 0.01047252
INFO:root:[93,   100] training loss: 0.01066528
INFO:root:[93,   150] training loss: 0.01090612
INFO:root:[93,   200] training loss: 0.01108045
INFO:root:[93,   250] training loss: 0.01329293
INFO:root:[93,   300] training loss: 0.01125311
INFO:root:[93,   350] training loss: 0.00970109
INFO:root:[93,   400] training loss: 0.00003841
INFO:root:[93,   450] training loss: 0.00004129
INFO:root:[93,   500] training loss: 0.00026379
INFO:root:[93,   550] training loss: 0.00031006
INFO:root:[93,   600] training loss: 0.00117570
INFO:root:[93,   650] training loss: 0.00016646
INFO:root:[93,   700] training loss: 0.00012256
INFO:root:[93,   750] training loss: 0.00067871
INFO:root:[93,   800] training loss: 0.00015216
INFO:root:[93,   850] training loss: 0.00008288
INFO:root:[93,   900] training loss: 0.01095886
INFO:root:[93,   950] training loss: 0.00266940
INFO:root:[93,  1000] training loss: 0.00020835
INFO:root:[93,  1050] training loss: 0.00008075
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8445    0.7674    0.8041      1720
   Telophase     0.8067    0.6027    0.6900      1032
           S     0.5000    0.5000    0.5000         8
          G2     0.2705    0.7671    0.4000        73
   Metaphase     0.5141    0.6538    0.5756      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.6929      3872
   macro avg     0.6004    0.7559    0.6457      3872
weighted avg     0.7344    0.6929    0.7044      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch93
INFO:root:[94,    50] training loss: 0.01034260
INFO:root:[94,   100] training loss: 0.01337053
INFO:root:[94,   150] training loss: 0.01133548
INFO:root:[94,   200] training loss: 0.01127809
INFO:root:[94,   250] training loss: 0.01004899
INFO:root:[94,   300] training loss: 0.01123559
INFO:root:[94,   350] training loss: 0.00939420
INFO:root:[94,   400] training loss: 0.00008151
INFO:root:[94,   450] training loss: 0.00004907
INFO:root:[94,   500] training loss: 0.00014561
INFO:root:[94,   550] training loss: 0.00028633
INFO:root:[94,   600] training loss: 0.00105769
INFO:root:[94,   650] training loss: 0.00015934
INFO:root:[94,   700] training loss: 0.00011474
INFO:root:[94,   750] training loss: 0.00071455
INFO:root:[94,   800] training loss: 0.00014443
INFO:root:[94,   850] training loss: 0.00009131
INFO:root:[94,   900] training loss: 0.01215708
INFO:root:[94,   950] training loss: 0.00263616
INFO:root:[94,  1000] training loss: 0.00018956
INFO:root:[94,  1050] training loss: 0.00007750
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8546    0.7994    0.8261      1720
   Telophase     0.7947    0.5514    0.6510      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.2489    0.8082    0.3806        73
   Metaphase     0.5243    0.6567    0.5831      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6947      3872
   macro avg     0.6020    0.7415    0.6390      3872
weighted avg     0.7378    0.6947    0.7052      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch94
INFO:root:[95,    50] training loss: 0.01071331
INFO:root:[95,   100] training loss: 0.01031198
INFO:root:[95,   150] training loss: 0.01263189
INFO:root:[95,   200] training loss: 0.01364949
INFO:root:[95,   250] training loss: 0.01043485
INFO:root:[95,   300] training loss: 0.01087709
INFO:root:[95,   350] training loss: 0.01019146
INFO:root:[95,   400] training loss: 0.00004545
INFO:root:[95,   450] training loss: 0.00003932
INFO:root:[95,   500] training loss: 0.00026245
INFO:root:[95,   550] training loss: 0.00026252
INFO:root:[95,   600] training loss: 0.00111207
INFO:root:[95,   650] training loss: 0.00016467
INFO:root:[95,   700] training loss: 0.00011426
INFO:root:[95,   750] training loss: 0.00067152
INFO:root:[95,   800] training loss: 0.00012690
INFO:root:[95,   850] training loss: 0.00008500
INFO:root:[95,   900] training loss: 0.01125841
INFO:root:[95,   950] training loss: 0.00280281
INFO:root:[95,  1000] training loss: 0.00020219
INFO:root:[95,  1050] training loss: 0.00007272
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8806    0.7331    0.8001      1720
   Telophase     0.7561    0.6037    0.6713      1032
           S     0.2857    0.5000    0.3636         8
          G2     0.2196    0.7671    0.3415        73
   Metaphase     0.5097    0.6605    0.5754      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6798      3872
   macro avg     0.5812    0.7521    0.6299      3872
weighted avg     0.7345    0.6798    0.6963      3872

INFO:root:Accuracy of the network on the 3872 validation images: 67 %
INFO:root:epoch95
INFO:root:[96,    50] training loss: 0.01000728
INFO:root:[96,   100] training loss: 0.01049763
INFO:root:[96,   150] training loss: 0.01094213
INFO:root:[96,   200] training loss: 0.01031042
INFO:root:[96,   250] training loss: 0.01016414
INFO:root:[96,   300] training loss: 0.01115016
INFO:root:[96,   350] training loss: 0.01001679
INFO:root:[96,   400] training loss: 0.00006476
INFO:root:[96,   450] training loss: 0.00006606
INFO:root:[96,   500] training loss: 0.00023116
INFO:root:[96,   550] training loss: 0.00024753
INFO:root:[96,   600] training loss: 0.00101343
INFO:root:[96,   650] training loss: 0.00015230
INFO:root:[96,   700] training loss: 0.00009980
INFO:root:[96,   750] training loss: 0.00061357
INFO:root:[96,   800] training loss: 0.00014575
INFO:root:[96,   850] training loss: 0.00008518
INFO:root:[96,   900] training loss: 0.01088260
INFO:root:[96,   950] training loss: 0.00341589
INFO:root:[96,  1000] training loss: 0.00017355
INFO:root:[96,  1050] training loss: 0.00007974
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8808    0.7820    0.8285      1720
   Telophase     0.7605    0.6492    0.7005      1032
           S     0.1714    0.7500    0.2791         8
          G2     0.2200    0.6027    0.3223        73
   Metaphase     0.5516    0.6518    0.5975      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7087      3872
   macro avg     0.5716    0.7765    0.6264      3872
weighted avg     0.7467    0.7087    0.7220      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch96
INFO:root:[97,    50] training loss: 0.01147074
INFO:root:[97,   100] training loss: 0.01089339
INFO:root:[97,   150] training loss: 0.01134987
INFO:root:[97,   200] training loss: 0.01112970
INFO:root:[97,   250] training loss: 0.01227636
INFO:root:[97,   300] training loss: 0.01102616
INFO:root:[97,   350] training loss: 0.01214765
INFO:root:[97,   400] training loss: 0.00008297
INFO:root:[97,   450] training loss: 0.00011408
INFO:root:[97,   500] training loss: 0.00024948
INFO:root:[97,   550] training loss: 0.00027854
INFO:root:[97,   600] training loss: 0.00144255
INFO:root:[97,   650] training loss: 0.00015060
INFO:root:[97,   700] training loss: 0.00010259
INFO:root:[97,   750] training loss: 0.00060176
INFO:root:[97,   800] training loss: 0.00013999
INFO:root:[97,   850] training loss: 0.00009830
INFO:root:[97,   900] training loss: 0.01059339
INFO:root:[97,   950] training loss: 0.00277355
INFO:root:[97,  1000] training loss: 0.00017192
INFO:root:[97,  1050] training loss: 0.00007450
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8465    0.7953    0.8201      1720
   Telophase     0.8029    0.6550    0.7215      1032
           S     0.1739    0.5000    0.2581         8
          G2     0.2616    0.6164    0.3673        73
   Metaphase     0.5421    0.6354    0.5850      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7115      3872
   macro avg     0.5777    0.7432    0.6299      3872
weighted avg     0.7410    0.7115    0.7214      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch97
INFO:root:[98,    50] training loss: 0.01006272
INFO:root:[98,   100] training loss: 0.01189341
INFO:root:[98,   150] training loss: 0.01187797
INFO:root:[98,   200] training loss: 0.01067579
INFO:root:[98,   250] training loss: 0.01022848
INFO:root:[98,   300] training loss: 0.01016301
INFO:root:[98,   350] training loss: 0.00867368
INFO:root:[98,   400] training loss: 0.00003413
INFO:root:[98,   450] training loss: 0.00004059
INFO:root:[98,   500] training loss: 0.00014854
INFO:root:[98,   550] training loss: 0.00022039
INFO:root:[98,   600] training loss: 0.00083684
INFO:root:[98,   650] training loss: 0.00016434
INFO:root:[98,   700] training loss: 0.00009418
INFO:root:[98,   750] training loss: 0.00076241
INFO:root:[98,   800] training loss: 0.00014191
INFO:root:[98,   850] training loss: 0.00008404
INFO:root:[98,   900] training loss: 0.00952070
INFO:root:[98,   950] training loss: 0.00253965
INFO:root:[98,  1000] training loss: 0.00012785
INFO:root:[98,  1050] training loss: 0.00006111
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8710    0.7849    0.8257      1720
   Telophase     0.7594    0.6056    0.6739      1032
           S     0.4444    0.5000    0.4706         8
          G2     0.2169    0.8082    0.3420        73
   Metaphase     0.5450    0.6383    0.5880      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6981      3872
   macro avg     0.6076    0.7624    0.6510      3872
weighted avg     0.7408    0.6981    0.7119      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch98
INFO:root:[99,    50] training loss: 0.00959035
INFO:root:[99,   100] training loss: 0.00974113
INFO:root:[99,   150] training loss: 0.00957760
INFO:root:[99,   200] training loss: 0.01058512
INFO:root:[99,   250] training loss: 0.00969685
INFO:root:[99,   300] training loss: 0.01097088
INFO:root:[99,   350] training loss: 0.00974189
INFO:root:[99,   400] training loss: 0.00003141
INFO:root:[99,   450] training loss: 0.00003239
INFO:root:[99,   500] training loss: 0.00012290
INFO:root:[99,   550] training loss: 0.00026667
INFO:root:[99,   600] training loss: 0.00075909
INFO:root:[99,   650] training loss: 0.00013445
INFO:root:[99,   700] training loss: 0.00009573
INFO:root:[99,   750] training loss: 0.00069407
INFO:root:[99,   800] training loss: 0.00013850
INFO:root:[99,   850] training loss: 0.00008381
INFO:root:[99,   900] training loss: 0.00916021
INFO:root:[99,   950] training loss: 0.00198212
INFO:root:[99,  1000] training loss: 0.00012680
INFO:root:[99,  1050] training loss: 0.00005913
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8562    0.7756    0.8139      1720
   Telophase     0.7828    0.6424    0.7057      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.2850    0.7534    0.4135        73
   Metaphase     0.5350    0.6509    0.5873      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7058      3872
   macro avg     0.6013    0.7425    0.6472      3872
weighted avg     0.7388    0.7058    0.7161      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch99
INFO:root:[100,    50] training loss: 0.00948761
INFO:root:[100,   100] training loss: 0.00944169
INFO:root:[100,   150] training loss: 0.01044297
INFO:root:[100,   200] training loss: 0.01296061
INFO:root:[100,   250] training loss: 0.01080462
INFO:root:[100,   300] training loss: 0.01030534
INFO:root:[100,   350] training loss: 0.00857008
INFO:root:[100,   400] training loss: 0.00003122
INFO:root:[100,   450] training loss: 0.00016922
INFO:root:[100,   500] training loss: 0.00017815
INFO:root:[100,   550] training loss: 0.00023413
INFO:root:[100,   600] training loss: 0.00068730
INFO:root:[100,   650] training loss: 0.00013535
INFO:root:[100,   700] training loss: 0.00008928
INFO:root:[100,   750] training loss: 0.00068200
INFO:root:[100,   800] training loss: 0.00012959
INFO:root:[100,   850] training loss: 0.00008942
INFO:root:[100,   900] training loss: 0.01061503
INFO:root:[100,   950] training loss: 0.00209846
INFO:root:[100,  1000] training loss: 0.00012461
INFO:root:[100,  1050] training loss: 0.00005739
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8704    0.8041    0.8359      1720
   Telophase     0.7744    0.6221    0.6900      1032
           S     0.2857    0.5000    0.3636         8
          G2     0.2105    0.7671    0.3304        73
   Metaphase     0.5720    0.6451    0.6064      1034
    Prophase     0.6000    1.0000    0.7500         3

    accuracy                         0.7120      3872
   macro avg     0.5685    0.7626    0.6252      3872
weighted avg     0.7512    0.7120    0.7251      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch100
INFO:root:[101,    50] training loss: 0.00957932
INFO:root:[101,   100] training loss: 0.01199007
INFO:root:[101,   150] training loss: 0.01100165
INFO:root:[101,   200] training loss: 0.01018677
INFO:root:[101,   250] training loss: 0.00956175
INFO:root:[101,   300] training loss: 0.00974596
INFO:root:[101,   350] training loss: 0.00837881
INFO:root:[101,   400] training loss: 0.00003058
INFO:root:[101,   450] training loss: 0.00003203
INFO:root:[101,   500] training loss: 0.00015047
INFO:root:[101,   550] training loss: 0.00023317
INFO:root:[101,   600] training loss: 0.00076009
INFO:root:[101,   650] training loss: 0.00012437
INFO:root:[101,   700] training loss: 0.00008583
INFO:root:[101,   750] training loss: 0.00071765
INFO:root:[101,   800] training loss: 0.00012795
INFO:root:[101,   850] training loss: 0.00006974
INFO:root:[101,   900] training loss: 0.00929061
INFO:root:[101,   950] training loss: 0.00212398
INFO:root:[101,  1000] training loss: 0.00009892
INFO:root:[101,  1050] training loss: 0.00004531
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8647    0.8023    0.8323      1720
   Telophase     0.7746    0.6328    0.6965      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.2346    0.8356    0.3664        73
   Metaphase     0.5618    0.6286    0.5933      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7107      3872
   macro avg     0.5980    0.7535    0.6427      3872
weighted avg     0.7466    0.7107    0.7225      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch101
INFO:root:[102,    50] training loss: 0.00900654
INFO:root:[102,   100] training loss: 0.01207517
INFO:root:[102,   150] training loss: 0.01084840
INFO:root:[102,   200] training loss: 0.01098012
INFO:root:[102,   250] training loss: 0.01140038
INFO:root:[102,   300] training loss: 0.01124242
INFO:root:[102,   350] training loss: 0.00936302
INFO:root:[102,   400] training loss: 0.00004083
INFO:root:[102,   450] training loss: 0.00002933
INFO:root:[102,   500] training loss: 0.00025031
INFO:root:[102,   550] training loss: 0.00024795
INFO:root:[102,   600] training loss: 0.00089273
INFO:root:[102,   650] training loss: 0.00013521
INFO:root:[102,   700] training loss: 0.00007461
INFO:root:[102,   750] training loss: 0.00074880
INFO:root:[102,   800] training loss: 0.00011531
INFO:root:[102,   850] training loss: 0.00007754
INFO:root:[102,   900] training loss: 0.00938312
INFO:root:[102,   950] training loss: 0.00264497
INFO:root:[102,  1000] training loss: 0.00011569
INFO:root:[102,  1050] training loss: 0.00005119
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8676    0.8000    0.8324      1720
   Telophase     0.7929    0.6308    0.7026      1032
           S     0.2667    0.5000    0.3478         8
          G2     0.2569    0.7671    0.3849        73
   Metaphase     0.5587    0.6625    0.6062      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7172      3872
   macro avg     0.6299    0.7658    0.6677      3872
weighted avg     0.7525    0.7172    0.7281      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch102
INFO:root:[103,    50] training loss: 0.01113527
INFO:root:[103,   100] training loss: 0.01234049
INFO:root:[103,   150] training loss: 0.01339640
INFO:root:[103,   200] training loss: 0.01211844
INFO:root:[103,   250] training loss: 0.01118889
INFO:root:[103,   300] training loss: 0.01105739
INFO:root:[103,   350] training loss: 0.00978230
INFO:root:[103,   400] training loss: 0.00004971
INFO:root:[103,   450] training loss: 0.00005261
INFO:root:[103,   500] training loss: 0.00017753
INFO:root:[103,   550] training loss: 0.00028378
INFO:root:[103,   600] training loss: 0.00067315
INFO:root:[103,   650] training loss: 0.00015790
INFO:root:[103,   700] training loss: 0.00009840
INFO:root:[103,   750] training loss: 0.00064410
INFO:root:[103,   800] training loss: 0.00013860
INFO:root:[103,   850] training loss: 0.00007474
INFO:root:[103,   900] training loss: 0.00892647
INFO:root:[103,   950] training loss: 0.00273611
INFO:root:[103,  1000] training loss: 0.00016049
INFO:root:[103,  1050] training loss: 0.00007368
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8644    0.7674    0.8131      1720
   Telophase     0.7749    0.6105    0.6829      1032
           S     0.2500    0.5000    0.3333         8
          G2     0.2350    0.7534    0.3583        73
   Metaphase     0.5263    0.6489    0.5812      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6934      3872
   macro avg     0.5810    0.7543    0.6323      3872
weighted avg     0.7369    0.6934    0.7069      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch103
INFO:root:[104,    50] training loss: 0.01049909
INFO:root:[104,   100] training loss: 0.01067396
INFO:root:[104,   150] training loss: 0.00972685
INFO:root:[104,   200] training loss: 0.00989216
INFO:root:[104,   250] training loss: 0.00951279
INFO:root:[104,   300] training loss: 0.00992962
INFO:root:[104,   350] training loss: 0.00871777
INFO:root:[104,   400] training loss: 0.00004938
INFO:root:[104,   450] training loss: 0.00002462
INFO:root:[104,   500] training loss: 0.00024964
INFO:root:[104,   550] training loss: 0.00021374
INFO:root:[104,   600] training loss: 0.00059777
INFO:root:[104,   650] training loss: 0.00009668
INFO:root:[104,   700] training loss: 0.00009270
INFO:root:[104,   750] training loss: 0.00059998
INFO:root:[104,   800] training loss: 0.00012898
INFO:root:[104,   850] training loss: 0.00006392
INFO:root:[104,   900] training loss: 0.00903226
INFO:root:[104,   950] training loss: 0.00208634
INFO:root:[104,  1000] training loss: 0.00011548
INFO:root:[104,  1050] training loss: 0.00006308
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8766    0.8012    0.8372      1720
   Telophase     0.7600    0.6657    0.7097      1032
           S     0.6000    0.3750    0.4615         8
          G2     0.2683    0.7534    0.3957        73
   Metaphase     0.5547    0.6325    0.5911      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7185      3872
   macro avg     0.6395    0.7468    0.6646      3872
weighted avg     0.7473    0.7185    0.7284      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch104
INFO:root:[105,    50] training loss: 0.00905166
INFO:root:[105,   100] training loss: 0.00961242
INFO:root:[105,   150] training loss: 0.00941437
INFO:root:[105,   200] training loss: 0.00981263
INFO:root:[105,   250] training loss: 0.01055034
INFO:root:[105,   300] training loss: 0.01051951
INFO:root:[105,   350] training loss: 0.00993525
INFO:root:[105,   400] training loss: 0.00002483
INFO:root:[105,   450] training loss: 0.00002558
INFO:root:[105,   500] training loss: 0.00008907
INFO:root:[105,   550] training loss: 0.00023598
INFO:root:[105,   600] training loss: 0.00050303
INFO:root:[105,   650] training loss: 0.00010129
INFO:root:[105,   700] training loss: 0.00007014
INFO:root:[105,   750] training loss: 0.00065166
INFO:root:[105,   800] training loss: 0.00013649
INFO:root:[105,   850] training loss: 0.00006608
INFO:root:[105,   900] training loss: 0.01125765
INFO:root:[105,   950] training loss: 0.00255929
INFO:root:[105,  1000] training loss: 0.00009413
INFO:root:[105,  1050] training loss: 0.00004762
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8869    0.7750    0.8272      1720
   Telophase     0.7651    0.5901    0.6663      1032
           S     0.2727    0.3750    0.3158         8
          G2     0.2261    0.8082    0.3533        73
   Metaphase     0.5425    0.6789    0.6031      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7002      3872
   macro avg     0.5871    0.7468    0.6318      3872
weighted avg     0.7485    0.7002    0.7145      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch105
INFO:root:[106,    50] training loss: 0.01021964
INFO:root:[106,   100] training loss: 0.00981245
INFO:root:[106,   150] training loss: 0.00984069
INFO:root:[106,   200] training loss: 0.01011633
INFO:root:[106,   250] training loss: 0.00916776
INFO:root:[106,   300] training loss: 0.00986100
INFO:root:[106,   350] training loss: 0.00924261
INFO:root:[106,   400] training loss: 0.00003063
INFO:root:[106,   450] training loss: 0.00002861
INFO:root:[106,   500] training loss: 0.00031869
INFO:root:[106,   550] training loss: 0.00014975
INFO:root:[106,   600] training loss: 0.00068354
INFO:root:[106,   650] training loss: 0.00015609
INFO:root:[106,   700] training loss: 0.00007341
INFO:root:[106,   750] training loss: 0.00069602
INFO:root:[106,   800] training loss: 0.00014285
INFO:root:[106,   850] training loss: 0.00008336
INFO:root:[106,   900] training loss: 0.00876044
INFO:root:[106,   950] training loss: 0.00180641
INFO:root:[106,  1000] training loss: 0.00015177
INFO:root:[106,  1050] training loss: 0.00006478
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8365    0.8390    0.8377      1720
   Telophase     0.7856    0.6037    0.6827      1032
           S     0.2222    0.2500    0.2353         8
          G2     0.2434    0.7534    0.3679        73
   Metaphase     0.5540    0.5957    0.5741      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7087      3872
   macro avg     0.5798    0.7203    0.6221      3872
weighted avg     0.7349    0.7087    0.7159      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch106
INFO:root:[107,    50] training loss: 0.00912128
INFO:root:[107,   100] training loss: 0.00942117
INFO:root:[107,   150] training loss: 0.00978962
INFO:root:[107,   200] training loss: 0.00973171
INFO:root:[107,   250] training loss: 0.00922975
INFO:root:[107,   300] training loss: 0.01032481
INFO:root:[107,   350] training loss: 0.00843266
INFO:root:[107,   400] training loss: 0.00002352
INFO:root:[107,   450] training loss: 0.00001959
INFO:root:[107,   500] training loss: 0.00017224
INFO:root:[107,   550] training loss: 0.00020320
INFO:root:[107,   600] training loss: 0.00058728
INFO:root:[107,   650] training loss: 0.00010602
INFO:root:[107,   700] training loss: 0.00006783
INFO:root:[107,   750] training loss: 0.00068857
INFO:root:[107,   800] training loss: 0.00014476
INFO:root:[107,   850] training loss: 0.00007341
INFO:root:[107,   900] training loss: 0.00883937
INFO:root:[107,   950] training loss: 0.00197623
INFO:root:[107,  1000] training loss: 0.00007679
INFO:root:[107,  1050] training loss: 0.00005383
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8826    0.7866    0.8318      1720
   Telophase     0.7150    0.6734    0.6936      1032
           S     0.2857    0.2500    0.2667         8
          G2     0.2332    0.8082    0.3620        73
   Metaphase     0.5455    0.5803    0.5623      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7009      3872
   macro avg     0.5827    0.7284    0.6248      3872
weighted avg     0.7342    0.7009    0.7130      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch107
INFO:root:[108,    50] training loss: 0.00928287
INFO:root:[108,   100] training loss: 0.01058902
INFO:root:[108,   150] training loss: 0.01126466
INFO:root:[108,   200] training loss: 0.00948695
INFO:root:[108,   250] training loss: 0.00994774
INFO:root:[108,   300] training loss: 0.01085410
INFO:root:[108,   350] training loss: 0.00842083
INFO:root:[108,   400] training loss: 0.00002861
INFO:root:[108,   450] training loss: 0.00003527
INFO:root:[108,   500] training loss: 0.00010242
INFO:root:[108,   550] training loss: 0.00022040
INFO:root:[108,   600] training loss: 0.00041078
INFO:root:[108,   650] training loss: 0.00010498
INFO:root:[108,   700] training loss: 0.00007729
INFO:root:[108,   750] training loss: 0.00071860
INFO:root:[108,   800] training loss: 0.00010477
INFO:root:[108,   850] training loss: 0.00007135
INFO:root:[108,   900] training loss: 0.00886556
INFO:root:[108,   950] training loss: 0.00235933
INFO:root:[108,  1000] training loss: 0.00014153
INFO:root:[108,  1050] training loss: 0.00005171
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8716    0.7855    0.8263      1720
   Telophase     0.7723    0.6279    0.6927      1032
           S     0.2500    0.3750    0.3000         8
          G2     0.2342    0.7123    0.3525        73
   Metaphase     0.5338    0.6412    0.5826      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7030      3872
   macro avg     0.5827    0.7346    0.6302      3872
weighted avg     0.7414    0.7030    0.7156      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch108
INFO:root:[109,    50] training loss: 0.00982010
INFO:root:[109,   100] training loss: 0.01022598
INFO:root:[109,   150] training loss: 0.00938227
INFO:root:[109,   200] training loss: 0.00903081
INFO:root:[109,   250] training loss: 0.00913641
INFO:root:[109,   300] training loss: 0.00943008
INFO:root:[109,   350] training loss: 0.00816855
INFO:root:[109,   400] training loss: 0.00013763
INFO:root:[109,   450] training loss: 0.00002423
INFO:root:[109,   500] training loss: 0.00016129
INFO:root:[109,   550] training loss: 0.00020364
INFO:root:[109,   600] training loss: 0.00049575
INFO:root:[109,   650] training loss: 0.00009930
INFO:root:[109,   700] training loss: 0.00009429
INFO:root:[109,   750] training loss: 0.00075035
INFO:root:[109,   800] training loss: 0.00013245
INFO:root:[109,   850] training loss: 0.00009293
INFO:root:[109,   900] training loss: 0.00904539
INFO:root:[109,   950] training loss: 0.00173731
INFO:root:[109,  1000] training loss: 0.00013570
INFO:root:[109,  1050] training loss: 0.00004988
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    1.0000    0.6667         2
    Anaphase     0.8901    0.8006    0.8430      1720
   Telophase     0.7806    0.6793    0.7264      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.2557    0.7671    0.3836        73
   Metaphase     0.5742    0.6625    0.6152      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7301      3872
   macro avg     0.6251    0.7549    0.6585      3872
weighted avg     0.7634    0.7301    0.7415      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch109
INFO:root:[110,    50] training loss: 0.00866253
INFO:root:[110,   100] training loss: 0.01048927
INFO:root:[110,   150] training loss: 0.00924545
INFO:root:[110,   200] training loss: 0.00960034
INFO:root:[110,   250] training loss: 0.00886935
INFO:root:[110,   300] training loss: 0.00936155
INFO:root:[110,   350] training loss: 0.01014658
INFO:root:[110,   400] training loss: 0.00003007
INFO:root:[110,   450] training loss: 0.00002693
INFO:root:[110,   500] training loss: 0.00009076
INFO:root:[110,   550] training loss: 0.00020036
INFO:root:[110,   600] training loss: 0.00041642
INFO:root:[110,   650] training loss: 0.00011965
INFO:root:[110,   700] training loss: 0.00007489
INFO:root:[110,   750] training loss: 0.00068772
INFO:root:[110,   800] training loss: 0.00014372
INFO:root:[110,   850] training loss: 0.00007160
INFO:root:[110,   900] training loss: 0.01062230
INFO:root:[110,   950] training loss: 0.00203107
INFO:root:[110,  1000] training loss: 0.00012821
INFO:root:[110,  1050] training loss: 0.00005552
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8934    0.7994    0.8438      1720
   Telophase     0.7605    0.6831    0.7198      1032
           S     0.1765    0.3750    0.2400         8
          G2     0.2366    0.7260    0.3569        73
   Metaphase     0.5772    0.6470    0.6101      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7257      3872
   macro avg     0.6158    0.7472    0.6529      3872
weighted avg     0.7597    0.7257    0.7380      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch110
INFO:root:[111,    50] training loss: 0.00975582
INFO:root:[111,   100] training loss: 0.00977221
INFO:root:[111,   150] training loss: 0.01074354
INFO:root:[111,   200] training loss: 0.00922650
INFO:root:[111,   250] training loss: 0.00925684
INFO:root:[111,   300] training loss: 0.01007403
INFO:root:[111,   350] training loss: 0.00819428
INFO:root:[111,   400] training loss: 0.00003649
INFO:root:[111,   450] training loss: 0.00004075
INFO:root:[111,   500] training loss: 0.00011562
INFO:root:[111,   550] training loss: 0.00024653
INFO:root:[111,   600] training loss: 0.00064073
INFO:root:[111,   650] training loss: 0.00012298
INFO:root:[111,   700] training loss: 0.00007230
INFO:root:[111,   750] training loss: 0.00077902
INFO:root:[111,   800] training loss: 0.00013029
INFO:root:[111,   850] training loss: 0.00007701
INFO:root:[111,   900] training loss: 0.00928543
INFO:root:[111,   950] training loss: 0.00174434
INFO:root:[111,  1000] training loss: 0.00017964
INFO:root:[111,  1050] training loss: 0.00004594
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8654    0.8151    0.8395      1720
   Telophase     0.7469    0.6347    0.6862      1032
           S     0.2500    0.2500    0.2500         8
          G2     0.2130    0.8082    0.3371        73
   Metaphase     0.5618    0.5890    0.5751      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7056      3872
   macro avg     0.6148    0.7281    0.6411      3872
weighted avg     0.7392    0.7056    0.7175      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch111
INFO:root:[112,    50] training loss: 0.00868858
INFO:root:[112,   100] training loss: 0.00885989
INFO:root:[112,   150] training loss: 0.00831014
INFO:root:[112,   200] training loss: 0.00918477
INFO:root:[112,   250] training loss: 0.00918240
INFO:root:[112,   300] training loss: 0.00954285
INFO:root:[112,   350] training loss: 0.00981078
INFO:root:[112,   400] training loss: 0.00004767
INFO:root:[112,   450] training loss: 0.00003077
INFO:root:[112,   500] training loss: 0.00009254
INFO:root:[112,   550] training loss: 0.00020353
INFO:root:[112,   600] training loss: 0.00065601
INFO:root:[112,   650] training loss: 0.00011812
INFO:root:[112,   700] training loss: 0.00007352
INFO:root:[112,   750] training loss: 0.00075684
INFO:root:[112,   800] training loss: 0.00013989
INFO:root:[112,   850] training loss: 0.00009599
INFO:root:[112,   900] training loss: 0.00797109
INFO:root:[112,   950] training loss: 0.00214818
INFO:root:[112,  1000] training loss: 0.00008547
INFO:root:[112,  1050] training loss: 0.00003635
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8740    0.7907    0.8303      1720
   Telophase     0.7397    0.6802    0.7087      1032
           S     0.2727    0.3750    0.3158         8
          G2     0.2254    0.7534    0.3470        73
   Metaphase     0.5538    0.5919    0.5722      1034
    Prophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7069      3872
   macro avg     0.5832    0.7416    0.6330      3872
weighted avg     0.7391    0.7069    0.7188      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch112
INFO:root:[113,    50] training loss: 0.00892213
INFO:root:[113,   100] training loss: 0.00977706
INFO:root:[113,   150] training loss: 0.00837279
INFO:root:[113,   200] training loss: 0.00900255
INFO:root:[113,   250] training loss: 0.00847327
INFO:root:[113,   300] training loss: 0.00983228
INFO:root:[113,   350] training loss: 0.00773166
INFO:root:[113,   400] training loss: 0.00001431
INFO:root:[113,   450] training loss: 0.00001763
INFO:root:[113,   500] training loss: 0.00010537
INFO:root:[113,   550] training loss: 0.00019441
INFO:root:[113,   600] training loss: 0.00033488
INFO:root:[113,   650] training loss: 0.00010595
INFO:root:[113,   700] training loss: 0.00006608
INFO:root:[113,   750] training loss: 0.00070259
INFO:root:[113,   800] training loss: 0.00012276
INFO:root:[113,   850] training loss: 0.00010394
INFO:root:[113,   900] training loss: 0.00812350
INFO:root:[113,   950] training loss: 0.00189745
INFO:root:[113,  1000] training loss: 0.00009658
INFO:root:[113,  1050] training loss: 0.00003901
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8764    0.8041    0.8387      1720
   Telophase     0.7791    0.7141    0.7452      1032
           S     0.3125    0.6250    0.4167         8
          G2     0.2703    0.6849    0.3876        73
   Metaphase     0.5793    0.6393    0.6078      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7337      3872
   macro avg     0.6406    0.7811    0.6851      3872
weighted avg     0.7585    0.7337    0.7428      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch113
INFO:root:[114,    50] training loss: 0.00942029
INFO:root:[114,   100] training loss: 0.01051366
INFO:root:[114,   150] training loss: 0.00948303
INFO:root:[114,   200] training loss: 0.00874367
INFO:root:[114,   250] training loss: 0.00886977
INFO:root:[114,   300] training loss: 0.00968731
INFO:root:[114,   350] training loss: 0.00903417
INFO:root:[114,   400] training loss: 0.00002563
INFO:root:[114,   450] training loss: 0.00001991
INFO:root:[114,   500] training loss: 0.00012053
INFO:root:[114,   550] training loss: 0.00017008
INFO:root:[114,   600] training loss: 0.00051023
INFO:root:[114,   650] training loss: 0.00011511
INFO:root:[114,   700] training loss: 0.00006479
INFO:root:[114,   750] training loss: 0.00067900
INFO:root:[114,   800] training loss: 0.00012055
INFO:root:[114,   850] training loss: 0.00007875
INFO:root:[114,   900] training loss: 0.00907649
INFO:root:[114,   950] training loss: 0.00205036
INFO:root:[114,  1000] training loss: 0.00008643
INFO:root:[114,  1050] training loss: 0.00004165
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8880    0.8110    0.8478      1720
   Telophase     0.7327    0.6986    0.7153      1032
           S     0.2667    0.5000    0.3478         8
          G2     0.2184    0.7808    0.3413        73
   Metaphase     0.5855    0.5861    0.5858      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7200      3872
   macro avg     0.6226    0.7681    0.6626      3872
weighted avg     0.7519    0.7200    0.7320      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch114
INFO:root:[115,    50] training loss: 0.00899548
INFO:root:[115,   100] training loss: 0.00929627
INFO:root:[115,   150] training loss: 0.00871382
INFO:root:[115,   200] training loss: 0.00867875
INFO:root:[115,   250] training loss: 0.00934648
INFO:root:[115,   300] training loss: 0.00984793
INFO:root:[115,   350] training loss: 0.00924749
INFO:root:[115,   400] training loss: 0.00001921
INFO:root:[115,   450] training loss: 0.00002938
INFO:root:[115,   500] training loss: 0.00010475
INFO:root:[115,   550] training loss: 0.00017596
INFO:root:[115,   600] training loss: 0.00046311
INFO:root:[115,   650] training loss: 0.00008446
INFO:root:[115,   700] training loss: 0.00006728
INFO:root:[115,   750] training loss: 0.00066642
INFO:root:[115,   800] training loss: 0.00013377
INFO:root:[115,   850] training loss: 0.00006845
INFO:root:[115,   900] training loss: 0.00658310
INFO:root:[115,   950] training loss: 0.00138622
INFO:root:[115,  1000] training loss: 0.00007854
INFO:root:[115,  1050] training loss: 0.00003996
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8860    0.8134    0.8481      1720
   Telophase     0.7284    0.7200    0.7242      1032
           S     0.4286    0.3750    0.4000         8
          G2     0.2320    0.7945    0.3591        73
   Metaphase     0.5960    0.5822    0.5890      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7257      3872
   macro avg     0.6482    0.7550    0.6744      3872
weighted avg     0.7533    0.7257    0.7359      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch115
INFO:root:[116,    50] training loss: 0.00862269
INFO:root:[116,   100] training loss: 0.00848144
INFO:root:[116,   150] training loss: 0.00846442
INFO:root:[116,   200] training loss: 0.00897240
INFO:root:[116,   250] training loss: 0.00937643
INFO:root:[116,   300] training loss: 0.00971295
INFO:root:[116,   350] training loss: 0.01409359
INFO:root:[116,   400] training loss: 0.00004342
INFO:root:[116,   450] training loss: 0.00003379
INFO:root:[116,   500] training loss: 0.00030253
INFO:root:[116,   550] training loss: 0.00015703
INFO:root:[116,   600] training loss: 0.00060060
INFO:root:[116,   650] training loss: 0.00008499
INFO:root:[116,   700] training loss: 0.00006082
INFO:root:[116,   750] training loss: 0.00071446
INFO:root:[116,   800] training loss: 0.00011613
INFO:root:[116,   850] training loss: 0.00006603
INFO:root:[116,   900] training loss: 0.00785688
INFO:root:[116,   950] training loss: 0.00240236
INFO:root:[116,  1000] training loss: 0.00010083
INFO:root:[116,  1050] training loss: 0.00004366
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8478    0.8547    0.8512      1720
   Telophase     0.7709    0.6357    0.6968      1032
           S     0.1600    0.5000    0.2424         8
          G2     0.1825    0.6575    0.2857        73
   Metaphase     0.6042    0.5803    0.5920      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7188      3872
   macro avg     0.6046    0.7469    0.6383      3872
weighted avg     0.7483    0.7188    0.7290      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch116
INFO:root:[117,    50] training loss: 0.01056225
INFO:root:[117,   100] training loss: 0.01002725
INFO:root:[117,   150] training loss: 0.00930278
INFO:root:[117,   200] training loss: 0.00923262
INFO:root:[117,   250] training loss: 0.00893026
INFO:root:[117,   300] training loss: 0.00901990
INFO:root:[117,   350] training loss: 0.00747518
INFO:root:[117,   400] training loss: 0.00004107
INFO:root:[117,   450] training loss: 0.00003590
INFO:root:[117,   500] training loss: 0.00007505
INFO:root:[117,   550] training loss: 0.00043601
INFO:root:[117,   600] training loss: 0.00101837
INFO:root:[117,   650] training loss: 0.00050656
INFO:root:[117,   700] training loss: 0.00041325
INFO:root:[117,   750] training loss: 0.00351835
INFO:root:[117,   800] training loss: 0.00153788
INFO:root:[117,   850] training loss: 0.00096188
INFO:root:[117,   900] training loss: 0.00718246
INFO:root:[117,   950] training loss: 0.00293351
INFO:root:[117,  1000] training loss: 0.00011986
INFO:root:[117,  1050] training loss: 0.00008877
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9028    0.8314    0.8656      1720
   Telophase     0.7480    0.8285    0.7862      1032
           S     0.3636    0.5000    0.4211         8
          G2     0.3551    0.6712    0.4645        73
   Metaphase     0.6333    0.6064    0.6196      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7670      3872
   macro avg     0.6671    0.7768    0.7081      3872
weighted avg     0.7781    0.7670    0.7703      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch117
INFO:root:[118,    50] training loss: 0.00913395
INFO:root:[118,   100] training loss: 0.00927684
INFO:root:[118,   150] training loss: 0.00870817
INFO:root:[118,   200] training loss: 0.00828577
INFO:root:[118,   250] training loss: 0.00800490
INFO:root:[118,   300] training loss: 0.00857607
INFO:root:[118,   350] training loss: 0.00692075
INFO:root:[118,   400] training loss: 0.00002377
INFO:root:[118,   450] training loss: 0.00002631
INFO:root:[118,   500] training loss: 0.00007095
INFO:root:[118,   550] training loss: 0.00049695
INFO:root:[118,   600] training loss: 0.00041565
INFO:root:[118,   650] training loss: 0.00023401
INFO:root:[118,   700] training loss: 0.00017492
INFO:root:[118,   750] training loss: 0.00248100
INFO:root:[118,   800] training loss: 0.00130285
INFO:root:[118,   850] training loss: 0.00084865
INFO:root:[118,   900] training loss: 0.00620944
INFO:root:[118,   950] training loss: 0.00261663
INFO:root:[118,  1000] training loss: 0.00011902
INFO:root:[118,  1050] training loss: 0.00006219
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8988    0.8523    0.8750      1720
   Telophase     0.7980    0.7733    0.7854      1032
           S     0.2500    0.2500    0.2500         8
          G2     0.3214    0.7397    0.4481        73
   Metaphase     0.6516    0.6673    0.6593      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7787      3872
   macro avg     0.6552    0.7547    0.6883      3872
weighted avg     0.7937    0.7787    0.7842      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch118
INFO:root:[119,    50] training loss: 0.00847215
INFO:root:[119,   100] training loss: 0.00987114
INFO:root:[119,   150] training loss: 0.00786328
INFO:root:[119,   200] training loss: 0.00812571
INFO:root:[119,   250] training loss: 0.00826806
INFO:root:[119,   300] training loss: 0.00917336
INFO:root:[119,   350] training loss: 0.00669938
INFO:root:[119,   400] training loss: 0.00001925
INFO:root:[119,   450] training loss: 0.00002416
INFO:root:[119,   500] training loss: 0.00005130
INFO:root:[119,   550] training loss: 0.00038482
INFO:root:[119,   600] training loss: 0.00038463
INFO:root:[119,   650] training loss: 0.00015406
INFO:root:[119,   700] training loss: 0.00015576
INFO:root:[119,   750] training loss: 0.00200742
INFO:root:[119,   800] training loss: 0.00113344
INFO:root:[119,   850] training loss: 0.00076596
INFO:root:[119,   900] training loss: 0.00611386
INFO:root:[119,   950] training loss: 0.00263667
INFO:root:[119,  1000] training loss: 0.00007899
INFO:root:[119,  1050] training loss: 0.00007981
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9010    0.8517    0.8757      1720
   Telophase     0.8107    0.7510    0.7797      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3073    0.7534    0.4365        73
   Metaphase     0.6496    0.6886    0.6685      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7787      3872
   macro avg     0.6669    0.7742    0.7019      3872
weighted avg     0.7974    0.7787    0.7855      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch119
INFO:root:[120,    50] training loss: 0.00856030
INFO:root:[120,   100] training loss: 0.00823060
INFO:root:[120,   150] training loss: 0.00806957
INFO:root:[120,   200] training loss: 0.00785468
INFO:root:[120,   250] training loss: 0.00786604
INFO:root:[120,   300] training loss: 0.00828488
INFO:root:[120,   350] training loss: 0.00728285
INFO:root:[120,   400] training loss: 0.00001544
INFO:root:[120,   450] training loss: 0.00001860
INFO:root:[120,   500] training loss: 0.00005364
INFO:root:[120,   550] training loss: 0.00034960
INFO:root:[120,   600] training loss: 0.00030444
INFO:root:[120,   650] training loss: 0.00010408
INFO:root:[120,   700] training loss: 0.00009301
INFO:root:[120,   750] training loss: 0.00194961
INFO:root:[120,   800] training loss: 0.00099260
INFO:root:[120,   850] training loss: 0.00063723
INFO:root:[120,   900] training loss: 0.00546372
INFO:root:[120,   950] training loss: 0.00215637
INFO:root:[120,  1000] training loss: 0.00010870
INFO:root:[120,  1050] training loss: 0.00005676
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9019    0.8448    0.8724      1720
   Telophase     0.8138    0.7539    0.7827      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3107    0.7534    0.4400        73
   Metaphase     0.6451    0.6944    0.6688      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7779      3872
   macro avg     0.6674    0.7745    0.7024      3872
weighted avg     0.7975    0.7779    0.7850      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch120
INFO:root:[121,    50] training loss: 0.00780339
INFO:root:[121,   100] training loss: 0.00853693
INFO:root:[121,   150] training loss: 0.00757014
INFO:root:[121,   200] training loss: 0.00785974
INFO:root:[121,   250] training loss: 0.00806532
INFO:root:[121,   300] training loss: 0.00860750
INFO:root:[121,   350] training loss: 0.00672284
INFO:root:[121,   400] training loss: 0.00002849
INFO:root:[121,   450] training loss: 0.00002239
INFO:root:[121,   500] training loss: 0.00006351
INFO:root:[121,   550] training loss: 0.00036942
INFO:root:[121,   600] training loss: 0.00032173
INFO:root:[121,   650] training loss: 0.00014689
INFO:root:[121,   700] training loss: 0.00011242
INFO:root:[121,   750] training loss: 0.00183222
INFO:root:[121,   800] training loss: 0.00093613
INFO:root:[121,   850] training loss: 0.00060848
INFO:root:[121,   900] training loss: 0.00586898
INFO:root:[121,   950] training loss: 0.00203290
INFO:root:[121,  1000] training loss: 0.00012422
INFO:root:[121,  1050] training loss: 0.00006465
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8997    0.8500    0.8741      1720
   Telophase     0.8186    0.7345    0.7743      1032
           S     0.3000    0.3750    0.3333         8
          G2     0.3011    0.7671    0.4324        73
   Metaphase     0.6434    0.6963    0.6688      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7758      3872
   macro avg     0.6613    0.7747    0.6976      3872
weighted avg     0.7971    0.7758    0.7833      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch121
INFO:root:[122,    50] training loss: 0.00791981
INFO:root:[122,   100] training loss: 0.00799986
INFO:root:[122,   150] training loss: 0.00796795
INFO:root:[122,   200] training loss: 0.00806249
INFO:root:[122,   250] training loss: 0.00900906
INFO:root:[122,   300] training loss: 0.00865754
INFO:root:[122,   350] training loss: 0.00763858
INFO:root:[122,   400] training loss: 0.00001940
INFO:root:[122,   450] training loss: 0.00002081
INFO:root:[122,   500] training loss: 0.00004990
INFO:root:[122,   550] training loss: 0.00032636
INFO:root:[122,   600] training loss: 0.00030419
INFO:root:[122,   650] training loss: 0.00008445
INFO:root:[122,   700] training loss: 0.00008916
INFO:root:[122,   750] training loss: 0.00158737
INFO:root:[122,   800] training loss: 0.00084850
INFO:root:[122,   850] training loss: 0.00050774
INFO:root:[122,   900] training loss: 0.00563122
INFO:root:[122,   950] training loss: 0.00236234
INFO:root:[122,  1000] training loss: 0.00011787
INFO:root:[122,  1050] training loss: 0.00005233
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8987    0.8558    0.8767      1720
   Telophase     0.8230    0.7345    0.7762      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.2947    0.7671    0.4259        73
   Metaphase     0.6525    0.6992    0.6751      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7792      3872
   macro avg     0.6670    0.7760    0.7010      3872
weighted avg     0.8002    0.7792    0.7866      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch122
INFO:root:[123,    50] training loss: 0.00775636
INFO:root:[123,   100] training loss: 0.00806045
INFO:root:[123,   150] training loss: 0.00765238
INFO:root:[123,   200] training loss: 0.00755190
INFO:root:[123,   250] training loss: 0.00741054
INFO:root:[123,   300] training loss: 0.00813303
INFO:root:[123,   350] training loss: 0.00682775
INFO:root:[123,   400] training loss: 0.00001817
INFO:root:[123,   450] training loss: 0.00001741
INFO:root:[123,   500] training loss: 0.00005578
INFO:root:[123,   550] training loss: 0.00034833
INFO:root:[123,   600] training loss: 0.00027072
INFO:root:[123,   650] training loss: 0.00006342
INFO:root:[123,   700] training loss: 0.00009174
INFO:root:[123,   750] training loss: 0.00144409
INFO:root:[123,   800] training loss: 0.00081406
INFO:root:[123,   850] training loss: 0.00049667
INFO:root:[123,   900] training loss: 0.00543168
INFO:root:[123,   950] training loss: 0.00265707
INFO:root:[123,  1000] training loss: 0.00008745
INFO:root:[123,  1050] training loss: 0.00006469
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8970    0.8558    0.8759      1720
   Telophase     0.8171    0.7403    0.7768      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3043    0.7671    0.4358        73
   Metaphase     0.6509    0.6905    0.6701      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7784      3872
   macro avg     0.6670    0.7755    0.7017      3872
weighted avg     0.7976    0.7784    0.7852      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch123
INFO:root:[124,    50] training loss: 0.00743974
INFO:root:[124,   100] training loss: 0.00854009
INFO:root:[124,   150] training loss: 0.00707772
INFO:root:[124,   200] training loss: 0.00754554
INFO:root:[124,   250] training loss: 0.00744695
INFO:root:[124,   300] training loss: 0.00896690
INFO:root:[124,   350] training loss: 0.00673402
INFO:root:[124,   400] training loss: 0.00001657
INFO:root:[124,   450] training loss: 0.00003598
INFO:root:[124,   500] training loss: 0.00008779
INFO:root:[124,   550] training loss: 0.00026685
INFO:root:[124,   600] training loss: 0.00028517
INFO:root:[124,   650] training loss: 0.00009064
INFO:root:[124,   700] training loss: 0.00007764
INFO:root:[124,   750] training loss: 0.00129900
INFO:root:[124,   800] training loss: 0.00089212
INFO:root:[124,   850] training loss: 0.00056507
INFO:root:[124,   900] training loss: 0.00509193
INFO:root:[124,   950] training loss: 0.00220391
INFO:root:[124,  1000] training loss: 0.00007910
INFO:root:[124,  1050] training loss: 0.00004212
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9006    0.8483    0.8737      1720
   Telophase     0.8190    0.7277    0.7707      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.2865    0.7534    0.4151        73
   Metaphase     0.6454    0.7041    0.6735      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7751      3872
   macro avg     0.6645    0.7726    0.6980      3872
weighted avg     0.7979    0.7751    0.7831      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch124
INFO:root:[125,    50] training loss: 0.00760144
INFO:root:[125,   100] training loss: 0.01081446
INFO:root:[125,   150] training loss: 0.00725593
INFO:root:[125,   200] training loss: 0.00758738
INFO:root:[125,   250] training loss: 0.00730975
INFO:root:[125,   300] training loss: 0.00796074
INFO:root:[125,   350] training loss: 0.00638262
INFO:root:[125,   400] training loss: 0.00001290
INFO:root:[125,   450] training loss: 0.00006624
INFO:root:[125,   500] training loss: 0.00004576
INFO:root:[125,   550] training loss: 0.00033540
INFO:root:[125,   600] training loss: 0.00021770
INFO:root:[125,   650] training loss: 0.00005911
INFO:root:[125,   700] training loss: 0.00006554
INFO:root:[125,   750] training loss: 0.00132969
INFO:root:[125,   800] training loss: 0.00074153
INFO:root:[125,   850] training loss: 0.00047112
INFO:root:[125,   900] training loss: 0.00545863
INFO:root:[125,   950] training loss: 0.00261703
INFO:root:[125,  1000] training loss: 0.00009139
INFO:root:[125,  1050] training loss: 0.00004581
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8975    0.8599    0.8783      1720
   Telophase     0.8195    0.7345    0.7747      1032
           S     0.3000    0.3750    0.3333         8
          G2     0.2926    0.7534    0.4215        73
   Metaphase     0.6548    0.6934    0.6736      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7792      3872
   macro avg     0.6616    0.7737    0.6973      3872
weighted avg     0.7992    0.7792    0.7863      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch125
INFO:root:[126,    50] training loss: 0.00794824
INFO:root:[126,   100] training loss: 0.00806101
INFO:root:[126,   150] training loss: 0.00744902
INFO:root:[126,   200] training loss: 0.00756000
INFO:root:[126,   250] training loss: 0.00695833
INFO:root:[126,   300] training loss: 0.00796703
INFO:root:[126,   350] training loss: 0.00688094
INFO:root:[126,   400] training loss: 0.00001333
INFO:root:[126,   450] training loss: 0.00001479
INFO:root:[126,   500] training loss: 0.00004690
INFO:root:[126,   550] training loss: 0.00044315
INFO:root:[126,   600] training loss: 0.00024511
INFO:root:[126,   650] training loss: 0.00007066
INFO:root:[126,   700] training loss: 0.00006996
INFO:root:[126,   750] training loss: 0.00126016
INFO:root:[126,   800] training loss: 0.00074613
INFO:root:[126,   850] training loss: 0.00042665
INFO:root:[126,   900] training loss: 0.00427436
INFO:root:[126,   950] training loss: 0.00174034
INFO:root:[126,  1000] training loss: 0.00009554
INFO:root:[126,  1050] training loss: 0.00005191
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8988    0.8517    0.8746      1720
   Telophase     0.8205    0.7442    0.7805      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3060    0.7671    0.4375        73
   Metaphase     0.6507    0.6973    0.6732      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7794      3872
   macro avg     0.6680    0.7765    0.7027      3872
weighted avg     0.7993    0.7794    0.7865      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch126
INFO:root:[127,    50] training loss: 0.00802774
INFO:root:[127,   100] training loss: 0.00811810
INFO:root:[127,   150] training loss: 0.00715513
INFO:root:[127,   200] training loss: 0.00809208
INFO:root:[127,   250] training loss: 0.00733604
INFO:root:[127,   300] training loss: 0.00776920
INFO:root:[127,   350] training loss: 0.00646766
INFO:root:[127,   400] training loss: 0.00001356
INFO:root:[127,   450] training loss: 0.00001463
INFO:root:[127,   500] training loss: 0.00007430
INFO:root:[127,   550] training loss: 0.00033285
INFO:root:[127,   600] training loss: 0.00022133
INFO:root:[127,   650] training loss: 0.00008862
INFO:root:[127,   700] training loss: 0.00006115
INFO:root:[127,   750] training loss: 0.00121109
INFO:root:[127,   800] training loss: 0.00058646
INFO:root:[127,   850] training loss: 0.00040741
INFO:root:[127,   900] training loss: 0.00521023
INFO:root:[127,   950] training loss: 0.00173230
INFO:root:[127,  1000] training loss: 0.00008421
INFO:root:[127,  1050] training loss: 0.00004797
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8972    0.8622    0.8793      1720
   Telophase     0.8253    0.7277    0.7734      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.2938    0.7808    0.4270        73
   Metaphase     0.6600    0.7021    0.6804      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7812      3872
   macro avg     0.6680    0.7783    0.7019      3872
weighted avg     0.8021    0.7812    0.7884      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch127
INFO:root:[128,    50] training loss: 0.00758042
INFO:root:[128,   100] training loss: 0.00814926
INFO:root:[128,   150] training loss: 0.00720138
INFO:root:[128,   200] training loss: 0.00732061
INFO:root:[128,   250] training loss: 0.00730649
INFO:root:[128,   300] training loss: 0.00938270
INFO:root:[128,   350] training loss: 0.00726541
INFO:root:[128,   400] training loss: 0.00001299
INFO:root:[128,   450] training loss: 0.00004592
INFO:root:[128,   500] training loss: 0.00004506
INFO:root:[128,   550] training loss: 0.00022670
INFO:root:[128,   600] training loss: 0.00028911
INFO:root:[128,   650] training loss: 0.00006827
INFO:root:[128,   700] training loss: 0.00005577
INFO:root:[128,   750] training loss: 0.00102482
INFO:root:[128,   800] training loss: 0.00075365
INFO:root:[128,   850] training loss: 0.00039230
INFO:root:[128,   900] training loss: 0.00454739
INFO:root:[128,   950] training loss: 0.00163550
INFO:root:[128,  1000] training loss: 0.00008261
INFO:root:[128,  1050] training loss: 0.00005012
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9029    0.8593    0.8805      1720
   Telophase     0.8315    0.7316    0.7784      1032
           S     0.3000    0.3750    0.3333         8
          G2     0.2957    0.7534    0.4247        73
   Metaphase     0.6596    0.7176    0.6874      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7846      3872
   macro avg     0.6652    0.7767    0.7006      3872
weighted avg     0.8061    0.7846    0.7920      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch128
INFO:root:[129,    50] training loss: 0.00732705
INFO:root:[129,   100] training loss: 0.00753323
INFO:root:[129,   150] training loss: 0.00726160
INFO:root:[129,   200] training loss: 0.00739077
INFO:root:[129,   250] training loss: 0.00827830
INFO:root:[129,   300] training loss: 0.00836830
INFO:root:[129,   350] training loss: 0.00652867
INFO:root:[129,   400] training loss: 0.00001293
INFO:root:[129,   450] training loss: 0.00002035
INFO:root:[129,   500] training loss: 0.00004870
INFO:root:[129,   550] training loss: 0.00024776
INFO:root:[129,   600] training loss: 0.00023450
INFO:root:[129,   650] training loss: 0.00007059
INFO:root:[129,   700] training loss: 0.00006644
INFO:root:[129,   750] training loss: 0.00108672
INFO:root:[129,   800] training loss: 0.00056876
INFO:root:[129,   850] training loss: 0.00048693
INFO:root:[129,   900] training loss: 0.00482417
INFO:root:[129,   950] training loss: 0.00166269
INFO:root:[129,  1000] training loss: 0.00009534
INFO:root:[129,  1050] training loss: 0.00005453
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8960    0.8616    0.8785      1720
   Telophase     0.8267    0.7490    0.7860      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3161    0.7534    0.4453        73
   Metaphase     0.6581    0.6963    0.6767      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7846      3872
   macro avg     0.6710    0.7765    0.7056      3872
weighted avg     0.8019    0.7846    0.7907      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch129
INFO:root:[130,    50] training loss: 0.00802356
INFO:root:[130,   100] training loss: 0.00817388
INFO:root:[130,   150] training loss: 0.00773290
INFO:root:[130,   200] training loss: 0.00725198
INFO:root:[130,   250] training loss: 0.00758747
INFO:root:[130,   300] training loss: 0.00771693
INFO:root:[130,   350] training loss: 0.00662258
INFO:root:[130,   400] training loss: 0.00001476
INFO:root:[130,   450] training loss: 0.00007875
INFO:root:[130,   500] training loss: 0.00004688
INFO:root:[130,   550] training loss: 0.00030296
INFO:root:[130,   600] training loss: 0.00020452
INFO:root:[130,   650] training loss: 0.00005864
INFO:root:[130,   700] training loss: 0.00004812
INFO:root:[130,   750] training loss: 0.00095319
INFO:root:[130,   800] training loss: 0.00059915
INFO:root:[130,   850] training loss: 0.00034335
INFO:root:[130,   900] training loss: 0.00523347
INFO:root:[130,   950] training loss: 0.00186877
INFO:root:[130,  1000] training loss: 0.00006276
INFO:root:[130,  1050] training loss: 0.00004556
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9029    0.8488    0.8750      1720
   Telophase     0.8222    0.7529    0.7860      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3143    0.7534    0.4435        73
   Metaphase     0.6491    0.7031    0.6750      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7818      3872
   macro avg     0.6698    0.7762    0.7047      3872
weighted avg     0.8013    0.7818    0.7887      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch130
INFO:root:[131,    50] training loss: 0.00718924
INFO:root:[131,   100] training loss: 0.00747327
INFO:root:[131,   150] training loss: 0.00701708
INFO:root:[131,   200] training loss: 0.00703496
INFO:root:[131,   250] training loss: 0.00717993
INFO:root:[131,   300] training loss: 0.00753248
INFO:root:[131,   350] training loss: 0.00634118
INFO:root:[131,   400] training loss: 0.00001229
INFO:root:[131,   450] training loss: 0.00001646
INFO:root:[131,   500] training loss: 0.00003569
INFO:root:[131,   550] training loss: 0.00030541
INFO:root:[131,   600] training loss: 0.00021392
INFO:root:[131,   650] training loss: 0.00006392
INFO:root:[131,   700] training loss: 0.00006767
INFO:root:[131,   750] training loss: 0.00098327
INFO:root:[131,   800] training loss: 0.00063262
INFO:root:[131,   850] training loss: 0.00034299
INFO:root:[131,   900] training loss: 0.00437028
INFO:root:[131,   950] training loss: 0.00236003
INFO:root:[131,  1000] training loss: 0.00007479
INFO:root:[131,  1050] training loss: 0.00005220
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8907    0.8721    0.8813      1720
   Telophase     0.8366    0.7442    0.7877      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3143    0.7534    0.4435        73
   Metaphase     0.6660    0.6963    0.6809      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7880      3872
   macro avg     0.6785    0.7773    0.7098      3872
weighted avg     0.8043    0.7880    0.7936      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch131
INFO:root:[132,    50] training loss: 0.00719518
INFO:root:[132,   100] training loss: 0.00767830
INFO:root:[132,   150] training loss: 0.00702704
INFO:root:[132,   200] training loss: 0.00723899
INFO:root:[132,   250] training loss: 0.00699266
INFO:root:[132,   300] training loss: 0.00743065
INFO:root:[132,   350] training loss: 0.00636210
INFO:root:[132,   400] training loss: 0.00001371
INFO:root:[132,   450] training loss: 0.00001385
INFO:root:[132,   500] training loss: 0.00011483
INFO:root:[132,   550] training loss: 0.00028944
INFO:root:[132,   600] training loss: 0.00021343
INFO:root:[132,   650] training loss: 0.00006363
INFO:root:[132,   700] training loss: 0.00004688
INFO:root:[132,   750] training loss: 0.00104875
INFO:root:[132,   800] training loss: 0.00057382
INFO:root:[132,   850] training loss: 0.00045116
INFO:root:[132,   900] training loss: 0.00494253
INFO:root:[132,   950] training loss: 0.00143373
INFO:root:[132,  1000] training loss: 0.00005761
INFO:root:[132,  1050] training loss: 0.00005832
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9055    0.8576    0.8809      1720
   Telophase     0.8306    0.7461    0.7861      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3073    0.7534    0.4365        73
   Metaphase     0.6607    0.7176    0.6880      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7877      3872
   macro avg     0.6780    0.7785    0.7095      3872
weighted avg     0.8077    0.7877    0.7947      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch132
INFO:root:[133,    50] training loss: 0.00770450
INFO:root:[133,   100] training loss: 0.00767184
INFO:root:[133,   150] training loss: 0.00726365
INFO:root:[133,   200] training loss: 0.00777554
INFO:root:[133,   250] training loss: 0.00711034
INFO:root:[133,   300] training loss: 0.00790225
INFO:root:[133,   350] training loss: 0.00619593
INFO:root:[133,   400] training loss: 0.00000931
INFO:root:[133,   450] training loss: 0.00001618
INFO:root:[133,   500] training loss: 0.00003952
INFO:root:[133,   550] training loss: 0.00020793
INFO:root:[133,   600] training loss: 0.00019392
INFO:root:[133,   650] training loss: 0.00005443
INFO:root:[133,   700] training loss: 0.00005398
INFO:root:[133,   750] training loss: 0.00096411
INFO:root:[133,   800] training loss: 0.00061592
INFO:root:[133,   850] training loss: 0.00039818
INFO:root:[133,   900] training loss: 0.00459725
INFO:root:[133,   950] training loss: 0.00149738
INFO:root:[133,  1000] training loss: 0.00009816
INFO:root:[133,  1050] training loss: 0.00004130
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9047    0.8552    0.8793      1720
   Telophase     0.8228    0.7558    0.7879      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3216    0.7534    0.4508        73
   Metaphase     0.6577    0.7079    0.6819      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7867      3872
   macro avg     0.6783    0.7782    0.7107      3872
weighted avg     0.8048    0.7867    0.7931      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch133
INFO:root:[134,    50] training loss: 0.00746612
INFO:root:[134,   100] training loss: 0.00751628
INFO:root:[134,   150] training loss: 0.00683172
INFO:root:[134,   200] training loss: 0.00682218
INFO:root:[134,   250] training loss: 0.00762010
INFO:root:[134,   300] training loss: 0.00871006
INFO:root:[134,   350] training loss: 0.00593703
INFO:root:[134,   400] training loss: 0.00001078
INFO:root:[134,   450] training loss: 0.00001614
INFO:root:[134,   500] training loss: 0.00005593
INFO:root:[134,   550] training loss: 0.00022563
INFO:root:[134,   600] training loss: 0.00018829
INFO:root:[134,   650] training loss: 0.00005993
INFO:root:[134,   700] training loss: 0.00003417
INFO:root:[134,   750] training loss: 0.00071131
INFO:root:[134,   800] training loss: 0.00052834
INFO:root:[134,   850] training loss: 0.00038804
INFO:root:[134,   900] training loss: 0.00414811
INFO:root:[134,   950] training loss: 0.00149246
INFO:root:[134,  1000] training loss: 0.00009876
INFO:root:[134,  1050] training loss: 0.00005246
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8998    0.8669    0.8830      1720
   Telophase     0.8378    0.7510    0.7920      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3313    0.7534    0.4603        73
   Metaphase     0.6658    0.7147    0.6894      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7924      3872
   macro avg     0.6823    0.7801    0.7142      3872
weighted avg     0.8090    0.7924    0.7981      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch134
INFO:root:[135,    50] training loss: 0.00717138
INFO:root:[135,   100] training loss: 0.00772635
INFO:root:[135,   150] training loss: 0.00684812
INFO:root:[135,   200] training loss: 0.00698780
INFO:root:[135,   250] training loss: 0.00719443
INFO:root:[135,   300] training loss: 0.00741216
INFO:root:[135,   350] training loss: 0.00589673
INFO:root:[135,   400] training loss: 0.00001081
INFO:root:[135,   450] training loss: 0.00001275
INFO:root:[135,   500] training loss: 0.00003098
INFO:root:[135,   550] training loss: 0.00026431
INFO:root:[135,   600] training loss: 0.00016508
INFO:root:[135,   650] training loss: 0.00005990
INFO:root:[135,   700] training loss: 0.00003636
INFO:root:[135,   750] training loss: 0.00076747
INFO:root:[135,   800] training loss: 0.00055542
INFO:root:[135,   850] training loss: 0.00034644
INFO:root:[135,   900] training loss: 0.00513185
INFO:root:[135,   950] training loss: 0.00142357
INFO:root:[135,  1000] training loss: 0.00006910
INFO:root:[135,  1050] training loss: 0.00004484
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8987    0.8616    0.8798      1720
   Telophase     0.8304    0.7403    0.7828      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3216    0.7534    0.4508        73
   Metaphase     0.6538    0.7070    0.6794      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7851      3872
   macro avg     0.6780    0.7768    0.7097      3872
weighted avg     0.8031    0.7851    0.7913      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch135
INFO:root:[136,    50] training loss: 0.00726772
INFO:root:[136,   100] training loss: 0.00765857
INFO:root:[136,   150] training loss: 0.00662678
INFO:root:[136,   200] training loss: 0.00685614
INFO:root:[136,   250] training loss: 0.00734146
INFO:root:[136,   300] training loss: 0.00762836
INFO:root:[136,   350] training loss: 0.00701060
INFO:root:[136,   400] training loss: 0.00001024
INFO:root:[136,   450] training loss: 0.00002190
INFO:root:[136,   500] training loss: 0.00004959
INFO:root:[136,   550] training loss: 0.00022414
INFO:root:[136,   600] training loss: 0.00020677
INFO:root:[136,   650] training loss: 0.00005922
INFO:root:[136,   700] training loss: 0.00005019
INFO:root:[136,   750] training loss: 0.00077302
INFO:root:[136,   800] training loss: 0.00052422
INFO:root:[136,   850] training loss: 0.00031597
INFO:root:[136,   900] training loss: 0.00464835
INFO:root:[136,   950] training loss: 0.00197584
INFO:root:[136,  1000] training loss: 0.00008152
INFO:root:[136,  1050] training loss: 0.00004356
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9021    0.8622    0.8817      1720
   Telophase     0.8283    0.7481    0.7862      1032
           S     0.3000    0.3750    0.3333         8
          G2     0.3107    0.7534    0.4400        73
   Metaphase     0.6646    0.7089    0.6860      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7880      3872
   macro avg     0.6675    0.7782    0.7039      3872
weighted avg     0.8065    0.7880    0.7946      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch136
INFO:root:[137,    50] training loss: 0.00730465
INFO:root:[137,   100] training loss: 0.00722263
INFO:root:[137,   150] training loss: 0.00693150
INFO:root:[137,   200] training loss: 0.00762952
INFO:root:[137,   250] training loss: 0.00723134
INFO:root:[137,   300] training loss: 0.00833014
INFO:root:[137,   350] training loss: 0.00586377
INFO:root:[137,   400] training loss: 0.00001139
INFO:root:[137,   450] training loss: 0.00001348
INFO:root:[137,   500] training loss: 0.00003277
INFO:root:[137,   550] training loss: 0.00022781
INFO:root:[137,   600] training loss: 0.00016130
INFO:root:[137,   650] training loss: 0.00004908
INFO:root:[137,   700] training loss: 0.00003947
INFO:root:[137,   750] training loss: 0.00078693
INFO:root:[137,   800] training loss: 0.00044146
INFO:root:[137,   850] training loss: 0.00034356
INFO:root:[137,   900] training loss: 0.00419996
INFO:root:[137,   950] training loss: 0.00158629
INFO:root:[137,  1000] training loss: 0.00007149
INFO:root:[137,  1050] training loss: 0.00004681
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9072    0.8523    0.8789      1720
   Telophase     0.8340    0.7548    0.7925      1032
           S     0.3333    0.3750    0.3529         8
          G2     0.3396    0.7397    0.4655        73
   Metaphase     0.6524    0.7244    0.6865      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7893      3872
   macro avg     0.6762    0.7780    0.7109      3872
weighted avg     0.8077    0.7893    0.7957      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch137
INFO:root:[138,    50] training loss: 0.00799622
INFO:root:[138,   100] training loss: 0.00735973
INFO:root:[138,   150] training loss: 0.00694352
INFO:root:[138,   200] training loss: 0.00702102
INFO:root:[138,   250] training loss: 0.00719900
INFO:root:[138,   300] training loss: 0.00783706
INFO:root:[138,   350] training loss: 0.00616315
INFO:root:[138,   400] training loss: 0.00000981
INFO:root:[138,   450] training loss: 0.00001273
INFO:root:[138,   500] training loss: 0.00006862
INFO:root:[138,   550] training loss: 0.00022137
INFO:root:[138,   600] training loss: 0.00016719
INFO:root:[138,   650] training loss: 0.00006095
INFO:root:[138,   700] training loss: 0.00004720
INFO:root:[138,   750] training loss: 0.00078595
INFO:root:[138,   800] training loss: 0.00050822
INFO:root:[138,   850] training loss: 0.00037955
INFO:root:[138,   900] training loss: 0.00381652
INFO:root:[138,   950] training loss: 0.00151872
INFO:root:[138,  1000] training loss: 0.00009506
INFO:root:[138,  1050] training loss: 0.00005760
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.8958    0.8651    0.8802      1720
   Telophase     0.8317    0.7568    0.7925      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3313    0.7534    0.4603        73
   Metaphase     0.6630    0.7002    0.6811      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7893      3872
   macro avg     0.6805    0.7786    0.7127      3872
weighted avg     0.8048    0.7893    0.7947      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch138
INFO:root:[139,    50] training loss: 0.00715593
INFO:root:[139,   100] training loss: 0.00932836
INFO:root:[139,   150] training loss: 0.00679941
INFO:root:[139,   200] training loss: 0.00708436
INFO:root:[139,   250] training loss: 0.00724738
INFO:root:[139,   300] training loss: 0.00765250
INFO:root:[139,   350] training loss: 0.00625552
INFO:root:[139,   400] training loss: 0.00000933
INFO:root:[139,   450] training loss: 0.00001160
INFO:root:[139,   500] training loss: 0.00005478
INFO:root:[139,   550] training loss: 0.00024707
INFO:root:[139,   600] training loss: 0.00015945
INFO:root:[139,   650] training loss: 0.00004287
INFO:root:[139,   700] training loss: 0.00004480
INFO:root:[139,   750] training loss: 0.00082427
INFO:root:[139,   800] training loss: 0.00044235
INFO:root:[139,   850] training loss: 0.00034856
INFO:root:[139,   900] training loss: 0.00431095
INFO:root:[139,   950] training loss: 0.00160539
INFO:root:[139,  1000] training loss: 0.00005065
INFO:root:[139,  1050] training loss: 0.00003380
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9023    0.8593    0.8803      1720
   Telophase     0.8314    0.7500    0.7886      1032
           S     0.4286    0.3750    0.4000         8
          G2     0.3220    0.7808    0.4560        73
   Metaphase     0.6622    0.7128    0.6865      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7887      3872
   macro avg     0.6876    0.7826    0.7159      3872
weighted avg     0.8073    0.7887    0.7952      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch139
INFO:root:[140,    50] training loss: 0.00784229
INFO:root:[140,   100] training loss: 0.00916140
INFO:root:[140,   150] training loss: 0.00765298
INFO:root:[140,   200] training loss: 0.00702939
INFO:root:[140,   250] training loss: 0.00685662
INFO:root:[140,   300] training loss: 0.00728583
INFO:root:[140,   350] training loss: 0.00588124
INFO:root:[140,   400] training loss: 0.00001086
INFO:root:[140,   450] training loss: 0.00001168
INFO:root:[140,   500] training loss: 0.00003417
INFO:root:[140,   550] training loss: 0.00020626
INFO:root:[140,   600] training loss: 0.00017946
INFO:root:[140,   650] training loss: 0.00005125
INFO:root:[140,   700] training loss: 0.00003915
INFO:root:[140,   750] training loss: 0.00093083
INFO:root:[140,   800] training loss: 0.00085211
INFO:root:[140,   850] training loss: 0.00070286
INFO:root:[140,   900] training loss: 0.00364183
INFO:root:[140,   950] training loss: 0.00162822
INFO:root:[140,  1000] training loss: 0.00005306
INFO:root:[140,  1050] training loss: 0.00003428
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9069    0.8500    0.8776      1720
   Telophase     0.8339    0.7539    0.7919      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3274    0.7534    0.4564        73
   Metaphase     0.6550    0.7253    0.6884      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7885      3872
   macro avg     0.6807    0.7797    0.7127      3872
weighted avg     0.8081    0.7885    0.7953      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch140
INFO:root:[141,    50] training loss: 0.00725713
INFO:root:[141,   100] training loss: 0.00753213
INFO:root:[141,   150] training loss: 0.00693359
INFO:root:[141,   200] training loss: 0.00673444
INFO:root:[141,   250] training loss: 0.00707583
INFO:root:[141,   300] training loss: 0.00721113
INFO:root:[141,   350] training loss: 0.00606521
INFO:root:[141,   400] training loss: 0.00000916
INFO:root:[141,   450] training loss: 0.00001314
INFO:root:[141,   500] training loss: 0.00004374
INFO:root:[141,   550] training loss: 0.00024086
INFO:root:[141,   600] training loss: 0.00019992
INFO:root:[141,   650] training loss: 0.00003798
INFO:root:[141,   700] training loss: 0.00004751
INFO:root:[141,   750] training loss: 0.00068677
INFO:root:[141,   800] training loss: 0.00069363
INFO:root:[141,   850] training loss: 0.00057040
INFO:root:[141,   900] training loss: 0.00349584
INFO:root:[141,   950] training loss: 0.00147967
INFO:root:[141,  1000] training loss: 0.00004873
INFO:root:[141,  1050] training loss: 0.00003515
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9063    0.8488    0.8766      1720
   Telophase     0.8355    0.7578    0.7947      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3313    0.7397    0.4576        73
   Metaphase     0.6542    0.7263    0.6884      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7890      3872
   macro avg     0.6813    0.7782    0.7132      3872
weighted avg     0.8081    0.7890    0.7956      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch141
INFO:root:[142,    50] training loss: 0.00700459
INFO:root:[142,   100] training loss: 0.00737584
INFO:root:[142,   150] training loss: 0.00733961
INFO:root:[142,   200] training loss: 0.00714009
INFO:root:[142,   250] training loss: 0.00724000
INFO:root:[142,   300] training loss: 0.00731367
INFO:root:[142,   350] training loss: 0.00586074
INFO:root:[142,   400] training loss: 0.00000941
INFO:root:[142,   450] training loss: 0.00002088
INFO:root:[142,   500] training loss: 0.00003378
INFO:root:[142,   550] training loss: 0.00024742
INFO:root:[142,   600] training loss: 0.00015922
INFO:root:[142,   650] training loss: 0.00003499
INFO:root:[142,   700] training loss: 0.00003965
INFO:root:[142,   750] training loss: 0.00076653
INFO:root:[142,   800] training loss: 0.00089467
INFO:root:[142,   850] training loss: 0.00059488
INFO:root:[142,   900] training loss: 0.00361557
INFO:root:[142,   950] training loss: 0.00142860
INFO:root:[142,  1000] training loss: 0.00005301
INFO:root:[142,  1050] training loss: 0.00003318
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9073    0.8477    0.8765      1720
   Telophase     0.8388    0.7665    0.8010      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3484    0.7397    0.4737        73
   Metaphase     0.6531    0.7282    0.6886      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7913      3872
   macro avg     0.6842    0.7796    0.7164      3872
weighted avg     0.8095    0.7913    0.7976      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch142
INFO:root:[143,    50] training loss: 0.00741615
INFO:root:[143,   100] training loss: 0.00734806
INFO:root:[143,   150] training loss: 0.00664940
INFO:root:[143,   200] training loss: 0.00681184
INFO:root:[143,   250] training loss: 0.00668631
INFO:root:[143,   300] training loss: 0.00716135
INFO:root:[143,   350] training loss: 0.00579248
INFO:root:[143,   400] training loss: 0.00000885
INFO:root:[143,   450] training loss: 0.00001255
INFO:root:[143,   500] training loss: 0.00004252
INFO:root:[143,   550] training loss: 0.00026475
INFO:root:[143,   600] training loss: 0.00019726
INFO:root:[143,   650] training loss: 0.00003246
INFO:root:[143,   700] training loss: 0.00002869
INFO:root:[143,   750] training loss: 0.00062744
INFO:root:[143,   800] training loss: 0.00055664
INFO:root:[143,   850] training loss: 0.00049934
INFO:root:[143,   900] training loss: 0.00336854
INFO:root:[143,   950] training loss: 0.00169824
INFO:root:[143,  1000] training loss: 0.00007146
INFO:root:[143,  1050] training loss: 0.00004306
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9080    0.8494    0.8777      1720
   Telophase     0.8378    0.7655    0.8000      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3529    0.7397    0.4779        73
   Metaphase     0.6539    0.7292    0.6895      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7921      3872
   macro avg     0.6849    0.7798    0.7172      3872
weighted avg     0.8098    0.7921    0.7982      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch143
INFO:root:[144,    50] training loss: 0.00725118
INFO:root:[144,   100] training loss: 0.00694707
INFO:root:[144,   150] training loss: 0.00685334
INFO:root:[144,   200] training loss: 0.00774707
INFO:root:[144,   250] training loss: 0.00687564
INFO:root:[144,   300] training loss: 0.00722486
INFO:root:[144,   350] training loss: 0.00583620
INFO:root:[144,   400] training loss: 0.00001047
INFO:root:[144,   450] training loss: 0.00001371
INFO:root:[144,   500] training loss: 0.00004496
INFO:root:[144,   550] training loss: 0.00021593
INFO:root:[144,   600] training loss: 0.00022347
INFO:root:[144,   650] training loss: 0.00002735
INFO:root:[144,   700] training loss: 0.00003594
INFO:root:[144,   750] training loss: 0.00059480
INFO:root:[144,   800] training loss: 0.00062993
INFO:root:[144,   850] training loss: 0.00052438
INFO:root:[144,   900] training loss: 0.00349665
INFO:root:[144,   950] training loss: 0.00166843
INFO:root:[144,  1000] training loss: 0.00006020
INFO:root:[144,  1050] training loss: 0.00004227
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9111    0.8459    0.8773      1720
   Telophase     0.8369    0.7655    0.7996      1032
           S     0.4286    0.3750    0.4000         8
          G2     0.3548    0.7534    0.4825        73
   Metaphase     0.6535    0.7350    0.6919      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7924      3872
   macro avg     0.6931    0.7821    0.7216      3872
weighted avg     0.8110    0.7924    0.7987      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch144
INFO:root:[145,    50] training loss: 0.00702139
INFO:root:[145,   100] training loss: 0.00768730
INFO:root:[145,   150] training loss: 0.00713725
INFO:root:[145,   200] training loss: 0.00727416
INFO:root:[145,   250] training loss: 0.00703499
INFO:root:[145,   300] training loss: 0.00771679
INFO:root:[145,   350] training loss: 0.00607006
INFO:root:[145,   400] training loss: 0.00001130
INFO:root:[145,   450] training loss: 0.00001889
INFO:root:[145,   500] training loss: 0.00004793
INFO:root:[145,   550] training loss: 0.00025491
INFO:root:[145,   600] training loss: 0.00021165
INFO:root:[145,   650] training loss: 0.00003381
INFO:root:[145,   700] training loss: 0.00003500
INFO:root:[145,   750] training loss: 0.00056294
INFO:root:[145,   800] training loss: 0.00054156
INFO:root:[145,   850] training loss: 0.00052255
INFO:root:[145,   900] training loss: 0.00361360
INFO:root:[145,   950] training loss: 0.00158499
INFO:root:[145,  1000] training loss: 0.00007088
INFO:root:[145,  1050] training loss: 0.00003588
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9105    0.8459    0.8770      1720
   Telophase     0.8370    0.7665    0.8002      1032
           S     0.4286    0.3750    0.4000         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6540    0.7331    0.6913      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7921      3872
   macro avg     0.6924    0.7820    0.7210      3872
weighted avg     0.8108    0.7921    0.7985      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch145
INFO:root:[146,    50] training loss: 0.00701399
INFO:root:[146,   100] training loss: 0.00743778
INFO:root:[146,   150] training loss: 0.00693798
INFO:root:[146,   200] training loss: 0.00682161
INFO:root:[146,   250] training loss: 0.00646309
INFO:root:[146,   300] training loss: 0.00737669
INFO:root:[146,   350] training loss: 0.00597495
INFO:root:[146,   400] training loss: 0.00000990
INFO:root:[146,   450] training loss: 0.00001350
INFO:root:[146,   500] training loss: 0.00006679
INFO:root:[146,   550] training loss: 0.00024419
INFO:root:[146,   600] training loss: 0.00027002
INFO:root:[146,   650] training loss: 0.00003251
INFO:root:[146,   700] training loss: 0.00002672
INFO:root:[146,   750] training loss: 0.00058986
INFO:root:[146,   800] training loss: 0.00066832
INFO:root:[146,   850] training loss: 0.00050879
INFO:root:[146,   900] training loss: 0.00338944
INFO:root:[146,   950] training loss: 0.00142277
INFO:root:[146,  1000] training loss: 0.00009159
INFO:root:[146,  1050] training loss: 0.00005004
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9095    0.8471    0.8772      1720
   Telophase     0.8385    0.7645    0.7998      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6537    0.7321    0.6907      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7918      3872
   macro avg     0.6848    0.7817    0.7173      3872
weighted avg     0.8106    0.7918    0.7983      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch146
INFO:root:[147,    50] training loss: 0.00677308
INFO:root:[147,   100] training loss: 0.00756626
INFO:root:[147,   150] training loss: 0.00688779
INFO:root:[147,   200] training loss: 0.00727881
INFO:root:[147,   250] training loss: 0.00666700
INFO:root:[147,   300] training loss: 0.00752638
INFO:root:[147,   350] training loss: 0.00609168
INFO:root:[147,   400] training loss: 0.00001032
INFO:root:[147,   450] training loss: 0.00001460
INFO:root:[147,   500] training loss: 0.00003895
INFO:root:[147,   550] training loss: 0.00028433
INFO:root:[147,   600] training loss: 0.00014585
INFO:root:[147,   650] training loss: 0.00004141
INFO:root:[147,   700] training loss: 0.00002641
INFO:root:[147,   750] training loss: 0.00052861
INFO:root:[147,   800] training loss: 0.00053905
INFO:root:[147,   850] training loss: 0.00048675
INFO:root:[147,   900] training loss: 0.00382025
INFO:root:[147,   950] training loss: 0.00145508
INFO:root:[147,  1000] training loss: 0.00005554
INFO:root:[147,  1050] training loss: 0.00004679
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9075    0.8500    0.8778      1720
   Telophase     0.8417    0.7626    0.8002      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6563    0.7331    0.6926      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7929      3872
   macro avg     0.6854    0.7820    0.7177      3872
weighted avg     0.8112    0.7929    0.7991      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch147
INFO:root:[148,    50] training loss: 0.00752085
INFO:root:[148,   100] training loss: 0.00696423
INFO:root:[148,   150] training loss: 0.00651299
INFO:root:[148,   200] training loss: 0.00672444
INFO:root:[148,   250] training loss: 0.00687378
INFO:root:[148,   300] training loss: 0.00765007
INFO:root:[148,   350] training loss: 0.00619557
INFO:root:[148,   400] training loss: 0.00001007
INFO:root:[148,   450] training loss: 0.00002805
INFO:root:[148,   500] training loss: 0.00003477
INFO:root:[148,   550] training loss: 0.00024270
INFO:root:[148,   600] training loss: 0.00014892
INFO:root:[148,   650] training loss: 0.00003080
INFO:root:[148,   700] training loss: 0.00003725
INFO:root:[148,   750] training loss: 0.00047490
INFO:root:[148,   800] training loss: 0.00048597
INFO:root:[148,   850] training loss: 0.00040564
INFO:root:[148,   900] training loss: 0.00347074
INFO:root:[148,   950] training loss: 0.00137807
INFO:root:[148,  1000] training loss: 0.00005916
INFO:root:[148,  1050] training loss: 0.00005973
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9085    0.8483    0.8773      1720
   Telophase     0.8373    0.7578    0.7955      1032
           S     0.4286    0.3750    0.4000         8
          G2     0.3522    0.7671    0.4828        73
   Metaphase     0.6517    0.7311    0.6892      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6921    0.7828    0.7207      3872
weighted avg     0.8094    0.7905    0.7969      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch148
INFO:root:[149,    50] training loss: 0.00685663
INFO:root:[149,   100] training loss: 0.00700409
INFO:root:[149,   150] training loss: 0.00677451
INFO:root:[149,   200] training loss: 0.00882288
INFO:root:[149,   250] training loss: 0.00694327
INFO:root:[149,   300] training loss: 0.00776166
INFO:root:[149,   350] training loss: 0.00591774
INFO:root:[149,   400] training loss: 0.00001138
INFO:root:[149,   450] training loss: 0.00001064
INFO:root:[149,   500] training loss: 0.00003635
INFO:root:[149,   550] training loss: 0.00023303
INFO:root:[149,   600] training loss: 0.00019501
INFO:root:[149,   650] training loss: 0.00002626
INFO:root:[149,   700] training loss: 0.00003291
INFO:root:[149,   750] training loss: 0.00058442
INFO:root:[149,   800] training loss: 0.00052438
INFO:root:[149,   850] training loss: 0.00044367
INFO:root:[149,   900] training loss: 0.00366551
INFO:root:[149,   950] training loss: 0.00123033
INFO:root:[149,  1000] training loss: 0.00007212
INFO:root:[149,  1050] training loss: 0.00003904
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9090    0.8477    0.8773      1720
   Telophase     0.8395    0.7655    0.8008      1032
           S     0.4286    0.3750    0.4000         8
          G2     0.3567    0.7671    0.4870        73
   Metaphase     0.6543    0.7321    0.6910      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7926      3872
   macro avg     0.6935    0.7839    0.7223      3872
weighted avg     0.8110    0.7926    0.7989      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch149
INFO:root:[150,    50] training loss: 0.00680944
INFO:root:[150,   100] training loss: 0.00828230
INFO:root:[150,   150] training loss: 0.00723059
INFO:root:[150,   200] training loss: 0.00673499
INFO:root:[150,   250] training loss: 0.00670570
INFO:root:[150,   300] training loss: 0.00718934
INFO:root:[150,   350] training loss: 0.00578937
INFO:root:[150,   400] training loss: 0.00001078
INFO:root:[150,   450] training loss: 0.00001552
INFO:root:[150,   500] training loss: 0.00003214
INFO:root:[150,   550] training loss: 0.00026719
INFO:root:[150,   600] training loss: 0.00020000
INFO:root:[150,   650] training loss: 0.00003954
INFO:root:[150,   700] training loss: 0.00002425
INFO:root:[150,   750] training loss: 0.00053820
INFO:root:[150,   800] training loss: 0.00049970
INFO:root:[150,   850] training loss: 0.00044360
INFO:root:[150,   900] training loss: 0.00426488
INFO:root:[150,   950] training loss: 0.00137336
INFO:root:[150,  1000] training loss: 0.00005564
INFO:root:[150,  1050] training loss: 0.00005441
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9090    0.8477    0.8773      1720
   Telophase     0.8419    0.7636    0.8008      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6546    0.7350    0.6925      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7926      3872
   macro avg     0.6854    0.7821    0.7177      3872
weighted avg     0.8115    0.7926    0.7990      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch150
INFO:root:[151,    50] training loss: 0.00740148
INFO:root:[151,   100] training loss: 0.00706647
INFO:root:[151,   150] training loss: 0.00679043
INFO:root:[151,   200] training loss: 0.00684981
INFO:root:[151,   250] training loss: 0.00636276
INFO:root:[151,   300] training loss: 0.00739716
INFO:root:[151,   350] training loss: 0.00606511
INFO:root:[151,   400] training loss: 0.00001093
INFO:root:[151,   450] training loss: 0.00001201
INFO:root:[151,   500] training loss: 0.00003002
INFO:root:[151,   550] training loss: 0.00035337
INFO:root:[151,   600] training loss: 0.00015918
INFO:root:[151,   650] training loss: 0.00003621
INFO:root:[151,   700] training loss: 0.00002779
INFO:root:[151,   750] training loss: 0.00047807
INFO:root:[151,   800] training loss: 0.00047752
INFO:root:[151,   850] training loss: 0.00047964
INFO:root:[151,   900] training loss: 0.00381050
INFO:root:[151,   950] training loss: 0.00267408
INFO:root:[151,  1000] training loss: 0.00005530
INFO:root:[151,  1050] training loss: 0.00003927
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9089    0.8471    0.8769      1720
   Telophase     0.8412    0.7645    0.8010      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6543    0.7340    0.6919      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7924      3872
   macro avg     0.6852    0.7820    0.7176      3872
weighted avg     0.8112    0.7924    0.7988      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch151
INFO:root:[152,    50] training loss: 0.00668869
INFO:root:[152,   100] training loss: 0.00716522
INFO:root:[152,   150] training loss: 0.00690413
INFO:root:[152,   200] training loss: 0.00657138
INFO:root:[152,   250] training loss: 0.00668707
INFO:root:[152,   300] training loss: 0.00702900
INFO:root:[152,   350] training loss: 0.00583999
INFO:root:[152,   400] training loss: 0.00001284
INFO:root:[152,   450] training loss: 0.00001703
INFO:root:[152,   500] training loss: 0.00003555
INFO:root:[152,   550] training loss: 0.00017875
INFO:root:[152,   600] training loss: 0.00017695
INFO:root:[152,   650] training loss: 0.00003428
INFO:root:[152,   700] training loss: 0.00003631
INFO:root:[152,   750] training loss: 0.00055394
INFO:root:[152,   800] training loss: 0.00050171
INFO:root:[152,   850] training loss: 0.00040632
INFO:root:[152,   900] training loss: 0.00379346
INFO:root:[152,   950] training loss: 0.00194261
INFO:root:[152,  1000] training loss: 0.00007142
INFO:root:[152,  1050] training loss: 0.00004720
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9089    0.8465    0.8766      1720
   Telophase     0.8412    0.7645    0.8010      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6537    0.7340    0.6916      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7921      3872
   macro avg     0.6851    0.7819    0.7175      3872
weighted avg     0.8110    0.7921    0.7985      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch152
INFO:root:[153,    50] training loss: 0.00714438
INFO:root:[153,   100] training loss: 0.00764863
INFO:root:[153,   150] training loss: 0.00726318
INFO:root:[153,   200] training loss: 0.00657297
INFO:root:[153,   250] training loss: 0.00667514
INFO:root:[153,   300] training loss: 0.00768541
INFO:root:[153,   350] training loss: 0.00591384
INFO:root:[153,   400] training loss: 0.00000957
INFO:root:[153,   450] training loss: 0.00001342
INFO:root:[153,   500] training loss: 0.00006809
INFO:root:[153,   550] training loss: 0.00020952
INFO:root:[153,   600] training loss: 0.00019567
INFO:root:[153,   650] training loss: 0.00002959
INFO:root:[153,   700] training loss: 0.00003433
INFO:root:[153,   750] training loss: 0.00048784
INFO:root:[153,   800] training loss: 0.00048854
INFO:root:[153,   850] training loss: 0.00047048
INFO:root:[153,   900] training loss: 0.00342506
INFO:root:[153,   950] training loss: 0.00174897
INFO:root:[153,  1000] training loss: 0.00005741
INFO:root:[153,  1050] training loss: 0.00003988
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9087    0.8448    0.8756      1720
   Telophase     0.8412    0.7645    0.8010      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6521    0.7340    0.6906      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7913      3872
   macro avg     0.6848    0.7817    0.7172      3872
weighted avg     0.8105    0.7913    0.7978      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch153
INFO:root:[154,    50] training loss: 0.00671353
INFO:root:[154,   100] training loss: 0.00677933
INFO:root:[154,   150] training loss: 0.00687438
INFO:root:[154,   200] training loss: 0.00678904
INFO:root:[154,   250] training loss: 0.00741341
INFO:root:[154,   300] training loss: 0.00751663
INFO:root:[154,   350] training loss: 0.00713518
INFO:root:[154,   400] training loss: 0.00001082
INFO:root:[154,   450] training loss: 0.00001446
INFO:root:[154,   500] training loss: 0.00002876
INFO:root:[154,   550] training loss: 0.00027202
INFO:root:[154,   600] training loss: 0.00013727
INFO:root:[154,   650] training loss: 0.00003453
INFO:root:[154,   700] training loss: 0.00002583
INFO:root:[154,   750] training loss: 0.00048234
INFO:root:[154,   800] training loss: 0.00048034
INFO:root:[154,   850] training loss: 0.00055908
INFO:root:[154,   900] training loss: 0.00336874
INFO:root:[154,   950] training loss: 0.00170894
INFO:root:[154,  1000] training loss: 0.00005065
INFO:root:[154,  1050] training loss: 0.00004771
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9094    0.8459    0.8765      1720
   Telophase     0.8412    0.7645    0.8010      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6535    0.7350    0.6919      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7921      3872
   macro avg     0.6851    0.7820    0.7175      3872
weighted avg     0.8112    0.7921    0.7986      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch154
INFO:root:[155,    50] training loss: 0.00703396
INFO:root:[155,   100] training loss: 0.00736645
INFO:root:[155,   150] training loss: 0.00665816
INFO:root:[155,   200] training loss: 0.00727915
INFO:root:[155,   250] training loss: 0.00685381
INFO:root:[155,   300] training loss: 0.00765459
INFO:root:[155,   350] training loss: 0.00543122
INFO:root:[155,   400] training loss: 0.00000949
INFO:root:[155,   450] training loss: 0.00001157
INFO:root:[155,   500] training loss: 0.00002873
INFO:root:[155,   550] training loss: 0.00028460
INFO:root:[155,   600] training loss: 0.00014929
INFO:root:[155,   650] training loss: 0.00002463
INFO:root:[155,   700] training loss: 0.00002369
INFO:root:[155,   750] training loss: 0.00049378
INFO:root:[155,   800] training loss: 0.00053880
INFO:root:[155,   850] training loss: 0.00049211
INFO:root:[155,   900] training loss: 0.00340725
INFO:root:[155,   950] training loss: 0.00183425
INFO:root:[155,  1000] training loss: 0.00005905
INFO:root:[155,  1050] training loss: 0.00005927
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9093    0.8448    0.8758      1720
   Telophase     0.8408    0.7626    0.7998      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6512    0.7350    0.6906      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7911      3872
   macro avg     0.6848    0.7815    0.7171      3872
weighted avg     0.8104    0.7911    0.7976      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch155
INFO:root:[156,    50] training loss: 0.00672656
INFO:root:[156,   100] training loss: 0.00720348
INFO:root:[156,   150] training loss: 0.00720561
INFO:root:[156,   200] training loss: 0.00705945
INFO:root:[156,   250] training loss: 0.00709491
INFO:root:[156,   300] training loss: 0.00728287
INFO:root:[156,   350] training loss: 0.00562986
INFO:root:[156,   400] training loss: 0.00001603
INFO:root:[156,   450] training loss: 0.00001330
INFO:root:[156,   500] training loss: 0.00003754
INFO:root:[156,   550] training loss: 0.00017636
INFO:root:[156,   600] training loss: 0.00013789
INFO:root:[156,   650] training loss: 0.00005428
INFO:root:[156,   700] training loss: 0.00003344
INFO:root:[156,   750] training loss: 0.00052239
INFO:root:[156,   800] training loss: 0.00055722
INFO:root:[156,   850] training loss: 0.00043801
INFO:root:[156,   900] training loss: 0.00363828
INFO:root:[156,   950] training loss: 0.00152919
INFO:root:[156,  1000] training loss: 0.00004298
INFO:root:[156,  1050] training loss: 0.00003654
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9093    0.8448    0.8758      1720
   Telophase     0.8385    0.7645    0.7998      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6515    0.7321    0.6894      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7908      3872
   macro avg     0.6845    0.7814    0.7169      3872
weighted avg     0.8099    0.7908    0.7973      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch156
INFO:root:[157,    50] training loss: 0.00706011
INFO:root:[157,   100] training loss: 0.00747627
INFO:root:[157,   150] training loss: 0.00672059
INFO:root:[157,   200] training loss: 0.00713822
INFO:root:[157,   250] training loss: 0.00678156
INFO:root:[157,   300] training loss: 0.00808283
INFO:root:[157,   350] training loss: 0.00586702
INFO:root:[157,   400] training loss: 0.00001034
INFO:root:[157,   450] training loss: 0.00001131
INFO:root:[157,   500] training loss: 0.00004117
INFO:root:[157,   550] training loss: 0.00022793
INFO:root:[157,   600] training loss: 0.00015034
INFO:root:[157,   650] training loss: 0.00002715
INFO:root:[157,   700] training loss: 0.00002779
INFO:root:[157,   750] training loss: 0.00055087
INFO:root:[157,   800] training loss: 0.00048500
INFO:root:[157,   850] training loss: 0.00045489
INFO:root:[157,   900] training loss: 0.00361332
INFO:root:[157,   950] training loss: 0.00185305
INFO:root:[157,  1000] training loss: 0.00004651
INFO:root:[157,  1050] training loss: 0.00004610
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9093    0.8448    0.8758      1720
   Telophase     0.8406    0.7616    0.7992      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6507    0.7350    0.6903      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7908      3872
   macro avg     0.6847    0.7814    0.7169      3872
weighted avg     0.8102    0.7908    0.7974      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch157
INFO:root:[158,    50] training loss: 0.00709389
INFO:root:[158,   100] training loss: 0.00876851
INFO:root:[158,   150] training loss: 0.00676033
INFO:root:[158,   200] training loss: 0.00676100
INFO:root:[158,   250] training loss: 0.00687522
INFO:root:[158,   300] training loss: 0.00736057
INFO:root:[158,   350] training loss: 0.00577635
INFO:root:[158,   400] training loss: 0.00001094
INFO:root:[158,   450] training loss: 0.00001525
INFO:root:[158,   500] training loss: 0.00003725
INFO:root:[158,   550] training loss: 0.00021274
INFO:root:[158,   600] training loss: 0.00020962
INFO:root:[158,   650] training loss: 0.00002748
INFO:root:[158,   700] training loss: 0.00003823
INFO:root:[158,   750] training loss: 0.00046994
INFO:root:[158,   800] training loss: 0.00052245
INFO:root:[158,   850] training loss: 0.00054555
INFO:root:[158,   900] training loss: 0.00339863
INFO:root:[158,   950] training loss: 0.00149774
INFO:root:[158,  1000] training loss: 0.00004682
INFO:root:[158,  1050] training loss: 0.00003087
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9098    0.8448    0.8761      1720
   Telophase     0.8415    0.7616    0.7996      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6513    0.7369    0.6915      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7913      3872
   macro avg     0.6849    0.7817    0.7172      3872
weighted avg     0.8109    0.7913    0.7979      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch158
INFO:root:[159,    50] training loss: 0.00774603
INFO:root:[159,   100] training loss: 0.00725180
INFO:root:[159,   150] training loss: 0.00724526
INFO:root:[159,   200] training loss: 0.00702691
INFO:root:[159,   250] training loss: 0.00691909
INFO:root:[159,   300] training loss: 0.00711412
INFO:root:[159,   350] training loss: 0.00640204
INFO:root:[159,   400] training loss: 0.00001154
INFO:root:[159,   450] training loss: 0.00001227
INFO:root:[159,   500] training loss: 0.00003864
INFO:root:[159,   550] training loss: 0.00022362
INFO:root:[159,   600] training loss: 0.00016471
INFO:root:[159,   650] training loss: 0.00002706
INFO:root:[159,   700] training loss: 0.00002515
INFO:root:[159,   750] training loss: 0.00044791
INFO:root:[159,   800] training loss: 0.00062108
INFO:root:[159,   850] training loss: 0.00043392
INFO:root:[159,   900] training loss: 0.00472148
INFO:root:[159,   950] training loss: 0.00153193
INFO:root:[159,  1000] training loss: 0.00004254
INFO:root:[159,  1050] training loss: 0.00003471
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9098    0.8448    0.8761      1720
   Telophase     0.8406    0.7616    0.7992      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6510    0.7360    0.6909      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7911      3872
   macro avg     0.6848    0.7815    0.7171      3872
weighted avg     0.8106    0.7911    0.7977      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch159
INFO:root:[160,    50] training loss: 0.00722531
INFO:root:[160,   100] training loss: 0.00731124
INFO:root:[160,   150] training loss: 0.00652849
INFO:root:[160,   200] training loss: 0.00689743
INFO:root:[160,   250] training loss: 0.00687680
INFO:root:[160,   300] training loss: 0.00724767
INFO:root:[160,   350] training loss: 0.00614045
INFO:root:[160,   400] training loss: 0.00000935
INFO:root:[160,   450] training loss: 0.00001303
INFO:root:[160,   500] training loss: 0.00004671
INFO:root:[160,   550] training loss: 0.00029304
INFO:root:[160,   600] training loss: 0.00015401
INFO:root:[160,   650] training loss: 0.00003065
INFO:root:[160,   700] training loss: 0.00002440
INFO:root:[160,   750] training loss: 0.00045103
INFO:root:[160,   800] training loss: 0.00050707
INFO:root:[160,   850] training loss: 0.00041781
INFO:root:[160,   900] training loss: 0.00365480
INFO:root:[160,   950] training loss: 0.00160154
INFO:root:[160,  1000] training loss: 0.00005109
INFO:root:[160,  1050] training loss: 0.00004174
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9098    0.8448    0.8761      1720
   Telophase     0.8397    0.7616    0.7988      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6507    0.7350    0.6903      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7908      3872
   macro avg     0.6846    0.7814    0.7169      3872
weighted avg     0.8102    0.7908    0.7974      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch160
INFO:root:[161,    50] training loss: 0.00703358
INFO:root:[161,   100] training loss: 0.00701116
INFO:root:[161,   150] training loss: 0.00651928
INFO:root:[161,   200] training loss: 0.00684708
INFO:root:[161,   250] training loss: 0.00660070
INFO:root:[161,   300] training loss: 0.00718232
INFO:root:[161,   350] training loss: 0.00591863
INFO:root:[161,   400] training loss: 0.00000948
INFO:root:[161,   450] training loss: 0.00001374
INFO:root:[161,   500] training loss: 0.00004433
INFO:root:[161,   550] training loss: 0.00028081
INFO:root:[161,   600] training loss: 0.00014491
INFO:root:[161,   650] training loss: 0.00003043
INFO:root:[161,   700] training loss: 0.00002745
INFO:root:[161,   750] training loss: 0.00046778
INFO:root:[161,   800] training loss: 0.00045396
INFO:root:[161,   850] training loss: 0.00046409
INFO:root:[161,   900] training loss: 0.00371414
INFO:root:[161,   950] training loss: 0.00220023
INFO:root:[161,  1000] training loss: 0.00006879
INFO:root:[161,  1050] training loss: 0.00003643
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9098    0.8448    0.8761      1720
   Telophase     0.8397    0.7616    0.7988      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6507    0.7350    0.6903      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7908      3872
   macro avg     0.6846    0.7814    0.7169      3872
weighted avg     0.8102    0.7908    0.7974      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch161
INFO:root:[162,    50] training loss: 0.00685722
INFO:root:[162,   100] training loss: 0.00722710
INFO:root:[162,   150] training loss: 0.00677269
INFO:root:[162,   200] training loss: 0.00676060
INFO:root:[162,   250] training loss: 0.00695343
INFO:root:[162,   300] training loss: 0.00706399
INFO:root:[162,   350] training loss: 0.00563138
INFO:root:[162,   400] training loss: 0.00001276
INFO:root:[162,   450] training loss: 0.00001386
INFO:root:[162,   500] training loss: 0.00004637
INFO:root:[162,   550] training loss: 0.00022473
INFO:root:[162,   600] training loss: 0.00015266
INFO:root:[162,   650] training loss: 0.00002654
INFO:root:[162,   700] training loss: 0.00002661
INFO:root:[162,   750] training loss: 0.00044910
INFO:root:[162,   800] training loss: 0.00049033
INFO:root:[162,   850] training loss: 0.00040194
INFO:root:[162,   900] training loss: 0.00313357
INFO:root:[162,   950] training loss: 0.00150019
INFO:root:[162,  1000] training loss: 0.00006712
INFO:root:[162,  1050] training loss: 0.00004579
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9104    0.8448    0.8764      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6507    0.7350    0.6903      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7908      3872
   macro avg     0.6846    0.7814    0.7169      3872
weighted avg     0.8103    0.7908    0.7974      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch162
INFO:root:[163,    50] training loss: 0.00683507
INFO:root:[163,   100] training loss: 0.00736470
INFO:root:[163,   150] training loss: 0.00652007
INFO:root:[163,   200] training loss: 0.00682323
INFO:root:[163,   250] training loss: 0.00666108
INFO:root:[163,   300] training loss: 0.00710148
INFO:root:[163,   350] training loss: 0.00576675
INFO:root:[163,   400] training loss: 0.00001165
INFO:root:[163,   450] training loss: 0.00001388
INFO:root:[163,   500] training loss: 0.00006001
INFO:root:[163,   550] training loss: 0.00028323
INFO:root:[163,   600] training loss: 0.00020358
INFO:root:[163,   650] training loss: 0.00003954
INFO:root:[163,   700] training loss: 0.00002679
INFO:root:[163,   750] training loss: 0.00046862
INFO:root:[163,   800] training loss: 0.00050586
INFO:root:[163,   850] training loss: 0.00046573
INFO:root:[163,   900] training loss: 0.00370601
INFO:root:[163,   950] training loss: 0.00140636
INFO:root:[163,  1000] training loss: 0.00005817
INFO:root:[163,  1050] training loss: 0.00003983
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9104    0.8448    0.8764      1720
   Telophase     0.8397    0.7616    0.7988      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6510    0.7360    0.6909      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7911      3872
   macro avg     0.6847    0.7815    0.7170      3872
weighted avg     0.8106    0.7911    0.7977      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch163
INFO:root:[164,    50] training loss: 0.00708973
INFO:root:[164,   100] training loss: 0.00703762
INFO:root:[164,   150] training loss: 0.00669633
INFO:root:[164,   200] training loss: 0.00773176
INFO:root:[164,   250] training loss: 0.00681617
INFO:root:[164,   300] training loss: 0.00696566
INFO:root:[164,   350] training loss: 0.00618463
INFO:root:[164,   400] training loss: 0.00000995
INFO:root:[164,   450] training loss: 0.00001139
INFO:root:[164,   500] training loss: 0.00004107
INFO:root:[164,   550] training loss: 0.00020974
INFO:root:[164,   600] training loss: 0.00017770
INFO:root:[164,   650] training loss: 0.00002590
INFO:root:[164,   700] training loss: 0.00002998
INFO:root:[164,   750] training loss: 0.00044738
INFO:root:[164,   800] training loss: 0.00052195
INFO:root:[164,   850] training loss: 0.00048346
INFO:root:[164,   900] training loss: 0.00347827
INFO:root:[164,   950] training loss: 0.00188896
INFO:root:[164,  1000] training loss: 0.00006104
INFO:root:[164,  1050] training loss: 0.00003930
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch164
INFO:root:[165,    50] training loss: 0.00707523
INFO:root:[165,   100] training loss: 0.00693831
INFO:root:[165,   150] training loss: 0.00671849
INFO:root:[165,   200] training loss: 0.00676094
INFO:root:[165,   250] training loss: 0.00682890
INFO:root:[165,   300] training loss: 0.00845723
INFO:root:[165,   350] training loss: 0.00624049
INFO:root:[165,   400] training loss: 0.00001011
INFO:root:[165,   450] training loss: 0.00001267
INFO:root:[165,   500] training loss: 0.00003934
INFO:root:[165,   550] training loss: 0.00022126
INFO:root:[165,   600] training loss: 0.00014888
INFO:root:[165,   650] training loss: 0.00003308
INFO:root:[165,   700] training loss: 0.00002465
INFO:root:[165,   750] training loss: 0.00047236
INFO:root:[165,   800] training loss: 0.00053673
INFO:root:[165,   850] training loss: 0.00049555
INFO:root:[165,   900] training loss: 0.00378225
INFO:root:[165,   950] training loss: 0.00135223
INFO:root:[165,  1000] training loss: 0.00005820
INFO:root:[165,  1050] training loss: 0.00003799
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch165
INFO:root:[166,    50] training loss: 0.00673198
INFO:root:[166,   100] training loss: 0.00772185
INFO:root:[166,   150] training loss: 0.00701157
INFO:root:[166,   200] training loss: 0.00717989
INFO:root:[166,   250] training loss: 0.00665579
INFO:root:[166,   300] training loss: 0.00725579
INFO:root:[166,   350] training loss: 0.00612827
INFO:root:[166,   400] training loss: 0.00001182
INFO:root:[166,   450] training loss: 0.00001483
INFO:root:[166,   500] training loss: 0.00004274
INFO:root:[166,   550] training loss: 0.00022365
INFO:root:[166,   600] training loss: 0.00014191
INFO:root:[166,   650] training loss: 0.00002271
INFO:root:[166,   700] training loss: 0.00002381
INFO:root:[166,   750] training loss: 0.00052168
INFO:root:[166,   800] training loss: 0.00055421
INFO:root:[166,   850] training loss: 0.00044669
INFO:root:[166,   900] training loss: 0.00424613
INFO:root:[166,   950] training loss: 0.00138092
INFO:root:[166,  1000] training loss: 0.00005626
INFO:root:[166,  1050] training loss: 0.00003870
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch166
INFO:root:[167,    50] training loss: 0.00696052
INFO:root:[167,   100] training loss: 0.00733571
INFO:root:[167,   150] training loss: 0.00718211
INFO:root:[167,   200] training loss: 0.00718827
INFO:root:[167,   250] training loss: 0.00748438
INFO:root:[167,   300] training loss: 0.00703292
INFO:root:[167,   350] training loss: 0.00580288
INFO:root:[167,   400] training loss: 0.00000922
INFO:root:[167,   450] training loss: 0.00001199
INFO:root:[167,   500] training loss: 0.00005199
INFO:root:[167,   550] training loss: 0.00021187
INFO:root:[167,   600] training loss: 0.00025883
INFO:root:[167,   650] training loss: 0.00002432
INFO:root:[167,   700] training loss: 0.00003907
INFO:root:[167,   750] training loss: 0.00045718
INFO:root:[167,   800] training loss: 0.00056389
INFO:root:[167,   850] training loss: 0.00040844
INFO:root:[167,   900] training loss: 0.00328164
INFO:root:[167,   950] training loss: 0.00179713
INFO:root:[167,  1000] training loss: 0.00005004
INFO:root:[167,  1050] training loss: 0.00004637
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch167
INFO:root:[168,    50] training loss: 0.00702394
INFO:root:[168,   100] training loss: 0.00730441
INFO:root:[168,   150] training loss: 0.00717082
INFO:root:[168,   200] training loss: 0.00663765
INFO:root:[168,   250] training loss: 0.00721020
INFO:root:[168,   300] training loss: 0.00771314
INFO:root:[168,   350] training loss: 0.00580414
INFO:root:[168,   400] training loss: 0.00000967
INFO:root:[168,   450] training loss: 0.00001448
INFO:root:[168,   500] training loss: 0.00003667
INFO:root:[168,   550] training loss: 0.00023935
INFO:root:[168,   600] training loss: 0.00016999
INFO:root:[168,   650] training loss: 0.00002931
INFO:root:[168,   700] training loss: 0.00002808
INFO:root:[168,   750] training loss: 0.00059728
INFO:root:[168,   800] training loss: 0.00047541
INFO:root:[168,   850] training loss: 0.00047188
INFO:root:[168,   900] training loss: 0.00349268
INFO:root:[168,   950] training loss: 0.00157018
INFO:root:[168,  1000] training loss: 0.00005202
INFO:root:[168,  1050] training loss: 0.00003593
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch168
INFO:root:[169,    50] training loss: 0.00715179
INFO:root:[169,   100] training loss: 0.00711977
INFO:root:[169,   150] training loss: 0.00654130
INFO:root:[169,   200] training loss: 0.00754827
INFO:root:[169,   250] training loss: 0.00733517
INFO:root:[169,   300] training loss: 0.00732198
INFO:root:[169,   350] training loss: 0.00585204
INFO:root:[169,   400] training loss: 0.00001020
INFO:root:[169,   450] training loss: 0.00001333
INFO:root:[169,   500] training loss: 0.00002817
INFO:root:[169,   550] training loss: 0.00019617
INFO:root:[169,   600] training loss: 0.00012396
INFO:root:[169,   650] training loss: 0.00005714
INFO:root:[169,   700] training loss: 0.00002189
INFO:root:[169,   750] training loss: 0.00048014
INFO:root:[169,   800] training loss: 0.00065858
INFO:root:[169,   850] training loss: 0.00045268
INFO:root:[169,   900] training loss: 0.00328431
INFO:root:[169,   950] training loss: 0.00144360
INFO:root:[169,  1000] training loss: 0.00004958
INFO:root:[169,  1050] training loss: 0.00004167
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch169
INFO:root:[170,    50] training loss: 0.00726994
INFO:root:[170,   100] training loss: 0.00701730
INFO:root:[170,   150] training loss: 0.00675727
INFO:root:[170,   200] training loss: 0.00673472
INFO:root:[170,   250] training loss: 0.00668613
INFO:root:[170,   300] training loss: 0.00711832
INFO:root:[170,   350] training loss: 0.00570521
INFO:root:[170,   400] training loss: 0.00001060
INFO:root:[170,   450] training loss: 0.00001160
INFO:root:[170,   500] training loss: 0.00008735
INFO:root:[170,   550] training loss: 0.00025960
INFO:root:[170,   600] training loss: 0.00018910
INFO:root:[170,   650] training loss: 0.00003807
INFO:root:[170,   700] training loss: 0.00002734
INFO:root:[170,   750] training loss: 0.00045600
INFO:root:[170,   800] training loss: 0.00055781
INFO:root:[170,   850] training loss: 0.00055494
INFO:root:[170,   900] training loss: 0.00318395
INFO:root:[170,   950] training loss: 0.00229808
INFO:root:[170,  1000] training loss: 0.00006196
INFO:root:[170,  1050] training loss: 0.00006460
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch170
INFO:root:[171,    50] training loss: 0.00684638
INFO:root:[171,   100] training loss: 0.00739728
INFO:root:[171,   150] training loss: 0.00648426
INFO:root:[171,   200] training loss: 0.00698869
INFO:root:[171,   250] training loss: 0.00726466
INFO:root:[171,   300] training loss: 0.00753713
INFO:root:[171,   350] training loss: 0.00557787
INFO:root:[171,   400] training loss: 0.00001067
INFO:root:[171,   450] training loss: 0.00001481
INFO:root:[171,   500] training loss: 0.00004973
INFO:root:[171,   550] training loss: 0.00026457
INFO:root:[171,   600] training loss: 0.00015302
INFO:root:[171,   650] training loss: 0.00003062
INFO:root:[171,   700] training loss: 0.00002945
INFO:root:[171,   750] training loss: 0.00048658
INFO:root:[171,   800] training loss: 0.00044978
INFO:root:[171,   850] training loss: 0.00047277
INFO:root:[171,   900] training loss: 0.00322597
INFO:root:[171,   950] training loss: 0.00141350
INFO:root:[171,  1000] training loss: 0.00006354
INFO:root:[171,  1050] training loss: 0.00003345
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch171
INFO:root:[172,    50] training loss: 0.00734171
INFO:root:[172,   100] training loss: 0.00687244
INFO:root:[172,   150] training loss: 0.00700410
INFO:root:[172,   200] training loss: 0.00709915
INFO:root:[172,   250] training loss: 0.00651190
INFO:root:[172,   300] training loss: 0.00773703
INFO:root:[172,   350] training loss: 0.00675631
INFO:root:[172,   400] training loss: 0.00001175
INFO:root:[172,   450] training loss: 0.00001411
INFO:root:[172,   500] training loss: 0.00003028
INFO:root:[172,   550] training loss: 0.00027043
INFO:root:[172,   600] training loss: 0.00015663
INFO:root:[172,   650] training loss: 0.00002673
INFO:root:[172,   700] training loss: 0.00003396
INFO:root:[172,   750] training loss: 0.00050097
INFO:root:[172,   800] training loss: 0.00054787
INFO:root:[172,   850] training loss: 0.00051147
INFO:root:[172,   900] training loss: 0.00411272
INFO:root:[172,   950] training loss: 0.00160299
INFO:root:[172,  1000] training loss: 0.00005141
INFO:root:[172,  1050] training loss: 0.00003937
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch172
INFO:root:[173,    50] training loss: 0.00698726
INFO:root:[173,   100] training loss: 0.00746083
INFO:root:[173,   150] training loss: 0.00668485
INFO:root:[173,   200] training loss: 0.00666149
INFO:root:[173,   250] training loss: 0.00967005
INFO:root:[173,   300] training loss: 0.00718890
INFO:root:[173,   350] training loss: 0.00573872
INFO:root:[173,   400] training loss: 0.00001088
INFO:root:[173,   450] training loss: 0.00001262
INFO:root:[173,   500] training loss: 0.00003695
INFO:root:[173,   550] training loss: 0.00028228
INFO:root:[173,   600] training loss: 0.00014812
INFO:root:[173,   650] training loss: 0.00003901
INFO:root:[173,   700] training loss: 0.00003922
INFO:root:[173,   750] training loss: 0.00061365
INFO:root:[173,   800] training loss: 0.00050175
INFO:root:[173,   850] training loss: 0.00055110
INFO:root:[173,   900] training loss: 0.00423596
INFO:root:[173,   950] training loss: 0.00159433
INFO:root:[173,  1000] training loss: 0.00006446
INFO:root:[173,  1050] training loss: 0.00003788
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch173
INFO:root:[174,    50] training loss: 0.00737130
INFO:root:[174,   100] training loss: 0.00732207
INFO:root:[174,   150] training loss: 0.00689435
INFO:root:[174,   200] training loss: 0.00684335
INFO:root:[174,   250] training loss: 0.00679147
INFO:root:[174,   300] training loss: 0.00734686
INFO:root:[174,   350] training loss: 0.00584492
INFO:root:[174,   400] training loss: 0.00001090
INFO:root:[174,   450] training loss: 0.00001239
INFO:root:[174,   500] training loss: 0.00005350
INFO:root:[174,   550] training loss: 0.00029728
INFO:root:[174,   600] training loss: 0.00015184
INFO:root:[174,   650] training loss: 0.00002526
INFO:root:[174,   700] training loss: 0.00003180
INFO:root:[174,   750] training loss: 0.00048832
INFO:root:[174,   800] training loss: 0.00055379
INFO:root:[174,   850] training loss: 0.00046999
INFO:root:[174,   900] training loss: 0.00328138
INFO:root:[174,   950] training loss: 0.00184775
INFO:root:[174,  1000] training loss: 0.00008627
INFO:root:[174,  1050] training loss: 0.00006691
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch174
INFO:root:[175,    50] training loss: 0.00709931
INFO:root:[175,   100] training loss: 0.00720306
INFO:root:[175,   150] training loss: 0.00702070
INFO:root:[175,   200] training loss: 0.00722347
INFO:root:[175,   250] training loss: 0.00705601
INFO:root:[175,   300] training loss: 0.00706071
INFO:root:[175,   350] training loss: 0.00787073
INFO:root:[175,   400] training loss: 0.00000980
INFO:root:[175,   450] training loss: 0.00001561
INFO:root:[175,   500] training loss: 0.00005151
INFO:root:[175,   550] training loss: 0.00026500
INFO:root:[175,   600] training loss: 0.00018963
INFO:root:[175,   650] training loss: 0.00004051
INFO:root:[175,   700] training loss: 0.00002945
INFO:root:[175,   750] training loss: 0.00051918
INFO:root:[175,   800] training loss: 0.00050605
INFO:root:[175,   850] training loss: 0.00042923
INFO:root:[175,   900] training loss: 0.00370092
INFO:root:[175,   950] training loss: 0.00167109
INFO:root:[175,  1000] training loss: 0.00005692
INFO:root:[175,  1050] training loss: 0.00003800
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch175
INFO:root:[176,    50] training loss: 0.00689737
INFO:root:[176,   100] training loss: 0.00697441
INFO:root:[176,   150] training loss: 0.00657875
INFO:root:[176,   200] training loss: 0.00671016
INFO:root:[176,   250] training loss: 0.00651838
INFO:root:[176,   300] training loss: 0.00795234
INFO:root:[176,   350] training loss: 0.00607299
INFO:root:[176,   400] training loss: 0.00001089
INFO:root:[176,   450] training loss: 0.00001036
INFO:root:[176,   500] training loss: 0.00002420
INFO:root:[176,   550] training loss: 0.00021155
INFO:root:[176,   600] training loss: 0.00020336
INFO:root:[176,   650] training loss: 0.00002549
INFO:root:[176,   700] training loss: 0.00002724
INFO:root:[176,   750] training loss: 0.00045496
INFO:root:[176,   800] training loss: 0.00054520
INFO:root:[176,   850] training loss: 0.00054660
INFO:root:[176,   900] training loss: 0.00436619
INFO:root:[176,   950] training loss: 0.00258014
INFO:root:[176,  1000] training loss: 0.00005597
INFO:root:[176,  1050] training loss: 0.00003726
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch176
INFO:root:[177,    50] training loss: 0.00699886
INFO:root:[177,   100] training loss: 0.00753000
INFO:root:[177,   150] training loss: 0.00648309
INFO:root:[177,   200] training loss: 0.00648913
INFO:root:[177,   250] training loss: 0.00744430
INFO:root:[177,   300] training loss: 0.00730968
INFO:root:[177,   350] training loss: 0.00571393
INFO:root:[177,   400] training loss: 0.00001073
INFO:root:[177,   450] training loss: 0.00001260
INFO:root:[177,   500] training loss: 0.00003241
INFO:root:[177,   550] training loss: 0.00023649
INFO:root:[177,   600] training loss: 0.00015427
INFO:root:[177,   650] training loss: 0.00003874
INFO:root:[177,   700] training loss: 0.00003340
INFO:root:[177,   750] training loss: 0.00052220
INFO:root:[177,   800] training loss: 0.00063771
INFO:root:[177,   850] training loss: 0.00049808
INFO:root:[177,   900] training loss: 0.00358945
INFO:root:[177,   950] training loss: 0.00113848
INFO:root:[177,  1000] training loss: 0.00004898
INFO:root:[177,  1050] training loss: 0.00011180
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch177
INFO:root:[178,    50] training loss: 0.00720896
INFO:root:[178,   100] training loss: 0.00717253
INFO:root:[178,   150] training loss: 0.00684851
INFO:root:[178,   200] training loss: 0.00760236
INFO:root:[178,   250] training loss: 0.00719972
INFO:root:[178,   300] training loss: 0.00712932
INFO:root:[178,   350] training loss: 0.00601062
INFO:root:[178,   400] training loss: 0.00000995
INFO:root:[178,   450] training loss: 0.00001354
INFO:root:[178,   500] training loss: 0.00003446
INFO:root:[178,   550] training loss: 0.00026247
INFO:root:[178,   600] training loss: 0.00016505
INFO:root:[178,   650] training loss: 0.00003333
INFO:root:[178,   700] training loss: 0.00003503
INFO:root:[178,   750] training loss: 0.00048654
INFO:root:[178,   800] training loss: 0.00048469
INFO:root:[178,   850] training loss: 0.00051591
INFO:root:[178,   900] training loss: 0.00372727
INFO:root:[178,   950] training loss: 0.00139120
INFO:root:[178,  1000] training loss: 0.00004848
INFO:root:[178,  1050] training loss: 0.00003690
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch178
INFO:root:[179,    50] training loss: 0.00704596
INFO:root:[179,   100] training loss: 0.00816130
INFO:root:[179,   150] training loss: 0.00660396
INFO:root:[179,   200] training loss: 0.00885860
INFO:root:[179,   250] training loss: 0.00702586
INFO:root:[179,   300] training loss: 0.00744771
INFO:root:[179,   350] training loss: 0.00576624
INFO:root:[179,   400] training loss: 0.00001015
INFO:root:[179,   450] training loss: 0.00001544
INFO:root:[179,   500] training loss: 0.00003398
INFO:root:[179,   550] training loss: 0.00019166
INFO:root:[179,   600] training loss: 0.00018054
INFO:root:[179,   650] training loss: 0.00003937
INFO:root:[179,   700] training loss: 0.00002516
INFO:root:[179,   750] training loss: 0.00049540
INFO:root:[179,   800] training loss: 0.00074639
INFO:root:[179,   850] training loss: 0.00047400
INFO:root:[179,   900] training loss: 0.00338503
INFO:root:[179,   950] training loss: 0.00232758
INFO:root:[179,  1000] training loss: 0.00005275
INFO:root:[179,  1050] training loss: 0.00003521
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch179
INFO:root:[180,    50] training loss: 0.00702278
INFO:root:[180,   100] training loss: 0.00741383
INFO:root:[180,   150] training loss: 0.00671956
INFO:root:[180,   200] training loss: 0.00692325
INFO:root:[180,   250] training loss: 0.00720409
INFO:root:[180,   300] training loss: 0.00704772
INFO:root:[180,   350] training loss: 0.00584703
INFO:root:[180,   400] training loss: 0.00001051
INFO:root:[180,   450] training loss: 0.00001277
INFO:root:[180,   500] training loss: 0.00004633
INFO:root:[180,   550] training loss: 0.00021464
INFO:root:[180,   600] training loss: 0.00018254
INFO:root:[180,   650] training loss: 0.00002541
INFO:root:[180,   700] training loss: 0.00003265
INFO:root:[180,   750] training loss: 0.00062811
INFO:root:[180,   800] training loss: 0.00046028
INFO:root:[180,   850] training loss: 0.00055156
INFO:root:[180,   900] training loss: 0.00291404
INFO:root:[180,   950] training loss: 0.00135711
INFO:root:[180,  1000] training loss: 0.00004626
INFO:root:[180,  1050] training loss: 0.00003471
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch180
INFO:root:[181,    50] training loss: 0.00759079
INFO:root:[181,   100] training loss: 0.00671814
INFO:root:[181,   150] training loss: 0.00686060
INFO:root:[181,   200] training loss: 0.00716605
INFO:root:[181,   250] training loss: 0.00675977
INFO:root:[181,   300] training loss: 0.00703069
INFO:root:[181,   350] training loss: 0.00621884
INFO:root:[181,   400] training loss: 0.00001084
INFO:root:[181,   450] training loss: 0.00001364
INFO:root:[181,   500] training loss: 0.00003331
INFO:root:[181,   550] training loss: 0.00031084
INFO:root:[181,   600] training loss: 0.00013993
INFO:root:[181,   650] training loss: 0.00002963
INFO:root:[181,   700] training loss: 0.00002778
INFO:root:[181,   750] training loss: 0.00049957
INFO:root:[181,   800] training loss: 0.00048536
INFO:root:[181,   850] training loss: 0.00050580
INFO:root:[181,   900] training loss: 0.00378114
INFO:root:[181,   950] training loss: 0.00199093
INFO:root:[181,  1000] training loss: 0.00007620
INFO:root:[181,  1050] training loss: 0.00005518
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch181
INFO:root:[182,    50] training loss: 0.00818967
INFO:root:[182,   100] training loss: 0.00713630
INFO:root:[182,   150] training loss: 0.00864185
INFO:root:[182,   200] training loss: 0.00676918
INFO:root:[182,   250] training loss: 0.00672245
INFO:root:[182,   300] training loss: 0.00733337
INFO:root:[182,   350] training loss: 0.00628296
INFO:root:[182,   400] training loss: 0.00001000
INFO:root:[182,   450] training loss: 0.00001183
INFO:root:[182,   500] training loss: 0.00003669
INFO:root:[182,   550] training loss: 0.00019332
INFO:root:[182,   600] training loss: 0.00015747
INFO:root:[182,   650] training loss: 0.00003020
INFO:root:[182,   700] training loss: 0.00002997
INFO:root:[182,   750] training loss: 0.00053147
INFO:root:[182,   800] training loss: 0.00058829
INFO:root:[182,   850] training loss: 0.00047068
INFO:root:[182,   900] training loss: 0.00297766
INFO:root:[182,   950] training loss: 0.00151543
INFO:root:[182,  1000] training loss: 0.00007706
INFO:root:[182,  1050] training loss: 0.00003517
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch182
INFO:root:[183,    50] training loss: 0.00703351
INFO:root:[183,   100] training loss: 0.00718373
INFO:root:[183,   150] training loss: 0.00699054
INFO:root:[183,   200] training loss: 0.00698791
INFO:root:[183,   250] training loss: 0.00671298
INFO:root:[183,   300] training loss: 0.00718990
INFO:root:[183,   350] training loss: 0.00622483
INFO:root:[183,   400] training loss: 0.00001092
INFO:root:[183,   450] training loss: 0.00001233
INFO:root:[183,   500] training loss: 0.00004219
INFO:root:[183,   550] training loss: 0.00022974
INFO:root:[183,   600] training loss: 0.00019186
INFO:root:[183,   650] training loss: 0.00003061
INFO:root:[183,   700] training loss: 0.00002544
INFO:root:[183,   750] training loss: 0.00057953
INFO:root:[183,   800] training loss: 0.00044373
INFO:root:[183,   850] training loss: 0.00044978
INFO:root:[183,   900] training loss: 0.00350676
INFO:root:[183,   950] training loss: 0.00179728
INFO:root:[183,  1000] training loss: 0.00006984
INFO:root:[183,  1050] training loss: 0.00003988
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch183
INFO:root:[184,    50] training loss: 0.00694991
INFO:root:[184,   100] training loss: 0.00768812
INFO:root:[184,   150] training loss: 0.00964137
INFO:root:[184,   200] training loss: 0.00750763
INFO:root:[184,   250] training loss: 0.00669653
INFO:root:[184,   300] training loss: 0.00732822
INFO:root:[184,   350] training loss: 0.00639025
INFO:root:[184,   400] training loss: 0.00001110
INFO:root:[184,   450] training loss: 0.00001247
INFO:root:[184,   500] training loss: 0.00004306
INFO:root:[184,   550] training loss: 0.00021508
INFO:root:[184,   600] training loss: 0.00020431
INFO:root:[184,   650] training loss: 0.00002837
INFO:root:[184,   700] training loss: 0.00002671
INFO:root:[184,   750] training loss: 0.00052694
INFO:root:[184,   800] training loss: 0.00052182
INFO:root:[184,   850] training loss: 0.00042625
INFO:root:[184,   900] training loss: 0.00405065
INFO:root:[184,   950] training loss: 0.00129030
INFO:root:[184,  1000] training loss: 0.00005418
INFO:root:[184,  1050] training loss: 0.00005120
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch184
INFO:root:[185,    50] training loss: 0.00671335
INFO:root:[185,   100] training loss: 0.00741040
INFO:root:[185,   150] training loss: 0.00656882
INFO:root:[185,   200] training loss: 0.00664121
INFO:root:[185,   250] training loss: 0.00696207
INFO:root:[185,   300] training loss: 0.00714732
INFO:root:[185,   350] training loss: 0.00609145
INFO:root:[185,   400] training loss: 0.00001085
INFO:root:[185,   450] training loss: 0.00001298
INFO:root:[185,   500] training loss: 0.00002904
INFO:root:[185,   550] training loss: 0.00022267
INFO:root:[185,   600] training loss: 0.00014811
INFO:root:[185,   650] training loss: 0.00002841
INFO:root:[185,   700] training loss: 0.00002635
INFO:root:[185,   750] training loss: 0.00054238
INFO:root:[185,   800] training loss: 0.00062834
INFO:root:[185,   850] training loss: 0.00047563
INFO:root:[185,   900] training loss: 0.00352773
INFO:root:[185,   950] training loss: 0.00134716
INFO:root:[185,  1000] training loss: 0.00004659
INFO:root:[185,  1050] training loss: 0.00003411
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch185
INFO:root:[186,    50] training loss: 0.00706211
INFO:root:[186,   100] training loss: 0.00734878
INFO:root:[186,   150] training loss: 0.00875862
INFO:root:[186,   200] training loss: 0.00662071
INFO:root:[186,   250] training loss: 0.00705477
INFO:root:[186,   300] training loss: 0.00718201
INFO:root:[186,   350] training loss: 0.00589450
INFO:root:[186,   400] training loss: 0.00000991
INFO:root:[186,   450] training loss: 0.00001227
INFO:root:[186,   500] training loss: 0.00005262
INFO:root:[186,   550] training loss: 0.00023354
INFO:root:[186,   600] training loss: 0.00015620
INFO:root:[186,   650] training loss: 0.00002891
INFO:root:[186,   700] training loss: 0.00003565
INFO:root:[186,   750] training loss: 0.00040100
INFO:root:[186,   800] training loss: 0.00058599
INFO:root:[186,   850] training loss: 0.00058229
INFO:root:[186,   900] training loss: 0.00336996
INFO:root:[186,   950] training loss: 0.00265693
INFO:root:[186,  1000] training loss: 0.00005497
INFO:root:[186,  1050] training loss: 0.00003626
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch186
INFO:root:[187,    50] training loss: 0.00710048
INFO:root:[187,   100] training loss: 0.00719778
INFO:root:[187,   150] training loss: 0.00690830
INFO:root:[187,   200] training loss: 0.00757854
INFO:root:[187,   250] training loss: 0.00676788
INFO:root:[187,   300] training loss: 0.00700970
INFO:root:[187,   350] training loss: 0.00604408
INFO:root:[187,   400] training loss: 0.00001793
INFO:root:[187,   450] training loss: 0.00001357
INFO:root:[187,   500] training loss: 0.00004315
INFO:root:[187,   550] training loss: 0.00024936
INFO:root:[187,   600] training loss: 0.00016293
INFO:root:[187,   650] training loss: 0.00003150
INFO:root:[187,   700] training loss: 0.00002825
INFO:root:[187,   750] training loss: 0.00052029
INFO:root:[187,   800] training loss: 0.00056958
INFO:root:[187,   850] training loss: 0.00045520
INFO:root:[187,   900] training loss: 0.00294079
INFO:root:[187,   950] training loss: 0.00154170
INFO:root:[187,  1000] training loss: 0.00005766
INFO:root:[187,  1050] training loss: 0.00004075
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch187
INFO:root:[188,    50] training loss: 0.00701243
INFO:root:[188,   100] training loss: 0.00725771
INFO:root:[188,   150] training loss: 0.00661638
INFO:root:[188,   200] training loss: 0.00783607
INFO:root:[188,   250] training loss: 0.00698119
INFO:root:[188,   300] training loss: 0.00729961
INFO:root:[188,   350] training loss: 0.00557655
INFO:root:[188,   400] training loss: 0.00001065
INFO:root:[188,   450] training loss: 0.00001813
INFO:root:[188,   500] training loss: 0.00004274
INFO:root:[188,   550] training loss: 0.00022031
INFO:root:[188,   600] training loss: 0.00015726
INFO:root:[188,   650] training loss: 0.00002603
INFO:root:[188,   700] training loss: 0.00003702
INFO:root:[188,   750] training loss: 0.00054082
INFO:root:[188,   800] training loss: 0.00052852
INFO:root:[188,   850] training loss: 0.00049063
INFO:root:[188,   900] training loss: 0.00404269
INFO:root:[188,   950] training loss: 0.00146441
INFO:root:[188,  1000] training loss: 0.00004389
INFO:root:[188,  1050] training loss: 0.00003758
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch188
INFO:root:[189,    50] training loss: 0.00683107
INFO:root:[189,   100] training loss: 0.00711406
INFO:root:[189,   150] training loss: 0.00666961
INFO:root:[189,   200] training loss: 0.00712595
INFO:root:[189,   250] training loss: 0.00659349
INFO:root:[189,   300] training loss: 0.00731246
INFO:root:[189,   350] training loss: 0.00583428
INFO:root:[189,   400] training loss: 0.00001108
INFO:root:[189,   450] training loss: 0.00001340
INFO:root:[189,   500] training loss: 0.00005820
INFO:root:[189,   550] training loss: 0.00021254
INFO:root:[189,   600] training loss: 0.00016372
INFO:root:[189,   650] training loss: 0.00002786
INFO:root:[189,   700] training loss: 0.00002672
INFO:root:[189,   750] training loss: 0.00049620
INFO:root:[189,   800] training loss: 0.00050390
INFO:root:[189,   850] training loss: 0.00047153
INFO:root:[189,   900] training loss: 0.00320833
INFO:root:[189,   950] training loss: 0.00151141
INFO:root:[189,  1000] training loss: 0.00006210
INFO:root:[189,  1050] training loss: 0.00003564
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch189
INFO:root:[190,    50] training loss: 0.00738602
INFO:root:[190,   100] training loss: 0.00755342
INFO:root:[190,   150] training loss: 0.00674726
INFO:root:[190,   200] training loss: 0.00671460
INFO:root:[190,   250] training loss: 0.00661560
INFO:root:[190,   300] training loss: 0.00713243
INFO:root:[190,   350] training loss: 0.00642566
INFO:root:[190,   400] training loss: 0.00000862
INFO:root:[190,   450] training loss: 0.00001736
INFO:root:[190,   500] training loss: 0.00002464
INFO:root:[190,   550] training loss: 0.00019755
INFO:root:[190,   600] training loss: 0.00017338
INFO:root:[190,   650] training loss: 0.00002318
INFO:root:[190,   700] training loss: 0.00002659
INFO:root:[190,   750] training loss: 0.00054411
INFO:root:[190,   800] training loss: 0.00057389
INFO:root:[190,   850] training loss: 0.00046107
INFO:root:[190,   900] training loss: 0.00366581
INFO:root:[190,   950] training loss: 0.00159910
INFO:root:[190,  1000] training loss: 0.00004555
INFO:root:[190,  1050] training loss: 0.00004265
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch190
INFO:root:[191,    50] training loss: 0.00712784
INFO:root:[191,   100] training loss: 0.00726863
INFO:root:[191,   150] training loss: 0.00722949
INFO:root:[191,   200] training loss: 0.00645804
INFO:root:[191,   250] training loss: 0.00727653
INFO:root:[191,   300] training loss: 0.00701533
INFO:root:[191,   350] training loss: 0.00606985
INFO:root:[191,   400] training loss: 0.00001113
INFO:root:[191,   450] training loss: 0.00001262
INFO:root:[191,   500] training loss: 0.00004521
INFO:root:[191,   550] training loss: 0.00029397
INFO:root:[191,   600] training loss: 0.00016641
INFO:root:[191,   650] training loss: 0.00003345
INFO:root:[191,   700] training loss: 0.00003491
INFO:root:[191,   750] training loss: 0.00056926
INFO:root:[191,   800] training loss: 0.00056685
INFO:root:[191,   850] training loss: 0.00049377
INFO:root:[191,   900] training loss: 0.00352837
INFO:root:[191,   950] training loss: 0.00152300
INFO:root:[191,  1000] training loss: 0.00005392
INFO:root:[191,  1050] training loss: 0.00005032
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch191
INFO:root:[192,    50] training loss: 0.00698789
INFO:root:[192,   100] training loss: 0.00754349
INFO:root:[192,   150] training loss: 0.00702828
INFO:root:[192,   200] training loss: 0.00664450
INFO:root:[192,   250] training loss: 0.00751777
INFO:root:[192,   300] training loss: 0.00727084
INFO:root:[192,   350] training loss: 0.00564176
INFO:root:[192,   400] training loss: 0.00000953
INFO:root:[192,   450] training loss: 0.00001011
INFO:root:[192,   500] training loss: 0.00003068
INFO:root:[192,   550] training loss: 0.00048007
INFO:root:[192,   600] training loss: 0.00014484
INFO:root:[192,   650] training loss: 0.00002508
INFO:root:[192,   700] training loss: 0.00002289
INFO:root:[192,   750] training loss: 0.00047607
INFO:root:[192,   800] training loss: 0.00051612
INFO:root:[192,   850] training loss: 0.00059886
INFO:root:[192,   900] training loss: 0.00316982
INFO:root:[192,   950] training loss: 0.00139731
INFO:root:[192,  1000] training loss: 0.00005935
INFO:root:[192,  1050] training loss: 0.00003823
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch192
INFO:root:[193,    50] training loss: 0.00738739
INFO:root:[193,   100] training loss: 0.00751634
INFO:root:[193,   150] training loss: 0.00691318
INFO:root:[193,   200] training loss: 0.00676929
INFO:root:[193,   250] training loss: 0.00664016
INFO:root:[193,   300] training loss: 0.00695369
INFO:root:[193,   350] training loss: 0.00606697
INFO:root:[193,   400] training loss: 0.00000915
INFO:root:[193,   450] training loss: 0.00001362
INFO:root:[193,   500] training loss: 0.00003128
INFO:root:[193,   550] training loss: 0.00018071
INFO:root:[193,   600] training loss: 0.00014958
INFO:root:[193,   650] training loss: 0.00003356
INFO:root:[193,   700] training loss: 0.00002808
INFO:root:[193,   750] training loss: 0.00047515
INFO:root:[193,   800] training loss: 0.00055557
INFO:root:[193,   850] training loss: 0.00045759
INFO:root:[193,   900] training loss: 0.00372588
INFO:root:[193,   950] training loss: 0.00125003
INFO:root:[193,  1000] training loss: 0.00004392
INFO:root:[193,  1050] training loss: 0.00003289
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch193
INFO:root:[194,    50] training loss: 0.00722956
INFO:root:[194,   100] training loss: 0.00704948
INFO:root:[194,   150] training loss: 0.00709949
INFO:root:[194,   200] training loss: 0.00684727
INFO:root:[194,   250] training loss: 0.00655627
INFO:root:[194,   300] training loss: 0.00719291
INFO:root:[194,   350] training loss: 0.00591409
INFO:root:[194,   400] training loss: 0.00001006
INFO:root:[194,   450] training loss: 0.00001883
INFO:root:[194,   500] training loss: 0.00005923
INFO:root:[194,   550] training loss: 0.00023465
INFO:root:[194,   600] training loss: 0.00019677
INFO:root:[194,   650] training loss: 0.00003331
INFO:root:[194,   700] training loss: 0.00002904
INFO:root:[194,   750] training loss: 0.00053129
INFO:root:[194,   800] training loss: 0.00055267
INFO:root:[194,   850] training loss: 0.00052141
INFO:root:[194,   900] training loss: 0.00353393
INFO:root:[194,   950] training loss: 0.00166060
INFO:root:[194,  1000] training loss: 0.00005778
INFO:root:[194,  1050] training loss: 0.00004480
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch194
INFO:root:[195,    50] training loss: 0.00736222
INFO:root:[195,   100] training loss: 0.00738638
INFO:root:[195,   150] training loss: 0.00856636
INFO:root:[195,   200] training loss: 0.00658044
INFO:root:[195,   250] training loss: 0.00745103
INFO:root:[195,   300] training loss: 0.00718462
INFO:root:[195,   350] training loss: 0.00576134
INFO:root:[195,   400] training loss: 0.00000988
INFO:root:[195,   450] training loss: 0.00001695
INFO:root:[195,   500] training loss: 0.00003040
INFO:root:[195,   550] training loss: 0.00023493
INFO:root:[195,   600] training loss: 0.00015504
INFO:root:[195,   650] training loss: 0.00003051
INFO:root:[195,   700] training loss: 0.00002523
INFO:root:[195,   750] training loss: 0.00048987
INFO:root:[195,   800] training loss: 0.00045452
INFO:root:[195,   850] training loss: 0.00045988
INFO:root:[195,   900] training loss: 0.00347696
INFO:root:[195,   950] training loss: 0.00129192
INFO:root:[195,  1000] training loss: 0.00005876
INFO:root:[195,  1050] training loss: 0.00003666
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch195
INFO:root:[196,    50] training loss: 0.00753854
INFO:root:[196,   100] training loss: 0.00721859
INFO:root:[196,   150] training loss: 0.00658493
INFO:root:[196,   200] training loss: 0.00690915
INFO:root:[196,   250] training loss: 0.00695099
INFO:root:[196,   300] training loss: 0.00720957
INFO:root:[196,   350] training loss: 0.00622060
INFO:root:[196,   400] training loss: 0.00001104
INFO:root:[196,   450] training loss: 0.00001248
INFO:root:[196,   500] training loss: 0.00006059
INFO:root:[196,   550] training loss: 0.00023073
INFO:root:[196,   600] training loss: 0.00018606
INFO:root:[196,   650] training loss: 0.00002980
INFO:root:[196,   700] training loss: 0.00002760
INFO:root:[196,   750] training loss: 0.00052247
INFO:root:[196,   800] training loss: 0.00054131
INFO:root:[196,   850] training loss: 0.00051295
INFO:root:[196,   900] training loss: 0.00441421
INFO:root:[196,   950] training loss: 0.00159196
INFO:root:[196,  1000] training loss: 0.00007935
INFO:root:[196,  1050] training loss: 0.00004085
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch196
INFO:root:[197,    50] training loss: 0.00692867
INFO:root:[197,   100] training loss: 0.00701387
INFO:root:[197,   150] training loss: 0.00673981
INFO:root:[197,   200] training loss: 0.00678861
INFO:root:[197,   250] training loss: 0.00739899
INFO:root:[197,   300] training loss: 0.00909799
INFO:root:[197,   350] training loss: 0.00618971
INFO:root:[197,   400] training loss: 0.00000996
INFO:root:[197,   450] training loss: 0.00001127
INFO:root:[197,   500] training loss: 0.00003284
INFO:root:[197,   550] training loss: 0.00029260
INFO:root:[197,   600] training loss: 0.00016688
INFO:root:[197,   650] training loss: 0.00003485
INFO:root:[197,   700] training loss: 0.00002916
INFO:root:[197,   750] training loss: 0.00054037
INFO:root:[197,   800] training loss: 0.00050085
INFO:root:[197,   850] training loss: 0.00047784
INFO:root:[197,   900] training loss: 0.00339375
INFO:root:[197,   950] training loss: 0.00168826
INFO:root:[197,  1000] training loss: 0.00006165
INFO:root:[197,  1050] training loss: 0.00004252
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch197
INFO:root:[198,    50] training loss: 0.00695120
INFO:root:[198,   100] training loss: 0.00712298
INFO:root:[198,   150] training loss: 0.00688741
INFO:root:[198,   200] training loss: 0.00661424
INFO:root:[198,   250] training loss: 0.00658832
INFO:root:[198,   300] training loss: 0.00703557
INFO:root:[198,   350] training loss: 0.00649612
INFO:root:[198,   400] training loss: 0.00001012
INFO:root:[198,   450] training loss: 0.00001226
INFO:root:[198,   500] training loss: 0.00003843
INFO:root:[198,   550] training loss: 0.00025128
INFO:root:[198,   600] training loss: 0.00016383
INFO:root:[198,   650] training loss: 0.00002568
INFO:root:[198,   700] training loss: 0.00002910
INFO:root:[198,   750] training loss: 0.00062740
INFO:root:[198,   800] training loss: 0.00053162
INFO:root:[198,   850] training loss: 0.00056942
INFO:root:[198,   900] training loss: 0.00390363
INFO:root:[198,   950] training loss: 0.00156668
INFO:root:[198,  1000] training loss: 0.00006079
INFO:root:[198,  1050] training loss: 0.00003561
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch198
INFO:root:[199,    50] training loss: 0.00718502
INFO:root:[199,   100] training loss: 0.00913659
INFO:root:[199,   150] training loss: 0.00674513
INFO:root:[199,   200] training loss: 0.00935355
INFO:root:[199,   250] training loss: 0.00685765
INFO:root:[199,   300] training loss: 0.00711588
INFO:root:[199,   350] training loss: 0.00663789
INFO:root:[199,   400] training loss: 0.00001190
INFO:root:[199,   450] training loss: 0.00001267
INFO:root:[199,   500] training loss: 0.00004787
INFO:root:[199,   550] training loss: 0.00020318
INFO:root:[199,   600] training loss: 0.00014966
INFO:root:[199,   650] training loss: 0.00003312
INFO:root:[199,   700] training loss: 0.00004466
INFO:root:[199,   750] training loss: 0.00053712
INFO:root:[199,   800] training loss: 0.00054209
INFO:root:[199,   850] training loss: 0.00046903
INFO:root:[199,   900] training loss: 0.00349871
INFO:root:[199,   950] training loss: 0.00153960
INFO:root:[199,  1000] training loss: 0.00006509
INFO:root:[199,  1050] training loss: 0.00003155
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch199
INFO:root:[200,    50] training loss: 0.00699813
INFO:root:[200,   100] training loss: 0.00715580
INFO:root:[200,   150] training loss: 0.00662991
INFO:root:[200,   200] training loss: 0.00760999
INFO:root:[200,   250] training loss: 0.00675129
INFO:root:[200,   300] training loss: 0.00790149
INFO:root:[200,   350] training loss: 0.00622217
INFO:root:[200,   400] training loss: 0.00001068
INFO:root:[200,   450] training loss: 0.00001345
INFO:root:[200,   500] training loss: 0.00003957
INFO:root:[200,   550] training loss: 0.00021895
INFO:root:[200,   600] training loss: 0.00019974
INFO:root:[200,   650] training loss: 0.00002628
INFO:root:[200,   700] training loss: 0.00003432
INFO:root:[200,   750] training loss: 0.00047719
INFO:root:[200,   800] training loss: 0.00051382
INFO:root:[200,   850] training loss: 0.00047533
INFO:root:[200,   900] training loss: 0.00358541
INFO:root:[200,   950] training loss: 0.00145355
INFO:root:[200,  1000] training loss: 0.00005152
INFO:root:[200,  1050] training loss: 0.00004075
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch200
INFO:root:[201,    50] training loss: 0.00719442
INFO:root:[201,   100] training loss: 0.00818685
INFO:root:[201,   150] training loss: 0.00665283
INFO:root:[201,   200] training loss: 0.00667690
INFO:root:[201,   250] training loss: 0.00673338
INFO:root:[201,   300] training loss: 0.00784059
INFO:root:[201,   350] training loss: 0.00589340
INFO:root:[201,   400] training loss: 0.00001092
INFO:root:[201,   450] training loss: 0.00001259
INFO:root:[201,   500] training loss: 0.00005154
INFO:root:[201,   550] training loss: 0.00022953
INFO:root:[201,   600] training loss: 0.00017510
INFO:root:[201,   650] training loss: 0.00003185
INFO:root:[201,   700] training loss: 0.00002861
INFO:root:[201,   750] training loss: 0.00047783
INFO:root:[201,   800] training loss: 0.00050054
INFO:root:[201,   850] training loss: 0.00056080
INFO:root:[201,   900] training loss: 0.00395900
INFO:root:[201,   950] training loss: 0.00120029
INFO:root:[201,  1000] training loss: 0.00006517
INFO:root:[201,  1050] training loss: 0.00003857
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch201
INFO:root:[202,    50] training loss: 0.00714968
INFO:root:[202,   100] training loss: 0.00739506
INFO:root:[202,   150] training loss: 0.00800473
INFO:root:[202,   200] training loss: 0.00686974
INFO:root:[202,   250] training loss: 0.00654226
INFO:root:[202,   300] training loss: 0.00748375
INFO:root:[202,   350] training loss: 0.00593107
INFO:root:[202,   400] training loss: 0.00001057
INFO:root:[202,   450] training loss: 0.00001357
INFO:root:[202,   500] training loss: 0.00003665
INFO:root:[202,   550] training loss: 0.00030608
INFO:root:[202,   600] training loss: 0.00017948
INFO:root:[202,   650] training loss: 0.00003054
INFO:root:[202,   700] training loss: 0.00002904
INFO:root:[202,   750] training loss: 0.00056450
INFO:root:[202,   800] training loss: 0.00051152
INFO:root:[202,   850] training loss: 0.00050148
INFO:root:[202,   900] training loss: 0.00365682
INFO:root:[202,   950] training loss: 0.00145630
INFO:root:[202,  1000] training loss: 0.00005863
INFO:root:[202,  1050] training loss: 0.00003963
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch202
INFO:root:[203,    50] training loss: 0.00758419
INFO:root:[203,   100] training loss: 0.00721276
INFO:root:[203,   150] training loss: 0.00654344
INFO:root:[203,   200] training loss: 0.00680782
INFO:root:[203,   250] training loss: 0.00671978
INFO:root:[203,   300] training loss: 0.00717398
INFO:root:[203,   350] training loss: 0.00580105
INFO:root:[203,   400] training loss: 0.00001056
INFO:root:[203,   450] training loss: 0.00001143
INFO:root:[203,   500] training loss: 0.00003749
INFO:root:[203,   550] training loss: 0.00017728
INFO:root:[203,   600] training loss: 0.00016819
INFO:root:[203,   650] training loss: 0.00002747
INFO:root:[203,   700] training loss: 0.00002885
INFO:root:[203,   750] training loss: 0.00052083
INFO:root:[203,   800] training loss: 0.00048771
INFO:root:[203,   850] training loss: 0.00054814
INFO:root:[203,   900] training loss: 0.00404554
INFO:root:[203,   950] training loss: 0.00210099
INFO:root:[203,  1000] training loss: 0.00007823
INFO:root:[203,  1050] training loss: 0.00003813
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch203
INFO:root:[204,    50] training loss: 0.00679342
INFO:root:[204,   100] training loss: 0.00719461
INFO:root:[204,   150] training loss: 0.00701396
INFO:root:[204,   200] training loss: 0.00670324
INFO:root:[204,   250] training loss: 0.00668830
INFO:root:[204,   300] training loss: 0.00718282
INFO:root:[204,   350] training loss: 0.00608137
INFO:root:[204,   400] training loss: 0.00000980
INFO:root:[204,   450] training loss: 0.00001401
INFO:root:[204,   500] training loss: 0.00005727
INFO:root:[204,   550] training loss: 0.00023283
INFO:root:[204,   600] training loss: 0.00017086
INFO:root:[204,   650] training loss: 0.00002691
INFO:root:[204,   700] training loss: 0.00002969
INFO:root:[204,   750] training loss: 0.00055361
INFO:root:[204,   800] training loss: 0.00067041
INFO:root:[204,   850] training loss: 0.00054231
INFO:root:[204,   900] training loss: 0.00356991
INFO:root:[204,   950] training loss: 0.00150849
INFO:root:[204,  1000] training loss: 0.00005320
INFO:root:[204,  1050] training loss: 0.00003953
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch204
INFO:root:[205,    50] training loss: 0.00668256
INFO:root:[205,   100] training loss: 0.00682840
INFO:root:[205,   150] training loss: 0.00720792
INFO:root:[205,   200] training loss: 0.00683590
INFO:root:[205,   250] training loss: 0.00676476
INFO:root:[205,   300] training loss: 0.00715140
INFO:root:[205,   350] training loss: 0.00637067
INFO:root:[205,   400] training loss: 0.00000944
INFO:root:[205,   450] training loss: 0.00001527
INFO:root:[205,   500] training loss: 0.00003252
INFO:root:[205,   550] training loss: 0.00015890
INFO:root:[205,   600] training loss: 0.00016901
INFO:root:[205,   650] training loss: 0.00003345
INFO:root:[205,   700] training loss: 0.00002502
INFO:root:[205,   750] training loss: 0.00062649
INFO:root:[205,   800] training loss: 0.00050540
INFO:root:[205,   850] training loss: 0.00047312
INFO:root:[205,   900] training loss: 0.00360143
INFO:root:[205,   950] training loss: 0.00115034
INFO:root:[205,  1000] training loss: 0.00004921
INFO:root:[205,  1050] training loss: 0.00003384
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch205
INFO:root:[206,    50] training loss: 0.00722776
INFO:root:[206,   100] training loss: 0.00699031
INFO:root:[206,   150] training loss: 0.00679535
INFO:root:[206,   200] training loss: 0.00688383
INFO:root:[206,   250] training loss: 0.00680969
INFO:root:[206,   300] training loss: 0.00746389
INFO:root:[206,   350] training loss: 0.00581468
INFO:root:[206,   400] training loss: 0.00001020
INFO:root:[206,   450] training loss: 0.00001356
INFO:root:[206,   500] training loss: 0.00002853
INFO:root:[206,   550] training loss: 0.00019831
INFO:root:[206,   600] training loss: 0.00015671
INFO:root:[206,   650] training loss: 0.00003632
INFO:root:[206,   700] training loss: 0.00002149
INFO:root:[206,   750] training loss: 0.00047882
INFO:root:[206,   800] training loss: 0.00058327
INFO:root:[206,   850] training loss: 0.00044721
INFO:root:[206,   900] training loss: 0.00368517
INFO:root:[206,   950] training loss: 0.00128714
INFO:root:[206,  1000] training loss: 0.00004741
INFO:root:[206,  1050] training loss: 0.00003810
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch206
INFO:root:[207,    50] training loss: 0.00683930
INFO:root:[207,   100] training loss: 0.00803862
INFO:root:[207,   150] training loss: 0.00688284
INFO:root:[207,   200] training loss: 0.00723722
INFO:root:[207,   250] training loss: 0.00655035
INFO:root:[207,   300] training loss: 0.00730199
INFO:root:[207,   350] training loss: 0.00616889
INFO:root:[207,   400] training loss: 0.00000952
INFO:root:[207,   450] training loss: 0.00001518
INFO:root:[207,   500] training loss: 0.00003252
INFO:root:[207,   550] training loss: 0.00025745
INFO:root:[207,   600] training loss: 0.00027757
INFO:root:[207,   650] training loss: 0.00003531
INFO:root:[207,   700] training loss: 0.00002280
INFO:root:[207,   750] training loss: 0.00049056
INFO:root:[207,   800] training loss: 0.00046663
INFO:root:[207,   850] training loss: 0.00047246
INFO:root:[207,   900] training loss: 0.00302014
INFO:root:[207,   950] training loss: 0.00170368
INFO:root:[207,  1000] training loss: 0.00008370
INFO:root:[207,  1050] training loss: 0.00003387
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch207
INFO:root:[208,    50] training loss: 0.00713436
INFO:root:[208,   100] training loss: 0.00721464
INFO:root:[208,   150] training loss: 0.00666715
INFO:root:[208,   200] training loss: 0.00695961
INFO:root:[208,   250] training loss: 0.00658564
INFO:root:[208,   300] training loss: 0.00695816
INFO:root:[208,   350] training loss: 0.00579592
INFO:root:[208,   400] training loss: 0.00001239
INFO:root:[208,   450] training loss: 0.00001451
INFO:root:[208,   500] training loss: 0.00004050
INFO:root:[208,   550] training loss: 0.00025516
INFO:root:[208,   600] training loss: 0.00015754
INFO:root:[208,   650] training loss: 0.00003489
INFO:root:[208,   700] training loss: 0.00002768
INFO:root:[208,   750] training loss: 0.00046627
INFO:root:[208,   800] training loss: 0.00047411
INFO:root:[208,   850] training loss: 0.00050423
INFO:root:[208,   900] training loss: 0.00315007
INFO:root:[208,   950] training loss: 0.00154584
INFO:root:[208,  1000] training loss: 0.00007852
INFO:root:[208,  1050] training loss: 0.00003604
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch208
INFO:root:[209,    50] training loss: 0.00693915
INFO:root:[209,   100] training loss: 0.00690365
INFO:root:[209,   150] training loss: 0.00689461
INFO:root:[209,   200] training loss: 0.00679743
INFO:root:[209,   250] training loss: 0.00670549
INFO:root:[209,   300] training loss: 0.00711597
INFO:root:[209,   350] training loss: 0.00592879
INFO:root:[209,   400] training loss: 0.00001036
INFO:root:[209,   450] training loss: 0.00001315
INFO:root:[209,   500] training loss: 0.00004944
INFO:root:[209,   550] training loss: 0.00026762
INFO:root:[209,   600] training loss: 0.00015035
INFO:root:[209,   650] training loss: 0.00002948
INFO:root:[209,   700] training loss: 0.00009847
INFO:root:[209,   750] training loss: 0.00047164
INFO:root:[209,   800] training loss: 0.00054708
INFO:root:[209,   850] training loss: 0.00043285
INFO:root:[209,   900] training loss: 0.00312804
INFO:root:[209,   950] training loss: 0.00169795
INFO:root:[209,  1000] training loss: 0.00006536
INFO:root:[209,  1050] training loss: 0.00003643
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch209
INFO:root:[210,    50] training loss: 0.00750687
INFO:root:[210,   100] training loss: 0.00690045
INFO:root:[210,   150] training loss: 0.00648007
INFO:root:[210,   200] training loss: 0.00649240
INFO:root:[210,   250] training loss: 0.00701982
INFO:root:[210,   300] training loss: 0.00712195
INFO:root:[210,   350] training loss: 0.00594884
INFO:root:[210,   400] training loss: 0.00001050
INFO:root:[210,   450] training loss: 0.00002488
INFO:root:[210,   500] training loss: 0.00005902
INFO:root:[210,   550] training loss: 0.00020692
INFO:root:[210,   600] training loss: 0.00016435
INFO:root:[210,   650] training loss: 0.00002841
INFO:root:[210,   700] training loss: 0.00003022
INFO:root:[210,   750] training loss: 0.00052952
INFO:root:[210,   800] training loss: 0.00048395
INFO:root:[210,   850] training loss: 0.00059480
INFO:root:[210,   900] training loss: 0.00347164
INFO:root:[210,   950] training loss: 0.00152427
INFO:root:[210,  1000] training loss: 0.00005644
INFO:root:[210,  1050] training loss: 0.00004104
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch210
INFO:root:[211,    50] training loss: 0.00701134
INFO:root:[211,   100] training loss: 0.00732696
INFO:root:[211,   150] training loss: 0.00674261
INFO:root:[211,   200] training loss: 0.00850011
INFO:root:[211,   250] training loss: 0.00666267
INFO:root:[211,   300] training loss: 0.00729167
INFO:root:[211,   350] training loss: 0.00670654
INFO:root:[211,   400] training loss: 0.00001108
INFO:root:[211,   450] training loss: 0.00001470
INFO:root:[211,   500] training loss: 0.00002770
INFO:root:[211,   550] training loss: 0.00023956
INFO:root:[211,   600] training loss: 0.00018881
INFO:root:[211,   650] training loss: 0.00002901
INFO:root:[211,   700] training loss: 0.00003264
INFO:root:[211,   750] training loss: 0.00047140
INFO:root:[211,   800] training loss: 0.00055917
INFO:root:[211,   850] training loss: 0.00059315
INFO:root:[211,   900] training loss: 0.00400311
INFO:root:[211,   950] training loss: 0.00168008
INFO:root:[211,  1000] training loss: 0.00007801
INFO:root:[211,  1050] training loss: 0.00003734
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch211
INFO:root:[212,    50] training loss: 0.00702410
INFO:root:[212,   100] training loss: 0.00758097
INFO:root:[212,   150] training loss: 0.00656816
INFO:root:[212,   200] training loss: 0.00749164
INFO:root:[212,   250] training loss: 0.00661105
INFO:root:[212,   300] training loss: 0.01026668
INFO:root:[212,   350] training loss: 0.00611605
INFO:root:[212,   400] training loss: 0.00001052
INFO:root:[212,   450] training loss: 0.00001620
INFO:root:[212,   500] training loss: 0.00002955
INFO:root:[212,   550] training loss: 0.00025193
INFO:root:[212,   600] training loss: 0.00014930
INFO:root:[212,   650] training loss: 0.00002583
INFO:root:[212,   700] training loss: 0.00002953
INFO:root:[212,   750] training loss: 0.00047811
INFO:root:[212,   800] training loss: 0.00056557
INFO:root:[212,   850] training loss: 0.00048173
INFO:root:[212,   900] training loss: 0.00346903
INFO:root:[212,   950] training loss: 0.00138389
INFO:root:[212,  1000] training loss: 0.00004224
INFO:root:[212,  1050] training loss: 0.00003609
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch212
INFO:root:[213,    50] training loss: 0.00734338
INFO:root:[213,   100] training loss: 0.00708286
INFO:root:[213,   150] training loss: 0.00680203
INFO:root:[213,   200] training loss: 0.00727726
INFO:root:[213,   250] training loss: 0.00674498
INFO:root:[213,   300] training loss: 0.00708493
INFO:root:[213,   350] training loss: 0.00584506
INFO:root:[213,   400] training loss: 0.00001157
INFO:root:[213,   450] training loss: 0.00001295
INFO:root:[213,   500] training loss: 0.00008041
INFO:root:[213,   550] training loss: 0.00024210
INFO:root:[213,   600] training loss: 0.00015235
INFO:root:[213,   650] training loss: 0.00003263
INFO:root:[213,   700] training loss: 0.00002865
INFO:root:[213,   750] training loss: 0.00054772
INFO:root:[213,   800] training loss: 0.00052198
INFO:root:[213,   850] training loss: 0.00052138
INFO:root:[213,   900] training loss: 0.00345746
INFO:root:[213,   950] training loss: 0.00322698
INFO:root:[213,  1000] training loss: 0.00004320
INFO:root:[213,  1050] training loss: 0.00004583
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch213
INFO:root:[214,    50] training loss: 0.00766321
INFO:root:[214,   100] training loss: 0.00723525
INFO:root:[214,   150] training loss: 0.00693865
INFO:root:[214,   200] training loss: 0.00657304
INFO:root:[214,   250] training loss: 0.00692593
INFO:root:[214,   300] training loss: 0.00710335
INFO:root:[214,   350] training loss: 0.00600085
INFO:root:[214,   400] training loss: 0.00001043
INFO:root:[214,   450] training loss: 0.00001741
INFO:root:[214,   500] training loss: 0.00003757
INFO:root:[214,   550] training loss: 0.00020971
INFO:root:[214,   600] training loss: 0.00020625
INFO:root:[214,   650] training loss: 0.00002675
INFO:root:[214,   700] training loss: 0.00002652
INFO:root:[214,   750] training loss: 0.00052997
INFO:root:[214,   800] training loss: 0.00057563
INFO:root:[214,   850] training loss: 0.00046684
INFO:root:[214,   900] training loss: 0.00305062
INFO:root:[214,   950] training loss: 0.00146943
INFO:root:[214,  1000] training loss: 0.00005416
INFO:root:[214,  1050] training loss: 0.00004688
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch214
INFO:root:[215,    50] training loss: 0.00727242
INFO:root:[215,   100] training loss: 0.00711866
INFO:root:[215,   150] training loss: 0.00669070
INFO:root:[215,   200] training loss: 0.00695661
INFO:root:[215,   250] training loss: 0.00692085
INFO:root:[215,   300] training loss: 0.00731796
INFO:root:[215,   350] training loss: 0.00574436
INFO:root:[215,   400] training loss: 0.00001123
INFO:root:[215,   450] training loss: 0.00001312
INFO:root:[215,   500] training loss: 0.00003817
INFO:root:[215,   550] training loss: 0.00026452
INFO:root:[215,   600] training loss: 0.00019570
INFO:root:[215,   650] training loss: 0.00002906
INFO:root:[215,   700] training loss: 0.00002634
INFO:root:[215,   750] training loss: 0.00053633
INFO:root:[215,   800] training loss: 0.00049522
INFO:root:[215,   850] training loss: 0.00047040
INFO:root:[215,   900] training loss: 0.00319403
INFO:root:[215,   950] training loss: 0.00273303
INFO:root:[215,  1000] training loss: 0.00004284
INFO:root:[215,  1050] training loss: 0.00003612
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch215
INFO:root:[216,    50] training loss: 0.00761676
INFO:root:[216,   100] training loss: 0.00745450
INFO:root:[216,   150] training loss: 0.00699223
INFO:root:[216,   200] training loss: 0.00804242
INFO:root:[216,   250] training loss: 0.00668114
INFO:root:[216,   300] training loss: 0.00716883
INFO:root:[216,   350] training loss: 0.00602076
INFO:root:[216,   400] training loss: 0.00001452
INFO:root:[216,   450] training loss: 0.00001296
INFO:root:[216,   500] training loss: 0.00003051
INFO:root:[216,   550] training loss: 0.00023682
INFO:root:[216,   600] training loss: 0.00018367
INFO:root:[216,   650] training loss: 0.00002679
INFO:root:[216,   700] training loss: 0.00002770
INFO:root:[216,   750] training loss: 0.00055526
INFO:root:[216,   800] training loss: 0.00050076
INFO:root:[216,   850] training loss: 0.00050291
INFO:root:[216,   900] training loss: 0.00331342
INFO:root:[216,   950] training loss: 0.00119901
INFO:root:[216,  1000] training loss: 0.00005223
INFO:root:[216,  1050] training loss: 0.00003426
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch216
INFO:root:[217,    50] training loss: 0.00714384
INFO:root:[217,   100] training loss: 0.00697242
INFO:root:[217,   150] training loss: 0.00651387
INFO:root:[217,   200] training loss: 0.00696107
INFO:root:[217,   250] training loss: 0.00703045
INFO:root:[217,   300] training loss: 0.00744609
INFO:root:[217,   350] training loss: 0.00566388
INFO:root:[217,   400] training loss: 0.00001240
INFO:root:[217,   450] training loss: 0.00001288
INFO:root:[217,   500] training loss: 0.00003513
INFO:root:[217,   550] training loss: 0.00022654
INFO:root:[217,   600] training loss: 0.00014602
INFO:root:[217,   650] training loss: 0.00003097
INFO:root:[217,   700] training loss: 0.00002595
INFO:root:[217,   750] training loss: 0.00048283
INFO:root:[217,   800] training loss: 0.00048525
INFO:root:[217,   850] training loss: 0.00057955
INFO:root:[217,   900] training loss: 0.00362548
INFO:root:[217,   950] training loss: 0.00247080
INFO:root:[217,  1000] training loss: 0.00006588
INFO:root:[217,  1050] training loss: 0.00006033
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch217
INFO:root:[218,    50] training loss: 0.00676145
INFO:root:[218,   100] training loss: 0.00718735
INFO:root:[218,   150] training loss: 0.00678317
INFO:root:[218,   200] training loss: 0.00742777
INFO:root:[218,   250] training loss: 0.00933139
INFO:root:[218,   300] training loss: 0.00743372
INFO:root:[218,   350] training loss: 0.00583474
INFO:root:[218,   400] training loss: 0.00001066
INFO:root:[218,   450] training loss: 0.00001386
INFO:root:[218,   500] training loss: 0.00004423
INFO:root:[218,   550] training loss: 0.00029048
INFO:root:[218,   600] training loss: 0.00015529
INFO:root:[218,   650] training loss: 0.00002800
INFO:root:[218,   700] training loss: 0.00004484
INFO:root:[218,   750] training loss: 0.00056062
INFO:root:[218,   800] training loss: 0.00062558
INFO:root:[218,   850] training loss: 0.00047670
INFO:root:[218,   900] training loss: 0.00417501
INFO:root:[218,   950] training loss: 0.00150988
INFO:root:[218,  1000] training loss: 0.00004397
INFO:root:[218,  1050] training loss: 0.00003589
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch218
INFO:root:[219,    50] training loss: 0.00683610
INFO:root:[219,   100] training loss: 0.00694211
INFO:root:[219,   150] training loss: 0.00660509
INFO:root:[219,   200] training loss: 0.00687697
INFO:root:[219,   250] training loss: 0.00677519
INFO:root:[219,   300] training loss: 0.00738180
INFO:root:[219,   350] training loss: 0.00608714
INFO:root:[219,   400] training loss: 0.00000963
INFO:root:[219,   450] training loss: 0.00001259
INFO:root:[219,   500] training loss: 0.00010279
INFO:root:[219,   550] training loss: 0.00024573
INFO:root:[219,   600] training loss: 0.00017976
INFO:root:[219,   650] training loss: 0.00003040
INFO:root:[219,   700] training loss: 0.00002821
INFO:root:[219,   750] training loss: 0.00046935
INFO:root:[219,   800] training loss: 0.00053019
INFO:root:[219,   850] training loss: 0.00045708
INFO:root:[219,   900] training loss: 0.00383854
INFO:root:[219,   950] training loss: 0.00149669
INFO:root:[219,  1000] training loss: 0.00005161
INFO:root:[219,  1050] training loss: 0.00003782
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch219
INFO:root:[220,    50] training loss: 0.00742038
INFO:root:[220,   100] training loss: 0.00700956
INFO:root:[220,   150] training loss: 0.00691605
INFO:root:[220,   200] training loss: 0.00674356
INFO:root:[220,   250] training loss: 0.00679609
INFO:root:[220,   300] training loss: 0.00677624
INFO:root:[220,   350] training loss: 0.00599787
INFO:root:[220,   400] training loss: 0.00001238
INFO:root:[220,   450] training loss: 0.00004748
INFO:root:[220,   500] training loss: 0.00003550
INFO:root:[220,   550] training loss: 0.00023099
INFO:root:[220,   600] training loss: 0.00016338
INFO:root:[220,   650] training loss: 0.00003040
INFO:root:[220,   700] training loss: 0.00002933
INFO:root:[220,   750] training loss: 0.00054632
INFO:root:[220,   800] training loss: 0.00061265
INFO:root:[220,   850] training loss: 0.00048780
INFO:root:[220,   900] training loss: 0.00487211
INFO:root:[220,   950] training loss: 0.00138081
INFO:root:[220,  1000] training loss: 0.00006160
INFO:root:[220,  1050] training loss: 0.00006362
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch220
INFO:root:[221,    50] training loss: 0.00713473
INFO:root:[221,   100] training loss: 0.00750150
INFO:root:[221,   150] training loss: 0.00669072
INFO:root:[221,   200] training loss: 0.00759622
INFO:root:[221,   250] training loss: 0.01025325
INFO:root:[221,   300] training loss: 0.00724768
INFO:root:[221,   350] training loss: 0.00617564
INFO:root:[221,   400] training loss: 0.00001216
INFO:root:[221,   450] training loss: 0.00001738
INFO:root:[221,   500] training loss: 0.00004334
INFO:root:[221,   550] training loss: 0.00025590
INFO:root:[221,   600] training loss: 0.00015636
INFO:root:[221,   650] training loss: 0.00002277
INFO:root:[221,   700] training loss: 0.00003795
INFO:root:[221,   750] training loss: 0.00051091
INFO:root:[221,   800] training loss: 0.00053598
INFO:root:[221,   850] training loss: 0.00047375
INFO:root:[221,   900] training loss: 0.00378926
INFO:root:[221,   950] training loss: 0.00155528
INFO:root:[221,  1000] training loss: 0.00005977
INFO:root:[221,  1050] training loss: 0.00003338
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch221
INFO:root:[222,    50] training loss: 0.00719454
INFO:root:[222,   100] training loss: 0.00734093
INFO:root:[222,   150] training loss: 0.00727788
INFO:root:[222,   200] training loss: 0.00684525
INFO:root:[222,   250] training loss: 0.00678237
INFO:root:[222,   300] training loss: 0.00719842
INFO:root:[222,   350] training loss: 0.00667431
INFO:root:[222,   400] training loss: 0.00001080
INFO:root:[222,   450] training loss: 0.00001412
INFO:root:[222,   500] training loss: 0.00003504
INFO:root:[222,   550] training loss: 0.00020959
INFO:root:[222,   600] training loss: 0.00026123
INFO:root:[222,   650] training loss: 0.00002569
INFO:root:[222,   700] training loss: 0.00002479
INFO:root:[222,   750] training loss: 0.00050697
INFO:root:[222,   800] training loss: 0.00052396
INFO:root:[222,   850] training loss: 0.00049023
INFO:root:[222,   900] training loss: 0.00358497
INFO:root:[222,   950] training loss: 0.00230055
INFO:root:[222,  1000] training loss: 0.00008009
INFO:root:[222,  1050] training loss: 0.00004570
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch222
INFO:root:[223,    50] training loss: 0.00764382
INFO:root:[223,   100] training loss: 0.00699193
INFO:root:[223,   150] training loss: 0.00696091
INFO:root:[223,   200] training loss: 0.00678730
INFO:root:[223,   250] training loss: 0.00717841
INFO:root:[223,   300] training loss: 0.00742878
INFO:root:[223,   350] training loss: 0.00628569
INFO:root:[223,   400] training loss: 0.00001068
INFO:root:[223,   450] training loss: 0.00001294
INFO:root:[223,   500] training loss: 0.00004285
INFO:root:[223,   550] training loss: 0.00020996
INFO:root:[223,   600] training loss: 0.00016684
INFO:root:[223,   650] training loss: 0.00002783
INFO:root:[223,   700] training loss: 0.00002308
INFO:root:[223,   750] training loss: 0.00047868
INFO:root:[223,   800] training loss: 0.00057611
INFO:root:[223,   850] training loss: 0.00048930
INFO:root:[223,   900] training loss: 0.00411440
INFO:root:[223,   950] training loss: 0.00203949
INFO:root:[223,  1000] training loss: 0.00005856
INFO:root:[223,  1050] training loss: 0.00003527
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch223
INFO:root:[224,    50] training loss: 0.00753896
INFO:root:[224,   100] training loss: 0.00713015
INFO:root:[224,   150] training loss: 0.00702724
INFO:root:[224,   200] training loss: 0.00715730
INFO:root:[224,   250] training loss: 0.00704250
INFO:root:[224,   300] training loss: 0.00712186
INFO:root:[224,   350] training loss: 0.00603317
INFO:root:[224,   400] training loss: 0.00001080
INFO:root:[224,   450] training loss: 0.00001125
INFO:root:[224,   500] training loss: 0.00003444
INFO:root:[224,   550] training loss: 0.00020628
INFO:root:[224,   600] training loss: 0.00015347
INFO:root:[224,   650] training loss: 0.00002354
INFO:root:[224,   700] training loss: 0.00002437
INFO:root:[224,   750] training loss: 0.00051655
INFO:root:[224,   800] training loss: 0.00051461
INFO:root:[224,   850] training loss: 0.00050932
INFO:root:[224,   900] training loss: 0.00349004
INFO:root:[224,   950] training loss: 0.00135858
INFO:root:[224,  1000] training loss: 0.00008042
INFO:root:[224,  1050] training loss: 0.00005211
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch224
INFO:root:[225,    50] training loss: 0.00700948
INFO:root:[225,   100] training loss: 0.00853035
INFO:root:[225,   150] training loss: 0.00729833
INFO:root:[225,   200] training loss: 0.00694752
INFO:root:[225,   250] training loss: 0.00654147
INFO:root:[225,   300] training loss: 0.00699844
INFO:root:[225,   350] training loss: 0.00600944
INFO:root:[225,   400] training loss: 0.00000985
INFO:root:[225,   450] training loss: 0.00001253
INFO:root:[225,   500] training loss: 0.00004386
INFO:root:[225,   550] training loss: 0.00022587
INFO:root:[225,   600] training loss: 0.00014976
INFO:root:[225,   650] training loss: 0.00002665
INFO:root:[225,   700] training loss: 0.00002971
INFO:root:[225,   750] training loss: 0.00052748
INFO:root:[225,   800] training loss: 0.00053350
INFO:root:[225,   850] training loss: 0.00049564
INFO:root:[225,   900] training loss: 0.00355706
INFO:root:[225,   950] training loss: 0.00176868
INFO:root:[225,  1000] training loss: 0.00005061
INFO:root:[225,  1050] training loss: 0.00003742
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch225
INFO:root:[226,    50] training loss: 0.00711246
INFO:root:[226,   100] training loss: 0.00695780
INFO:root:[226,   150] training loss: 0.00693907
INFO:root:[226,   200] training loss: 0.00699152
INFO:root:[226,   250] training loss: 0.00672772
INFO:root:[226,   300] training loss: 0.00710362
INFO:root:[226,   350] training loss: 0.00619953
INFO:root:[226,   400] training loss: 0.00001270
INFO:root:[226,   450] training loss: 0.00001272
INFO:root:[226,   500] training loss: 0.00004196
INFO:root:[226,   550] training loss: 0.00022931
INFO:root:[226,   600] training loss: 0.00016456
INFO:root:[226,   650] training loss: 0.00002766
INFO:root:[226,   700] training loss: 0.00002776
INFO:root:[226,   750] training loss: 0.00047780
INFO:root:[226,   800] training loss: 0.00057799
INFO:root:[226,   850] training loss: 0.00040956
INFO:root:[226,   900] training loss: 0.00332128
INFO:root:[226,   950] training loss: 0.00168327
INFO:root:[226,  1000] training loss: 0.00005244
INFO:root:[226,  1050] training loss: 0.00004035
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch226
INFO:root:[227,    50] training loss: 0.00697036
INFO:root:[227,   100] training loss: 0.00738845
INFO:root:[227,   150] training loss: 0.00658673
INFO:root:[227,   200] training loss: 0.00690169
INFO:root:[227,   250] training loss: 0.00683499
INFO:root:[227,   300] training loss: 0.00716241
INFO:root:[227,   350] training loss: 0.00625696
INFO:root:[227,   400] training loss: 0.00001101
INFO:root:[227,   450] training loss: 0.00001232
INFO:root:[227,   500] training loss: 0.00005440
INFO:root:[227,   550] training loss: 0.00023804
INFO:root:[227,   600] training loss: 0.00016163
INFO:root:[227,   650] training loss: 0.00002845
INFO:root:[227,   700] training loss: 0.00002725
INFO:root:[227,   750] training loss: 0.00054788
INFO:root:[227,   800] training loss: 0.00059953
INFO:root:[227,   850] training loss: 0.00045864
INFO:root:[227,   900] training loss: 0.00368330
INFO:root:[227,   950] training loss: 0.00123366
INFO:root:[227,  1000] training loss: 0.00006970
INFO:root:[227,  1050] training loss: 0.00004000
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch227
INFO:root:[228,    50] training loss: 0.00738970
INFO:root:[228,   100] training loss: 0.00734223
INFO:root:[228,   150] training loss: 0.00658185
INFO:root:[228,   200] training loss: 0.00686633
INFO:root:[228,   250] training loss: 0.00663782
INFO:root:[228,   300] training loss: 0.00737153
INFO:root:[228,   350] training loss: 0.00628996
INFO:root:[228,   400] training loss: 0.00000928
INFO:root:[228,   450] training loss: 0.00001488
INFO:root:[228,   500] training loss: 0.00005013
INFO:root:[228,   550] training loss: 0.00017090
INFO:root:[228,   600] training loss: 0.00016601
INFO:root:[228,   650] training loss: 0.00002960
INFO:root:[228,   700] training loss: 0.00002684
INFO:root:[228,   750] training loss: 0.00050752
INFO:root:[228,   800] training loss: 0.00056383
INFO:root:[228,   850] training loss: 0.00047697
INFO:root:[228,   900] training loss: 0.00318267
INFO:root:[228,   950] training loss: 0.00146603
INFO:root:[228,  1000] training loss: 0.00004146
INFO:root:[228,  1050] training loss: 0.00004915
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch228
INFO:root:[229,    50] training loss: 0.00724665
INFO:root:[229,   100] training loss: 0.00749015
INFO:root:[229,   150] training loss: 0.00786901
INFO:root:[229,   200] training loss: 0.00683907
INFO:root:[229,   250] training loss: 0.00709861
INFO:root:[229,   300] training loss: 0.00802619
INFO:root:[229,   350] training loss: 0.00637417
INFO:root:[229,   400] training loss: 0.00001181
INFO:root:[229,   450] training loss: 0.00001281
INFO:root:[229,   500] training loss: 0.00005460
INFO:root:[229,   550] training loss: 0.00025225
INFO:root:[229,   600] training loss: 0.00018084
INFO:root:[229,   650] training loss: 0.00003049
INFO:root:[229,   700] training loss: 0.00002393
INFO:root:[229,   750] training loss: 0.00049764
INFO:root:[229,   800] training loss: 0.00048785
INFO:root:[229,   850] training loss: 0.00049675
INFO:root:[229,   900] training loss: 0.00346270
INFO:root:[229,   950] training loss: 0.00141737
INFO:root:[229,  1000] training loss: 0.00006055
INFO:root:[229,  1050] training loss: 0.00004029
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch229
INFO:root:[230,    50] training loss: 0.00771861
INFO:root:[230,   100] training loss: 0.00725102
INFO:root:[230,   150] training loss: 0.00699332
INFO:root:[230,   200] training loss: 0.00737169
INFO:root:[230,   250] training loss: 0.00702707
INFO:root:[230,   300] training loss: 0.00752465
INFO:root:[230,   350] training loss: 0.00611972
INFO:root:[230,   400] training loss: 0.00001089
INFO:root:[230,   450] training loss: 0.00003283
INFO:root:[230,   500] training loss: 0.00003925
INFO:root:[230,   550] training loss: 0.00044213
INFO:root:[230,   600] training loss: 0.00013020
INFO:root:[230,   650] training loss: 0.00003534
INFO:root:[230,   700] training loss: 0.00003240
INFO:root:[230,   750] training loss: 0.00046631
INFO:root:[230,   800] training loss: 0.00053543
INFO:root:[230,   850] training loss: 0.00053727
INFO:root:[230,   900] training loss: 0.00376737
INFO:root:[230,   950] training loss: 0.00141101
INFO:root:[230,  1000] training loss: 0.00005661
INFO:root:[230,  1050] training loss: 0.00004237
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch230
INFO:root:[231,    50] training loss: 0.00691639
INFO:root:[231,   100] training loss: 0.00757085
INFO:root:[231,   150] training loss: 0.00666992
INFO:root:[231,   200] training loss: 0.00662524
INFO:root:[231,   250] training loss: 0.00712884
INFO:root:[231,   300] training loss: 0.00716640
INFO:root:[231,   350] training loss: 0.00606554
INFO:root:[231,   400] training loss: 0.00001208
INFO:root:[231,   450] training loss: 0.00001512
INFO:root:[231,   500] training loss: 0.00004172
INFO:root:[231,   550] training loss: 0.00024725
INFO:root:[231,   600] training loss: 0.00019158
INFO:root:[231,   650] training loss: 0.00003675
INFO:root:[231,   700] training loss: 0.00003289
INFO:root:[231,   750] training loss: 0.00045002
INFO:root:[231,   800] training loss: 0.00048540
INFO:root:[231,   850] training loss: 0.00049364
INFO:root:[231,   900] training loss: 0.00335348
INFO:root:[231,   950] training loss: 0.00153884
INFO:root:[231,  1000] training loss: 0.00006246
INFO:root:[231,  1050] training loss: 0.00005675
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch231
INFO:root:[232,    50] training loss: 0.00708477
INFO:root:[232,   100] training loss: 0.00770615
INFO:root:[232,   150] training loss: 0.00715554
INFO:root:[232,   200] training loss: 0.00691413
INFO:root:[232,   250] training loss: 0.00672216
INFO:root:[232,   300] training loss: 0.00733208
INFO:root:[232,   350] training loss: 0.00589262
INFO:root:[232,   400] training loss: 0.00001032
INFO:root:[232,   450] training loss: 0.00001194
INFO:root:[232,   500] training loss: 0.00002973
INFO:root:[232,   550] training loss: 0.00024041
INFO:root:[232,   600] training loss: 0.00017880
INFO:root:[232,   650] training loss: 0.00003207
INFO:root:[232,   700] training loss: 0.00002932
INFO:root:[232,   750] training loss: 0.00052293
INFO:root:[232,   800] training loss: 0.00048483
INFO:root:[232,   850] training loss: 0.00047617
INFO:root:[232,   900] training loss: 0.00361460
INFO:root:[232,   950] training loss: 0.00176845
INFO:root:[232,  1000] training loss: 0.00005427
INFO:root:[232,  1050] training loss: 0.00004787
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch232
INFO:root:[233,    50] training loss: 0.00718003
INFO:root:[233,   100] training loss: 0.00691141
INFO:root:[233,   150] training loss: 0.00706622
INFO:root:[233,   200] training loss: 0.00672621
INFO:root:[233,   250] training loss: 0.00683203
INFO:root:[233,   300] training loss: 0.00817044
INFO:root:[233,   350] training loss: 0.00617282
INFO:root:[233,   400] training loss: 0.00001008
INFO:root:[233,   450] training loss: 0.00001260
INFO:root:[233,   500] training loss: 0.00003750
INFO:root:[233,   550] training loss: 0.00026705
INFO:root:[233,   600] training loss: 0.00015375
INFO:root:[233,   650] training loss: 0.00003756
INFO:root:[233,   700] training loss: 0.00002351
INFO:root:[233,   750] training loss: 0.00045515
INFO:root:[233,   800] training loss: 0.00057605
INFO:root:[233,   850] training loss: 0.00049350
INFO:root:[233,   900] training loss: 0.00344424
INFO:root:[233,   950] training loss: 0.00218364
INFO:root:[233,  1000] training loss: 0.00005894
INFO:root:[233,  1050] training loss: 0.00003874
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch233
INFO:root:[234,    50] training loss: 0.00745101
INFO:root:[234,   100] training loss: 0.00758138
INFO:root:[234,   150] training loss: 0.00692436
INFO:root:[234,   200] training loss: 0.00691468
INFO:root:[234,   250] training loss: 0.00688160
INFO:root:[234,   300] training loss: 0.00732924
INFO:root:[234,   350] training loss: 0.00568310
INFO:root:[234,   400] training loss: 0.00001121
INFO:root:[234,   450] training loss: 0.00001363
INFO:root:[234,   500] training loss: 0.00003926
INFO:root:[234,   550] training loss: 0.00026222
INFO:root:[234,   600] training loss: 0.00023529
INFO:root:[234,   650] training loss: 0.00003202
INFO:root:[234,   700] training loss: 0.00020188
INFO:root:[234,   750] training loss: 0.00051464
INFO:root:[234,   800] training loss: 0.00051350
INFO:root:[234,   850] training loss: 0.00045994
INFO:root:[234,   900] training loss: 0.00390741
INFO:root:[234,   950] training loss: 0.00186621
INFO:root:[234,  1000] training loss: 0.00004996
INFO:root:[234,  1050] training loss: 0.00004064
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch234
INFO:root:[235,    50] training loss: 0.00736974
INFO:root:[235,   100] training loss: 0.00717694
INFO:root:[235,   150] training loss: 0.00646152
INFO:root:[235,   200] training loss: 0.00713845
INFO:root:[235,   250] training loss: 0.00719308
INFO:root:[235,   300] training loss: 0.00724806
INFO:root:[235,   350] training loss: 0.00618608
INFO:root:[235,   400] training loss: 0.00000993
INFO:root:[235,   450] training loss: 0.00001304
INFO:root:[235,   500] training loss: 0.00003830
INFO:root:[235,   550] training loss: 0.00024676
INFO:root:[235,   600] training loss: 0.00021879
INFO:root:[235,   650] training loss: 0.00002643
INFO:root:[235,   700] training loss: 0.00002627
INFO:root:[235,   750] training loss: 0.00049076
INFO:root:[235,   800] training loss: 0.00048529
INFO:root:[235,   850] training loss: 0.00046299
INFO:root:[235,   900] training loss: 0.00506632
INFO:root:[235,   950] training loss: 0.00119557
INFO:root:[235,  1000] training loss: 0.00004954
INFO:root:[235,  1050] training loss: 0.00009313
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch235
INFO:root:[236,    50] training loss: 0.00742843
INFO:root:[236,   100] training loss: 0.00737678
INFO:root:[236,   150] training loss: 0.00819440
INFO:root:[236,   200] training loss: 0.00695158
INFO:root:[236,   250] training loss: 0.00666125
INFO:root:[236,   300] training loss: 0.00788056
INFO:root:[236,   350] training loss: 0.00624153
INFO:root:[236,   400] training loss: 0.00001031
INFO:root:[236,   450] training loss: 0.00001786
INFO:root:[236,   500] training loss: 0.00003446
INFO:root:[236,   550] training loss: 0.00025042
INFO:root:[236,   600] training loss: 0.00016515
INFO:root:[236,   650] training loss: 0.00002994
INFO:root:[236,   700] training loss: 0.00002629
INFO:root:[236,   750] training loss: 0.00049959
INFO:root:[236,   800] training loss: 0.00053092
INFO:root:[236,   850] training loss: 0.00048973
INFO:root:[236,   900] training loss: 0.00351291
INFO:root:[236,   950] training loss: 0.00164739
INFO:root:[236,  1000] training loss: 0.00007322
INFO:root:[236,  1050] training loss: 0.00003746
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch236
INFO:root:[237,    50] training loss: 0.00700586
INFO:root:[237,   100] training loss: 0.00697566
INFO:root:[237,   150] training loss: 0.00705591
INFO:root:[237,   200] training loss: 0.00713662
INFO:root:[237,   250] training loss: 0.00707977
INFO:root:[237,   300] training loss: 0.00736322
INFO:root:[237,   350] training loss: 0.00589259
INFO:root:[237,   400] training loss: 0.00001055
INFO:root:[237,   450] training loss: 0.00001365
INFO:root:[237,   500] training loss: 0.00003878
INFO:root:[237,   550] training loss: 0.00022749
INFO:root:[237,   600] training loss: 0.00029308
INFO:root:[237,   650] training loss: 0.00002703
INFO:root:[237,   700] training loss: 0.00002887
INFO:root:[237,   750] training loss: 0.00051816
INFO:root:[237,   800] training loss: 0.00052771
INFO:root:[237,   850] training loss: 0.00038241
INFO:root:[237,   900] training loss: 0.00345783
INFO:root:[237,   950] training loss: 0.00189824
INFO:root:[237,  1000] training loss: 0.00008893
INFO:root:[237,  1050] training loss: 0.00008594
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch237
INFO:root:[238,    50] training loss: 0.00685088
INFO:root:[238,   100] training loss: 0.00760191
INFO:root:[238,   150] training loss: 0.00650375
INFO:root:[238,   200] training loss: 0.00699880
INFO:root:[238,   250] training loss: 0.00657816
INFO:root:[238,   300] training loss: 0.00701461
INFO:root:[238,   350] training loss: 0.00578063
INFO:root:[238,   400] training loss: 0.00001043
INFO:root:[238,   450] training loss: 0.00001241
INFO:root:[238,   500] training loss: 0.00003289
INFO:root:[238,   550] training loss: 0.00022620
INFO:root:[238,   600] training loss: 0.00016126
INFO:root:[238,   650] training loss: 0.00004100
INFO:root:[238,   700] training loss: 0.00002488
INFO:root:[238,   750] training loss: 0.00046390
INFO:root:[238,   800] training loss: 0.00051882
INFO:root:[238,   850] training loss: 0.00043561
INFO:root:[238,   900] training loss: 0.00307799
INFO:root:[238,   950] training loss: 0.00139670
INFO:root:[238,  1000] training loss: 0.00004583
INFO:root:[238,  1050] training loss: 0.00004837
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch238
INFO:root:[239,    50] training loss: 0.00727177
INFO:root:[239,   100] training loss: 0.00795028
INFO:root:[239,   150] training loss: 0.00671017
INFO:root:[239,   200] training loss: 0.00681997
INFO:root:[239,   250] training loss: 0.00735967
INFO:root:[239,   300] training loss: 0.00734984
INFO:root:[239,   350] training loss: 0.00555091
INFO:root:[239,   400] training loss: 0.00001151
INFO:root:[239,   450] training loss: 0.00001393
INFO:root:[239,   500] training loss: 0.00003525
INFO:root:[239,   550] training loss: 0.00019633
INFO:root:[239,   600] training loss: 0.00013374
INFO:root:[239,   650] training loss: 0.00002954
INFO:root:[239,   700] training loss: 0.00003033
INFO:root:[239,   750] training loss: 0.00045356
INFO:root:[239,   800] training loss: 0.00056348
INFO:root:[239,   850] training loss: 0.00062044
INFO:root:[239,   900] training loss: 0.00390133
INFO:root:[239,   950] training loss: 0.00145759
INFO:root:[239,  1000] training loss: 0.00005625
INFO:root:[239,  1050] training loss: 0.00004654
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch239
INFO:root:[240,    50] training loss: 0.00747058
INFO:root:[240,   100] training loss: 0.00728346
INFO:root:[240,   150] training loss: 0.00671576
INFO:root:[240,   200] training loss: 0.00701068
INFO:root:[240,   250] training loss: 0.00674875
INFO:root:[240,   300] training loss: 0.00714684
INFO:root:[240,   350] training loss: 0.00585570
INFO:root:[240,   400] training loss: 0.00000977
INFO:root:[240,   450] training loss: 0.00001301
INFO:root:[240,   500] training loss: 0.00002600
INFO:root:[240,   550] training loss: 0.00021977
INFO:root:[240,   600] training loss: 0.00019146
INFO:root:[240,   650] training loss: 0.00003865
INFO:root:[240,   700] training loss: 0.00003216
INFO:root:[240,   750] training loss: 0.00046992
INFO:root:[240,   800] training loss: 0.00054139
INFO:root:[240,   850] training loss: 0.00048747
INFO:root:[240,   900] training loss: 0.00362688
INFO:root:[240,   950] training loss: 0.00140137
INFO:root:[240,  1000] training loss: 0.00006370
INFO:root:[240,  1050] training loss: 0.00003385
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch240
INFO:root:[241,    50] training loss: 0.00703275
INFO:root:[241,   100] training loss: 0.00753703
INFO:root:[241,   150] training loss: 0.00700451
INFO:root:[241,   200] training loss: 0.00870283
INFO:root:[241,   250] training loss: 0.00660203
INFO:root:[241,   300] training loss: 0.00706364
INFO:root:[241,   350] training loss: 0.00625984
INFO:root:[241,   400] training loss: 0.00001213
INFO:root:[241,   450] training loss: 0.00001239
INFO:root:[241,   500] training loss: 0.00003230
INFO:root:[241,   550] training loss: 0.00025400
INFO:root:[241,   600] training loss: 0.00014554
INFO:root:[241,   650] training loss: 0.00002958
INFO:root:[241,   700] training loss: 0.00002731
INFO:root:[241,   750] training loss: 0.00051512
INFO:root:[241,   800] training loss: 0.00056126
INFO:root:[241,   850] training loss: 0.00046277
INFO:root:[241,   900] training loss: 0.00351899
INFO:root:[241,   950] training loss: 0.00129117
INFO:root:[241,  1000] training loss: 0.00004464
INFO:root:[241,  1050] training loss: 0.00003330
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch241
INFO:root:[242,    50] training loss: 0.00691727
INFO:root:[242,   100] training loss: 0.00709631
INFO:root:[242,   150] training loss: 0.00689268
INFO:root:[242,   200] training loss: 0.00664584
INFO:root:[242,   250] training loss: 0.00682621
INFO:root:[242,   300] training loss: 0.00702924
INFO:root:[242,   350] training loss: 0.00622378
INFO:root:[242,   400] training loss: 0.00001111
INFO:root:[242,   450] training loss: 0.00001465
INFO:root:[242,   500] training loss: 0.00003391
INFO:root:[242,   550] training loss: 0.00019826
INFO:root:[242,   600] training loss: 0.00016833
INFO:root:[242,   650] training loss: 0.00002873
INFO:root:[242,   700] training loss: 0.00003426
INFO:root:[242,   750] training loss: 0.00051556
INFO:root:[242,   800] training loss: 0.00047491
INFO:root:[242,   850] training loss: 0.00048874
INFO:root:[242,   900] training loss: 0.00361082
INFO:root:[242,   950] training loss: 0.00165710
INFO:root:[242,  1000] training loss: 0.00005737
INFO:root:[242,  1050] training loss: 0.00003133
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch242
INFO:root:[243,    50] training loss: 0.00716152
INFO:root:[243,   100] training loss: 0.00748805
INFO:root:[243,   150] training loss: 0.00702658
INFO:root:[243,   200] training loss: 0.00752389
INFO:root:[243,   250] training loss: 0.00657678
INFO:root:[243,   300] training loss: 0.00700833
INFO:root:[243,   350] training loss: 0.00621816
INFO:root:[243,   400] training loss: 0.00001075
INFO:root:[243,   450] training loss: 0.00001321
INFO:root:[243,   500] training loss: 0.00004615
INFO:root:[243,   550] training loss: 0.00022495
INFO:root:[243,   600] training loss: 0.00017850
INFO:root:[243,   650] training loss: 0.00002578
INFO:root:[243,   700] training loss: 0.00002727
INFO:root:[243,   750] training loss: 0.00049233
INFO:root:[243,   800] training loss: 0.00049490
INFO:root:[243,   850] training loss: 0.00045737
INFO:root:[243,   900] training loss: 0.00342927
INFO:root:[243,   950] training loss: 0.00129974
INFO:root:[243,  1000] training loss: 0.00006370
INFO:root:[243,  1050] training loss: 0.00004153
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch243
INFO:root:[244,    50] training loss: 0.00716682
INFO:root:[244,   100] training loss: 0.00743770
INFO:root:[244,   150] training loss: 0.00654501
INFO:root:[244,   200] training loss: 0.00693481
INFO:root:[244,   250] training loss: 0.00694581
INFO:root:[244,   300] training loss: 0.00739358
INFO:root:[244,   350] training loss: 0.00640554
INFO:root:[244,   400] training loss: 0.00001010
INFO:root:[244,   450] training loss: 0.00001262
INFO:root:[244,   500] training loss: 0.00003256
INFO:root:[244,   550] training loss: 0.00026480
INFO:root:[244,   600] training loss: 0.00015053
INFO:root:[244,   650] training loss: 0.00003828
INFO:root:[244,   700] training loss: 0.00003082
INFO:root:[244,   750] training loss: 0.00053914
INFO:root:[244,   800] training loss: 0.00058084
INFO:root:[244,   850] training loss: 0.00045772
INFO:root:[244,   900] training loss: 0.00373731
INFO:root:[244,   950] training loss: 0.00135044
INFO:root:[244,  1000] training loss: 0.00004153
INFO:root:[244,  1050] training loss: 0.00004834
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch244
INFO:root:[245,    50] training loss: 0.00694655
INFO:root:[245,   100] training loss: 0.00728269
INFO:root:[245,   150] training loss: 0.00694585
INFO:root:[245,   200] training loss: 0.00682162
INFO:root:[245,   250] training loss: 0.00703234
INFO:root:[245,   300] training loss: 0.00731163
INFO:root:[245,   350] training loss: 0.00798434
INFO:root:[245,   400] training loss: 0.00001008
INFO:root:[245,   450] training loss: 0.00001193
INFO:root:[245,   500] training loss: 0.00003677
INFO:root:[245,   550] training loss: 0.00023155
INFO:root:[245,   600] training loss: 0.00018488
INFO:root:[245,   650] training loss: 0.00002585
INFO:root:[245,   700] training loss: 0.00002773
INFO:root:[245,   750] training loss: 0.00053173
INFO:root:[245,   800] training loss: 0.00053681
INFO:root:[245,   850] training loss: 0.00040853
INFO:root:[245,   900] training loss: 0.00368709
INFO:root:[245,   950] training loss: 0.00183060
INFO:root:[245,  1000] training loss: 0.00006406
INFO:root:[245,  1050] training loss: 0.00003455
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch245
INFO:root:[246,    50] training loss: 0.00726927
INFO:root:[246,   100] training loss: 0.00729916
INFO:root:[246,   150] training loss: 0.00675711
INFO:root:[246,   200] training loss: 0.00709927
INFO:root:[246,   250] training loss: 0.00654705
INFO:root:[246,   300] training loss: 0.00726560
INFO:root:[246,   350] training loss: 0.00610704
INFO:root:[246,   400] training loss: 0.00001045
INFO:root:[246,   450] training loss: 0.00001182
INFO:root:[246,   500] training loss: 0.00002563
INFO:root:[246,   550] training loss: 0.00021863
INFO:root:[246,   600] training loss: 0.00018375
INFO:root:[246,   650] training loss: 0.00003309
INFO:root:[246,   700] training loss: 0.00003743
INFO:root:[246,   750] training loss: 0.00048057
INFO:root:[246,   800] training loss: 0.00056072
INFO:root:[246,   850] training loss: 0.00044893
INFO:root:[246,   900] training loss: 0.00316808
INFO:root:[246,   950] training loss: 0.00222135
INFO:root:[246,  1000] training loss: 0.00005694
INFO:root:[246,  1050] training loss: 0.00003341
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch246
INFO:root:[247,    50] training loss: 0.00694450
INFO:root:[247,   100] training loss: 0.00674112
INFO:root:[247,   150] training loss: 0.00673299
INFO:root:[247,   200] training loss: 0.00699037
INFO:root:[247,   250] training loss: 0.00694655
INFO:root:[247,   300] training loss: 0.00726098
INFO:root:[247,   350] training loss: 0.00616213
INFO:root:[247,   400] training loss: 0.00001061
INFO:root:[247,   450] training loss: 0.00001171
INFO:root:[247,   500] training loss: 0.00002868
INFO:root:[247,   550] training loss: 0.00023602
INFO:root:[247,   600] training loss: 0.00016998
INFO:root:[247,   650] training loss: 0.00004933
INFO:root:[247,   700] training loss: 0.00002466
INFO:root:[247,   750] training loss: 0.00053466
INFO:root:[247,   800] training loss: 0.00065290
INFO:root:[247,   850] training loss: 0.00053985
INFO:root:[247,   900] training loss: 0.00316054
INFO:root:[247,   950] training loss: 0.00141971
INFO:root:[247,  1000] training loss: 0.00005170
INFO:root:[247,  1050] training loss: 0.00004154
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch247
INFO:root:[248,    50] training loss: 0.00691190
INFO:root:[248,   100] training loss: 0.00701376
INFO:root:[248,   150] training loss: 0.00679757
INFO:root:[248,   200] training loss: 0.00666070
INFO:root:[248,   250] training loss: 0.00672873
INFO:root:[248,   300] training loss: 0.00683780
INFO:root:[248,   350] training loss: 0.00570898
INFO:root:[248,   400] training loss: 0.00001124
INFO:root:[248,   450] training loss: 0.00001460
INFO:root:[248,   500] training loss: 0.00004961
INFO:root:[248,   550] training loss: 0.00021369
INFO:root:[248,   600] training loss: 0.00017990
INFO:root:[248,   650] training loss: 0.00002819
INFO:root:[248,   700] training loss: 0.00002793
INFO:root:[248,   750] training loss: 0.00046151
INFO:root:[248,   800] training loss: 0.00051459
INFO:root:[248,   850] training loss: 0.00047661
INFO:root:[248,   900] training loss: 0.00313941
INFO:root:[248,   950] training loss: 0.00153113
INFO:root:[248,  1000] training loss: 0.00006306
INFO:root:[248,  1050] training loss: 0.00008165
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch248
INFO:root:[249,    50] training loss: 0.00763563
INFO:root:[249,   100] training loss: 0.00720189
INFO:root:[249,   150] training loss: 0.00656840
INFO:root:[249,   200] training loss: 0.00698114
INFO:root:[249,   250] training loss: 0.00681277
INFO:root:[249,   300] training loss: 0.00710245
INFO:root:[249,   350] training loss: 0.00566009
INFO:root:[249,   400] training loss: 0.00001021
INFO:root:[249,   450] training loss: 0.00001298
INFO:root:[249,   500] training loss: 0.00004744
INFO:root:[249,   550] training loss: 0.00017695
INFO:root:[249,   600] training loss: 0.00015087
INFO:root:[249,   650] training loss: 0.00002854
INFO:root:[249,   700] training loss: 0.00002472
INFO:root:[249,   750] training loss: 0.00051458
INFO:root:[249,   800] training loss: 0.00054546
INFO:root:[249,   850] training loss: 0.00054450
INFO:root:[249,   900] training loss: 0.00341992
INFO:root:[249,   950] training loss: 0.00144830
INFO:root:[249,  1000] training loss: 0.00004972
INFO:root:[249,  1050] training loss: 0.00004255
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch249
INFO:root:[250,    50] training loss: 0.00726042
INFO:root:[250,   100] training loss: 0.00725819
INFO:root:[250,   150] training loss: 0.00665038
INFO:root:[250,   200] training loss: 0.00762709
INFO:root:[250,   250] training loss: 0.00694504
INFO:root:[250,   300] training loss: 0.00749017
INFO:root:[250,   350] training loss: 0.00587481
INFO:root:[250,   400] training loss: 0.00001023
INFO:root:[250,   450] training loss: 0.00001262
INFO:root:[250,   500] training loss: 0.00004920
INFO:root:[250,   550] training loss: 0.00032869
INFO:root:[250,   600] training loss: 0.00013621
INFO:root:[250,   650] training loss: 0.00002948
INFO:root:[250,   700] training loss: 0.00003148
INFO:root:[250,   750] training loss: 0.00045580
INFO:root:[250,   800] training loss: 0.00049406
INFO:root:[250,   850] training loss: 0.00044636
INFO:root:[250,   900] training loss: 0.00349392
INFO:root:[250,   950] training loss: 0.00157067
INFO:root:[250,  1000] training loss: 0.00004440
INFO:root:[250,  1050] training loss: 0.00004185
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch250
INFO:root:[251,    50] training loss: 0.00706085
INFO:root:[251,   100] training loss: 0.00748425
INFO:root:[251,   150] training loss: 0.00659779
INFO:root:[251,   200] training loss: 0.00668481
INFO:root:[251,   250] training loss: 0.00680783
INFO:root:[251,   300] training loss: 0.00740976
INFO:root:[251,   350] training loss: 0.00602266
INFO:root:[251,   400] training loss: 0.00001380
INFO:root:[251,   450] training loss: 0.00001380
INFO:root:[251,   500] training loss: 0.00003398
INFO:root:[251,   550] training loss: 0.00023896
INFO:root:[251,   600] training loss: 0.00016916
INFO:root:[251,   650] training loss: 0.00002614
INFO:root:[251,   700] training loss: 0.00003719
INFO:root:[251,   750] training loss: 0.00050737
INFO:root:[251,   800] training loss: 0.00046789
INFO:root:[251,   850] training loss: 0.00045442
INFO:root:[251,   900] training loss: 0.00341382
INFO:root:[251,   950] training loss: 0.00162049
INFO:root:[251,  1000] training loss: 0.00004888
INFO:root:[251,  1050] training loss: 0.00003570
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch251
INFO:root:[252,    50] training loss: 0.00793758
INFO:root:[252,   100] training loss: 0.00726896
INFO:root:[252,   150] training loss: 0.00701276
INFO:root:[252,   200] training loss: 0.00678080
INFO:root:[252,   250] training loss: 0.00667398
INFO:root:[252,   300] training loss: 0.00746864
INFO:root:[252,   350] training loss: 0.00547372
INFO:root:[252,   400] training loss: 0.00000962
INFO:root:[252,   450] training loss: 0.00001222
INFO:root:[252,   500] training loss: 0.00005487
INFO:root:[252,   550] training loss: 0.00020008
INFO:root:[252,   600] training loss: 0.00017449
INFO:root:[252,   650] training loss: 0.00003057
INFO:root:[252,   700] training loss: 0.00002865
INFO:root:[252,   750] training loss: 0.00048772
INFO:root:[252,   800] training loss: 0.00049880
INFO:root:[252,   850] training loss: 0.00043712
INFO:root:[252,   900] training loss: 0.00316617
INFO:root:[252,   950] training loss: 0.00160683
INFO:root:[252,  1000] training loss: 0.00005955
INFO:root:[252,  1050] training loss: 0.00004479
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch252
INFO:root:[253,    50] training loss: 0.00762990
INFO:root:[253,   100] training loss: 0.00775147
INFO:root:[253,   150] training loss: 0.00650425
INFO:root:[253,   200] training loss: 0.00668511
INFO:root:[253,   250] training loss: 0.00669536
INFO:root:[253,   300] training loss: 0.00730009
INFO:root:[253,   350] training loss: 0.00594696
INFO:root:[253,   400] training loss: 0.00001036
INFO:root:[253,   450] training loss: 0.00001329
INFO:root:[253,   500] training loss: 0.00003549
INFO:root:[253,   550] training loss: 0.00031303
INFO:root:[253,   600] training loss: 0.00023385
INFO:root:[253,   650] training loss: 0.00003376
INFO:root:[253,   700] training loss: 0.00002535
INFO:root:[253,   750] training loss: 0.00060147
INFO:root:[253,   800] training loss: 0.00054375
INFO:root:[253,   850] training loss: 0.00050980
INFO:root:[253,   900] training loss: 0.00327269
INFO:root:[253,   950] training loss: 0.00107469
INFO:root:[253,  1000] training loss: 0.00007459
INFO:root:[253,  1050] training loss: 0.00004568
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch253
INFO:root:[254,    50] training loss: 0.00760034
INFO:root:[254,   100] training loss: 0.00695562
INFO:root:[254,   150] training loss: 0.00698394
INFO:root:[254,   200] training loss: 0.00698026
INFO:root:[254,   250] training loss: 0.00671785
INFO:root:[254,   300] training loss: 0.00743658
INFO:root:[254,   350] training loss: 0.00583175
INFO:root:[254,   400] training loss: 0.00001111
INFO:root:[254,   450] training loss: 0.00001324
INFO:root:[254,   500] training loss: 0.00002889
INFO:root:[254,   550] training loss: 0.00021721
INFO:root:[254,   600] training loss: 0.00016430
INFO:root:[254,   650] training loss: 0.00002810
INFO:root:[254,   700] training loss: 0.00002811
INFO:root:[254,   750] training loss: 0.00053473
INFO:root:[254,   800] training loss: 0.00043675
INFO:root:[254,   850] training loss: 0.00046491
INFO:root:[254,   900] training loss: 0.00479239
INFO:root:[254,   950] training loss: 0.00150306
INFO:root:[254,  1000] training loss: 0.00008393
INFO:root:[254,  1050] training loss: 0.00004837
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch254
INFO:root:[255,    50] training loss: 0.00747345
INFO:root:[255,   100] training loss: 0.00760861
INFO:root:[255,   150] training loss: 0.00665717
INFO:root:[255,   200] training loss: 0.00660653
INFO:root:[255,   250] training loss: 0.00672052
INFO:root:[255,   300] training loss: 0.00727853
INFO:root:[255,   350] training loss: 0.00650986
INFO:root:[255,   400] training loss: 0.00001047
INFO:root:[255,   450] training loss: 0.00001448
INFO:root:[255,   500] training loss: 0.00003802
INFO:root:[255,   550] training loss: 0.00023573
INFO:root:[255,   600] training loss: 0.00014633
INFO:root:[255,   650] training loss: 0.00002897
INFO:root:[255,   700] training loss: 0.00003812
INFO:root:[255,   750] training loss: 0.00051962
INFO:root:[255,   800] training loss: 0.00054245
INFO:root:[255,   850] training loss: 0.00048608
INFO:root:[255,   900] training loss: 0.00349107
INFO:root:[255,   950] training loss: 0.00153326
INFO:root:[255,  1000] training loss: 0.00005852
INFO:root:[255,  1050] training loss: 0.00003275
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch255
INFO:root:[256,    50] training loss: 0.00764017
INFO:root:[256,   100] training loss: 0.00741308
INFO:root:[256,   150] training loss: 0.00672266
INFO:root:[256,   200] training loss: 0.00656264
INFO:root:[256,   250] training loss: 0.00691748
INFO:root:[256,   300] training loss: 0.00717046
INFO:root:[256,   350] training loss: 0.00624790
INFO:root:[256,   400] training loss: 0.00001006
INFO:root:[256,   450] training loss: 0.00001416
INFO:root:[256,   500] training loss: 0.00003678
INFO:root:[256,   550] training loss: 0.00024364
INFO:root:[256,   600] training loss: 0.00017231
INFO:root:[256,   650] training loss: 0.00005983
INFO:root:[256,   700] training loss: 0.00002891
INFO:root:[256,   750] training loss: 0.00048789
INFO:root:[256,   800] training loss: 0.00048140
INFO:root:[256,   850] training loss: 0.00042492
INFO:root:[256,   900] training loss: 0.00410523
INFO:root:[256,   950] training loss: 0.00111273
INFO:root:[256,  1000] training loss: 0.00004986
INFO:root:[256,  1050] training loss: 0.00003583
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch256
INFO:root:[257,    50] training loss: 0.00709214
INFO:root:[257,   100] training loss: 0.00747449
INFO:root:[257,   150] training loss: 0.00663669
INFO:root:[257,   200] training loss: 0.00706518
INFO:root:[257,   250] training loss: 0.00659391
INFO:root:[257,   300] training loss: 0.00747515
INFO:root:[257,   350] training loss: 0.00614027
INFO:root:[257,   400] training loss: 0.00000971
INFO:root:[257,   450] training loss: 0.00002181
INFO:root:[257,   500] training loss: 0.00003043
INFO:root:[257,   550] training loss: 0.00044391
INFO:root:[257,   600] training loss: 0.00019012
INFO:root:[257,   650] training loss: 0.00003257
INFO:root:[257,   700] training loss: 0.00002773
INFO:root:[257,   750] training loss: 0.00044769
INFO:root:[257,   800] training loss: 0.00054808
INFO:root:[257,   850] training loss: 0.00056325
INFO:root:[257,   900] training loss: 0.00355143
INFO:root:[257,   950] training loss: 0.00131239
INFO:root:[257,  1000] training loss: 0.00007433
INFO:root:[257,  1050] training loss: 0.00004741
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch257
INFO:root:[258,    50] training loss: 0.00727782
INFO:root:[258,   100] training loss: 0.00726181
INFO:root:[258,   150] training loss: 0.00641112
INFO:root:[258,   200] training loss: 0.00661187
INFO:root:[258,   250] training loss: 0.00674341
INFO:root:[258,   300] training loss: 0.00801059
INFO:root:[258,   350] training loss: 0.00561231
INFO:root:[258,   400] training loss: 0.00001032
INFO:root:[258,   450] training loss: 0.00001162
INFO:root:[258,   500] training loss: 0.00004760
INFO:root:[258,   550] training loss: 0.00023405
INFO:root:[258,   600] training loss: 0.00015396
INFO:root:[258,   650] training loss: 0.00002860
INFO:root:[258,   700] training loss: 0.00002799
INFO:root:[258,   750] training loss: 0.00054781
INFO:root:[258,   800] training loss: 0.00052883
INFO:root:[258,   850] training loss: 0.00047114
INFO:root:[258,   900] training loss: 0.00360150
INFO:root:[258,   950] training loss: 0.00138027
INFO:root:[258,  1000] training loss: 0.00005967
INFO:root:[258,  1050] training loss: 0.00004836
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch258
INFO:root:[259,    50] training loss: 0.00718796
INFO:root:[259,   100] training loss: 0.00754582
INFO:root:[259,   150] training loss: 0.00649919
INFO:root:[259,   200] training loss: 0.00649743
INFO:root:[259,   250] training loss: 0.00704376
INFO:root:[259,   300] training loss: 0.00703475
INFO:root:[259,   350] training loss: 0.00632645
INFO:root:[259,   400] training loss: 0.00001119
INFO:root:[259,   450] training loss: 0.00001355
INFO:root:[259,   500] training loss: 0.00002144
INFO:root:[259,   550] training loss: 0.00020917
INFO:root:[259,   600] training loss: 0.00014519
INFO:root:[259,   650] training loss: 0.00003421
INFO:root:[259,   700] training loss: 0.00002855
INFO:root:[259,   750] training loss: 0.00047481
INFO:root:[259,   800] training loss: 0.00047367
INFO:root:[259,   850] training loss: 0.00052299
INFO:root:[259,   900] training loss: 0.00349984
INFO:root:[259,   950] training loss: 0.00131865
INFO:root:[259,  1000] training loss: 0.00005623
INFO:root:[259,  1050] training loss: 0.00003944
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch259
INFO:root:[260,    50] training loss: 0.00703563
INFO:root:[260,   100] training loss: 0.00702012
INFO:root:[260,   150] training loss: 0.00688144
INFO:root:[260,   200] training loss: 0.00731972
INFO:root:[260,   250] training loss: 0.00677399
INFO:root:[260,   300] training loss: 0.00720808
INFO:root:[260,   350] training loss: 0.00627853
INFO:root:[260,   400] training loss: 0.00001125
INFO:root:[260,   450] training loss: 0.00001664
INFO:root:[260,   500] training loss: 0.00002916
INFO:root:[260,   550] training loss: 0.00024383
INFO:root:[260,   600] training loss: 0.00017483
INFO:root:[260,   650] training loss: 0.00002611
INFO:root:[260,   700] training loss: 0.00002519
INFO:root:[260,   750] training loss: 0.00053428
INFO:root:[260,   800] training loss: 0.00053665
INFO:root:[260,   850] training loss: 0.00048057
INFO:root:[260,   900] training loss: 0.00367978
INFO:root:[260,   950] training loss: 0.00147819
INFO:root:[260,  1000] training loss: 0.00005746
INFO:root:[260,  1050] training loss: 0.00006015
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch260
INFO:root:[261,    50] training loss: 0.00712840
INFO:root:[261,   100] training loss: 0.00740669
INFO:root:[261,   150] training loss: 0.00705780
INFO:root:[261,   200] training loss: 0.00677047
INFO:root:[261,   250] training loss: 0.00909066
INFO:root:[261,   300] training loss: 0.00694230
INFO:root:[261,   350] training loss: 0.00674416
INFO:root:[261,   400] training loss: 0.00001052
INFO:root:[261,   450] training loss: 0.00001884
INFO:root:[261,   500] training loss: 0.00005670
INFO:root:[261,   550] training loss: 0.00020968
INFO:root:[261,   600] training loss: 0.00018531
INFO:root:[261,   650] training loss: 0.00002526
INFO:root:[261,   700] training loss: 0.00003508
INFO:root:[261,   750] training loss: 0.00054548
INFO:root:[261,   800] training loss: 0.00056819
INFO:root:[261,   850] training loss: 0.00048255
INFO:root:[261,   900] training loss: 0.00358724
INFO:root:[261,   950] training loss: 0.00161840
INFO:root:[261,  1000] training loss: 0.00004402
INFO:root:[261,  1050] training loss: 0.00003652
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch261
INFO:root:[262,    50] training loss: 0.00759213
INFO:root:[262,   100] training loss: 0.00753634
INFO:root:[262,   150] training loss: 0.00683307
INFO:root:[262,   200] training loss: 0.00753772
INFO:root:[262,   250] training loss: 0.00693692
INFO:root:[262,   300] training loss: 0.00742925
INFO:root:[262,   350] training loss: 0.00556136
INFO:root:[262,   400] training loss: 0.00001068
INFO:root:[262,   450] training loss: 0.00001279
INFO:root:[262,   500] training loss: 0.00004864
INFO:root:[262,   550] training loss: 0.00016842
INFO:root:[262,   600] training loss: 0.00019528
INFO:root:[262,   650] training loss: 0.00002887
INFO:root:[262,   700] training loss: 0.00002945
INFO:root:[262,   750] training loss: 0.00041865
INFO:root:[262,   800] training loss: 0.00054789
INFO:root:[262,   850] training loss: 0.00052802
INFO:root:[262,   900] training loss: 0.00393332
INFO:root:[262,   950] training loss: 0.00132639
INFO:root:[262,  1000] training loss: 0.00007740
INFO:root:[262,  1050] training loss: 0.00003906
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch262
INFO:root:[263,    50] training loss: 0.00683333
INFO:root:[263,   100] training loss: 0.00723400
INFO:root:[263,   150] training loss: 0.00641537
INFO:root:[263,   200] training loss: 0.00713571
INFO:root:[263,   250] training loss: 0.00703327
INFO:root:[263,   300] training loss: 0.00735054
INFO:root:[263,   350] training loss: 0.00581383
INFO:root:[263,   400] training loss: 0.00001000
INFO:root:[263,   450] training loss: 0.00002574
INFO:root:[263,   500] training loss: 0.00003859
INFO:root:[263,   550] training loss: 0.00022226
INFO:root:[263,   600] training loss: 0.00018465
INFO:root:[263,   650] training loss: 0.00002860
INFO:root:[263,   700] training loss: 0.00003355
INFO:root:[263,   750] training loss: 0.00044716
INFO:root:[263,   800] training loss: 0.00055109
INFO:root:[263,   850] training loss: 0.00052266
INFO:root:[263,   900] training loss: 0.00367509
INFO:root:[263,   950] training loss: 0.00157639
INFO:root:[263,  1000] training loss: 0.00005690
INFO:root:[263,  1050] training loss: 0.00003823
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch263
INFO:root:[264,    50] training loss: 0.00693509
INFO:root:[264,   100] training loss: 0.00690985
INFO:root:[264,   150] training loss: 0.00677316
INFO:root:[264,   200] training loss: 0.00675082
INFO:root:[264,   250] training loss: 0.00667724
INFO:root:[264,   300] training loss: 0.00708360
INFO:root:[264,   350] training loss: 0.00606446
INFO:root:[264,   400] training loss: 0.00000931
INFO:root:[264,   450] training loss: 0.00001346
INFO:root:[264,   500] training loss: 0.00003107
INFO:root:[264,   550] training loss: 0.00019687
INFO:root:[264,   600] training loss: 0.00015169
INFO:root:[264,   650] training loss: 0.00002979
INFO:root:[264,   700] training loss: 0.00003041
INFO:root:[264,   750] training loss: 0.00052655
INFO:root:[264,   800] training loss: 0.00050520
INFO:root:[264,   850] training loss: 0.00048084
INFO:root:[264,   900] training loss: 0.00380278
INFO:root:[264,   950] training loss: 0.00174076
INFO:root:[264,  1000] training loss: 0.00008990
INFO:root:[264,  1050] training loss: 0.00006866
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch264
INFO:root:[265,    50] training loss: 0.00708132
INFO:root:[265,   100] training loss: 0.00696548
INFO:root:[265,   150] training loss: 0.00666070
INFO:root:[265,   200] training loss: 0.00703661
INFO:root:[265,   250] training loss: 0.00656065
INFO:root:[265,   300] training loss: 0.00760961
INFO:root:[265,   350] training loss: 0.00639190
INFO:root:[265,   400] training loss: 0.00000963
INFO:root:[265,   450] training loss: 0.00001200
INFO:root:[265,   500] training loss: 0.00004182
INFO:root:[265,   550] training loss: 0.00022979
INFO:root:[265,   600] training loss: 0.00013677
INFO:root:[265,   650] training loss: 0.00003756
INFO:root:[265,   700] training loss: 0.00002512
INFO:root:[265,   750] training loss: 0.00057978
INFO:root:[265,   800] training loss: 0.00048649
INFO:root:[265,   850] training loss: 0.00046318
INFO:root:[265,   900] training loss: 0.00393288
INFO:root:[265,   950] training loss: 0.00162928
INFO:root:[265,  1000] training loss: 0.00005643
INFO:root:[265,  1050] training loss: 0.00003645
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch265
INFO:root:[266,    50] training loss: 0.00710019
INFO:root:[266,   100] training loss: 0.00701621
INFO:root:[266,   150] training loss: 0.00684245
INFO:root:[266,   200] training loss: 0.00713188
INFO:root:[266,   250] training loss: 0.00651810
INFO:root:[266,   300] training loss: 0.00742457
INFO:root:[266,   350] training loss: 0.00625998
INFO:root:[266,   400] training loss: 0.00001036
INFO:root:[266,   450] training loss: 0.00001272
INFO:root:[266,   500] training loss: 0.00003895
INFO:root:[266,   550] training loss: 0.00022920
INFO:root:[266,   600] training loss: 0.00015283
INFO:root:[266,   650] training loss: 0.00002807
INFO:root:[266,   700] training loss: 0.00002993
INFO:root:[266,   750] training loss: 0.00052550
INFO:root:[266,   800] training loss: 0.00055758
INFO:root:[266,   850] training loss: 0.00045989
INFO:root:[266,   900] training loss: 0.00333630
INFO:root:[266,   950] training loss: 0.00170819
INFO:root:[266,  1000] training loss: 0.00004552
INFO:root:[266,  1050] training loss: 0.00004296
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch266
INFO:root:[267,    50] training loss: 0.00695880
INFO:root:[267,   100] training loss: 0.00771778
INFO:root:[267,   150] training loss: 0.00691589
INFO:root:[267,   200] training loss: 0.00721231
INFO:root:[267,   250] training loss: 0.00662870
INFO:root:[267,   300] training loss: 0.00753132
INFO:root:[267,   350] training loss: 0.00610794
INFO:root:[267,   400] training loss: 0.00001191
INFO:root:[267,   450] training loss: 0.00001533
INFO:root:[267,   500] training loss: 0.00002993
INFO:root:[267,   550] training loss: 0.00020609
INFO:root:[267,   600] training loss: 0.00016480
INFO:root:[267,   650] training loss: 0.00002766
INFO:root:[267,   700] training loss: 0.00002459
INFO:root:[267,   750] training loss: 0.00045669
INFO:root:[267,   800] training loss: 0.00052101
INFO:root:[267,   850] training loss: 0.00045327
INFO:root:[267,   900] training loss: 0.00440256
INFO:root:[267,   950] training loss: 0.00141809
INFO:root:[267,  1000] training loss: 0.00005713
INFO:root:[267,  1050] training loss: 0.00003979
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch267
INFO:root:[268,    50] training loss: 0.00726051
INFO:root:[268,   100] training loss: 0.00711637
INFO:root:[268,   150] training loss: 0.00723781
INFO:root:[268,   200] training loss: 0.00734905
INFO:root:[268,   250] training loss: 0.00691616
INFO:root:[268,   300] training loss: 0.00719341
INFO:root:[268,   350] training loss: 0.00575428
INFO:root:[268,   400] training loss: 0.00001142
INFO:root:[268,   450] training loss: 0.00001349
INFO:root:[268,   500] training loss: 0.00004524
INFO:root:[268,   550] training loss: 0.00028046
INFO:root:[268,   600] training loss: 0.00016623
INFO:root:[268,   650] training loss: 0.00003301
INFO:root:[268,   700] training loss: 0.00002264
INFO:root:[268,   750] training loss: 0.00057129
INFO:root:[268,   800] training loss: 0.00054762
INFO:root:[268,   850] training loss: 0.00047695
INFO:root:[268,   900] training loss: 0.00382877
INFO:root:[268,   950] training loss: 0.00161424
INFO:root:[268,  1000] training loss: 0.00004858
INFO:root:[268,  1050] training loss: 0.00003846
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch268
INFO:root:[269,    50] training loss: 0.00711122
INFO:root:[269,   100] training loss: 0.00811759
INFO:root:[269,   150] training loss: 0.00700853
INFO:root:[269,   200] training loss: 0.00676959
INFO:root:[269,   250] training loss: 0.00646119
INFO:root:[269,   300] training loss: 0.00738218
INFO:root:[269,   350] training loss: 0.00622882
INFO:root:[269,   400] training loss: 0.00001127
INFO:root:[269,   450] training loss: 0.00001231
INFO:root:[269,   500] training loss: 0.00008437
INFO:root:[269,   550] training loss: 0.00021455
INFO:root:[269,   600] training loss: 0.00014798
INFO:root:[269,   650] training loss: 0.00002444
INFO:root:[269,   700] training loss: 0.00002918
INFO:root:[269,   750] training loss: 0.00049217
INFO:root:[269,   800] training loss: 0.00057401
INFO:root:[269,   850] training loss: 0.00037254
INFO:root:[269,   900] training loss: 0.00369031
INFO:root:[269,   950] training loss: 0.00162063
INFO:root:[269,  1000] training loss: 0.00005986
INFO:root:[269,  1050] training loss: 0.00003238
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch269
INFO:root:[270,    50] training loss: 0.00696697
INFO:root:[270,   100] training loss: 0.00732975
INFO:root:[270,   150] training loss: 0.00664719
INFO:root:[270,   200] training loss: 0.00643762
INFO:root:[270,   250] training loss: 0.00702923
INFO:root:[270,   300] training loss: 0.00740857
INFO:root:[270,   350] training loss: 0.00596130
INFO:root:[270,   400] training loss: 0.00001016
INFO:root:[270,   450] training loss: 0.00001667
INFO:root:[270,   500] training loss: 0.00004835
INFO:root:[270,   550] training loss: 0.00028110
INFO:root:[270,   600] training loss: 0.00015461
INFO:root:[270,   650] training loss: 0.00003069
INFO:root:[270,   700] training loss: 0.00002899
INFO:root:[270,   750] training loss: 0.00057976
INFO:root:[270,   800] training loss: 0.00050882
INFO:root:[270,   850] training loss: 0.00054577
INFO:root:[270,   900] training loss: 0.00362422
INFO:root:[270,   950] training loss: 0.00138581
INFO:root:[270,  1000] training loss: 0.00005436
INFO:root:[270,  1050] training loss: 0.00004975
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch270
INFO:root:[271,    50] training loss: 0.00699651
INFO:root:[271,   100] training loss: 0.00721426
INFO:root:[271,   150] training loss: 0.00665265
INFO:root:[271,   200] training loss: 0.00778078
INFO:root:[271,   250] training loss: 0.00699498
INFO:root:[271,   300] training loss: 0.00723388
INFO:root:[271,   350] training loss: 0.00577128
INFO:root:[271,   400] training loss: 0.00001029
INFO:root:[271,   450] training loss: 0.00010626
INFO:root:[271,   500] training loss: 0.00003505
INFO:root:[271,   550] training loss: 0.00020298
INFO:root:[271,   600] training loss: 0.00014641
INFO:root:[271,   650] training loss: 0.00003561
INFO:root:[271,   700] training loss: 0.00002417
INFO:root:[271,   750] training loss: 0.00054292
INFO:root:[271,   800] training loss: 0.00061413
INFO:root:[271,   850] training loss: 0.00046415
INFO:root:[271,   900] training loss: 0.00342221
INFO:root:[271,   950] training loss: 0.00179887
INFO:root:[271,  1000] training loss: 0.00006276
INFO:root:[271,  1050] training loss: 0.00003767
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch271
INFO:root:[272,    50] training loss: 0.00693920
INFO:root:[272,   100] training loss: 0.00747307
INFO:root:[272,   150] training loss: 0.00681638
INFO:root:[272,   200] training loss: 0.00680491
INFO:root:[272,   250] training loss: 0.00678083
INFO:root:[272,   300] training loss: 0.00754158
INFO:root:[272,   350] training loss: 0.00571091
INFO:root:[272,   400] training loss: 0.00001083
INFO:root:[272,   450] training loss: 0.00001494
INFO:root:[272,   500] training loss: 0.00003691
INFO:root:[272,   550] training loss: 0.00023946
INFO:root:[272,   600] training loss: 0.00012462
INFO:root:[272,   650] training loss: 0.00002607
INFO:root:[272,   700] training loss: 0.00002677
INFO:root:[272,   750] training loss: 0.00043811
INFO:root:[272,   800] training loss: 0.00049043
INFO:root:[272,   850] training loss: 0.00056721
INFO:root:[272,   900] training loss: 0.00423055
INFO:root:[272,   950] training loss: 0.00144830
INFO:root:[272,  1000] training loss: 0.00005975
INFO:root:[272,  1050] training loss: 0.00003994
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch272
INFO:root:[273,    50] training loss: 0.00674821
INFO:root:[273,   100] training loss: 0.00695981
INFO:root:[273,   150] training loss: 0.00634291
INFO:root:[273,   200] training loss: 0.00728005
INFO:root:[273,   250] training loss: 0.00662732
INFO:root:[273,   300] training loss: 0.00733189
INFO:root:[273,   350] training loss: 0.00560750
INFO:root:[273,   400] training loss: 0.00001392
INFO:root:[273,   450] training loss: 0.00001415
INFO:root:[273,   500] training loss: 0.00004515
INFO:root:[273,   550] training loss: 0.00020861
INFO:root:[273,   600] training loss: 0.00016004
INFO:root:[273,   650] training loss: 0.00002619
INFO:root:[273,   700] training loss: 0.00005591
INFO:root:[273,   750] training loss: 0.00049803
INFO:root:[273,   800] training loss: 0.00048583
INFO:root:[273,   850] training loss: 0.00052963
INFO:root:[273,   900] training loss: 0.00340478
INFO:root:[273,   950] training loss: 0.00182643
INFO:root:[273,  1000] training loss: 0.00004810
INFO:root:[273,  1050] training loss: 0.00003509
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch273
INFO:root:[274,    50] training loss: 0.00679065
INFO:root:[274,   100] training loss: 0.00689876
INFO:root:[274,   150] training loss: 0.00667690
INFO:root:[274,   200] training loss: 0.00760762
INFO:root:[274,   250] training loss: 0.00676520
INFO:root:[274,   300] training loss: 0.00747625
INFO:root:[274,   350] training loss: 0.00619054
INFO:root:[274,   400] training loss: 0.00000941
INFO:root:[274,   450] training loss: 0.00001166
INFO:root:[274,   500] training loss: 0.00006226
INFO:root:[274,   550] training loss: 0.00027338
INFO:root:[274,   600] training loss: 0.00014313
INFO:root:[274,   650] training loss: 0.00003583
INFO:root:[274,   700] training loss: 0.00003268
INFO:root:[274,   750] training loss: 0.00061433
INFO:root:[274,   800] training loss: 0.00052917
INFO:root:[274,   850] training loss: 0.00039695
INFO:root:[274,   900] training loss: 0.00373431
INFO:root:[274,   950] training loss: 0.00146436
INFO:root:[274,  1000] training loss: 0.00006086
INFO:root:[274,  1050] training loss: 0.00003638
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch274
INFO:root:[275,    50] training loss: 0.00708619
INFO:root:[275,   100] training loss: 0.00731162
INFO:root:[275,   150] training loss: 0.00681965
INFO:root:[275,   200] training loss: 0.00693684
INFO:root:[275,   250] training loss: 0.00845148
INFO:root:[275,   300] training loss: 0.00729941
INFO:root:[275,   350] training loss: 0.00564518
INFO:root:[275,   400] training loss: 0.00001049
INFO:root:[275,   450] training loss: 0.00001528
INFO:root:[275,   500] training loss: 0.00005683
INFO:root:[275,   550] training loss: 0.00024348
INFO:root:[275,   600] training loss: 0.00020752
INFO:root:[275,   650] training loss: 0.00003180
INFO:root:[275,   700] training loss: 0.00002840
INFO:root:[275,   750] training loss: 0.00052015
INFO:root:[275,   800] training loss: 0.00047685
INFO:root:[275,   850] training loss: 0.00049811
INFO:root:[275,   900] training loss: 0.00397680
INFO:root:[275,   950] training loss: 0.00168251
INFO:root:[275,  1000] training loss: 0.00005484
INFO:root:[275,  1050] training loss: 0.00004361
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch275
INFO:root:[276,    50] training loss: 0.00714115
INFO:root:[276,   100] training loss: 0.00744188
INFO:root:[276,   150] training loss: 0.00650543
INFO:root:[276,   200] training loss: 0.00682155
INFO:root:[276,   250] training loss: 0.00825278
INFO:root:[276,   300] training loss: 0.00749044
INFO:root:[276,   350] training loss: 0.00599833
INFO:root:[276,   400] training loss: 0.00001080
INFO:root:[276,   450] training loss: 0.00001207
INFO:root:[276,   500] training loss: 0.00002659
INFO:root:[276,   550] training loss: 0.00023799
INFO:root:[276,   600] training loss: 0.00016284
INFO:root:[276,   650] training loss: 0.00002835
INFO:root:[276,   700] training loss: 0.00003069
INFO:root:[276,   750] training loss: 0.00051913
INFO:root:[276,   800] training loss: 0.00053888
INFO:root:[276,   850] training loss: 0.00046250
INFO:root:[276,   900] training loss: 0.00365181
INFO:root:[276,   950] training loss: 0.00155154
INFO:root:[276,  1000] training loss: 0.00005097
INFO:root:[276,  1050] training loss: 0.00004185
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch276
INFO:root:[277,    50] training loss: 0.00725855
INFO:root:[277,   100] training loss: 0.00750891
INFO:root:[277,   150] training loss: 0.00656817
INFO:root:[277,   200] training loss: 0.00671998
INFO:root:[277,   250] training loss: 0.00665211
INFO:root:[277,   300] training loss: 0.00750733
INFO:root:[277,   350] training loss: 0.00626050
INFO:root:[277,   400] training loss: 0.00001164
INFO:root:[277,   450] training loss: 0.00001451
INFO:root:[277,   500] training loss: 0.00003965
INFO:root:[277,   550] training loss: 0.00021854
INFO:root:[277,   600] training loss: 0.00018386
INFO:root:[277,   650] training loss: 0.00003727
INFO:root:[277,   700] training loss: 0.00002582
INFO:root:[277,   750] training loss: 0.00044068
INFO:root:[277,   800] training loss: 0.00051170
INFO:root:[277,   850] training loss: 0.00045900
INFO:root:[277,   900] training loss: 0.00367745
INFO:root:[277,   950] training loss: 0.00136949
INFO:root:[277,  1000] training loss: 0.00005442
INFO:root:[277,  1050] training loss: 0.00004309
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch277
INFO:root:[278,    50] training loss: 0.00716337
INFO:root:[278,   100] training loss: 0.00705710
INFO:root:[278,   150] training loss: 0.00676274
INFO:root:[278,   200] training loss: 0.00730054
INFO:root:[278,   250] training loss: 0.00686905
INFO:root:[278,   300] training loss: 0.00687827
INFO:root:[278,   350] training loss: 0.00672430
INFO:root:[278,   400] training loss: 0.00001054
INFO:root:[278,   450] training loss: 0.00001558
INFO:root:[278,   500] training loss: 0.00006712
INFO:root:[278,   550] training loss: 0.00025860
INFO:root:[278,   600] training loss: 0.00016457
INFO:root:[278,   650] training loss: 0.00003404
INFO:root:[278,   700] training loss: 0.00003367
INFO:root:[278,   750] training loss: 0.00051830
INFO:root:[278,   800] training loss: 0.00052289
INFO:root:[278,   850] training loss: 0.00047802
INFO:root:[278,   900] training loss: 0.00369905
INFO:root:[278,   950] training loss: 0.00148261
INFO:root:[278,  1000] training loss: 0.00006029
INFO:root:[278,  1050] training loss: 0.00003746
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch278
INFO:root:[279,    50] training loss: 0.00700267
INFO:root:[279,   100] training loss: 0.00762010
INFO:root:[279,   150] training loss: 0.00702033
INFO:root:[279,   200] training loss: 0.00654996
INFO:root:[279,   250] training loss: 0.00655384
INFO:root:[279,   300] training loss: 0.00785953
INFO:root:[279,   350] training loss: 0.00590251
INFO:root:[279,   400] training loss: 0.00001053
INFO:root:[279,   450] training loss: 0.00001246
INFO:root:[279,   500] training loss: 0.00003349
INFO:root:[279,   550] training loss: 0.00023436
INFO:root:[279,   600] training loss: 0.00017288
INFO:root:[279,   650] training loss: 0.00002706
INFO:root:[279,   700] training loss: 0.00002363
INFO:root:[279,   750] training loss: 0.00054478
INFO:root:[279,   800] training loss: 0.00050672
INFO:root:[279,   850] training loss: 0.00051024
INFO:root:[279,   900] training loss: 0.00409103
INFO:root:[279,   950] training loss: 0.00125877
INFO:root:[279,  1000] training loss: 0.00005122
INFO:root:[279,  1050] training loss: 0.00005376
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch279
INFO:root:[280,    50] training loss: 0.00738359
INFO:root:[280,   100] training loss: 0.00719462
INFO:root:[280,   150] training loss: 0.00722939
INFO:root:[280,   200] training loss: 0.00693239
INFO:root:[280,   250] training loss: 0.00697992
INFO:root:[280,   300] training loss: 0.00701441
INFO:root:[280,   350] training loss: 0.00608686
INFO:root:[280,   400] training loss: 0.00001019
INFO:root:[280,   450] training loss: 0.00001147
INFO:root:[280,   500] training loss: 0.00002491
INFO:root:[280,   550] training loss: 0.00026357
INFO:root:[280,   600] training loss: 0.00019667
INFO:root:[280,   650] training loss: 0.00002954
INFO:root:[280,   700] training loss: 0.00002469
INFO:root:[280,   750] training loss: 0.00045941
INFO:root:[280,   800] training loss: 0.00054574
INFO:root:[280,   850] training loss: 0.00057846
INFO:root:[280,   900] training loss: 0.00358288
INFO:root:[280,   950] training loss: 0.00155409
INFO:root:[280,  1000] training loss: 0.00007653
INFO:root:[280,  1050] training loss: 0.00003750
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch280
INFO:root:[281,    50] training loss: 0.00693205
INFO:root:[281,   100] training loss: 0.00770919
INFO:root:[281,   150] training loss: 0.00668906
INFO:root:[281,   200] training loss: 0.00727734
INFO:root:[281,   250] training loss: 0.00692696
INFO:root:[281,   300] training loss: 0.00749979
INFO:root:[281,   350] training loss: 0.00582856
INFO:root:[281,   400] training loss: 0.00001087
INFO:root:[281,   450] training loss: 0.00001353
INFO:root:[281,   500] training loss: 0.00006762
INFO:root:[281,   550] training loss: 0.00024883
INFO:root:[281,   600] training loss: 0.00025165
INFO:root:[281,   650] training loss: 0.00002492
INFO:root:[281,   700] training loss: 0.00002831
INFO:root:[281,   750] training loss: 0.00047384
INFO:root:[281,   800] training loss: 0.00045866
INFO:root:[281,   850] training loss: 0.00042238
INFO:root:[281,   900] training loss: 0.00349577
INFO:root:[281,   950] training loss: 0.00160286
INFO:root:[281,  1000] training loss: 0.00008842
INFO:root:[281,  1050] training loss: 0.00006883
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch281
INFO:root:[282,    50] training loss: 0.00674392
INFO:root:[282,   100] training loss: 0.00739658
INFO:root:[282,   150] training loss: 0.00659497
INFO:root:[282,   200] training loss: 0.00702129
INFO:root:[282,   250] training loss: 0.00696976
INFO:root:[282,   300] training loss: 0.00745432
INFO:root:[282,   350] training loss: 0.00586778
INFO:root:[282,   400] training loss: 0.00000986
INFO:root:[282,   450] training loss: 0.00001109
INFO:root:[282,   500] training loss: 0.00002791
INFO:root:[282,   550] training loss: 0.00019201
INFO:root:[282,   600] training loss: 0.00016132
INFO:root:[282,   650] training loss: 0.00005025
INFO:root:[282,   700] training loss: 0.00002712
INFO:root:[282,   750] training loss: 0.00049902
INFO:root:[282,   800] training loss: 0.00057845
INFO:root:[282,   850] training loss: 0.00045901
INFO:root:[282,   900] training loss: 0.00382018
INFO:root:[282,   950] training loss: 0.00169805
INFO:root:[282,  1000] training loss: 0.00004445
INFO:root:[282,  1050] training loss: 0.00004482
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch282
INFO:root:[283,    50] training loss: 0.00702216
INFO:root:[283,   100] training loss: 0.00724150
INFO:root:[283,   150] training loss: 0.00727548
INFO:root:[283,   200] training loss: 0.00696378
INFO:root:[283,   250] training loss: 0.00681559
INFO:root:[283,   300] training loss: 0.00714865
INFO:root:[283,   350] training loss: 0.00613410
INFO:root:[283,   400] training loss: 0.00000979
INFO:root:[283,   450] training loss: 0.00001528
INFO:root:[283,   500] training loss: 0.00003909
INFO:root:[283,   550] training loss: 0.00022771
INFO:root:[283,   600] training loss: 0.00016860
INFO:root:[283,   650] training loss: 0.00002964
INFO:root:[283,   700] training loss: 0.00002276
INFO:root:[283,   750] training loss: 0.00064867
INFO:root:[283,   800] training loss: 0.00052709
INFO:root:[283,   850] training loss: 0.00049364
INFO:root:[283,   900] training loss: 0.00348884
INFO:root:[283,   950] training loss: 0.00156184
INFO:root:[283,  1000] training loss: 0.00005670
INFO:root:[283,  1050] training loss: 0.00003879
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch283
INFO:root:[284,    50] training loss: 0.00721342
INFO:root:[284,   100] training loss: 0.00703150
INFO:root:[284,   150] training loss: 0.00676782
INFO:root:[284,   200] training loss: 0.00729551
INFO:root:[284,   250] training loss: 0.00704131
INFO:root:[284,   300] training loss: 0.00703939
INFO:root:[284,   350] training loss: 0.00615550
INFO:root:[284,   400] training loss: 0.00001147
INFO:root:[284,   450] training loss: 0.00001371
INFO:root:[284,   500] training loss: 0.00002991
INFO:root:[284,   550] training loss: 0.00033338
INFO:root:[284,   600] training loss: 0.00016102
INFO:root:[284,   650] training loss: 0.00002957
INFO:root:[284,   700] training loss: 0.00002846
INFO:root:[284,   750] training loss: 0.00057109
INFO:root:[284,   800] training loss: 0.00055415
INFO:root:[284,   850] training loss: 0.00040417
INFO:root:[284,   900] training loss: 0.00337491
INFO:root:[284,   950] training loss: 0.00134604
INFO:root:[284,  1000] training loss: 0.00005232
INFO:root:[284,  1050] training loss: 0.00003270
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch284
INFO:root:[285,    50] training loss: 0.00687976
INFO:root:[285,   100] training loss: 0.00755391
INFO:root:[285,   150] training loss: 0.00701876
INFO:root:[285,   200] training loss: 0.00656255
INFO:root:[285,   250] training loss: 0.00692178
INFO:root:[285,   300] training loss: 0.00711363
INFO:root:[285,   350] training loss: 0.00614268
INFO:root:[285,   400] training loss: 0.00001066
INFO:root:[285,   450] training loss: 0.00001370
INFO:root:[285,   500] training loss: 0.00003476
INFO:root:[285,   550] training loss: 0.00021795
INFO:root:[285,   600] training loss: 0.00017976
INFO:root:[285,   650] training loss: 0.00003482
INFO:root:[285,   700] training loss: 0.00003513
INFO:root:[285,   750] training loss: 0.00060295
INFO:root:[285,   800] training loss: 0.00060625
INFO:root:[285,   850] training loss: 0.00045784
INFO:root:[285,   900] training loss: 0.00331424
INFO:root:[285,   950] training loss: 0.00119235
INFO:root:[285,  1000] training loss: 0.00005854
INFO:root:[285,  1050] training loss: 0.00003841
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch285
INFO:root:[286,    50] training loss: 0.00678035
INFO:root:[286,   100] training loss: 0.00781861
INFO:root:[286,   150] training loss: 0.00689665
INFO:root:[286,   200] training loss: 0.00660971
INFO:root:[286,   250] training loss: 0.00651589
INFO:root:[286,   300] training loss: 0.00711148
INFO:root:[286,   350] training loss: 0.00607568
INFO:root:[286,   400] training loss: 0.00001001
INFO:root:[286,   450] training loss: 0.00001203
INFO:root:[286,   500] training loss: 0.00002870
INFO:root:[286,   550] training loss: 0.00027364
INFO:root:[286,   600] training loss: 0.00018243
INFO:root:[286,   650] training loss: 0.00002729
INFO:root:[286,   700] training loss: 0.00002718
INFO:root:[286,   750] training loss: 0.00046903
INFO:root:[286,   800] training loss: 0.00054580
INFO:root:[286,   850] training loss: 0.00047350
INFO:root:[286,   900] training loss: 0.00333806
INFO:root:[286,   950] training loss: 0.00171013
INFO:root:[286,  1000] training loss: 0.00006039
INFO:root:[286,  1050] training loss: 0.00003745
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch286
INFO:root:[287,    50] training loss: 0.00724112
INFO:root:[287,   100] training loss: 0.00731114
INFO:root:[287,   150] training loss: 0.00728613
INFO:root:[287,   200] training loss: 0.00670830
INFO:root:[287,   250] training loss: 0.00672716
INFO:root:[287,   300] training loss: 0.00684419
INFO:root:[287,   350] training loss: 0.00614002
INFO:root:[287,   400] training loss: 0.00001098
INFO:root:[287,   450] training loss: 0.00001297
INFO:root:[287,   500] training loss: 0.00004471
INFO:root:[287,   550] training loss: 0.00023679
INFO:root:[287,   600] training loss: 0.00024217
INFO:root:[287,   650] training loss: 0.00003766
INFO:root:[287,   700] training loss: 0.00002718
INFO:root:[287,   750] training loss: 0.00046768
INFO:root:[287,   800] training loss: 0.00049363
INFO:root:[287,   850] training loss: 0.00046637
INFO:root:[287,   900] training loss: 0.00340792
INFO:root:[287,   950] training loss: 0.00206807
INFO:root:[287,  1000] training loss: 0.00004598
INFO:root:[287,  1050] training loss: 0.00004165
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch287
INFO:root:[288,    50] training loss: 0.00654681
INFO:root:[288,   100] training loss: 0.00674528
INFO:root:[288,   150] training loss: 0.00677041
INFO:root:[288,   200] training loss: 0.00673872
INFO:root:[288,   250] training loss: 0.00703053
INFO:root:[288,   300] training loss: 0.00795296
INFO:root:[288,   350] training loss: 0.00559209
INFO:root:[288,   400] training loss: 0.00001148
INFO:root:[288,   450] training loss: 0.00001328
INFO:root:[288,   500] training loss: 0.00003404
INFO:root:[288,   550] training loss: 0.00020979
INFO:root:[288,   600] training loss: 0.00015433
INFO:root:[288,   650] training loss: 0.00002613
INFO:root:[288,   700] training loss: 0.00002514
INFO:root:[288,   750] training loss: 0.00048619
INFO:root:[288,   800] training loss: 0.00053959
INFO:root:[288,   850] training loss: 0.00049843
INFO:root:[288,   900] training loss: 0.00387312
INFO:root:[288,   950] training loss: 0.00149997
INFO:root:[288,  1000] training loss: 0.00004808
INFO:root:[288,  1050] training loss: 0.00004532
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch288
INFO:root:[289,    50] training loss: 0.00728177
INFO:root:[289,   100] training loss: 0.00700270
INFO:root:[289,   150] training loss: 0.00684808
INFO:root:[289,   200] training loss: 0.00725030
INFO:root:[289,   250] training loss: 0.00686469
INFO:root:[289,   300] training loss: 0.00726889
INFO:root:[289,   350] training loss: 0.00612631
INFO:root:[289,   400] training loss: 0.00001130
INFO:root:[289,   450] training loss: 0.00001459
INFO:root:[289,   500] training loss: 0.00003665
INFO:root:[289,   550] training loss: 0.00026584
INFO:root:[289,   600] training loss: 0.00015229
INFO:root:[289,   650] training loss: 0.00002846
INFO:root:[289,   700] training loss: 0.00002331
INFO:root:[289,   750] training loss: 0.00044600
INFO:root:[289,   800] training loss: 0.00048880
INFO:root:[289,   850] training loss: 0.00047622
INFO:root:[289,   900] training loss: 0.00358251
INFO:root:[289,   950] training loss: 0.00144130
INFO:root:[289,  1000] training loss: 0.00004284
INFO:root:[289,  1050] training loss: 0.00004187
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch289
INFO:root:[290,    50] training loss: 0.00712255
INFO:root:[290,   100] training loss: 0.00735633
INFO:root:[290,   150] training loss: 0.00704466
INFO:root:[290,   200] training loss: 0.00705552
INFO:root:[290,   250] training loss: 0.00677088
INFO:root:[290,   300] training loss: 0.00740948
INFO:root:[290,   350] training loss: 0.00596160
INFO:root:[290,   400] training loss: 0.00000894
INFO:root:[290,   450] training loss: 0.00001194
INFO:root:[290,   500] training loss: 0.00004645
INFO:root:[290,   550] training loss: 0.00020884
INFO:root:[290,   600] training loss: 0.00016431
INFO:root:[290,   650] training loss: 0.00002905
INFO:root:[290,   700] training loss: 0.00002432
INFO:root:[290,   750] training loss: 0.00048855
INFO:root:[290,   800] training loss: 0.00051153
INFO:root:[290,   850] training loss: 0.00043299
INFO:root:[290,   900] training loss: 0.00372222
INFO:root:[290,   950] training loss: 0.00144599
INFO:root:[290,  1000] training loss: 0.00006244
INFO:root:[290,  1050] training loss: 0.00003611
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch290
INFO:root:[291,    50] training loss: 0.00694237
INFO:root:[291,   100] training loss: 0.00685043
INFO:root:[291,   150] training loss: 0.00664207
INFO:root:[291,   200] training loss: 0.00701670
INFO:root:[291,   250] training loss: 0.00718895
INFO:root:[291,   300] training loss: 0.00723541
INFO:root:[291,   350] training loss: 0.00591671
INFO:root:[291,   400] training loss: 0.00001067
INFO:root:[291,   450] training loss: 0.00001409
INFO:root:[291,   500] training loss: 0.00005532
INFO:root:[291,   550] training loss: 0.00022542
INFO:root:[291,   600] training loss: 0.00019046
INFO:root:[291,   650] training loss: 0.00002874
INFO:root:[291,   700] training loss: 0.00003755
INFO:root:[291,   750] training loss: 0.00052444
INFO:root:[291,   800] training loss: 0.00061631
INFO:root:[291,   850] training loss: 0.00047965
INFO:root:[291,   900] training loss: 0.00377016
INFO:root:[291,   950] training loss: 0.00212436
INFO:root:[291,  1000] training loss: 0.00005782
INFO:root:[291,  1050] training loss: 0.00003515
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch291
INFO:root:[292,    50] training loss: 0.00727210
INFO:root:[292,   100] training loss: 0.00719591
INFO:root:[292,   150] training loss: 0.00667971
INFO:root:[292,   200] training loss: 0.00704203
INFO:root:[292,   250] training loss: 0.00680357
INFO:root:[292,   300] training loss: 0.00733450
INFO:root:[292,   350] training loss: 0.00563842
INFO:root:[292,   400] training loss: 0.00001150
INFO:root:[292,   450] training loss: 0.00001179
INFO:root:[292,   500] training loss: 0.00003533
INFO:root:[292,   550] training loss: 0.00018556
INFO:root:[292,   600] training loss: 0.00017764
INFO:root:[292,   650] training loss: 0.00003109
INFO:root:[292,   700] training loss: 0.00002380
INFO:root:[292,   750] training loss: 0.00058485
INFO:root:[292,   800] training loss: 0.00050359
INFO:root:[292,   850] training loss: 0.00048539
INFO:root:[292,   900] training loss: 0.00406976
INFO:root:[292,   950] training loss: 0.00139719
INFO:root:[292,  1000] training loss: 0.00006889
INFO:root:[292,  1050] training loss: 0.00003462
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch292
INFO:root:[293,    50] training loss: 0.00749175
INFO:root:[293,   100] training loss: 0.00689430
INFO:root:[293,   150] training loss: 0.00681710
INFO:root:[293,   200] training loss: 0.00759188
INFO:root:[293,   250] training loss: 0.00734334
INFO:root:[293,   300] training loss: 0.00752721
INFO:root:[293,   350] training loss: 0.00649079
INFO:root:[293,   400] training loss: 0.00001078
INFO:root:[293,   450] training loss: 0.00001339
INFO:root:[293,   500] training loss: 0.00004046
INFO:root:[293,   550] training loss: 0.00019773
INFO:root:[293,   600] training loss: 0.00017646
INFO:root:[293,   650] training loss: 0.00002671
INFO:root:[293,   700] training loss: 0.00002984
INFO:root:[293,   750] training loss: 0.00045386
INFO:root:[293,   800] training loss: 0.00047714
INFO:root:[293,   850] training loss: 0.00046768
INFO:root:[293,   900] training loss: 0.00322121
INFO:root:[293,   950] training loss: 0.00180303
INFO:root:[293,  1000] training loss: 0.00004951
INFO:root:[293,  1050] training loss: 0.00003767
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch293
INFO:root:[294,    50] training loss: 0.00695744
INFO:root:[294,   100] training loss: 0.00716671
INFO:root:[294,   150] training loss: 0.00677060
INFO:root:[294,   200] training loss: 0.00645063
INFO:root:[294,   250] training loss: 0.00666679
INFO:root:[294,   300] training loss: 0.00727660
INFO:root:[294,   350] training loss: 0.00640069
INFO:root:[294,   400] training loss: 0.00000961
INFO:root:[294,   450] training loss: 0.00001326
INFO:root:[294,   500] training loss: 0.00005092
INFO:root:[294,   550] training loss: 0.00019984
INFO:root:[294,   600] training loss: 0.00016976
INFO:root:[294,   650] training loss: 0.00002830
INFO:root:[294,   700] training loss: 0.00002687
INFO:root:[294,   750] training loss: 0.00046438
INFO:root:[294,   800] training loss: 0.00043417
INFO:root:[294,   850] training loss: 0.00052760
INFO:root:[294,   900] training loss: 0.00348640
INFO:root:[294,   950] training loss: 0.00158577
INFO:root:[294,  1000] training loss: 0.00005039
INFO:root:[294,  1050] training loss: 0.00004320
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch294
INFO:root:[295,    50] training loss: 0.00746920
INFO:root:[295,   100] training loss: 0.00704202
INFO:root:[295,   150] training loss: 0.00674663
INFO:root:[295,   200] training loss: 0.00684971
INFO:root:[295,   250] training loss: 0.00674128
INFO:root:[295,   300] training loss: 0.00728996
INFO:root:[295,   350] training loss: 0.00588926
INFO:root:[295,   400] training loss: 0.00000983
INFO:root:[295,   450] training loss: 0.00001168
INFO:root:[295,   500] training loss: 0.00003064
INFO:root:[295,   550] training loss: 0.00019919
INFO:root:[295,   600] training loss: 0.00014936
INFO:root:[295,   650] training loss: 0.00002791
INFO:root:[295,   700] training loss: 0.00002713
INFO:root:[295,   750] training loss: 0.00043833
INFO:root:[295,   800] training loss: 0.00049389
INFO:root:[295,   850] training loss: 0.00054503
INFO:root:[295,   900] training loss: 0.00384491
INFO:root:[295,   950] training loss: 0.00168050
INFO:root:[295,  1000] training loss: 0.00006960
INFO:root:[295,  1050] training loss: 0.00003521
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch295
INFO:root:[296,    50] training loss: 0.00730924
INFO:root:[296,   100] training loss: 0.00726312
INFO:root:[296,   150] training loss: 0.00707914
INFO:root:[296,   200] training loss: 0.00706346
INFO:root:[296,   250] training loss: 0.00948156
INFO:root:[296,   300] training loss: 0.00728755
INFO:root:[296,   350] training loss: 0.00629284
INFO:root:[296,   400] training loss: 0.00001056
INFO:root:[296,   450] training loss: 0.00001094
INFO:root:[296,   500] training loss: 0.00004446
INFO:root:[296,   550] training loss: 0.00026282
INFO:root:[296,   600] training loss: 0.00016159
INFO:root:[296,   650] training loss: 0.00003058
INFO:root:[296,   700] training loss: 0.00003068
INFO:root:[296,   750] training loss: 0.00057385
INFO:root:[296,   800] training loss: 0.00049838
INFO:root:[296,   850] training loss: 0.00049447
INFO:root:[296,   900] training loss: 0.00346016
INFO:root:[296,   950] training loss: 0.00144493
INFO:root:[296,  1000] training loss: 0.00005054
INFO:root:[296,  1050] training loss: 0.00003683
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch296
INFO:root:[297,    50] training loss: 0.00727176
INFO:root:[297,   100] training loss: 0.00719103
INFO:root:[297,   150] training loss: 0.00747465
INFO:root:[297,   200] training loss: 0.00929100
INFO:root:[297,   250] training loss: 0.00657649
INFO:root:[297,   300] training loss: 0.00739179
INFO:root:[297,   350] training loss: 0.00598577
INFO:root:[297,   400] training loss: 0.00001025
INFO:root:[297,   450] training loss: 0.00001369
INFO:root:[297,   500] training loss: 0.00003942
INFO:root:[297,   550] training loss: 0.00028068
INFO:root:[297,   600] training loss: 0.00017748
INFO:root:[297,   650] training loss: 0.00003243
INFO:root:[297,   700] training loss: 0.00002842
INFO:root:[297,   750] training loss: 0.00048544
INFO:root:[297,   800] training loss: 0.00050726
INFO:root:[297,   850] training loss: 0.00047251
INFO:root:[297,   900] training loss: 0.00341623
INFO:root:[297,   950] training loss: 0.00145039
INFO:root:[297,  1000] training loss: 0.00005031
INFO:root:[297,  1050] training loss: 0.00004110
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch297
INFO:root:[298,    50] training loss: 0.00736736
INFO:root:[298,   100] training loss: 0.00756350
INFO:root:[298,   150] training loss: 0.00640767
INFO:root:[298,   200] training loss: 0.00683475
INFO:root:[298,   250] training loss: 0.00660642
INFO:root:[298,   300] training loss: 0.00706301
INFO:root:[298,   350] training loss: 0.00603330
INFO:root:[298,   400] training loss: 0.00001050
INFO:root:[298,   450] training loss: 0.00001178
INFO:root:[298,   500] training loss: 0.00003612
INFO:root:[298,   550] training loss: 0.00019776
INFO:root:[298,   600] training loss: 0.00018718
INFO:root:[298,   650] training loss: 0.00003096
INFO:root:[298,   700] training loss: 0.00002890
INFO:root:[298,   750] training loss: 0.00051167
INFO:root:[298,   800] training loss: 0.00059849
INFO:root:[298,   850] training loss: 0.00051688
INFO:root:[298,   900] training loss: 0.00339590
INFO:root:[298,   950] training loss: 0.00144205
INFO:root:[298,  1000] training loss: 0.00005880
INFO:root:[298,  1050] training loss: 0.00003898
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch298
INFO:root:[299,    50] training loss: 0.00671938
INFO:root:[299,   100] training loss: 0.00686880
INFO:root:[299,   150] training loss: 0.00651977
INFO:root:[299,   200] training loss: 0.00646516
INFO:root:[299,   250] training loss: 0.00678983
INFO:root:[299,   300] training loss: 0.00704688
INFO:root:[299,   350] training loss: 0.00593988
INFO:root:[299,   400] training loss: 0.00001163
INFO:root:[299,   450] training loss: 0.00001849
INFO:root:[299,   500] training loss: 0.00004617
INFO:root:[299,   550] training loss: 0.00030394
INFO:root:[299,   600] training loss: 0.00021325
INFO:root:[299,   650] training loss: 0.00002652
INFO:root:[299,   700] training loss: 0.00002530
INFO:root:[299,   750] training loss: 0.00047495
INFO:root:[299,   800] training loss: 0.00049834
INFO:root:[299,   850] training loss: 0.00052634
INFO:root:[299,   900] training loss: 0.00344931
INFO:root:[299,   950] training loss: 0.00127816
INFO:root:[299,  1000] training loss: 0.00005189
INFO:root:[299,  1050] training loss: 0.00003471
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:epoch299
INFO:root:[300,    50] training loss: 0.00728269
INFO:root:[300,   100] training loss: 0.00715796
INFO:root:[300,   150] training loss: 0.00686001
INFO:root:[300,   200] training loss: 0.00747300
INFO:root:[300,   250] training loss: 0.00685609
INFO:root:[300,   300] training loss: 0.00744869
INFO:root:[300,   350] training loss: 0.00620454
INFO:root:[300,   400] training loss: 0.00001132
INFO:root:[300,   450] training loss: 0.00001386
INFO:root:[300,   500] training loss: 0.00005757
INFO:root:[300,   550] training loss: 0.00018094
INFO:root:[300,   600] training loss: 0.00019848
INFO:root:[300,   650] training loss: 0.00002947
INFO:root:[300,   700] training loss: 0.00002771
INFO:root:[300,   750] training loss: 0.00052698
INFO:root:[300,   800] training loss: 0.00053726
INFO:root:[300,   850] training loss: 0.00047345
INFO:root:[300,   900] training loss: 0.00324298
INFO:root:[300,   950] training loss: 0.00166662
INFO:root:[300,  1000] training loss: 0.00005186
INFO:root:[300,  1050] training loss: 0.00003258
INFO:root:              precision    recall  f1-score   support

          G1     0.6667    1.0000    0.8000         2
    Anaphase     0.9103    0.8442    0.8760      1720
   Telophase     0.8388    0.7616    0.7984      1032
           S     0.3750    0.3750    0.3750         8
          G2     0.3503    0.7534    0.4783        73
   Metaphase     0.6501    0.7350    0.6900      1034
    Prophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7905      3872
   macro avg     0.6845    0.7813    0.7168      3872
weighted avg     0.8101    0.7905    0.7972      3872

INFO:root:Accuracy of the network on the 3872 validation images: 79 %
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6454 test images: 78 %
INFO:root:The model saved: final_model_dict_jcd_h5_wo_2.pth
INFO:root:              precision    recall  f1-score   support

          G1     0.5000    0.6667    0.5714         3
    Anaphase     0.9118    0.8364    0.8725      2867
   Telophase     0.8195    0.7605    0.7889      1720
           S     0.5556    0.7143    0.6250        14
          G2     0.3261    0.7438    0.4534       121
   Metaphase     0.6367    0.7106    0.6716      1724
    Prophase     0.8333    1.0000    0.9091         5

    accuracy                         0.7806      6454
   macro avg     0.6547    0.7760    0.6988      6454
weighted avg     0.8017    0.7806    0.7880      6454

INFO:root:         G1  Anaphase  Telophase      S        G2  Metaphase  Prophase
0  0.571429  0.872476   0.788902  0.625  0.453401   0.671601  0.909091
