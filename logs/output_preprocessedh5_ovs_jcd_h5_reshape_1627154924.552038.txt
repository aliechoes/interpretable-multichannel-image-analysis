INFO:root:the deviced being used is cuda:0
INFO:root:statistics used: {'mean': tensor([0.3079, 0.0614, 0.1428]), 'std': tensor([0.1656, 0.1625, 0.1261])}
INFO:root:test_indx used: 8237, 3382, 2361, 23748, 26770, 23949, 26217, 2657, 12907, 12557, 9901, 28753, 26388, 18315, 9953, 1279, 483, 29762, 10375, 15787, 19051, 2360, 15455, 3587, 18292, 15161, 23610, 3242, 14355, 6639, 26804, 8859, 23863, 8840, 14873, 7827, 20791, 4885, 26928, 3376, 13621, 29907, 25215, 22651, 14878, 23525, 26595, 3688, 17113, 26824, 25818, 5062, 30105, 24690, 3709, 28211, 21721, 2321, 25599, 29410, 21245, 31452, 4282, 29187, 24573, 9878, 8000, 3446, 644, 22650, 1335, 13040, 19767, 26185, 16244, 31665, 21214, 13237, 3835, 11641, 4531, 24304, 184, 32152, 2830, 3798, 2016, 5724, 14967, 23031, 4668, 19491, 8718, 24518, 18181, 24615, 24372, 6955, 25187, 19658, 14280, 11520, 7434, 23161, 18419, 9989, 7944, 1516, 13962, 25255, 494, 26071, 15251, 26837, 28784, 9727, 17183, 9126, 18414, 4571, 17614, 3525, 28278, 25052, 1204, 18733, 4201, 22394, 18005, 19869, 4714, 374, 10896, 13991, 20660, 22152, 18343, 5290, 16743, 8031, 16729, 3130, 821, 19211, 17013, 21072, 7150, 7269, 31594, 26072, 21791, 27380, 28244, 3787, 19620, 9722, 14850, 27137, 13317, 5825, 31670, 2478, 12442, 12667, 26485, 605, 15491, 28725, 10831, 22164, 4042, 31518, 20299, 10842, 20721, 23386, 24865, 29958, 6284, 16696, 7578, 7340, 15998, 3155, 281, 2502, 11972, 25068, 18715, 17557, 4092, 27294, 29398, 8727, 24955, 23843, 19948, 25833, 11, 7339, 6752, 26351, 7581, 28703, 22672, 16917, 23766, 10170, 21968, 14618, 23652, 30304, 19502, 6349, 9981, 6105, 29284, 31383, 11484, 723, 17148, 22157, 20793, 30586, 26887, 30567, 16194, 9103, 22575, 31661, 8018, 17678, 31432, 12527, 3405, 17967, 23714, 15446, 11855, 27814, 3005, 29645, 15198, 20116, 13329, 31738, 5200, 14352, 28782, 26009, 32106, 23850, 31657, 21179, 1524, 8133, 8033, 6404, 21969, 21166, 9264, 7751, 17431, 20037, 4184, 27590, 1097, 10211, 18290, 19859, 4984, 18502, 31241, 18262, 9229, 27825, 27387, 7263, 4955, 870, 21805, 15786, 30979, 20794, 639, 26601, 5265, 26069, 2545, 21116, 21041, 25149, 5844, 17633, 31103, 3494, 28466, 27043, 23506, 28407, 17139, 24015, 7542, 10597, 18466, 22357, 2967, 25492, 18219, 27109, 10483, 11859, 14654, 17022, 13340, 31428, 27430, 25244, 5593, 28534, 7121, 4296, 15091, 16119, 3550, 8274, 26397, 11655, 1666, 31688, 18596, 2524, 2381, 719, 26498, 9079, 9534, 28754, 22026, 16144, 11773, 17925, 24116, 1760, 25519, 12858, 29525, 8790, 2742, 19270, 8262, 6767, 2069, 15253, 22758, 11963, 19194, 24101, 1978, 3412, 15526, 14121, 7466, 31993, 16457, 26057, 28962, 20946, 27213, 137, 17838, 12030, 28502, 2225, 1183, 14440, 17182, 19985, 30974, 11158, 16765, 1567, 400, 25547, 7360, 14374, 5812, 2914, 21588, 16245, 12471, 4755, 6323, 2215, 7327, 29560, 17720, 16609, 19360, 11207, 5681, 20109, 5744, 140, 11868, 26510, 27553, 7433, 16271, 2243, 26212, 10574, 22537, 26935, 3485, 18131, 21135, 25744, 3613, 26242, 26295, 31987, 10943, 25884, 22205, 18910, 29941, 28069, 15292, 8037, 26146, 23384, 31834, 20731, 24913, 23944, 5049, 9159, 19341, 23958, 9661, 16330, 26324, 9548, 31580, 12232, 30522, 18473, 17061, 3048, 16233, 28617, 7647, 28866, 10111, 10229, 2701, 18109, 21319, 30064, 12051, 20733, 23915, 22478, 4290, 28408, 21310, 31275, 21329, 13159, 949, 8121, 29711, 10956, 9731, 19449, 12187, 27901, 28046, 3592, 3398, 29417, 956, 29536, 13459, 16834, 30927, 31161, 7440, 27701, 921, 10698, 9701, 8993, 20956, 6401, 30697, 30630, 24897, 11140, 25766, 25677, 18729, 677, 21785, 13228, 5650, 28779, 7529, 19577, 23857, 20048, 9699, 30863, 27881, 7276, 14153, 3045, 21274, 9030, 13789, 8633, 249, 30386, 29530, 4514, 13983, 5277, 29137, 25569, 22050, 25111, 4339, 20419, 2300, 671, 18565, 25020, 23791, 7428, 25437, 15064, 24799, 17860, 24662, 2986, 18849, 27083, 26632, 1184, 28469, 24777, 2955, 22692, 22281, 867, 9221, 9632, 12412, 30733, 14329, 21675, 20750, 8844, 11846, 7220, 30377, 24577, 10747, 23580, 27095, 12135, 27930, 24611, 28134, 22044, 20504, 17339, 12550, 28666, 10789, 25877, 31154, 19596, 6028, 3673, 9118, 23556, 14409, 26784, 24588, 1220, 28837, 10825, 29245, 10296, 9582, 8637, 31477, 9086, 28078, 31469, 2155, 4761, 18816, 28522, 30278, 18710, 975, 30354, 31948, 9149, 5293, 4789, 23950, 4827, 24961, 19281, 30465, 20730, 13300, 2601, 7379, 6820, 10741, 20136, 20663, 9184, 16769, 26328, 13772, 21302, 17365, 1342, 787, 29776, 27359, 31698, 7566, 4660, 4143, 19973, 17155, 6005, 24427, 16474, 1120, 764, 8480, 11008, 30742, 27745, 25212, 29715, 7783, 23804, 4864, 25556, 31339, 208, 21824, 9427, 4309, 521, 20044, 11974, 25074, 1339, 31437, 18033, 30773, 26059, 10655, 447, 18990, 9821, 28070, 28906, 29330, 24968, 7414, 9370, 31829, 25936, 6731, 14539, 13844, 9339, 27196, 16191, 19071, 10363, 10476, 19754, 15283, 14337, 10766, 339, 21477, 21173, 2448, 18339, 11244, 308, 15766, 765, 29901, 28077, 3535, 15338, 22828, 15578, 4500, 819, 18276, 3019, 19510, 26974, 7424, 19996, 19450, 672, 43, 2737, 13853, 13794, 31351, 9165, 9501, 20557, 18040, 1084, 2471, 19255, 22919, 23694, 13367, 8028, 3433, 30088, 26780, 15956, 21210, 21690, 12875, 31730, 10692, 5842, 9594, 12091, 25118, 18204, 28857, 30861, 21221, 11149, 26854, 21416, 28891, 25001, 31601, 31468, 25887, 26342, 25473, 6595, 7842, 3034, 26959, 17427, 8593, 11847, 19756, 24988, 4284, 16031, 8924, 17569, 31732, 10249, 14877, 29777, 17200, 31147, 22507, 15475, 9526, 24957, 3564, 26544, 31188, 12189, 21055, 2085, 14158, 7153, 22049, 6400, 15041, 4344, 6385, 16910, 25777, 25726, 890, 17541, 6539, 30984, 20756, 10749, 9016, 11511, 6930, 2572, 1062, 20790, 1246, 29106, 24920, 15457, 19599, 8776, 31516, 11902, 2124, 445, 8252, 4793, 16407, 32115, 15101, 7224, 14800, 2912, 14378, 25256, 11796, 31839, 3286, 29651, 26856, 21578, 20385, 11181, 14950, 23877, 18848, 17325, 11587, 27987, 17948, 12919, 9040, 21627, 1331, 10316, 11463, 1125, 8886, 10965, 29236, 16358, 26629, 12859, 30481, 26951, 20352, 7585, 23876, 6920, 29743, 7889, 28882, 14080, 6220, 2439, 24463, 30356, 13277, 24309, 23426, 11199, 19674, 21593, 1509, 10940, 19872, 14853, 16858, 7138, 11500, 11470, 26023, 18250, 18548, 18159, 25402, 14600, 29494, 22365, 12826, 12340, 29976, 14112, 19002, 31907, 16441, 23639, 1213, 12305, 7, 20588, 18855, 25038, 15940, 26752, 12096, 15716, 31376, 1648, 6844, 14495, 593, 15031, 12624, 264, 11085, 6709, 10009, 9651, 9122, 6317, 9643, 5309, 2858, 15148, 17961, 14855, 25309, 26257, 31964, 9074, 15236, 11635, 20994, 25121, 25448, 21684, 8631, 32221, 11789, 24459, 1405, 942, 12807, 31060, 16963, 26043, 30780, 30213, 25060, 1186, 15430, 1685, 29815, 5695, 27595, 4028, 11905, 27846, 16273, 26769, 9000, 14923, 5110, 17501, 4614, 30559, 5982, 17597, 10867, 28260, 15895, 26628, 26588, 15006, 4432, 280, 22748, 23038, 16655, 19538, 31861, 4118, 21664, 1455, 19048, 25137, 24894, 17897, 14266, 8191, 6086, 12903, 6366, 27914, 13223, 17081, 32233, 907, 28094, 2581, 15816, 22680, 22372, 10644, 24371, 876, 1529, 8873, 30242, 2077, 19889, 1259, 14545, 5499, 22765, 25642, 15702, 14433, 24972, 31041, 23218, 25082, 3506, 18869, 15137, 20966, 24675, 21209, 54, 18568, 25465, 8431, 6802, 10470, 15193, 30211, 25036, 2630, 7222, 12861, 5763, 9703, 25208, 1274, 882, 3324, 13022, 17172, 7164, 17128, 12687, 30678, 20257, 20881, 15808, 25580, 13952, 7331, 20182, 24107, 1114, 20957, 23824, 14647, 13805, 6109, 12976, 22501, 19992, 30887, 4037, 1140, 1308, 22894, 12148, 16016, 7574, 30023, 21162, 17184, 16651, 15051, 31527, 14714, 27288, 14784, 9589, 16579, 25911, 20414, 30367, 21013, 2740, 7501, 5371, 16490, 5440, 21841, 27838, 26325, 5250, 327, 6413, 7090, 29058, 24303, 3609, 14001, 21340, 32265, 25370, 19466, 24180, 29851, 4406, 6837, 24986, 10973, 16978, 20206, 14854, 13087, 20183, 4751, 15713, 20685, 22504, 13162, 226, 2262, 4404, 7296, 18388, 16644, 7936, 31369, 9573, 2627, 14429, 6344, 26129, 26656, 26038, 22103, 24625, 4508, 10138, 19991, 19402, 24815, 13118, 3760, 14096, 30541, 30017, 888, 2101, 31710, 23882, 32005, 5785, 22821, 29946, 884, 6883, 13857, 2506, 16062, 7375, 24457, 3674, 20917, 30384, 11830, 10693, 26688, 18089, 31439, 10742, 14649, 18612, 13615, 5319, 23928, 24438, 25451, 11072, 24395, 29881, 1719, 16738, 12439, 11049, 29027, 19633, 10953, 16930, 11423, 23983, 8719, 30056, 3336, 1245, 8452, 6535, 17655, 12229, 12584, 22363, 21265, 3911, 5624, 16276, 28825, 8444, 12566, 2008, 8657, 197, 21843, 17639, 23679, 17358, 9207, 6970, 8984, 10804, 1287, 3069, 1494, 15431, 29493, 18481, 22342, 12587, 22341, 11792, 12245, 22291, 14679, 7877, 6341, 4157, 1268, 19277, 31529, 6775, 19657, 19989, 30880, 27847, 1263, 4684, 7354, 15520, 23816, 19803, 22654, 25950, 13597, 10502, 3151, 31989, 6097, 4491, 14972, 11981, 3900, 20458, 7839, 18335, 21827, 11039, 2417, 15752, 15289, 15428, 2172, 26019, 9022, 16209, 29981, 23711, 29471, 32196, 7003, 4357, 23878, 9629, 28272, 23110, 14331, 9687, 23226, 8964, 6586, 16589, 11033, 2213, 4695, 22708, 16692, 15021, 16602, 10411, 11857, 1008, 20482, 169, 4079, 17645, 11130, 22697, 10936, 15233, 17438, 29473, 19417, 15931, 6974, 10270, 2982, 1452, 9474, 2276, 23343, 3620, 25913, 25819, 26457, 5980, 28201, 11376, 9174, 17464, 23196, 31930, 22732, 11209, 4504, 31209, 2120, 23137, 9900, 10208, 22448, 22881, 9347, 18141, 15473, 19815, 13992, 27280, 9434, 16952, 10186, 7870, 13734, 17849, 4393, 21718, 32133, 31471, 20122, 11840, 15648, 22845, 30126, 1537, 12603, 17770, 9664, 20736, 20275, 6650, 2419, 30285, 29721, 15103, 30123, 15965, 15901, 26934, 14777, 13780, 7111, 4685, 15708, 15217, 8130, 21409, 14081, 5345, 28328, 28307, 8740, 22611, 19490, 10365, 305, 18645, 19679, 1278, 8559, 17670, 31783, 23591, 2455, 17802, 27609, 17637, 14265, 13347, 2096, 12298, 19501, 15652, 1054, 13099, 21366, 9626, 27611, 14049, 27500, 24592, 23054, 5334, 27247, 29616, 7069, 1736, 8223, 11255, 14821, 23939, 27517, 6303, 17079, 10271, 8538, 10877, 30461, 27376, 15144, 9862, 20173, 16161, 28308, 26625, 27061, 20523, 18628, 21301, 16976, 23817, 30051, 4166, 23124, 2499, 899, 8503, 26910, 14024, 1089, 5075, 11050, 16518, 15516, 1823, 24143, 17932, 23311, 19800, 12682, 16059, 17271, 6636, 29948, 8685, 29865, 11147, 6507, 18340, 8699, 27835, 3191, 28654, 24357, 29565, 29729, 32173, 26381, 4259, 859, 21410, 4099, 27666, 4008, 8640, 6438, 17987, 19616, 25823, 26298, 1497, 27134, 5936, 18460, 10954, 10460, 5818, 8507, 1726, 32066, 3676, 7490, 8188, 20311, 25115, 31049, 22149, 21529, 7278, 14496, 3645, 1686, 14341, 31828, 5352, 31123, 22588, 1320, 28323, 1700, 9817, 18075, 30782, 24622, 20478, 22780, 31666, 21983, 21206, 3519, 28888, 12729, 25419, 19977, 28277, 29546, 26539, 5356, 23285, 4346, 15392, 16827, 20008, 19126, 26925, 511, 9223, 1348, 11251, 3213, 999, 31089, 25459, 10408, 18149, 8598, 6926, 6651, 16691, 16224, 15098, 20397, 4197, 21960, 18237, 27002, 12373, 12537, 23756, 20188, 6672, 28671, 10453, 29824, 23155, 10472, 5539, 10533, 16403, 2573, 20989, 18479, 1875, 6420, 31838, 5940, 14893, 6403, 4093, 15821, 13207, 18859, 8902, 21138, 25938, 11178, 6122, 13320, 31567, 3219, 18974, 12586, 29304, 15179, 12672, 10769, 22840, 30225, 15026, 30776, 31944, 21513, 29327, 30163, 21596, 10473, 17761, 29773, 26953, 14187, 16114, 18240, 2659, 14567, 15932, 18078, 23515, 26036, 2280, 19670, 20518, 31108, 11668, 23029, 12706, 22295, 31322, 216, 21984, 8330, 2888, 15948, 12509, 29692, 6626, 5688, 22477, 15048, 12287, 22570, 5311, 17419, 11022, 31733, 23337, 1495, 13333, 15227, 14446, 23961, 2458, 8627, 13895, 29778, 23096, 27863, 18238, 17455, 11913, 18213, 31668, 6255, 3729, 22045, 18947, 9237, 25326, 74, 16735, 30467, 32147, 12502, 29900, 27250, 630, 4526, 2513, 15728, 10521, 5141, 9255, 13619, 25487, 18592, 9317, 14479, 570, 31227, 22239, 11617, 11229, 23920, 17587, 17654, 13883, 12786, 19779, 30961, 7240, 10711, 27574, 3892, 3375, 17319, 7972, 11414, 28404, 7037, 31232, 26134, 13975, 7910, 14792, 3970, 29375, 18403, 18377, 15631, 9536, 16344, 26710, 15657, 15499, 15010, 8717, 3093, 27776, 22585, 21090, 12061, 19858, 28165, 21580, 23034, 4276, 10146, 959, 8187, 16082, 15335, 52, 29420, 26015, 30615, 20082, 1007, 24331, 10740, 3995, 27084, 30700, 31765, 25724, 6218, 14881, 18360, 19865, 17240, 30856, 28342, 778, 3431, 18563, 28532, 18202, 9825, 8663, 26386, 28836, 13463, 31412, 28509, 20761, 23237, 6083, 10761, 28817, 4240, 6503, 21736, 5943, 21819, 15037, 7230, 8417, 1908, 13707, 15605, 29001, 23051, 21204, 15426, 8609, 29975, 28313, 15921, 529, 28647, 17248, 25706, 31346, 26054, 21818, 23326, 30632, 27608, 16616, 12261, 3834, 21811, 3499, 30068, 1749, 7767, 798, 31750, 3419, 19110, 23405, 6804, 19293, 11097, 15421, 22126, 13033, 8275, 29730, 16645, 20374, 16552, 7097, 19615, 19956, 18172, 19480, 15820, 28928, 3921, 3393, 12169, 28974, 13750, 25701, 4196, 27099, 28935, 3300, 23310, 26265, 6197, 4502, 27026, 17680, 15237, 4999, 2870, 24077, 6684, 21018, 31082, 20462, 4341, 25312, 25509, 17432, 31484, 11738, 18654, 22921, 12464, 25254, 12474, 9697, 15302, 12841, 12408, 9719, 7306, 6725, 8085, 550, 27644, 10350, 25219, 15372, 9013, 8005, 28748, 3094, 2151, 3972, 8548, 24153, 1459, 8635, 21532, 18690, 13535, 16865, 16256, 27893, 10959, 27045, 10593, 19980, 14196, 23830, 5958, 27642, 3157, 24734, 15724, 5872, 22658, 26139, 15171, 18092, 30082, 5007, 20833, 15680, 27174, 18080, 27675, 7322, 27929, 27576, 18731, 30790, 11896, 24486, 6302, 5879, 24651, 19953, 18173, 343, 142, 27055, 3651, 18662, 10925, 15662, 17762, 23242, 19376, 26878, 9425, 6575, 22897, 18585, 858, 6965, 20555, 15813, 21283, 12777, 10200, 23754, 8746, 7163, 22936, 24339, 14097, 18137, 10580, 6673, 14680, 30237, 13020, 11524, 25644, 20824, 20466, 21577, 15867, 10094, 4046, 6838, 30542, 12529, 2979, 30346, 17605, 7503, 22211, 1340, 15564, 9782, 26300, 615, 646, 13927, 27248, 26542, 5231, 19418, 6191, 32071, 22717, 830, 918, 24052, 26533, 31873, 2854, 22767, 15399, 2777, 148, 18318, 14753, 2780, 12467, 21950, 30715, 22310, 13762, 23450, 14559, 13310, 1271, 20239, 12146, 4174, 25835, 12762, 750, 29217, 8378, 7682, 25695, 12226, 194, 19845, 31924, 21854, 1166, 6299, 357, 10116, 18933, 20914, 28757, 5283, 13722, 5279, 4004, 17449, 10503, 7038, 19287, 13471, 19247, 5153, 19649, 3531, 23581, 5511, 10003, 6616, 8695, 20408, 30628, 9974, 13997, 15740, 12863, 21999, 1221, 5662, 396, 1804, 2765, 24728, 26705, 3206, 15401, 29225, 19410, 26446, 13731, 8329, 27799, 12775, 20403, 5991, 10439, 8132, 21202, 9295, 22313, 10191, 27472, 24824, 16981, 748, 12748, 11875, 14973, 28439, 23333, 20106, 30335, 17276, 29850, 19612, 17429, 4712, 19748, 28246, 26560, 16685, 8875, 30477, 25563, 16639, 6777, 18441, 29594, 25144, 27433, 9604, 15109, 5995, 21348, 25453, 22012, 11481, 7730, 22877, 6409, 22700, 15733, 27076, 32042, 23803, 3714, 19580, 15477, 16225, 11082, 12739, 10485, 199, 16372, 29335, 28301, 11248, 14817, 9571, 23062, 13130, 10517, 8603, 31449, 3772, 190, 769, 30720, 17719, 30592, 31228, 32215, 14750, 3560, 5015, 31127, 11735, 23647, 3032, 7869, 27904, 2135, 18070, 11746, 25117, 26763, 20603, 4723, 1267, 10809, 31448, 12497, 27398, 30, 9084, 6139, 4264, 16318, 8567, 10760, 2984, 13760, 7216, 15699, 20906, 29866, 6776, 28058, 20715, 923, 8166, 15944, 6226, 4401, 7351, 12120, 26402, 40, 16666, 6842, 27710, 6206, 7016, 28724, 29596, 23348, 16763, 5180, 24, 118, 14452, 19877, 2148, 21153, 25817, 13149, 25456, 31669, 8457, 1751, 3041, 3091, 31012, 20795, 26106, 20317, 18935, 25405, 20604, 24784, 27983, 9806, 24912, 11518, 1446, 5391, 5273, 12158, 31336, 4939, 2815, 1565, 17090, 13242, 210, 23924, 26942, 16681, 19663, 27792, 21097, 17250, 20704, 20406, 19597, 1202, 12145, 2309, 2037, 594, 18437, 4302, 9218, 27241, 30124, 27848, 20404, 4692, 24991, 23838, 26263, 25838, 7248, 22246, 12734, 1261, 20639, 24355, 9653, 22679, 4878, 22252, 1444, 26756, 31910, 14305, 31796, 24204, 29591, 22506, 1761, 13925, 29099, 10241, 7894, 2767, 19757, 3180, 6015, 25653, 13044, 16730, 19512, 14652, 31584, 2980, 17865, 14309, 19622, 18490, 7557, 31005, 2074, 3708, 3218, 30328, 16453, 19613, 27720, 13945, 7820, 31848, 25645, 18815, 23345, 2704, 17471, 146, 2523, 28075, 18424, 17750, 17234, 24629, 16961, 25942, 16551, 7718, 21630, 26440, 15674, 6612, 24149, 18411, 30624, 9702, 23859, 16385, 21401, 25789, 13522, 16207, 19061, 28495, 13108, 30330, 31068, 14, 23043, 10122, 19887, 2269, 21461, 12248, 5145, 14050, 11562, 5292, 26535, 25989, 6452, 9847, 28065, 17843, 11865, 22104, 17370, 11151, 8094, 21010, 7745, 27916, 13143, 5834, 3566, 25890, 11477, 9923, 7076, 17992, 14614, 22480, 1750, 27667, 14333, 28412, 30310, 21536, 15106, 11897, 12493, 27053, 1240, 21350, 16949, 29441, 23757, 12462, 11739, 18409, 19155, 13811, 31318, 2103, 5126, 9794, 26151, 11314, 7811, 8721, 15968, 2597, 30371, 1779, 2526, 7661, 23484, 29402, 17033, 31895, 6863, 18436, 16915, 26897, 29713, 713, 1596, 12855, 3472, 185, 29397, 1309, 16994, 13995, 1995, 19310, 1661, 1924, 13376, 5165, 611, 6262, 31920, 1559, 11984, 3529, 13600, 15057, 2709, 5142, 12791, 12278, 1086, 6319, 11123, 15452, 31712, 12447, 3297, 6223, 29138, 2395, 30638, 14682, 9770, 29325, 31289, 29653, 1892, 4863, 26860, 32199, 16847, 16140, 7382, 30301, 1807, 50, 2610, 20889, 18902, 1463, 20595, 25691, 2019, 14262, 14686, 21043, 9954, 9251, 14302, 21782, 2390, 5326, 21894, 9959, 17623, 24800, 4176, 23126, 22125, 7497, 28011, 7632, 23462, 23774, 30654, 18429, 4926, 20574, 31559, 15329, 28222, 15258, 8492, 27682, 9105, 29745, 27290, 8095, 701, 5888, 23200, 19, 2050, 20270, 28911, 247, 29323, 15938, 24742, 8159, 365, 10595, 26020, 10345, 25012, 19018, 23283, 23763, 15332, 3000, 3655, 4209, 32256, 17157, 25486, 3424, 7132, 8110, 26290, 9637, 19550, 27686, 9739, 16132, 29884, 4142, 22178, 20249, 7071, 3008, 19204, 27344, 20203, 30291, 26492, 6482, 19629, 2466, 9771, 14515, 23175, 27781, 22961, 15991, 11825, 21189, 4888, 18919, 1448, 30999, 9222, 6331, 15519, 3953, 29443, 13049, 24082, 4877, 26987, 20307, 19294, 16436, 26364, 17629, 8244, 21831, 6058, 31966, 9217, 25601, 30871, 30257, 7707, 13054, 8212, 9160, 25986, 2757, 252, 24346, 17447, 31957, 20240, 3040, 24731, 11117, 19714, 5118, 5014, 5981, 31176, 7615, 27601, 19695, 31430, 16154, 5000, 20990, 26166, 15243, 11783, 2643, 28321, 8885, 28862, 31453, 30169, 26818, 22208, 2073, 4615, 7875, 22714, 14628, 20411, 12468, 31680, 23159, 3362, 21885, 7741, 10524, 8338, 24410, 1713, 5930, 17789, 1927, 11387, 11499, 18918, 22251, 29472, 14588, 27200, 7044, 24378, 8733, 4770, 3912, 10462, 3347, 26611, 20378, 11297, 19132, 26733, 22716, 29780, 2931, 5904, 26808, 20103, 30032, 30594, 23122, 7425, 11539, 9757, 31248, 26279, 8210, 14536, 13095, 32012, 16761, 11716, 985, 30004, 29332, 19879, 30235, 17586, 28961, 14691, 19994, 6877, 29016, 3601, 17377, 12705, 14052, 21272, 5649, 29334, 31748, 29404, 9422, 21865, 13953, 11582, 24112, 19130, 27797, 11372, 16954, 297, 14413, 16020, 8354, 15515, 6081, 23179, 13873, 27393, 28056, 4254, 678, 13127, 16373, 30719, 8176, 11586, 19473, 23374, 23017, 18800, 4333, 22218, 1354, 6908, 23511, 25314, 11765, 25893, 22174, 17894, 3195, 7668, 24758, 3497, 14580, 1464, 5295, 19906, 17044, 6379, 872, 9483, 29654, 17170, 26280, 2287, 26040, 9864, 3580, 31496, 27158, 8517, 5252, 10141, 15447, 11447, 6129, 9288, 16007, 19974, 16678, 7732, 23006, 8910, 26981, 11242, 27680, 11740, 15339, 24637, 4701, 19979, 2154, 6760, 16890, 5177, 2751, 18155, 18829, 5146, 30143, 20228, 11517, 22999, 23614, 24283, 30040, 2948, 364, 26427, 26035, 10451, 128, 27034, 8554, 5312, 31658, 7109, 22321, 12974, 22820, 20107, 28375, 21311, 22349, 14312, 7300, 22655, 13003, 9206, 25697, 6959, 26074, 8209, 17565, 25367, 24587, 4648, 28645, 7198, 27157, 4168, 25325, 30793, 28596, 30881, 5436, 25424, 19978, 25418, 19229, 1413, 18586, 28670, 24607, 10325, 21849, 17353, 21762, 10768, 27336, 17580, 28976, 10185, 13344, 19687, 24335, 26392, 23111, 31967, 22, 3307, 15984, 24943, 27022, 2181, 26285, 19691, 10103, 31380, 6417, 24614, 3367, 8907, 26990, 26975, 29867, 20015, 31314, 10275, 29366, 2182, 2505, 14250, 17300, 28304, 8380, 15538, 9982, 4441, 13684, 2747, 26453, 4239, 2987, 29078, 24760, 13080, 16236, 528, 9097, 13666, 17209, 6020, 22934, 6451, 29788, 12180, 20108, 6098, 17579, 4433, 13512, 17123, 8951, 602, 6562, 29083, 3552, 8313, 18527, 13343, 7711, 17064, 4158, 30976, 16795, 7527, 30593, 117, 29456, 9131, 19721, 28677, 350, 3853, 22324, 30308, 2748, 19241, 29025, 14075, 27480, 24061, 31931, 8622, 13039, 31479, 10628, 7962, 20431, 2336, 13468, 29833, 6254, 4833, 16054, 24092, 23297, 1178, 16878, 8039, 2079, 15493, 28903, 17813, 31233, 21386, 16267, 2916, 10305, 6954, 28942, 20931, 28319, 3397, 6696, 25343, 22933, 32183, 13433, 20297, 22707, 4036, 31189, 22860, 24964, 21954, 16266, 7495, 27015, 5975, 1013, 11161, 4835, 9373, 9278, 4687, 25286, 138, 17165, 9990, 11460, 24464, 14918, 10690, 1384, 6305, 30455, 29967, 14288, 20569, 11844, 20325, 26545, 22460, 29313, 21109, 24382, 30402, 18027, 25662, 8160, 4644, 352, 13700, 12813, 24044, 11941, 7564, 391, 13328, 24638, 27259, 16135, 9249, 5832, 19645, 21769, 26832, 10713, 27232, 3220, 29483, 16001, 20762, 8677, 23491, 22811, 28390, 1959, 19045, 1791, 25799, 13917, 17690, 6770, 1638, 7526, 4679, 6405, 27509, 14834, 29983, 12466, 727, 4855, 31778, 25288, 3198, 12286, 14945, 15803, 427, 28166, 30573, 7856, 21691, 14743, 26494, 2618, 16780, 27180, 18246, 5769, 13234, 2245, 13435, 22240, 2720, 4551, 15634, 18461, 27181, 19013, 17908, 15141, 21938, 25875, 30406, 17194, 1821, 10882, 12519, 8596, 23825, 24099, 23898, 4476, 15700, 31673, 5680, 1050, 6394, 27672, 29468, 4330, 15444, 30246, 7422, 24316, 9939, 22207, 26169, 14314, 18892, 6960, 30309, 21917, 3503, 10256, 18108, 30274, 19514, 5799, 20702, 4804, 8174, 6702, 28496, 30576, 17029, 18885, 29705, 13012, 11476, 22487, 11263, 24795, 7334, 21545, 24809, 31531, 14386, 15923, 28180, 16354, 29376, 8242, 25796, 5555, 1083, 10725, 8799, 248, 30067, 29545, 21962, 12312, 17945, 16987, 17242, 25004, 17672, 30820, 18726, 30202, 21468, 25031, 8773, 21563, 25661, 9835, 24858, 8250, 29899, 13291, 16049, 22074, 13813, 1314, 13161, 4492, 3150, 618, 17168, 11269, 1351, 19527, 4485, 8236, 7452, 21346, 14047, 27491, 26076, 31031, 21738, 17793, 23451, 10235, 18750, 11292, 27626, 14538, 17189, 15800, 7313, 26529, 27593, 31292, 31744, 28380, 31813, 10552, 22041, 4894, 31208, 26830, 26802, 23202, 932, 29119, 25017, 27841, 14172, 3701, 21369, 13674, 9958, 4415, 10137, 7544, 1952, 15594, 1866, 7486, 27834, 13928, 7131, 17917, 19311, 21944, 19626, 30434, 28437, 24903, 10053, 15412, 13658, 2032, 9018, 12653, 30933, 10049, 14092, 28786, 26606, 14846, 27912, 797, 5884, 4389, 26371, 17514, 20321, 9543, 19397, 22947, 9542, 1972, 15448, 17530, 12902, 29289, 11985, 32065, 9996, 26210, 28706, 26586, 21485, 7207, 4851, 2450, 26884, 29672, 18410, 26754, 21081, 106, 1987, 13282, 4620, 6145, 23373, 17944, 4010, 31976, 26228, 25257, 30326, 18307, 10223, 16703, 6367, 10636, 30440, 7963, 9488, 18773, 18201, 8710, 12581, 2446, 25462, 23976, 27448, 25227, 11249, 9468, 1090, 3748, 25120, 21082, 5464, 12941, 1311, 4821, 17485, 5488, 12443, 24697, 32021, 11658, 25452, 31092, 9520, 23759, 561, 31061, 20265, 19102, 25925, 14353, 2494, 22325, 30109, 18334, 15112, 3906, 3299, 31804, 14976, 180, 30862, 20722, 31406, 30053, 24019, 3342, 10516, 14400, 17369, 3885, 29156, 742, 5191, 3211, 31849, 13914, 30336, 1321, 8731, 1702, 9885, 20255, 20631, 16025, 20130, 29682, 6995, 29746, 10013, 29014, 6568, 8061, 28150, 10952, 21543, 430, 25204, 11872, 13202, 31358, 12461, 13213, 25279, 3224, 20101, 16237, 5589, 3186, 27124, 10088, 30468, 18907, 3699, 13372, 10433, 7113, 10264, 29748, 7627, 12664, 19261, 11722, 1805, 5109, 19267, 30315, 13402, 7367, 18299, 17930, 4831, 22599, 5028, 9714, 2921, 24882, 13969, 13057, 22112, 5073, 11619, 15545, 5272, 32254, 13240, 18044, 24627, 11510, 2641, 23888, 20613, 9054, 5508, 11924, 3126, 22215, 10617, 9749, 7595, 19609, 30251, 27277, 4808, 13103, 15717, 21759, 8564, 13356, 31356, 6119, 21882, 7396, 7474, 8126, 3851, 5781, 23776, 22411, 3828, 31144, 24177, 2408, 3166, 3073, 22959, 2706, 7699, 16122, 17034, 10132, 23014, 24792, 25171, 1168, 27419, 24055, 30232, 26489, 30572, 23627, 26999, 2415, 589, 22514, 9133, 25959, 28627, 10957, 28865, 8493, 20217, 11923, 5032, 16536, 6412, 361, 17884, 12909, 14593, 20312, 1879, 6088, 22525, 21498, 31674, 22533, 15424, 7350, 12434, 17445, 17403, 8170, 21644, 31, 18009, 12241, 18936, 23956, 19430, 10860, 15574, 16657, 31528, 15296, 12621, 10482, 20692, 24978, 22139, 29244, 10571, 31950, 14678, 20820, 22607, 6806, 28875, 2220, 30292, 6596, 20515, 26180, 27573, 6131, 26943, 22344, 23271, 10856, 5406, 28995, 14206, 21900, 7782, 18677, 23078, 14695, 18753, 16105, 14454, 8700, 1096, 11404, 9734, 27252, 7750, 15513, 9050, 15877, 25974, 3929, 18646, 18597, 29181, 25043, 12972, 30819, 14328, 1667, 10064, 10057, 29868, 4934, 30807, 7932, 25987, 29065, 23726, 27251, 11824, 8514, 4581, 28626, 16611, 19356, 23589, 685, 17293, 23113, 28858, 16659, 27994, 14327, 5382, 3833, 16781, 6705, 24141, 24334, 9401, 21361, 28760, 30777, 25643, 22786, 3830, 21168, 29864, 12479, 4289, 920, 23678, 29566, 25745, 27347, 298, 19181, 29671, 5122, 5735, 3979, 14162, 6011, 20195, 2461, 25100, 18618, 13503, 24387, 19854, 21328, 17159, 9308, 28577, 3824, 24640, 24804, 21773, 2029, 18963, 28127, 31971, 3141, 6689, 9212, 7187, 29998, 7120, 909, 24379, 8053, 23583, 24084, 1670, 17450, 22572, 24572, 27765, 16922, 4451, 28462, 7778, 30297, 3083, 15961, 10010, 29128, 11646, 30483, 4958, 23885, 28363, 9435, 4170, 22376, 9353, 6386, 5204, 3182, 31617, 22114, 9331, 30850, 23305, 9557, 30084, 20649, 22461, 22932, 3724, 13270, 288, 4018, 18637, 27309, 699, 7029, 23762, 3156, 19162, 20640, 31763, 29714, 16199, 18041, 16439, 4464, 9685, 2750, 14557, 30534, 6578, 7508, 27390, 10377, 7543, 722, 17740, 1945, 3735, 7622, 28861, 18650, 26343, 5517, 9480, 30012, 25590, 29753, 30229, 23986, 26089, 26883, 16313, 25855, 12926, 5615, 9121, 19098, 16622, 17251, 24170, 151, 4587, 23742, 9117, 13078, 6246, 5784, 12472, 22806, 24008, 16252, 14042, 1815, 253, 29147, 20204, 7249, 25006, 26487, 3337, 2184, 20087, 18175, 25594, 18926, 3444, 21859, 832, 11427, 27895, 681, 21459, 14948, 12917, 663, 14069, 23430, 17538, 5780, 18996, 19732, 1800, 21165, 17018, 26996, 3994, 5894, 10513, 7223, 29673, 7621, 19342, 9950, 25587, 29790, 21199, 15946, 7705, 5474, 9521, 25973, 12427, 24472, 12441, 9859, 14664, 15909, 15122, 23605, 7127, 22248, 16286, 9290, 9929, 31386, 2758, 9495, 24540, 31025, 14926, 14359, 24660, 737, 25104, 20461, 15206, 31579, 32239, 16523, 2375, 13038, 1944, 5765, 21457, 19063, 7516, 26709, 17267, 9227, 913, 13551, 18115, 29979, 27193, 24451, 27059, 29652, 21923, 20671, 13867, 18471, 310, 32181, 26437, 16939, 6056, 17266, 22419, 29219, 16635, 27255, 31328, 6280, 9019, 12561, 24698, 428, 26924, 31421, 7801, 30387, 14787, 31589, 4686, 28710, 15090, 24058, 1426, 10653, 6907, 28153, 20643, 15027, 21467, 11458, 6583, 22415, 13239, 26661, 22193, 14029, 17299, 4997, 24212, 29797, 15633, 5490, 2723, 19160, 5716, 23340, 7966, 7245, 5776, 26058, 30277, 9020, 30920, 17904, 6012, 8182, 881, 1167, 18688, 27207, 17259, 30028, 30395, 8777, 23145, 32052, 18701, 17619, 28275, 1264, 16073, 23076, 5881, 9779, 11706, 10144, 9781, 18779, 16264, 28483, 13275, 24095, 18737, 2250, 9726, 1617, 10303, 5910, 5690, 2296, 5577, 32014, 17069, 17487, 20158, 30250, 23241, 6318, 24041, 13821, 23981, 25122, 17292, 9992, 10511, 70, 18971, 17533, 14879, 10855, 26992, 21198, 10888, 14362, 12752, 22953, 16193, 31224, 29183, 30935, 5048, 31047, 7210, 22347, 26775, 3899, 3275, 17411, 19035, 17156, 12839, 8438, 26892, 6092, 27844, 16188, 17546, 10723, 20153, 8158, 15197, 8302, 16755, 19448, 27940, 738, 20904, 9355, 14046, 11975, 16770, 237, 19921, 17389, 6360, 7982, 19839, 6667, 30173, 16149, 11669, 32143, 17878, 26357, 4017, 15104, 4574, 25514, 21466, 1017, 18129, 17382, 30735, 20575, 17140, 22323, 31048, 601, 20180, 23633, 12632, 3496, 1272, 9554, 28735, 18474, 3395, 10629, 12115, 11012, 27883, 11250, 22849, 14865, 22261, 28081, 31002, 14176, 18493, 929, 5696, 27031, 28564, 18320, 21288, 16229, 3043, 30646, 9350, 31629, 10002, 6296, 15407, 15649, 3082, 18874, 19809, 23190, 20837, 7573, 23630, 26707, 14236, 7832, 22909, 3335, 27041, 1619, 1401, 22459, 31401, 31566, 14736, 3309, 3632, 6112, 21549, 17428, 11682, 6570, 6831, 17110, 21780, 18642, 5987, 21481, 11697, 21528, 17400, 30763, 8605, 20991, 6906, 13010, 26984, 1442, 695, 377, 28880, 31459, 7630, 4801, 18986, 344, 9475, 25758, 23854, 30831, 19008, 12449, 1211, 16901, 25670, 25152, 16841, 15727, 30110, 31856, 2308, 13461, 19208, 22184, 16838, 6969, 12834, 7404, 17863, 17824, 9127, 31623, 18054, 31694, 15586, 11845, 7380, 14875, 8485, 18349, 19966, 15751, 6046, 2968, 24851, 3481, 11622, 28358, 24677, 614, 14505, 15154, 31979, 29478, 28410, 5117, 7421, 2698, 19675, 6748, 30986, 9352, 20911, 8062, 5717, 6301, 13279, 3484, 21540, 20006, 31628, 19576, 22022, 28149, 26655, 12831, 20254, 27977, 18842, 7618, 4826, 14181, 17795, 24591, 17065, 20608, 21734, 4430, 9066, 23760, 24215, 24887, 4288, 25376, 7292, 16120, 7032, 1171, 1996, 28557, 15868, 15152, 19955, 37, 19056, 26360, 25461, 11432, 11395, 9587, 25180, 16178, 24460, 6304, 29287, 14561, 768, 2212, 14499, 9240, 23475, 20202, 30648, 26571, 5294, 25605, 27246, 20806, 12332, 19268, 16548, 23463, 29427, 10603, 19886, 19218, 13411, 30494, 29229, 1163, 10567, 31575, 17942, 3586, 6533, 9431, 7841, 19773, 17175, 3072, 18722, 9828, 31393, 14009, 16324, 9389, 941, 9665, 31447, 10632, 17352, 11116, 13863, 23811, 4930, 30527, 23716, 24152, 7110, 6740, 4151, 13395, 24120, 27004, 30463, 7341, 29980, 18176, 18598, 21429, 16029, 6259, 24632, 7301, 15298, 25336, 13807, 31199, 11333, 9819, 17379, 27542, 5360, 3761, 3183, 13197, 22756, 31833, 6864, 19265, 11373, 10355, 11171, 23066, 866, 20250, 31781, 24441, 2293, 19777, 22854, 2894, 28512, 25272, 2823, 2444, 4465, 2413, 28173, 29015, 23007, 12680, 17361, 25525, 31495, 23082, 19452, 11170, 1031, 5552, 9635, 13439, 31784, 8874, 4117, 10913, 15238, 23441, 457, 10828, 12253, 11350, 16338, 2267, 12531, 26562, 28337, 17499, 24779, 21874, 25185, 19870, 5854, 14577, 12401, 15190, 9116, 1349, 27733, 14783, 15834, 7887, 2826, 12065, 7169, 14003, 29112, 7174, 26969, 28112, 28573, 22766, 21713, 29584, 12657, 15914, 267, 2509, 26762, 4119, 29667, 15380, 18128, 23046, 4906, 30992, 24220, 25975, 19572, 3855, 13560, 12768, 13860, 1292, 31505, 6983, 11174, 10336, 30374, 28292, 4599, 10962, 15216, 928, 23980, 5493, 19107, 16418, 23385, 7882, 25982, 1106, 5002, 15370, 10691, 23146, 10181, 26012, 6320, 8327, 14525, 17286, 27104, 8857, 19436, 23442, 28230, 21196, 20581, 31297, 22918, 13491, 17435, 15825, 13602, 7643, 24926, 2566, 10790, 5595, 10125, 7748, 22308, 19444, 444, 468, 19070, 5495, 4849, 26753, 26363, 11336, 1855, 10210, 11909, 19363, 31259, 11799, 4769, 18943, 29926, 15123, 24258, 7664, 5563, 20209, 31253, 11726, 14859, 26296, 30418, 13757, 2303, 13383, 19788, 1087, 12223, 25879, 19925, 13168, 16411, 28711, 23787, 29135, 20176, 21904, 19394, 16581, 163, 25495, 22545, 29863, 7083, 10066, 26284, 1818, 21685, 24293, 14026, 5813, 1889, 18209, 4011, 8064, 28797, 30816, 31212, 5811, 3867, 30604, 17684, 12897, 21208, 4102, 19292, 15052, 14142, 5603, 26461, 11537, 13632, 4469, 19710, 20454, 27917, 25686, 12796, 26734, 13790, 12543, 13730, 4647, 30128, 2562, 2481, 13993, 4242, 14653, 26486, 25347, 5210, 29947, 8989, 8919, 16103, 25978, 17949, 30248, 24879, 26760, 23820, 9192, 8977, 4278, 24930, 9439, 22887, 19587, 23395, 16640, 19787, 8458, 1137, 27417, 5380, 31506, 11176, 23818, 24620, 31943, 1668, 7441, 2171, 26954, 12303, 29522, 19290, 27164, 30394, 20848, 23460, 19062, 1641, 1902, 29069, 27817, 5974, 20095, 31544, 8760, 18229, 28020, 19148, 5237, 9767, 24578, 9497, 883, 359, 2936, 8055, 6519, 15415, 28448, 6966, 9196, 21660, 3417, 12738, 6726, 22510, 10990, 17952, 30692, 6228, 30946, 10328, 22879, 6265, 28082, 25360, 31715, 25910, 3540, 19536, 6384, 8811, 27239, 18730, 6410, 24568, 18983, 2290, 21778, 631, 12579, 460, 13636, 23534, 17295, 31801, 3416, 5909, 26569, 19548, 15280, 11127, 19761, 11139, 29874, 25390, 6008, 8778, 20669, 16786, 2787, 8192, 11299, 12556, 2756, 3690, 25366, 4876, 20737, 25408, 6486, 24593, 19273, 15366, 11541, 25480, 149, 15753, 1485, 289, 26173, 2080, 18802, 13180, 20635, 22624, 28804, 22200, 31338, 566, 6830, 31585, 25848, 10801, 24096, 11230, 31095, 14527, 26553, 19214, 31532, 501, 31882, 29943, 6240, 14712, 11346, 18486, 20134, 20559, 30317, 24506, 1605, 12425, 23622, 5164, 17668, 21876, 588, 9300, 28803, 12302, 27299, 4842, 17994, 31357, 15270, 22542, 8526, 8035, 16960, 22058, 10569, 8269, 28982, 2683, 8201, 26055, 17270, 3287, 14439, 23847, 27702, 1657, 24716, 9924, 21977, 22623, 20624, 9418, 29241, 27110, 14734, 12246, 10490, 13884, 2402, 8802, 25947, 4138, 12414, 14519, 16746, 23093, 15769, 2398, 8001, 14668, 28416, 13827, 22356, 9948, 22117, 8550, 21356, 12948, 22132, 5381, 24308, 6961, 18060, 7218, 25625, 9944, 1318, 11498, 23540, 21303, 20785, 10889, 26132, 19355, 648, 5664, 22118, 624, 27341, 18804, 19813, 12023, 32023, 11774, 30305, 25960, 22973, 12103, 15772, 25246, 662, 28472, 13753, 5941, 27395, 31880, 5206, 13536, 2663, 9195, 31347, 10243, 20666, 24059, 30561, 10370, 20524, 5379, 4207, 13838, 5129, 17899, 1992, 4813, 20086, 16873, 27700, 20873, 8151, 23538, 879, 4204, 19655, 707, 22982, 491, 13269, 10351, 12370, 1711, 31274, 7915, 23042, 21394, 2382, 27742, 24270, 14531, 14267, 19221, 3501, 7052, 16412, 96, 11514, 8309, 26786, 11588, 15312, 18647, 27685, 8585, 30482, 5375, 24719, 13770, 27622, 10849, 11561, 3117, 22036, 15139, 13109, 1843, 17424, 20369, 9691, 3516, 11560, 11379, 13448, 32013, 29008, 13392, 4816, 4413, 30484, 25687, 26765, 8996, 1862, 22329, 15517, 3067, 1510, 27, 11624, 25968, 24458, 19993, 23987, 21435, 12124, 19935, 15175, 30115, 8664, 15709, 17716, 15667, 5667, 13591, 22105, 19715, 25920, 14586, 18587, 28377, 8077, 14115, 334, 22466, 29460, 27128, 2385, 12052, 22923, 21943, 12186, 14154, 25700, 7589, 3598, 18718, 22336, 27541, 28868, 15533, 14644, 4165, 4140, 27971, 20912, 5332, 4582, 24598, 29606, 30750, 28575, 24938, 2703, 6251, 8083, 11733, 23797, 2734, 18552, 16914, 965, 763, 14045, 12942, 31955, 5358, 16826, 7749, 25737, 3223, 15295, 10557, 27507, 7462, 30853, 25565, 5051, 22285, 7409, 21987, 30814, 2118, 26604, 8319, 23129, 23219, 17344, 2273, 23624, 24407, 762, 11576, 3443, 3910, 9659, 5330, 24271, 29755, 14136, 4275, 30410, 9676, 15262, 15892, 5476, 21628, 12382, 13738, 29760, 12674, 24069, 19133, 25631, 24822, 10914, 28896, 15646, 29122, 8195, 5133, 1573, 9822, 28831, 3504, 9262, 32184, 10104, 3860, 16998, 24706, 21681, 13091, 8097, 10119, 12155, 4973, 20525, 16406, 8181, 5713, 32041, 10732, 22014, 16129, 19517, 7143, 23319, 10018, 10069, 1965, 18015, 3746, 30408, 22454, 4610, 3449, 20489, 7549, 17198, 32208, 10835, 26407, 10177, 10432, 14285, 258, 4050, 12335, 28747, 20207, 31899, 17691, 11106, 9809, 12829, 1393, 15458, 4054, 31745, 14958, 30579, 21729, 16311, 22703, 29759, 10233, 14183, 24848, 8821, 29836, 6504, 157, 26243, 21661, 31888, 28199, 1857, 22928, 25430, 19307, 895, 9934, 13158, 21538, 27332, 4794, 30789, 24453, 12121, 25280, 5183, 23366, 25161, 27757, 3838, 16700, 21637, 26472, 20434, 23084, 21584, 7376, 4328, 5185, 19780, 3554, 8042, 14448, 14729, 676, 32046, 25648, 19096, 24650, 1193, 3770, 15880, 3455, 15941, 27898, 23777, 16821, 20971, 30382, 26739, 30228, 10906, 24242, 32171, 18387, 27878, 16819, 27176, 7597, 25772, 21052, 29050, 24740, 23120, 32085, 15675, 25218, 10645, 16417, 5486, 27423, 790, 25490, 32182, 10570, 24225, 28236, 23892, 26376, 8027, 22762, 12967, 25813, 13121, 4449, 20169, 27729, 15780, 19336, 6327, 30754, 15718, 27038, 3744, 9673, 14964, 8108, 24664, 2699, 17488, 11926, 586, 4322, 5613, 5264, 1936, 18337, 10285, 25449, 13251, 16159, 22950, 18475, 23413, 25166, 20822, 9253, 21453, 966, 30378, 8381, 17326, 9881, 10919, 31709, 1652, 24429, 19141, 28785, 14321, 15933, 5885, 17525, 2965, 1358, 3047, 27442, 26757, 21044, 17796, 22130, 20144, 22150, 10545, 26989, 24137, 5587, 25650, 21503, 27127, 7570, 13387, 25533, 22362, 14210, 23500, 16542, 17951, 11501, 28270, 25566, 13217, 597, 28682, 32192, 2903, 17378, 2928, 23004, 4747, 22052, 11718, 4499, 2517, 14177, 31084, 9695, 17588, 15855, 3357, 25088, 26896, 20360, 26662, 28460, 28039, 7010, 11185, 13345, 4774, 20335, 21752, 13990, 7975, 11218, 6560, 31215, 22315, 4584, 27525, 1390, 26862, 10705, 25189, 20802, 24768, 24935, 19933, 8148, 11986, 28353, 4218, 26509, 31954, 24494, 29570, 23590, 1997, 21003, 15024, 14737, 28543, 3464, 3366, 24693, 5621, 398, 29929, 20805, 21505, 8891, 17839, 31906, 25196, 12505, 19406, 10007, 8498, 8399, 9837, 24227, 657, 22098, 2864, 24793, 10497, 20626, 3064, 7817, 30025, 32130, 29044, 917, 5441, 536, 6823, 9999, 12508, 21598, 7273, 11689, 13355, 22954, 29655, 690, 1983, 31055, 14048, 30967, 628, 9152, 29796, 29696, 10084, 15182, 25832, 21881, 4267, 11584, 24884, 28676, 17608, 5905, 14962, 20251, 2790, 28241, 20609, 23547, 23058, 6611, 30182, 16512, 27042, 29728, 5105, 18959, 32158, 25553, 26633, 10777, 9873, 3795, 3298, 11843, 18381, 11569, 20975, 6925, 18435, 22747, 5638, 32150, 3949, 9951, 13782, 28352, 29712, 12220, 45, 12191, 6230, 28106, 8128, 10033, 24016, 22647, 15859, 8652, 10886, 31787, 29438, 1301, 27713, 4152, 28826, 1074, 29352, 20544, 18755, 17071, 11928, 21525, 21297, 12750, 20054, 22617, 27936, 7196, 8193, 4634, 4429, 22875, 19656, 21989, 98, 14789, 6461, 14776, 13635, 30922, 13803, 16003, 5162, 562, 4867, 26609, 25714, 1562, 6890, 24148, 1752, 5341, 30205, 32072, 9890, 28877, 15848, 4076, 21974, 11124, 19567, 599, 6138, 21755, 13146, 20825, 9226, 28133, 11445, 18594, 326, 4722, 15543, 2849, 21421, 4719, 7639, 31125, 984, 2774, 18077, 8051, 3296, 20792, 29170, 25069, 8946, 20030, 1504, 1696, 28183, 19726, 7183, 1132, 25688, 32026, 16606, 31009, 7498, 13923, 6337, 10858, 5796, 18803, 9426, 7017, 3101, 25902, 20668, 5654, 28434, 25548, 15007, 20442, 11079, 1198, 1000, 6248, 16283, 3819, 2072, 5308, 21100, 31142, 31729, 22653, 18783, 21758, 25593, 15436, 7935, 25399, 7530, 27274, 11644, 29639, 6252, 27671, 29567, 29450, 5895, 8826, 4366, 17766, 26493, 25895, 7033, 16628, 27559, 23490, 17304, 3898, 12692, 15593, 6094, 20542, 9937, 12874, 29415, 3753, 31863, 4380, 32209, 16158, 28668, 160, 7787, 13225, 19919, 13986, 16549, 20538, 2109, 19275, 14093, 3579, 28400, 19659, 3757, 17681, 2829, 22530, 30536, 23569, 4498, 2291, 20426, 18660, 2128, 10684, 6756, 17815, 30266, 7694, 7823, 11755, 11482, 29139, 4298, 10863, 18862, 19816, 13578, 4410, 11800, 16235, 3328, 5278, 24319, 7999, 27177, 23702, 18636, 21756, 552, 5507, 18311, 23831, 29210, 3608, 6497, 31652, 30027, 9575, 1477, 19740, 29484, 16437, 11115, 25972, 30127, 24240, 13786, 23585, 31592, 3517, 18453, 3279, 23520, 6075, 17152, 9988, 6921, 13764, 10201, 5157, 2933, 3341, 1070, 5261, 18255, 31130, 29917, 1682, 5396, 19497, 2012, 22551, 15916, 23260, 19124, 20861, 28498, 21309, 12727, 27968, 27085, 17205, 24417, 17166, 5839, 12279, 28811, 27997, 1853, 752, 14809, 31222, 12235, 9539, 15334, 13870, 25195, 15263, 23422, 9750, 15528, 30841, 29341, 436, 28594, 30141, 25611, 20127, 24526, 20928, 3505, 11167, 5100, 23660, 10859, 8772, 27087, 11475, 18941, 807, 3985, 21533, 25516, 12592, 14209, 2233, 10802, 12406, 26706, 4044, 1871, 21883, 11093, 28840, 12345, 17036, 29457, 8583, 9360, 11208, 30198, 12243, 30118, 5652, 7202, 2539, 16450, 12569, 1704, 13052, 3777, 11066, 11389, 25203, 15364, 29605, 14277, 13101, 16647, 28912, 5316, 24269, 5131, 14888, 6778, 24688, 26473, 19828, 3687, 16911, 31097, 1633, 9909, 26903, 20184, 29703, 9993, 23165, 4125, 17511, 12255, 29508, 2812, 2275, 18121, 25667, 3192, 30385, 4890, 30283, 12997, 5531, 9713, 29075, 29153, 12904, 7104, 18830, 21820, 29904, 26644, 27708, 21338, 32113, 13783, 8986, 7776, 6607, 29196, 11444, 18656, 14788, 28461, 16408, 30740, 25222, 4974, 20913, 14592, 23698, 10252, 18426, 28357, 4287, 19431, 23725, 1904, 31021, 4680, 2312, 18839, 12608, 12119, 16138, 23554, 31513, 23769, 10306, 20278, 27372, 26067, 21215, 27483, 31014, 17804, 18438, 28834, 19135, 3775, 17147, 28129, 1755, 31757, 23699, 3380, 10945, 30422, 23177, 15187, 16303, 2902, 18814, 3318, 18305, 9320, 17974, 13272, 19428, 18448, 27204, 19999, 6336, 7681, 13714, 7478, 28714, 9547, 5791, 731, 29102, 12164, 30039, 27627, 3401, 8716, 9949, 11595, 12289, 21585, 11851, 24261, 11035, 17869, 27907, 20422, 2196, 25928, 3802, 13112, 8339, 8476, 23187, 18399, 22675, 14796, 22696, 1473, 4935, 30575, 4929, 22151, 22038, 3893, 9428, 1860, 14021, 31017, 6593, 31502, 10989, 1101, 2534, 11061, 8847, 8292, 21760, 6841, 6511, 6932, 26985, 26895, 13820, 13364, 27122, 5021, 21548, 26598, 27149, 8871, 22316, 10352, 17832, 8117, 17063, 26374, 12534, 29333, 23116, 29593, 17638, 16707, 6860, 8533, 28656, 2149, 29216, 130, 6018, 14913, 22018, 25205, 28331, 31422, 17882, 12512, 31051, 3200, 188, 8078, 25575, 23052, 24366, 4104, 8036, 5597, 4583, 1778, 11764, 6828, 27357, 31295, 27638, 13832, 24554, 18522, 28642, 20485, 5339, 30666, 7606, 8131, 5962, 10048, 15573, 8179, 10327, 728, 13836, 7092, 10910, 1337, 21959, 7080, 27656, 9569, 4596, 22902, 31633, 17364, 15945, 3468, 16147, 23609, 10131, 22757, 30414, 2728, 24344, 4368, 10566, 25234, 17706, 21669, 27240, 24105, 20073, 5263, 28655, 15629, 3142, 6426, 18324, 6660, 5887, 23304, 9356, 23369, 28174, 22690, 11192, 4177, 8087, 20860, 12352, 30710, 25084, 26528, 12317, 5648, 12767, 31603, 3882, 31510, 5590, 16213, 5232, 30370, 31679, 20242, 6669, 13431, 29528, 28540, 13705, 23248, 6679, 4897, 26001, 15614, 18252, 25676, 6997, 2647, 26639, 17323, 31283, 3750, 28743, 11613, 8010, 7483, 17947, 19874, 1746, 14322, 16799, 22986, 17127, 13307, 23474, 7106, 28403, 31099, 11947, 15569, 16725, 27762, 9443, 6620, 25431, 12965, 5860, 20145, 8745, 2658, 20779, 14356, 25116, 12843, 892, 24192, 11162, 2482, 30340, 13763, 24599, 7330, 24739, 9151, 24583, 17188, 12132, 19057, 17554, 22274, 20071, 28314, 20695, 19981, 25849, 12862, 7461, 25298, 323, 8098, 12946, 22189, 6724, 15665, 29130, 31000, 18203, 25534, 14916, 11999, 1542, 25864, 31146, 1774, 3977, 28368, 30452, 19082, 1695, 26480, 18178, 29658, 9507, 24221, 8704, 19837, 21175, 17493, 20528, 28640, 15864, 10871, 15146, 12981, 1942, 6832, 11519, 4481, 21414, 3295, 7938, 15130, 32243, 2614, 5090, 3559, 16301, 25146, 19631, 22269, 23930, 4916, 10112, 7743, 20799, 13793, 5644, 15987, 1060, 10826, 13267, 14102, 22338, 18732, 17143, 31706, 13389, 31631, 10744, 14782, 27046, 28055, 31303, 27718, 31362, 28338, 28111, 875, 13745, 26144, 1637, 20113, 29744, 16594, 31904, 9700, 15611, 8521, 16282, 12179, 7518, 181, 9274, 10619, 21570, 9636, 14368, 26045, 17214, 20985, 1540, 9161, 27160, 23485, 29809, 11534, 20932, 23593, 7231, 15588, 7275, 23010, 15271, 17497, 27340, 31264, 16041, 23592, 20698, 25374, 30311, 14406, 3311, 19798, 14319, 26482, 9032, 25892, 16111, 2584, 38, 25432, 14036, 14896, 3658, 9065, 15632, 3968, 7493, 12964, 15729, 12994, 3400, 29115, 27633, 15854, 25540, 27445, 20959, 20843, 11473, 13524, 8122, 14523, 29060, 15554, 4486, 20857, 19316, 1439, 3482, 9324, 23640, 26267, 17898, 6277, 24222, 8189, 28429, 21112, 28958, 8205, 6526, 16015, 14665, 14524, 16985, 3021, 8681, 2131, 22158, 27691, 30872, 19603, 18029, 15488, 22608, 27897, 20798, 4746
INFO:root:train dataset: 68117, validation dataset: 3872, test dataset: 6454
INFO:root:used only channels: []; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.05019754
INFO:root:[1,   100] training loss: 0.04436738
INFO:root:[1,   150] training loss: 0.03499359
INFO:root:[1,   200] training loss: 0.03360386
INFO:root:[1,   250] training loss: 0.03046838
INFO:root:[1,   300] training loss: 0.03012217
INFO:root:[1,   350] training loss: 0.03268348
INFO:root:[1,   400] training loss: 0.00038980
INFO:root:[1,   450] training loss: 0.00016602
INFO:root:[1,   500] training loss: 0.00747729
INFO:root:[1,   550] training loss: 0.00606661
INFO:root:[1,   600] training loss: 0.02932348
INFO:root:[1,   650] training loss: 0.00001967
INFO:root:[1,   700] training loss: 0.00001088
INFO:root:[1,   750] training loss: 0.00001220
INFO:root:[1,   800] training loss: 0.00000888
INFO:root:[1,   850] training loss: 0.00000676
INFO:root:[1,   900] training loss: 0.08029973
INFO:root:[1,   950] training loss: 0.01711585
INFO:root:[1,  1000] training loss: 0.00000380
INFO:root:[1,  1050] training loss: 0.00000290
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.09609744
INFO:root:[2,   100] training loss: 0.02971165
INFO:root:[2,   150] training loss: 0.02901748
INFO:root:[2,   200] training loss: 0.02826886
INFO:root:[2,   250] training loss: 0.02516644
INFO:root:[2,   300] training loss: 0.02404562
INFO:root:[2,   350] training loss: 0.02681093
INFO:root:[2,   400] training loss: 0.00054624
INFO:root:[2,   450] training loss: 0.00018294
INFO:root:[2,   500] training loss: 0.00777936
INFO:root:[2,   550] training loss: 0.00574945
INFO:root:[2,   600] training loss: 0.02988364
INFO:root:[2,   650] training loss: 0.00001223
INFO:root:[2,   700] training loss: 0.00001133
INFO:root:[2,   750] training loss: 0.00001225
INFO:root:[2,   800] training loss: 0.00001282
INFO:root:[2,   850] training loss: 0.00000791
INFO:root:[2,   900] training loss: 0.06477823
INFO:root:[2,   950] training loss: 0.01871208
INFO:root:[2,  1000] training loss: 0.00018776
INFO:root:[2,  1050] training loss: 0.00008457
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.06929969
INFO:root:[3,   100] training loss: 0.03148804
INFO:root:[3,   150] training loss: 0.02663823
INFO:root:[3,   200] training loss: 0.02523567
INFO:root:[3,   250] training loss: 0.02564576
INFO:root:[3,   300] training loss: 0.02255640
INFO:root:[3,   350] training loss: 0.02772559
INFO:root:[3,   400] training loss: 0.00235465
INFO:root:[3,   450] training loss: 0.00023745
INFO:root:[3,   500] training loss: 0.00892753
INFO:root:[3,   550] training loss: 0.00639025
INFO:root:[3,   600] training loss: 0.03137613
INFO:root:[3,   650] training loss: 0.00010256
INFO:root:[3,   700] training loss: 0.00007850
INFO:root:[3,   750] training loss: 0.00006875
INFO:root:[3,   800] training loss: 0.00005342
INFO:root:[3,   850] training loss: 0.00004957
INFO:root:[3,   900] training loss: 0.06112781
INFO:root:[3,   950] training loss: 0.01933077
INFO:root:[3,  1000] training loss: 0.00040815
INFO:root:[3,  1050] training loss: 0.00023311
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.06122423
INFO:root:[4,   100] training loss: 0.02425691
INFO:root:[4,   150] training loss: 0.02544490
INFO:root:[4,   200] training loss: 0.02084156
INFO:root:[4,   250] training loss: 0.02119023
INFO:root:[4,   300] training loss: 0.02079429
INFO:root:[4,   350] training loss: 0.03746793
INFO:root:[4,   400] training loss: 0.00111482
INFO:root:[4,   450] training loss: 0.00016711
INFO:root:[4,   500] training loss: 0.00735508
INFO:root:[4,   550] training loss: 0.00489297
INFO:root:[4,   600] training loss: 0.03220516
INFO:root:[4,   650] training loss: 0.00008634
INFO:root:[4,   700] training loss: 0.00006679
INFO:root:[4,   750] training loss: 0.00004870
INFO:root:[4,   800] training loss: 0.00004603
INFO:root:[4,   850] training loss: 0.00003787
INFO:root:[4,   900] training loss: 0.08008946
INFO:root:[4,   950] training loss: 0.02904914
INFO:root:[4,  1000] training loss: 0.00035536
INFO:root:[4,  1050] training loss: 0.00021608
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.07700918
INFO:root:[5,   100] training loss: 0.02799068
INFO:root:[5,   150] training loss: 0.02376294
INFO:root:[5,   200] training loss: 0.02240747
INFO:root:[5,   250] training loss: 0.02262007
INFO:root:[5,   300] training loss: 0.02115358
INFO:root:[5,   350] training loss: 0.02547736
INFO:root:[5,   400] training loss: 0.00069726
INFO:root:[5,   450] training loss: 0.00014039
INFO:root:[5,   500] training loss: 0.00797866
INFO:root:[5,   550] training loss: 0.00508158
INFO:root:[5,   600] training loss: 0.03336084
INFO:root:[5,   650] training loss: 0.00020394
INFO:root:[5,   700] training loss: 0.00014322
INFO:root:[5,   750] training loss: 0.00010995
INFO:root:[5,   800] training loss: 0.00009050
INFO:root:[5,   850] training loss: 0.00008057
INFO:root:[5,   900] training loss: 0.05947312
INFO:root:[5,   950] training loss: 0.02190952
INFO:root:[5,  1000] training loss: 0.00045529
INFO:root:[5,  1050] training loss: 0.00026618
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.06115010
INFO:root:[6,   100] training loss: 0.02796915
INFO:root:[6,   150] training loss: 0.02644500
INFO:root:[6,   200] training loss: 0.02260088
INFO:root:[6,   250] training loss: 0.02018004
INFO:root:[6,   300] training loss: 0.02029102
INFO:root:[6,   350] training loss: 0.02339615
INFO:root:[6,   400] training loss: 0.00177252
INFO:root:[6,   450] training loss: 0.00024316
INFO:root:[6,   500] training loss: 0.00592959
INFO:root:[6,   550] training loss: 0.00799207
INFO:root:[6,   600] training loss: 0.03448163
INFO:root:[6,   650] training loss: 0.00019237
INFO:root:[6,   700] training loss: 0.00013951
INFO:root:[6,   750] training loss: 0.00011273
INFO:root:[6,   800] training loss: 0.00009882
INFO:root:[6,   850] training loss: 0.00008204
INFO:root:[6,   900] training loss: 0.05271668
INFO:root:[6,   950] training loss: 0.02116419
INFO:root:[6,  1000] training loss: 0.00076264
INFO:root:[6,  1050] training loss: 0.00035215
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.05905789
INFO:root:[7,   100] training loss: 0.02171178
INFO:root:[7,   150] training loss: 0.02231676
INFO:root:[7,   200] training loss: 0.02050014
INFO:root:[7,   250] training loss: 0.01958919
INFO:root:[7,   300] training loss: 0.02041592
INFO:root:[7,   350] training loss: 0.01980860
INFO:root:[7,   400] training loss: 0.00080535
INFO:root:[7,   450] training loss: 0.00016522
INFO:root:[7,   500] training loss: 0.00563109
INFO:root:[7,   550] training loss: 0.00743370
INFO:root:[7,   600] training loss: 0.02856076
INFO:root:[7,   650] training loss: 0.00023082
INFO:root:[7,   700] training loss: 0.00016392
INFO:root:[7,   750] training loss: 0.00012469
INFO:root:[7,   800] training loss: 0.00009929
INFO:root:[7,   850] training loss: 0.00008162
INFO:root:[7,   900] training loss: 0.05117983
INFO:root:[7,   950] training loss: 0.02012246
INFO:root:[7,  1000] training loss: 0.00081770
INFO:root:[7,  1050] training loss: 0.00041426
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     1.0000    0.0137    0.0270        73
   Telophase     0.2673    1.0000    0.4218      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.1810    0.1448    0.0641      3872
weighted avg     0.0902    0.2673    0.1131      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.05192030
INFO:root:[8,   100] training loss: 0.02259372
INFO:root:[8,   150] training loss: 0.02513600
INFO:root:[8,   200] training loss: 0.02024862
INFO:root:[8,   250] training loss: 0.02013900
INFO:root:[8,   300] training loss: 0.02134524
INFO:root:[8,   350] training loss: 0.01951033
INFO:root:[8,   400] training loss: 0.00121840
INFO:root:[8,   450] training loss: 0.00014582
INFO:root:[8,   500] training loss: 0.00537821
INFO:root:[8,   550] training loss: 0.00639054
INFO:root:[8,   600] training loss: 0.03056975
INFO:root:[8,   650] training loss: 0.00024362
INFO:root:[8,   700] training loss: 0.00017161
INFO:root:[8,   750] training loss: 0.00012814
INFO:root:[8,   800] training loss: 0.00010080
INFO:root:[8,   850] training loss: 0.00007673
INFO:root:[8,   900] training loss: 0.04908409
INFO:root:[8,   950] training loss: 0.01968088
INFO:root:[8,  1000] training loss: 0.00074236
INFO:root:[8,  1050] training loss: 0.00036565
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3333    0.3750    0.3529         8
   Metaphase     1.0000    0.0822    0.1519        73
   Telophase     0.2684    1.0000    0.4232      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2694      3872
   macro avg     0.2288    0.2082    0.1326      3872
weighted avg     0.0912    0.2694    0.1166      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.05042580
INFO:root:[9,   100] training loss: 0.01944013
INFO:root:[9,   150] training loss: 0.02067713
INFO:root:[9,   200] training loss: 0.01949808
INFO:root:[9,   250] training loss: 0.02227976
INFO:root:[9,   300] training loss: 0.02137591
INFO:root:[9,   350] training loss: 0.01910083
INFO:root:[9,   400] training loss: 0.00100769
INFO:root:[9,   450] training loss: 0.00014399
INFO:root:[9,   500] training loss: 0.00513664
INFO:root:[9,   550] training loss: 0.00798146
INFO:root:[9,   600] training loss: 0.02741526
INFO:root:[9,   650] training loss: 0.00029103
INFO:root:[9,   700] training loss: 0.00019188
INFO:root:[9,   750] training loss: 0.00014915
INFO:root:[9,   800] training loss: 0.00011356
INFO:root:[9,   850] training loss: 0.00010273
INFO:root:[9,   900] training loss: 0.04726208
INFO:root:[9,   950] training loss: 0.01992870
INFO:root:[9,  1000] training loss: 0.00074833
INFO:root:[9,  1050] training loss: 0.00037346
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1538    0.2500    0.1905         8
   Metaphase     1.0000    0.0548    0.1039        73
   Telophase     0.2682    1.0000    0.4230      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2686      3872
   macro avg     0.2032    0.1864    0.1025      3872
weighted avg     0.0908    0.2686    0.1153      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.05137291
INFO:root:[10,   100] training loss: 0.02067345
INFO:root:[10,   150] training loss: 0.02103931
INFO:root:[10,   200] training loss: 0.01993547
INFO:root:[10,   250] training loss: 0.01992382
INFO:root:[10,   300] training loss: 0.02055147
INFO:root:[10,   350] training loss: 0.01968525
INFO:root:[10,   400] training loss: 0.00131747
INFO:root:[10,   450] training loss: 0.00022914
INFO:root:[10,   500] training loss: 0.00551307
INFO:root:[10,   550] training loss: 0.00818812
INFO:root:[10,   600] training loss: 0.02844799
INFO:root:[10,   650] training loss: 0.00024359
INFO:root:[10,   700] training loss: 0.00016643
INFO:root:[10,   750] training loss: 0.00014057
INFO:root:[10,   800] training loss: 0.00010927
INFO:root:[10,   850] training loss: 0.00009498
INFO:root:[10,   900] training loss: 0.04859291
INFO:root:[10,   950] training loss: 0.02177676
INFO:root:[10,  1000] training loss: 0.00078620
INFO:root:[10,  1050] training loss: 0.00038128
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     1.0000    0.0137    0.0270        73
   Telophase     0.2672    1.0000    0.4217      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.1810    0.1448    0.0641      3872
weighted avg     0.0902    0.2673    0.1131      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.07309109
INFO:root:[11,   100] training loss: 0.02875182
INFO:root:[11,   150] training loss: 0.02810290
INFO:root:[11,   200] training loss: 0.02271203
INFO:root:[11,   250] training loss: 0.02891253
INFO:root:[11,   300] training loss: 0.02459385
INFO:root:[11,   350] training loss: 0.03024784
INFO:root:[11,   400] training loss: 0.00166238
INFO:root:[11,   450] training loss: 0.00020333
INFO:root:[11,   500] training loss: 0.00491127
INFO:root:[11,   550] training loss: 0.00669650
INFO:root:[11,   600] training loss: 0.02452311
INFO:root:[11,   650] training loss: 0.00017782
INFO:root:[11,   700] training loss: 0.00013251
INFO:root:[11,   750] training loss: 0.00011096
INFO:root:[11,   800] training loss: 0.00009003
INFO:root:[11,   850] training loss: 0.00007657
INFO:root:[11,   900] training loss: 0.05103807
INFO:root:[11,   950] training loss: 0.02099234
INFO:root:[11,  1000] training loss: 0.00101781
INFO:root:[11,  1050] training loss: 0.00039772
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2670    1.0000    0.4215      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.05154648
INFO:root:[12,   100] training loss: 0.02253303
INFO:root:[12,   150] training loss: 0.02339708
INFO:root:[12,   200] training loss: 0.02009035
INFO:root:[12,   250] training loss: 0.01970703
INFO:root:[12,   300] training loss: 0.02050657
INFO:root:[12,   350] training loss: 0.01899266
INFO:root:[12,   400] training loss: 0.00091616
INFO:root:[12,   450] training loss: 0.00029479
INFO:root:[12,   500] training loss: 0.00562902
INFO:root:[12,   550] training loss: 0.00849718
INFO:root:[12,   600] training loss: 0.02874057
INFO:root:[12,   650] training loss: 0.00027993
INFO:root:[12,   700] training loss: 0.00019168
INFO:root:[12,   750] training loss: 0.00017080
INFO:root:[12,   800] training loss: 0.00013694
INFO:root:[12,   850] training loss: 0.00011836
INFO:root:[12,   900] training loss: 0.04523512
INFO:root:[12,   950] training loss: 0.02115420
INFO:root:[12,  1000] training loss: 0.00098929
INFO:root:[12,  1050] training loss: 0.00044587
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2381    0.6250    0.3448         8
   Metaphase     0.2812    0.1233    0.1714        73
   Telophase     0.2710    1.0000    0.4265      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2709      3872
   macro avg     0.2558    0.2974    0.2061      3872
weighted avg     0.0789    0.2709    0.1182      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.04851435
INFO:root:[13,   100] training loss: 0.01918457
INFO:root:[13,   150] training loss: 0.01977826
INFO:root:[13,   200] training loss: 0.01883718
INFO:root:[13,   250] training loss: 0.02232791
INFO:root:[13,   300] training loss: 0.02055138
INFO:root:[13,   350] training loss: 0.02001146
INFO:root:[13,   400] training loss: 0.00087806
INFO:root:[13,   450] training loss: 0.00020306
INFO:root:[13,   500] training loss: 0.00520162
INFO:root:[13,   550] training loss: 0.00938882
INFO:root:[13,   600] training loss: 0.03138515
INFO:root:[13,   650] training loss: 0.00035447
INFO:root:[13,   700] training loss: 0.00022382
INFO:root:[13,   750] training loss: 0.00018610
INFO:root:[13,   800] training loss: 0.00013427
INFO:root:[13,   850] training loss: 0.00011605
INFO:root:[13,   900] training loss: 0.04751743
INFO:root:[13,   950] training loss: 0.02133773
INFO:root:[13,  1000] training loss: 0.00067726
INFO:root:[13,  1050] training loss: 0.00031726
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1667    0.3750    0.2308         8
   Metaphase     0.2683    0.1507    0.1930        73
   Telophase     0.2713    1.0000    0.4268      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2707      3872
   macro avg     0.1009    0.2180    0.1215      3872
weighted avg     0.0779    0.2707    0.1181      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.05396421
INFO:root:[14,   100] training loss: 0.02059974
INFO:root:[14,   150] training loss: 0.02035452
INFO:root:[14,   200] training loss: 0.01789924
INFO:root:[14,   250] training loss: 0.01992973
INFO:root:[14,   300] training loss: 0.01954842
INFO:root:[14,   350] training loss: 0.01808296
INFO:root:[14,   400] training loss: 0.00091234
INFO:root:[14,   450] training loss: 0.00024479
INFO:root:[14,   500] training loss: 0.00491583
INFO:root:[14,   550] training loss: 0.00834914
INFO:root:[14,   600] training loss: 0.02844792
INFO:root:[14,   650] training loss: 0.00046099
INFO:root:[14,   700] training loss: 0.00028661
INFO:root:[14,   750] training loss: 0.00022536
INFO:root:[14,   800] training loss: 0.00018459
INFO:root:[14,   850] training loss: 0.00015085
INFO:root:[14,   900] training loss: 0.04148223
INFO:root:[14,   950] training loss: 0.01939293
INFO:root:[14,  1000] training loss: 0.00081368
INFO:root:[14,  1050] training loss: 0.00030541
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2000    0.2500    0.2222         8
   Metaphase     0.4848    0.2192    0.3019        73
   Telophase     0.2701    1.0000    0.4253      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2720      3872
   macro avg     0.2793    0.2575    0.2071      3872
weighted avg     0.0825    0.2720    0.1201      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.05086991
INFO:root:[15,   100] training loss: 0.01886833
INFO:root:[15,   150] training loss: 0.01948854
INFO:root:[15,   200] training loss: 0.01801620
INFO:root:[15,   250] training loss: 0.01942976
INFO:root:[15,   300] training loss: 0.01889268
INFO:root:[15,   350] training loss: 0.01889340
INFO:root:[15,   400] training loss: 0.00118237
INFO:root:[15,   450] training loss: 0.00031511
INFO:root:[15,   500] training loss: 0.00478424
INFO:root:[15,   550] training loss: 0.01000478
INFO:root:[15,   600] training loss: 0.02951138
INFO:root:[15,   650] training loss: 0.00038149
INFO:root:[15,   700] training loss: 0.00025539
INFO:root:[15,   750] training loss: 0.00021247
INFO:root:[15,   800] training loss: 0.00015943
INFO:root:[15,   850] training loss: 0.00012201
INFO:root:[15,   900] training loss: 0.04633505
INFO:root:[15,   950] training loss: 0.02014215
INFO:root:[15,  1000] training loss: 0.00051217
INFO:root:[15,  1050] training loss: 0.00023421
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2000    0.5000    0.2857         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2400    0.7500    0.3636         8
   Metaphase     0.3750    0.1644    0.2286        73
   Telophase     0.2711    0.9990    0.4265      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2717      3872
   macro avg     0.1552    0.3448    0.1863      3872
weighted avg     0.0801    0.2717    0.1191      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.04918729
INFO:root:[16,   100] training loss: 0.02025111
INFO:root:[16,   150] training loss: 0.02140875
INFO:root:[16,   200] training loss: 0.01791483
INFO:root:[16,   250] training loss: 0.01786055
INFO:root:[16,   300] training loss: 0.01877762
INFO:root:[16,   350] training loss: 0.01792029
INFO:root:[16,   400] training loss: 0.00058399
INFO:root:[16,   450] training loss: 0.00016533
INFO:root:[16,   500] training loss: 0.00471680
INFO:root:[16,   550] training loss: 0.00844696
INFO:root:[16,   600] training loss: 0.02626937
INFO:root:[16,   650] training loss: 0.00034067
INFO:root:[16,   700] training loss: 0.00022909
INFO:root:[16,   750] training loss: 0.00019522
INFO:root:[16,   800] training loss: 0.00015739
INFO:root:[16,   850] training loss: 0.00012104
INFO:root:[16,   900] training loss: 0.04027284
INFO:root:[16,   950] training loss: 0.01874061
INFO:root:[16,  1000] training loss: 0.00085375
INFO:root:[16,  1050] training loss: 0.00035605
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1765    0.3750    0.2400         8
   Metaphase     0.3509    0.2740    0.3077        73
   Telophase     0.2723    1.0000    0.4281      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2732      3872
   macro avg     0.2571    0.2832    0.2108      3872
weighted avg     0.0805    0.2732    0.1210      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.04956595
INFO:root:[17,   100] training loss: 0.01923020
INFO:root:[17,   150] training loss: 0.01864285
INFO:root:[17,   200] training loss: 0.01808802
INFO:root:[17,   250] training loss: 0.01821939
INFO:root:[17,   300] training loss: 0.01919777
INFO:root:[17,   350] training loss: 0.01889632
INFO:root:[17,   400] training loss: 0.00049355
INFO:root:[17,   450] training loss: 0.00019938
INFO:root:[17,   500] training loss: 0.00444869
INFO:root:[17,   550] training loss: 0.00853712
INFO:root:[17,   600] training loss: 0.02664783
INFO:root:[17,   650] training loss: 0.00042249
INFO:root:[17,   700] training loss: 0.00028100
INFO:root:[17,   750] training loss: 0.00023147
INFO:root:[17,   800] training loss: 0.00017673
INFO:root:[17,   850] training loss: 0.00014563
INFO:root:[17,   900] training loss: 0.03965697
INFO:root:[17,   950] training loss: 0.01850306
INFO:root:[17,  1000] training loss: 0.00081413
INFO:root:[17,  1050] training loss: 0.00037429
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2500    0.5000    0.3333         8
   Metaphase     0.5370    0.3973    0.4567        73
   Telophase     0.2718    0.9990    0.4273      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2756      3872
   macro avg     0.2941    0.3185    0.2453      3872
weighted avg     0.0840    0.2756    0.1238      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.04522983
INFO:root:[18,   100] training loss: 0.01766307
INFO:root:[18,   150] training loss: 0.01870257
INFO:root:[18,   200] training loss: 0.01620402
INFO:root:[18,   250] training loss: 0.01851717
INFO:root:[18,   300] training loss: 0.01809554
INFO:root:[18,   350] training loss: 0.01653436
INFO:root:[18,   400] training loss: 0.00066951
INFO:root:[18,   450] training loss: 0.00032069
INFO:root:[18,   500] training loss: 0.00449944
INFO:root:[18,   550] training loss: 0.00901036
INFO:root:[18,   600] training loss: 0.02730787
INFO:root:[18,   650] training loss: 0.00042543
INFO:root:[18,   700] training loss: 0.00026693
INFO:root:[18,   750] training loss: 0.00023609
INFO:root:[18,   800] training loss: 0.00017835
INFO:root:[18,   850] training loss: 0.00014927
INFO:root:[18,   900] training loss: 0.03830258
INFO:root:[18,   950] training loss: 0.01740128
INFO:root:[18,  1000] training loss: 0.00080758
INFO:root:[18,  1050] training loss: 0.00038293
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2609    0.7500    0.3871         8
   Metaphase     0.4194    0.3562    0.3852        73
   Telophase     0.2728    0.9990    0.4285      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2751      3872
   macro avg     0.1361    0.3007    0.1715      3872
weighted avg     0.0813    0.2751    0.1225      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.04757104
INFO:root:[19,   100] training loss: 0.01745875
INFO:root:[19,   150] training loss: 0.01779524
INFO:root:[19,   200] training loss: 0.01606669
INFO:root:[19,   250] training loss: 0.01632883
INFO:root:[19,   300] training loss: 0.01728361
INFO:root:[19,   350] training loss: 0.01669142
INFO:root:[19,   400] training loss: 0.00060654
INFO:root:[19,   450] training loss: 0.00028923
INFO:root:[19,   500] training loss: 0.00491349
INFO:root:[19,   550] training loss: 0.00821336
INFO:root:[19,   600] training loss: 0.02889225
INFO:root:[19,   650] training loss: 0.00040177
INFO:root:[19,   700] training loss: 0.00027003
INFO:root:[19,   750] training loss: 0.00022530
INFO:root:[19,   800] training loss: 0.00017881
INFO:root:[19,   850] training loss: 0.00014400
INFO:root:[19,   900] training loss: 0.06117302
INFO:root:[19,   950] training loss: 0.01811388
INFO:root:[19,  1000] training loss: 0.00051519
INFO:root:[19,  1050] training loss: 0.00024669
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2632    0.6250    0.3704         8
   Metaphase     0.3608    0.4795    0.4118        73
   Telophase     0.2753    0.9990    0.4317      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2774      3872
   macro avg     0.1642    0.3719    0.2210      3872
weighted avg     0.0810    0.2774    0.1240      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.04493769
INFO:root:[20,   100] training loss: 0.01874230
INFO:root:[20,   150] training loss: 0.01771300
INFO:root:[20,   200] training loss: 0.01701742
INFO:root:[20,   250] training loss: 0.01648656
INFO:root:[20,   300] training loss: 0.01887881
INFO:root:[20,   350] training loss: 0.01650568
INFO:root:[20,   400] training loss: 0.00074210
INFO:root:[20,   450] training loss: 0.00017196
INFO:root:[20,   500] training loss: 0.00456781
INFO:root:[20,   550] training loss: 0.00875541
INFO:root:[20,   600] training loss: 0.02891332
INFO:root:[20,   650] training loss: 0.00031505
INFO:root:[20,   700] training loss: 0.00021285
INFO:root:[20,   750] training loss: 0.00026929
INFO:root:[20,   800] training loss: 0.00015966
INFO:root:[20,   850] training loss: 0.00012425
INFO:root:[20,   900] training loss: 0.03807508
INFO:root:[20,   950] training loss: 0.01787546
INFO:root:[20,  1000] training loss: 0.00066831
INFO:root:[20,  1050] training loss: 0.00036979
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2083    0.6250    0.3125         8
   Metaphase     0.4722    0.4658    0.4690        73
   Telophase     0.2730    0.9971    0.4287      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2763      3872
   macro avg     0.1362    0.2983    0.1729      3872
weighted avg     0.0822    0.2763    0.1240      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.04661181
INFO:root:[21,   100] training loss: 0.01803882
INFO:root:[21,   150] training loss: 0.01723675
INFO:root:[21,   200] training loss: 0.01625487
INFO:root:[21,   250] training loss: 0.01975937
INFO:root:[21,   300] training loss: 0.01803110
INFO:root:[21,   350] training loss: 0.01616219
INFO:root:[21,   400] training loss: 0.00101292
INFO:root:[21,   450] training loss: 0.00016526
INFO:root:[21,   500] training loss: 0.00436704
INFO:root:[21,   550] training loss: 0.00824613
INFO:root:[21,   600] training loss: 0.02742808
INFO:root:[21,   650] training loss: 0.00042319
INFO:root:[21,   700] training loss: 0.00026933
INFO:root:[21,   750] training loss: 0.00022093
INFO:root:[21,   800] training loss: 0.00019375
INFO:root:[21,   850] training loss: 0.00016087
INFO:root:[21,   900] training loss: 0.03337470
INFO:root:[21,   950] training loss: 0.02054539
INFO:root:[21,  1000] training loss: 0.00054414
INFO:root:[21,  1050] training loss: 0.00031000
INFO:root:              precision    recall  f1-score   support

    Prophase     0.3333    1.0000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1935    0.7500    0.3077         8
   Metaphase     0.3516    0.4384    0.3902        73
   Telophase     0.2748    0.9952    0.4307      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2761      3872
   macro avg     0.1648    0.4548    0.2327      3872
weighted avg     0.0806    0.2761    0.1233      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.04731740
INFO:root:[22,   100] training loss: 0.01882032
INFO:root:[22,   150] training loss: 0.01742971
INFO:root:[22,   200] training loss: 0.01554397
INFO:root:[22,   250] training loss: 0.01648806
INFO:root:[22,   300] training loss: 0.01664731
INFO:root:[22,   350] training loss: 0.01495422
INFO:root:[22,   400] training loss: 0.00040176
INFO:root:[22,   450] training loss: 0.00021502
INFO:root:[22,   500] training loss: 0.00456131
INFO:root:[22,   550] training loss: 0.00783900
INFO:root:[22,   600] training loss: 0.02811448
INFO:root:[22,   650] training loss: 0.00043178
INFO:root:[22,   700] training loss: 0.00030226
INFO:root:[22,   750] training loss: 0.00025753
INFO:root:[22,   800] training loss: 0.00019522
INFO:root:[22,   850] training loss: 0.00015037
INFO:root:[22,   900] training loss: 0.03477633
INFO:root:[22,   950] training loss: 0.01822152
INFO:root:[22,  1000] training loss: 0.00070388
INFO:root:[22,  1050] training loss: 0.00038237
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2069    0.7500    0.3243         8
   Metaphase     0.5500    0.4521    0.4962        73
   Telophase     0.2726    0.9971    0.4282      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2766      3872
   macro avg     0.2899    0.3618    0.2498      3872
weighted avg     0.0844    0.2766    0.1248      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.04512396
INFO:root:[23,   100] training loss: 0.01834731
INFO:root:[23,   150] training loss: 0.01665783
INFO:root:[23,   200] training loss: 0.01529544
INFO:root:[23,   250] training loss: 0.01580736
INFO:root:[23,   300] training loss: 0.01810755
INFO:root:[23,   350] training loss: 0.01490368
INFO:root:[23,   400] training loss: 0.00028622
INFO:root:[23,   450] training loss: 0.00025056
INFO:root:[23,   500] training loss: 0.00430018
INFO:root:[23,   550] training loss: 0.00854994
INFO:root:[23,   600] training loss: 0.02873243
INFO:root:[23,   650] training loss: 0.00045782
INFO:root:[23,   700] training loss: 0.00030943
INFO:root:[23,   750] training loss: 0.00022156
INFO:root:[23,   800] training loss: 0.00018721
INFO:root:[23,   850] training loss: 0.00015390
INFO:root:[23,   900] training loss: 0.04429350
INFO:root:[23,   950] training loss: 0.03304862
INFO:root:[23,  1000] training loss: 0.00043970
INFO:root:[23,  1050] training loss: 0.00022705
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1111    0.1250    0.1176         8
   Metaphase     0.5926    0.2192    0.3200        73
   Telophase     0.2693    0.9990    0.4242      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2712      3872
   macro avg     0.1390    0.1919    0.1231      3872
weighted avg     0.0833    0.2712    0.1196      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.04789719
INFO:root:[24,   100] training loss: 0.02197918
INFO:root:[24,   150] training loss: 0.02095386
INFO:root:[24,   200] training loss: 0.01602496
INFO:root:[24,   250] training loss: 0.01665772
INFO:root:[24,   300] training loss: 0.01968578
INFO:root:[24,   350] training loss: 0.01803467
INFO:root:[24,   400] training loss: 0.00021376
INFO:root:[24,   450] training loss: 0.00017828
INFO:root:[24,   500] training loss: 0.00458152
INFO:root:[24,   550] training loss: 0.00943902
INFO:root:[24,   600] training loss: 0.02716209
INFO:root:[24,   650] training loss: 0.00048572
INFO:root:[24,   700] training loss: 0.00032656
INFO:root:[24,   750] training loss: 0.00026672
INFO:root:[24,   800] training loss: 0.00021436
INFO:root:[24,   850] training loss: 0.00017363
INFO:root:[24,   900] training loss: 0.03979477
INFO:root:[24,   950] training loss: 0.02061892
INFO:root:[24,  1000] training loss: 0.00077461
INFO:root:[24,  1050] training loss: 0.00037774
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3125    0.6250    0.4167         8
   Metaphase     0.4286    0.4521    0.4400        73
   Telophase     0.2734    0.9981    0.4293      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2771      3872
   macro avg     0.2521    0.4393    0.3062      3872
weighted avg     0.0823    0.2771    0.1245      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.04476857
INFO:root:[25,   100] training loss: 0.01828442
INFO:root:[25,   150] training loss: 0.02155975
INFO:root:[25,   200] training loss: 0.04641071
INFO:root:[25,   250] training loss: 0.04254000
INFO:root:[25,   300] training loss: 0.03164921
INFO:root:[25,   350] training loss: 0.03247380
INFO:root:[25,   400] training loss: 0.00283656
INFO:root:[25,   450] training loss: 0.00021179
INFO:root:[25,   500] training loss: 0.00541950
INFO:root:[25,   550] training loss: 0.00719547
INFO:root:[25,   600] training loss: 0.02555283
INFO:root:[25,   650] training loss: 0.00032608
INFO:root:[25,   700] training loss: 0.00020934
INFO:root:[25,   750] training loss: 0.00017340
INFO:root:[25,   800] training loss: 0.00011604
INFO:root:[25,   850] training loss: 0.00006784
INFO:root:[25,   900] training loss: 0.05723299
INFO:root:[25,   950] training loss: 0.02137958
INFO:root:[25,  1000] training loss: 0.00047094
INFO:root:[25,  1050] training loss: 0.00025186
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2673    1.0000    0.4219      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0603      3872
weighted avg     0.0714    0.2670    0.1127      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.05429613
INFO:root:[26,   100] training loss: 0.02565542
INFO:root:[26,   150] training loss: 0.02600735
INFO:root:[26,   200] training loss: 0.02427770
INFO:root:[26,   250] training loss: 0.02170232
INFO:root:[26,   300] training loss: 0.02526886
INFO:root:[26,   350] training loss: 0.02187137
INFO:root:[26,   400] training loss: 0.00075809
INFO:root:[26,   450] training loss: 0.00032504
INFO:root:[26,   500] training loss: 0.00537315
INFO:root:[26,   550] training loss: 0.01011370
INFO:root:[26,   600] training loss: 0.02726895
INFO:root:[26,   650] training loss: 0.00057657
INFO:root:[26,   700] training loss: 0.00034381
INFO:root:[26,   750] training loss: 0.00025544
INFO:root:[26,   800] training loss: 0.00018729
INFO:root:[26,   850] training loss: 0.00015286
INFO:root:[26,   900] training loss: 0.05179974
INFO:root:[26,   950] training loss: 0.02311709
INFO:root:[26,  1000] training loss: 0.00078719
INFO:root:[26,  1050] training loss: 0.00039024
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2674    1.0000    0.4220      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0382    0.1429    0.0603      3872
weighted avg     0.0714    0.2670    0.1127      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.05211352
INFO:root:[27,   100] training loss: 0.02276281
INFO:root:[27,   150] training loss: 0.02393507
INFO:root:[27,   200] training loss: 0.02010356
INFO:root:[27,   250] training loss: 0.02270182
INFO:root:[27,   300] training loss: 0.02479523
INFO:root:[27,   350] training loss: 0.02110689
INFO:root:[27,   400] training loss: 0.00057991
INFO:root:[27,   450] training loss: 0.00017183
INFO:root:[27,   500] training loss: 0.00492580
INFO:root:[27,   550] training loss: 0.01122940
INFO:root:[27,   600] training loss: 0.02836397
INFO:root:[27,   650] training loss: 0.00049029
INFO:root:[27,   700] training loss: 0.00030438
INFO:root:[27,   750] training loss: 0.00024236
INFO:root:[27,   800] training loss: 0.00018671
INFO:root:[27,   850] training loss: 0.00015207
INFO:root:[27,   900] training loss: 0.05196395
INFO:root:[27,   950] training loss: 0.02285317
INFO:root:[27,  1000] training loss: 0.00089599
INFO:root:[27,  1050] training loss: 0.00042320
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2000    0.1250    0.1538         8
   Metaphase     0.8182    0.1233    0.2143        73
   Telophase     0.2684    1.0000    0.4232      1034
          G1     1.0000    0.6667    0.8000         3

    accuracy                         0.2701      3872
   macro avg     0.3266    0.2736    0.2273      3872
weighted avg     0.0883    0.2701    0.1180      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.04830908
INFO:root:[28,   100] training loss: 0.02048536
INFO:root:[28,   150] training loss: 0.02114544
INFO:root:[28,   200] training loss: 0.01862888
INFO:root:[28,   250] training loss: 0.01928728
INFO:root:[28,   300] training loss: 0.02297673
INFO:root:[28,   350] training loss: 0.02109569
INFO:root:[28,   400] training loss: 0.00051617
INFO:root:[28,   450] training loss: 0.00024148
INFO:root:[28,   500] training loss: 0.00479949
INFO:root:[28,   550] training loss: 0.01071327
INFO:root:[28,   600] training loss: 0.03036277
INFO:root:[28,   650] training loss: 0.00054591
INFO:root:[28,   700] training loss: 0.00032475
INFO:root:[28,   750] training loss: 0.00023613
INFO:root:[28,   800] training loss: 0.00017805
INFO:root:[28,   850] training loss: 0.00014138
INFO:root:[28,   900] training loss: 0.04856733
INFO:root:[28,   950] training loss: 0.02371730
INFO:root:[28,  1000] training loss: 0.00100098
INFO:root:[28,  1050] training loss: 0.00044641
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.5600    0.1918    0.2857        73
   Telophase     0.2693    1.0000    0.4244      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2714      3872
   macro avg     0.2613    0.3131    0.2443      3872
weighted avg     0.0833    0.2714    0.1195      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.04771921
INFO:root:[29,   100] training loss: 0.02002198
INFO:root:[29,   150] training loss: 0.02024558
INFO:root:[29,   200] training loss: 0.01695143
INFO:root:[29,   250] training loss: 0.01776757
INFO:root:[29,   300] training loss: 0.02300968
INFO:root:[29,   350] training loss: 0.02220535
INFO:root:[29,   400] training loss: 0.00049639
INFO:root:[29,   450] training loss: 0.00024629
INFO:root:[29,   500] training loss: 0.00458430
INFO:root:[29,   550] training loss: 0.01206473
INFO:root:[29,   600] training loss: 0.02947616
INFO:root:[29,   650] training loss: 0.00080752
INFO:root:[29,   700] training loss: 0.00045292
INFO:root:[29,   750] training loss: 0.00033034
INFO:root:[29,   800] training loss: 0.00024380
INFO:root:[29,   850] training loss: 0.00019973
INFO:root:[29,   900] training loss: 0.04817225
INFO:root:[29,   950] training loss: 0.02167474
INFO:root:[29,  1000] training loss: 0.00082861
INFO:root:[29,  1050] training loss: 0.00044055
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2000    0.2500    0.2222         8
   Metaphase     0.8000    0.1096    0.1928        73
   Telophase     0.2686    1.0000    0.4235      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2696      3872
   macro avg     0.1812    0.1942    0.1198      3872
weighted avg     0.0872    0.2696    0.1172      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.04935109
INFO:root:[30,   100] training loss: 0.02098497
INFO:root:[30,   150] training loss: 0.02104366
INFO:root:[30,   200] training loss: 0.01903986
INFO:root:[30,   250] training loss: 0.01900149
INFO:root:[30,   300] training loss: 0.02009768
INFO:root:[30,   350] training loss: 0.01772159
INFO:root:[30,   400] training loss: 0.00021655
INFO:root:[30,   450] training loss: 0.00032645
INFO:root:[30,   500] training loss: 0.00462590
INFO:root:[30,   550] training loss: 0.01060003
INFO:root:[30,   600] training loss: 0.02813982
INFO:root:[30,   650] training loss: 0.00062849
INFO:root:[30,   700] training loss: 0.00035984
INFO:root:[30,   750] training loss: 0.00028542
INFO:root:[30,   800] training loss: 0.00022414
INFO:root:[30,   850] training loss: 0.00017257
INFO:root:[30,   900] training loss: 0.05394218
INFO:root:[30,   950] training loss: 0.02190973
INFO:root:[30,  1000] training loss: 0.00072163
INFO:root:[30,  1050] training loss: 0.00040398
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1667    0.1250    0.1429         8
   Metaphase     0.6667    0.2740    0.3883        73
   Telophase     0.2697    1.0000    0.4248      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2727      3872
   macro avg     0.3004    0.2475    0.2080      3872
weighted avg     0.0857    0.2727    0.1214      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.04554708
INFO:root:[31,   100] training loss: 0.02080808
INFO:root:[31,   150] training loss: 0.01950619
INFO:root:[31,   200] training loss: 0.01702213
INFO:root:[31,   250] training loss: 0.01780430
INFO:root:[31,   300] training loss: 0.01876978
INFO:root:[31,   350] training loss: 0.01646689
INFO:root:[31,   400] training loss: 0.00058363
INFO:root:[31,   450] training loss: 0.00018207
INFO:root:[31,   500] training loss: 0.00466865
INFO:root:[31,   550] training loss: 0.01052759
INFO:root:[31,   600] training loss: 0.02907014
INFO:root:[31,   650] training loss: 0.00055749
INFO:root:[31,   700] training loss: 0.00032648
INFO:root:[31,   750] training loss: 0.00026051
INFO:root:[31,   800] training loss: 0.00020006
INFO:root:[31,   850] training loss: 0.00015995
INFO:root:[31,   900] training loss: 0.03836873
INFO:root:[31,   950] training loss: 0.01993505
INFO:root:[31,  1000] training loss: 0.00048260
INFO:root:[31,  1050] training loss: 0.00019178
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1538    0.2500    0.1905         8
   Metaphase     0.8750    0.0959    0.1728        73
   Telophase     0.2687    1.0000    0.4236      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2701      3872
   macro avg     0.3282    0.3351    0.2553      3872
weighted avg     0.0893    0.2701    0.1175      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.04590706
INFO:root:[32,   100] training loss: 0.02328836
INFO:root:[32,   150] training loss: 0.02070471
INFO:root:[32,   200] training loss: 0.01908995
INFO:root:[32,   250] training loss: 0.01879611
INFO:root:[32,   300] training loss: 0.02060238
INFO:root:[32,   350] training loss: 0.01951207
INFO:root:[32,   400] training loss: 0.00127142
INFO:root:[32,   450] training loss: 0.00027249
INFO:root:[32,   500] training loss: 0.00498475
INFO:root:[32,   550] training loss: 0.00987368
INFO:root:[32,   600] training loss: 0.02873409
INFO:root:[32,   650] training loss: 0.00054386
INFO:root:[32,   700] training loss: 0.00033531
INFO:root:[32,   750] training loss: 0.00027099
INFO:root:[32,   800] training loss: 0.00019785
INFO:root:[32,   850] training loss: 0.00015972
INFO:root:[32,   900] training loss: 0.04741889
INFO:root:[32,   950] training loss: 0.02152710
INFO:root:[32,  1000] training loss: 0.00092985
INFO:root:[32,  1050] training loss: 0.00041613
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1250    0.1250    0.1250         8
   Metaphase     0.4706    0.2192    0.2991        73
   Telophase     0.2700    1.0000    0.4253      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2717      3872
   macro avg     0.2665    0.2396    0.1928      3872
weighted avg     0.0820    0.2717    0.1198      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.04951980
INFO:root:[33,   100] training loss: 0.02271341
INFO:root:[33,   150] training loss: 0.02334415
INFO:root:[33,   200] training loss: 0.02117273
INFO:root:[33,   250] training loss: 0.01987190
INFO:root:[33,   300] training loss: 0.01961392
INFO:root:[33,   350] training loss: 0.01819671
INFO:root:[33,   400] training loss: 0.00040762
INFO:root:[33,   450] training loss: 0.00017108
INFO:root:[33,   500] training loss: 0.00466298
INFO:root:[33,   550] training loss: 0.01188704
INFO:root:[33,   600] training loss: 0.02932309
INFO:root:[33,   650] training loss: 0.00064046
INFO:root:[33,   700] training loss: 0.00037953
INFO:root:[33,   750] training loss: 0.00030357
INFO:root:[33,   800] training loss: 0.00023984
INFO:root:[33,   850] training loss: 0.00020305
INFO:root:[33,   900] training loss: 0.04334457
INFO:root:[33,   950] training loss: 0.02351253
INFO:root:[33,  1000] training loss: 0.00116280
INFO:root:[33,  1050] training loss: 0.00051526
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.1000    0.1250    0.1111         8
   Metaphase     0.4000    0.2192    0.2832        73
   Telophase     0.2709    1.0000    0.4263      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2722      3872
   macro avg     0.2530    0.3349    0.2601      3872
weighted avg     0.0809    0.2722    0.1202      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.04824835
INFO:root:[34,   100] training loss: 0.01888222
INFO:root:[34,   150] training loss: 0.01880060
INFO:root:[34,   200] training loss: 0.01907624
INFO:root:[34,   250] training loss: 0.01815523
INFO:root:[34,   300] training loss: 0.01849361
INFO:root:[34,   350] training loss: 0.01631581
INFO:root:[34,   400] training loss: 0.00024679
INFO:root:[34,   450] training loss: 0.00015172
INFO:root:[34,   500] training loss: 0.00450136
INFO:root:[34,   550] training loss: 0.01159260
INFO:root:[34,   600] training loss: 0.02912534
INFO:root:[34,   650] training loss: 0.00057238
INFO:root:[34,   700] training loss: 0.00031506
INFO:root:[34,   750] training loss: 0.00021886
INFO:root:[34,   800] training loss: 0.00011966
INFO:root:[34,   850] training loss: 0.00009857
INFO:root:[34,   900] training loss: 0.04113119
INFO:root:[34,   950] training loss: 0.02055285
INFO:root:[34,  1000] training loss: 0.00106503
INFO:root:[34,  1050] training loss: 0.00048120
INFO:root:              precision    recall  f1-score   support

    Prophase     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2500    0.2500    0.2500         8
   Metaphase     0.5306    0.3562    0.4262        73
   Telophase     0.2712    0.9990    0.4266      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2751      3872
   macro avg     0.3407    0.4436    0.3575      3872
weighted avg     0.0839    0.2751    0.1235      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.04418397
INFO:root:[35,   100] training loss: 0.02033251
INFO:root:[35,   150] training loss: 0.01874836
INFO:root:[35,   200] training loss: 0.01633384
INFO:root:[35,   250] training loss: 0.01811092
INFO:root:[35,   300] training loss: 0.01865492
INFO:root:[35,   350] training loss: 0.01686897
INFO:root:[35,   400] training loss: 0.00040788
INFO:root:[35,   450] training loss: 0.00045430
INFO:root:[35,   500] training loss: 0.00459734
INFO:root:[35,   550] training loss: 0.01208853
INFO:root:[35,   600] training loss: 0.03083835
INFO:root:[35,   650] training loss: 0.00065822
INFO:root:[35,   700] training loss: 0.00038621
INFO:root:[35,   750] training loss: 0.00026491
INFO:root:[35,   800] training loss: 0.00020439
INFO:root:[35,   850] training loss: 0.00017918
INFO:root:[35,   900] training loss: 0.03826848
INFO:root:[35,   950] training loss: 0.02080279
INFO:root:[35,  1000] training loss: 0.00093210
INFO:root:[35,  1050] training loss: 0.00050368
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3125    0.6250    0.4167         8
   Metaphase     0.6383    0.4110    0.5000        73
   Telophase     0.2712    0.9981    0.4265      1034
          G1     0.0000    0.0000    0.0000         3

    accuracy                         0.2756      3872
   macro avg     0.1746    0.2906    0.1919      3872
weighted avg     0.0851    0.2756    0.1242      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.04711010
INFO:root:[36,   100] training loss: 0.01902070
INFO:root:[36,   150] training loss: 0.01901441
INFO:root:[36,   200] training loss: 0.01734493
INFO:root:[36,   250] training loss: 0.01590889
INFO:root:[36,   300] training loss: 0.01945884
INFO:root:[36,   350] training loss: 0.01871460
INFO:root:[36,   400] training loss: 0.00065776
INFO:root:[36,   450] training loss: 0.00018423
INFO:root:[36,   500] training loss: 0.00443985
INFO:root:[36,   550] training loss: 0.01144579
INFO:root:[36,   600] training loss: 0.03058754
INFO:root:[36,   650] training loss: 0.00069730
INFO:root:[36,   700] training loss: 0.00038712
INFO:root:[36,   750] training loss: 0.00031500
INFO:root:[36,   800] training loss: 0.00024141
INFO:root:[36,   850] training loss: 0.00020885
INFO:root:[36,   900] training loss: 0.04115418
INFO:root:[36,   950] training loss: 0.02175643
INFO:root:[36,  1000] training loss: 0.00105660
INFO:root:[36,  1050] training loss: 0.00049441
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2273    0.6250    0.3333         8
   Metaphase     0.5778    0.3562    0.4407        73
   Telophase     0.2720    1.0000    0.4277      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2758      3872
   macro avg     0.2967    0.4259    0.3145      3872
weighted avg     0.0848    0.2758    0.1240      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.04391057
INFO:root:[37,   100] training loss: 0.02016548
INFO:root:[37,   150] training loss: 0.02039665
INFO:root:[37,   200] training loss: 0.01638800
INFO:root:[37,   250] training loss: 0.01652142
INFO:root:[37,   300] training loss: 0.01765185
INFO:root:[37,   350] training loss: 0.01521276
INFO:root:[37,   400] training loss: 0.00047219
INFO:root:[37,   450] training loss: 0.00030908
INFO:root:[37,   500] training loss: 0.00458287
INFO:root:[37,   550] training loss: 0.01091068
INFO:root:[37,   600] training loss: 0.03034875
INFO:root:[37,   650] training loss: 0.00079030
INFO:root:[37,   700] training loss: 0.00045772
INFO:root:[37,   750] training loss: 0.00035721
INFO:root:[37,   800] training loss: 0.00028081
INFO:root:[37,   850] training loss: 0.00022991
INFO:root:[37,   900] training loss: 0.03970768
INFO:root:[37,   950] training loss: 0.02182397
INFO:root:[37,  1000] training loss: 0.00110324
INFO:root:[37,  1050] training loss: 0.00056993
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3529    0.7500    0.4800         8
   Metaphase     0.4722    0.4658    0.4690        73
   Telophase     0.2734    0.9990    0.4293      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2782      3872
   macro avg     0.4069    0.5307    0.4146      3872
weighted avg     0.0837    0.2782    0.1255      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.04304345
INFO:root:[38,   100] training loss: 0.01873288
INFO:root:[38,   150] training loss: 0.01728071
INFO:root:[38,   200] training loss: 0.01579876
INFO:root:[38,   250] training loss: 0.01686738
INFO:root:[38,   300] training loss: 0.01718810
INFO:root:[38,   350] training loss: 0.01471001
INFO:root:[38,   400] training loss: 0.00036922
INFO:root:[38,   450] training loss: 0.00012590
INFO:root:[38,   500] training loss: 0.00440527
INFO:root:[38,   550] training loss: 0.01055529
INFO:root:[38,   600] training loss: 0.02922464
INFO:root:[38,   650] training loss: 0.00075537
INFO:root:[38,   700] training loss: 0.00043675
INFO:root:[38,   750] training loss: 0.00035555
INFO:root:[38,   800] training loss: 0.00028248
INFO:root:[38,   850] training loss: 0.00022758
INFO:root:[38,   900] training loss: 0.03597788
INFO:root:[38,   950] training loss: 0.02206424
INFO:root:[38,  1000] training loss: 0.00083930
INFO:root:[38,  1050] training loss: 0.00045520
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.7500    0.0411    0.0779        73
   Telophase     0.2677    1.0000    0.4223      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2686      3872
   macro avg     0.2882    0.2916    0.2143      3872
weighted avg     0.0864    0.2686    0.1150      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.04812940
INFO:root:[39,   100] training loss: 0.02232318
INFO:root:[39,   150] training loss: 0.01925443
INFO:root:[39,   200] training loss: 0.01926314
INFO:root:[39,   250] training loss: 0.01767358
INFO:root:[39,   300] training loss: 0.01967502
INFO:root:[39,   350] training loss: 0.01694845
INFO:root:[39,   400] training loss: 0.00039940
INFO:root:[39,   450] training loss: 0.00020894
INFO:root:[39,   500] training loss: 0.00418986
INFO:root:[39,   550] training loss: 0.01037053
INFO:root:[39,   600] training loss: 0.03089540
INFO:root:[39,   650] training loss: 0.00078883
INFO:root:[39,   700] training loss: 0.00046647
INFO:root:[39,   750] training loss: 0.00035506
INFO:root:[39,   800] training loss: 0.00026066
INFO:root:[39,   850] training loss: 0.00022053
INFO:root:[39,   900] training loss: 0.04106516
INFO:root:[39,   950] training loss: 0.02116968
INFO:root:[39,  1000] training loss: 0.00123568
INFO:root:[39,  1050] training loss: 0.00054808
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2000    0.2500    0.2222         8
   Metaphase     0.4697    0.4247    0.4460        73
   Telophase     0.2724    0.9990    0.4281      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.2763      3872
   macro avg     0.4203    0.4534    0.3947      3872
weighted avg     0.0833    0.2763    0.1243      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.04873228
INFO:root:[40,   100] training loss: 0.02012791
INFO:root:[40,   150] training loss: 0.02133403
INFO:root:[40,   200] training loss: 0.01900858
INFO:root:[40,   250] training loss: 0.01707257
INFO:root:[40,   300] training loss: 0.01858167
INFO:root:[40,   350] training loss: 0.01593074
INFO:root:[40,   400] training loss: 0.00027493
INFO:root:[40,   450] training loss: 0.00016309
INFO:root:[40,   500] training loss: 0.00439203
INFO:root:[40,   550] training loss: 0.01059106
INFO:root:[40,   600] training loss: 0.03031990
INFO:root:[40,   650] training loss: 0.00088271
INFO:root:[40,   700] training loss: 0.00049517
INFO:root:[40,   750] training loss: 0.00038718
INFO:root:[40,   800] training loss: 0.00027102
INFO:root:[40,   850] training loss: 0.00022957
INFO:root:[40,   900] training loss: 0.04166448
INFO:root:[40,   950] training loss: 0.02506308
INFO:root:[40,  1000] training loss: 0.00117645
INFO:root:[40,  1050] training loss: 0.00045692
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0000    0.0000    0.0000         8
   Metaphase     0.0000    0.0000    0.0000        73
   Telophase     0.2673    1.0000    0.4219      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2678      3872
   macro avg     0.1453    0.2857    0.1827      3872
weighted avg     0.0720    0.2678    0.1133      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.04726467
INFO:root:[41,   100] training loss: 0.02084904
INFO:root:[41,   150] training loss: 0.02176552
INFO:root:[41,   200] training loss: 0.01731183
INFO:root:[41,   250] training loss: 0.01820452
INFO:root:[41,   300] training loss: 0.02013375
INFO:root:[41,   350] training loss: 0.01696373
INFO:root:[41,   400] training loss: 0.00022678
INFO:root:[41,   450] training loss: 0.00020952
INFO:root:[41,   500] training loss: 0.00439493
INFO:root:[41,   550] training loss: 0.01055746
INFO:root:[41,   600] training loss: 0.03033907
INFO:root:[41,   650] training loss: 0.00092981
INFO:root:[41,   700] training loss: 0.00051190
INFO:root:[41,   750] training loss: 0.00037804
INFO:root:[41,   800] training loss: 0.00028925
INFO:root:[41,   850] training loss: 0.00024207
INFO:root:[41,   900] training loss: 0.04470867
INFO:root:[41,   950] training loss: 0.02327906
INFO:root:[41,  1000] training loss: 0.00119633
INFO:root:[41,  1050] training loss: 0.00050583
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2500    0.5000    0.3333         8
   Metaphase     0.4510    0.3151    0.3710        73
   Telophase     0.2718    0.9990    0.4274      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2748      3872
   macro avg     0.3890    0.4734    0.3794      3872
weighted avg     0.0827    0.2748    0.1228      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.04632560
INFO:root:[42,   100] training loss: 0.02015102
INFO:root:[42,   150] training loss: 0.02005365
INFO:root:[42,   200] training loss: 0.01725932
INFO:root:[42,   250] training loss: 0.01745400
INFO:root:[42,   300] training loss: 0.01913120
INFO:root:[42,   350] training loss: 0.01580183
INFO:root:[42,   400] training loss: 0.00036330
INFO:root:[42,   450] training loss: 0.00022592
INFO:root:[42,   500] training loss: 0.00428720
INFO:root:[42,   550] training loss: 0.01059394
INFO:root:[42,   600] training loss: 0.02965654
INFO:root:[42,   650] training loss: 0.00096779
INFO:root:[42,   700] training loss: 0.00054786
INFO:root:[42,   750] training loss: 0.00040316
INFO:root:[42,   800] training loss: 0.00030701
INFO:root:[42,   850] training loss: 0.00022875
INFO:root:[42,   900] training loss: 0.03817221
INFO:root:[42,   950] training loss: 0.02127543
INFO:root:[42,  1000] training loss: 0.00122973
INFO:root:[42,  1050] training loss: 0.00055375
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.2692    0.8750    0.4118         8
   Metaphase     0.3871    0.3288    0.3556        73
   Telophase     0.2730    0.9981    0.4287      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.2748      3872
   macro avg     0.2756    0.3622    0.2423      3872
weighted avg     0.0815    0.2748    0.1224      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.04484624
INFO:root:[43,   100] training loss: 0.02138119
INFO:root:[43,   150] training loss: 0.02237714
INFO:root:[43,   200] training loss: 0.01776042
INFO:root:[43,   250] training loss: 0.01704326
INFO:root:[43,   300] training loss: 0.01796403
INFO:root:[43,   350] training loss: 0.01634825
INFO:root:[43,   400] training loss: 0.00035227
INFO:root:[43,   450] training loss: 0.00017163
INFO:root:[43,   500] training loss: 0.00438195
INFO:root:[43,   550] training loss: 0.01044655
INFO:root:[43,   600] training loss: 0.02948668
INFO:root:[43,   650] training loss: 0.00088459
INFO:root:[43,   700] training loss: 0.00052217
INFO:root:[43,   750] training loss: 0.00043099
INFO:root:[43,   800] training loss: 0.00029870
INFO:root:[43,   850] training loss: 0.00025820
INFO:root:[43,   900] training loss: 0.03538373
INFO:root:[43,   950] training loss: 0.02100559
INFO:root:[43,  1000] training loss: 0.00109057
INFO:root:[43,  1050] training loss: 0.00054214
INFO:root:              precision    recall  f1-score   support

    Prophase     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3571    0.6250    0.4545         8
   Metaphase     0.4043    0.5205    0.4551        73
   Telophase     0.2749    0.9990    0.4311      1034
          G1     0.6667    0.6667    0.6667         3

    accuracy                         0.2787      3872
   macro avg     0.2909    0.4730    0.3439      3872
weighted avg     0.0825    0.2787    0.1254      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.04340886
INFO:root:[44,   100] training loss: 0.01854632
INFO:root:[44,   150] training loss: 0.01837578
INFO:root:[44,   200] training loss: 0.01637566
INFO:root:[44,   250] training loss: 0.01685446
INFO:root:[44,   300] training loss: 0.01788872
INFO:root:[44,   350] training loss: 0.01646678
INFO:root:[44,   400] training loss: 0.00036347
INFO:root:[44,   450] training loss: 0.00017151
INFO:root:[44,   500] training loss: 0.00424452
INFO:root:[44,   550] training loss: 0.00948352
INFO:root:[44,   600] training loss: 0.02963449
INFO:root:[44,   650] training loss: 0.00082179
INFO:root:[44,   700] training loss: 0.00045294
INFO:root:[44,   750] training loss: 0.00040522
INFO:root:[44,   800] training loss: 0.00031638
INFO:root:[44,   850] training loss: 0.00024380
INFO:root:[44,   900] training loss: 0.03563367
INFO:root:[44,   950] training loss: 0.02100609
INFO:root:[44,  1000] training loss: 0.00092732
INFO:root:[44,  1050] training loss: 0.00047923
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3333    0.3750    0.3529         8
   Metaphase     0.6032    0.5205    0.5588        73
   Telophase     0.2715    0.9961    0.4267      1034
          G1     1.0000    0.6667    0.8000         3

    accuracy                         0.2774      3872
   macro avg     0.3511    0.4369    0.3531      3872
weighted avg     0.0855    0.2774    0.1260      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.04272564
INFO:root:[45,   100] training loss: 0.01937202
INFO:root:[45,   150] training loss: 0.01891423
INFO:root:[45,   200] training loss: 0.01650218
INFO:root:[45,   250] training loss: 0.01667459
INFO:root:[45,   300] training loss: 0.01724107
INFO:root:[45,   350] training loss: 0.01501088
INFO:root:[45,   400] training loss: 0.00023661
INFO:root:[45,   450] training loss: 0.00021486
INFO:root:[45,   500] training loss: 0.00412619
INFO:root:[45,   550] training loss: 0.00866182
INFO:root:[45,   600] training loss: 0.02751175
INFO:root:[45,   650] training loss: 0.00079460
INFO:root:[45,   700] training loss: 0.00047712
INFO:root:[45,   750] training loss: 0.00045993
INFO:root:[45,   800] training loss: 0.00033627
INFO:root:[45,   850] training loss: 0.00027588
INFO:root:[45,   900] training loss: 0.03112809
INFO:root:[45,   950] training loss: 0.02017801
INFO:root:[45,  1000] training loss: 0.00090878
INFO:root:[45,  1050] training loss: 0.00047091
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3333    0.7500    0.4615         8
   Metaphase     0.3800    0.5205    0.4393        73
   Telophase     0.2753    0.9981    0.4315      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2787      3872
   macro avg     0.2484    0.4669    0.3128      3872
weighted avg     0.0819    0.2787    0.1251      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.04168230
INFO:root:[46,   100] training loss: 0.01820077
INFO:root:[46,   150] training loss: 0.01738028
INFO:root:[46,   200] training loss: 0.01836479
INFO:root:[46,   250] training loss: 0.02267982
INFO:root:[46,   300] training loss: 0.02182549
INFO:root:[46,   350] training loss: 0.01434341
INFO:root:[46,   400] training loss: 0.00024700
INFO:root:[46,   450] training loss: 0.00021131
INFO:root:[46,   500] training loss: 0.00392915
INFO:root:[46,   550] training loss: 0.00744527
INFO:root:[46,   600] training loss: 0.02785287
INFO:root:[46,   650] training loss: 0.00083538
INFO:root:[46,   700] training loss: 0.00044884
INFO:root:[46,   750] training loss: 0.00039095
INFO:root:[46,   800] training loss: 0.00029204
INFO:root:[46,   850] training loss: 0.00022187
INFO:root:[46,   900] training loss: 0.03620439
INFO:root:[46,   950] training loss: 0.01981055
INFO:root:[46,  1000] training loss: 0.00076792
INFO:root:[46,  1050] training loss: 0.00044326
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3571    0.6250    0.4545         8
   Metaphase     0.6136    0.3699    0.4615        73
   Telophase     0.2709    0.9981    0.4261      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2756      3872
   macro avg     0.2845    0.4276    0.3142      3872
weighted avg     0.0852    0.2756    0.1241      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.03903611
INFO:root:[47,   100] training loss: 0.01819345
INFO:root:[47,   150] training loss: 0.01852819
INFO:root:[47,   200] training loss: 0.01721720
INFO:root:[47,   250] training loss: 0.01748029
INFO:root:[47,   300] training loss: 0.01712541
INFO:root:[47,   350] training loss: 0.01770632
INFO:root:[47,   400] training loss: 0.00038412
INFO:root:[47,   450] training loss: 0.00018307
INFO:root:[47,   500] training loss: 0.00409369
INFO:root:[47,   550] training loss: 0.00769546
INFO:root:[47,   600] training loss: 0.02727192
INFO:root:[47,   650] training loss: 0.00090137
INFO:root:[47,   700] training loss: 0.00050883
INFO:root:[47,   750] training loss: 0.00043745
INFO:root:[47,   800] training loss: 0.00030713
INFO:root:[47,   850] training loss: 0.00024040
INFO:root:[47,   900] training loss: 0.03079603
INFO:root:[47,   950] training loss: 0.02262937
INFO:root:[47,  1000] training loss: 0.00091359
INFO:root:[47,  1050] training loss: 0.00050175
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3158    0.7500    0.4444         8
   Metaphase     0.5156    0.4521    0.4818        73
   Telophase     0.2728    0.9981    0.4285      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2776      3872
   macro avg     0.3363    0.5286    0.3874      3872
weighted avg     0.0841    0.2776    0.1253      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.03810156
INFO:root:[48,   100] training loss: 0.01840659
INFO:root:[48,   150] training loss: 0.01712570
INFO:root:[48,   200] training loss: 0.01623706
INFO:root:[48,   250] training loss: 0.01617439
INFO:root:[48,   300] training loss: 0.01674682
INFO:root:[48,   350] training loss: 0.01526810
INFO:root:[48,   400] training loss: 0.00022065
INFO:root:[48,   450] training loss: 0.00023884
INFO:root:[48,   500] training loss: 0.00353218
INFO:root:[48,   550] training loss: 0.00615402
INFO:root:[48,   600] training loss: 0.02313217
INFO:root:[48,   650] training loss: 0.00091012
INFO:root:[48,   700] training loss: 0.00047824
INFO:root:[48,   750] training loss: 0.00040966
INFO:root:[48,   800] training loss: 0.00033735
INFO:root:[48,   850] training loss: 0.00022716
INFO:root:[48,   900] training loss: 0.03059688
INFO:root:[48,   950] training loss: 0.01957053
INFO:root:[48,  1000] training loss: 0.00080060
INFO:root:[48,  1050] training loss: 0.00044802
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3684    0.8750    0.5185         8
   Metaphase     0.6038    0.4384    0.5079        73
   Telophase     0.2719    0.9981    0.4274      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2774      3872
   macro avg     0.2849    0.4731    0.3301      3872
weighted avg     0.0853    0.2774    0.1255      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.03914154
INFO:root:[49,   100] training loss: 0.01987830
INFO:root:[49,   150] training loss: 0.01727116
INFO:root:[49,   200] training loss: 0.01614306
INFO:root:[49,   250] training loss: 0.01957379
INFO:root:[49,   300] training loss: 0.02349980
INFO:root:[49,   350] training loss: 0.01548748
INFO:root:[49,   400] training loss: 0.00035572
INFO:root:[49,   450] training loss: 0.00015908
INFO:root:[49,   500] training loss: 0.00398406
INFO:root:[49,   550] training loss: 0.00572851
INFO:root:[49,   600] training loss: 0.02288890
INFO:root:[49,   650] training loss: 0.00084043
INFO:root:[49,   700] training loss: 0.00042459
INFO:root:[49,   750] training loss: 0.00038488
INFO:root:[49,   800] training loss: 0.00027115
INFO:root:[49,   850] training loss: 0.00017071
INFO:root:[49,   900] training loss: 0.02909147
INFO:root:[49,   950] training loss: 0.01806199
INFO:root:[49,  1000] training loss: 0.00076013
INFO:root:[49,  1050] training loss: 0.00042382
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2857    1.0000    0.4444         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3333    0.7500    0.4615         8
   Metaphase     0.4157    0.5068    0.4568        73
   Telophase     0.2744    0.9961    0.4302      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2784      3872
   macro avg     0.2942    0.6076    0.3786      3872
weighted avg     0.0825    0.2784    0.1254      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.03487303
INFO:root:[50,   100] training loss: 0.01668985
INFO:root:[50,   150] training loss: 0.01767164
INFO:root:[50,   200] training loss: 0.01564538
INFO:root:[50,   250] training loss: 0.01536508
INFO:root:[50,   300] training loss: 0.01741740
INFO:root:[50,   350] training loss: 0.01423362
INFO:root:[50,   400] training loss: 0.00026982
INFO:root:[50,   450] training loss: 0.00028226
INFO:root:[50,   500] training loss: 0.00363548
INFO:root:[50,   550] training loss: 0.00517735
INFO:root:[50,   600] training loss: 0.02099360
INFO:root:[50,   650] training loss: 0.00078937
INFO:root:[50,   700] training loss: 0.00041916
INFO:root:[50,   750] training loss: 0.00038819
INFO:root:[50,   800] training loss: 0.00026917
INFO:root:[50,   850] training loss: 0.00021106
INFO:root:[50,   900] training loss: 0.02666185
INFO:root:[50,   950] training loss: 0.01836326
INFO:root:[50,  1000] training loss: 0.00067217
INFO:root:[50,  1050] training loss: 0.00036080
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.3158    0.7500    0.4444         8
   Metaphase     0.4118    0.5753    0.4800        73
   Telophase     0.2745    0.9932    0.4301      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2789      3872
   macro avg     0.3074    0.6169    0.3976      3872
weighted avg     0.0825    0.2789    0.1258      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch50
INFO:root:[51,    50] training loss: 0.03446119
INFO:root:[51,   100] training loss: 0.01622756
INFO:root:[51,   150] training loss: 0.01713719
INFO:root:[51,   200] training loss: 0.01555103
INFO:root:[51,   250] training loss: 0.01481227
INFO:root:[51,   300] training loss: 0.01680466
INFO:root:[51,   350] training loss: 0.01402989
INFO:root:[51,   400] training loss: 0.00020900
INFO:root:[51,   450] training loss: 0.00011676
INFO:root:[51,   500] training loss: 0.00355460
INFO:root:[51,   550] training loss: 0.00455968
INFO:root:[51,   600] training loss: 0.02028254
INFO:root:[51,   650] training loss: 0.00079827
INFO:root:[51,   700] training loss: 0.00041568
INFO:root:[51,   750] training loss: 0.00038729
INFO:root:[51,   800] training loss: 0.00026608
INFO:root:[51,   850] training loss: 0.00020337
INFO:root:[51,   900] training loss: 0.02883929
INFO:root:[51,   950] training loss: 0.01937223
INFO:root:[51,  1000] training loss: 0.00063561
INFO:root:[51,  1050] training loss: 0.00032860
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.5000    0.6250    0.5556         8
   Metaphase     0.4694    0.6301    0.5380        73
   Telophase     0.2734    0.9932    0.4287      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2797      3872
   macro avg     0.3799    0.6069    0.4542      3872
weighted avg     0.0838    0.2797    0.1269      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch51
INFO:root:[52,    50] training loss: 0.03282176
INFO:root:[52,   100] training loss: 0.01583485
INFO:root:[52,   150] training loss: 0.01677786
INFO:root:[52,   200] training loss: 0.01416373
INFO:root:[52,   250] training loss: 0.01572278
INFO:root:[52,   300] training loss: 0.01632432
INFO:root:[52,   350] training loss: 0.01469795
INFO:root:[52,   400] training loss: 0.00020704
INFO:root:[52,   450] training loss: 0.00013157
INFO:root:[52,   500] training loss: 0.00316104
INFO:root:[52,   550] training loss: 0.00412526
INFO:root:[52,   600] training loss: 0.01871120
INFO:root:[52,   650] training loss: 0.00084180
INFO:root:[52,   700] training loss: 0.00042112
INFO:root:[52,   750] training loss: 0.00039354
INFO:root:[52,   800] training loss: 0.00025197
INFO:root:[52,   850] training loss: 0.00021166
INFO:root:[52,   900] training loss: 0.02432776
INFO:root:[52,   950] training loss: 0.01778805
INFO:root:[52,  1000] training loss: 0.00049869
INFO:root:[52,  1050] training loss: 0.00019974
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.0000    0.0000    0.0000      1032
          G2     0.0984    0.7500    0.1739         8
   Metaphase     0.2280    0.6027    0.3308        73
   Telophase     0.2804    0.9787    0.4359      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.2756      3872
   macro avg     0.2438    0.6188    0.3368      3872
weighted avg     0.0801    0.2756    0.1239      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch52
INFO:root:[53,    50] training loss: 0.03153078
INFO:root:[53,   100] training loss: 0.01746058
INFO:root:[53,   150] training loss: 0.01659090
INFO:root:[53,   200] training loss: 0.01566705
INFO:root:[53,   250] training loss: 0.01624555
INFO:root:[53,   300] training loss: 0.01655327
INFO:root:[53,   350] training loss: 0.01417141
INFO:root:[53,   400] training loss: 0.00013828
INFO:root:[53,   450] training loss: 0.00016661
INFO:root:[53,   500] training loss: 0.00304118
INFO:root:[53,   550] training loss: 0.00379742
INFO:root:[53,   600] training loss: 0.01761858
INFO:root:[53,   650] training loss: 0.00076338
INFO:root:[53,   700] training loss: 0.00039654
INFO:root:[53,   750] training loss: 0.00038679
INFO:root:[53,   800] training loss: 0.00028903
INFO:root:[53,   850] training loss: 0.00023321
INFO:root:[53,   900] training loss: 0.02425477
INFO:root:[53,   950] training loss: 0.01702076
INFO:root:[53,  1000] training loss: 0.00034321
INFO:root:[53,  1050] training loss: 0.00016343
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.5714    0.0039    0.0077      1032
          G2     0.1373    0.8750    0.2373         8
   Metaphase     0.1869    0.5479    0.2787        73
   Telophase     0.2840    0.9865    0.4411      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2779      3872
   macro avg     0.3328    0.6305    0.3419      3872
weighted avg     0.2328    0.2779    0.1265      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch53
INFO:root:[54,    50] training loss: 0.03007907
INFO:root:[54,   100] training loss: 0.01528435
INFO:root:[54,   150] training loss: 0.01804841
INFO:root:[54,   200] training loss: 0.01451726
INFO:root:[54,   250] training loss: 0.01591886
INFO:root:[54,   300] training loss: 0.01593505
INFO:root:[54,   350] training loss: 0.01463472
INFO:root:[54,   400] training loss: 0.00042950
INFO:root:[54,   450] training loss: 0.00010831
INFO:root:[54,   500] training loss: 0.00299620
INFO:root:[54,   550] training loss: 0.00342926
INFO:root:[54,   600] training loss: 0.01513825
INFO:root:[54,   650] training loss: 0.00076291
INFO:root:[54,   700] training loss: 0.00039641
INFO:root:[54,   750] training loss: 0.00050382
INFO:root:[54,   800] training loss: 0.00033542
INFO:root:[54,   850] training loss: 0.00025353
INFO:root:[54,   900] training loss: 0.02409447
INFO:root:[54,   950] training loss: 0.01604324
INFO:root:[54,  1000] training loss: 0.00029336
INFO:root:[54,  1050] training loss: 0.00011301
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.8000    0.0116    0.0229      1032
          G2     0.1600    1.0000    0.2759         8
   Metaphase     0.2268    0.6027    0.3296        73
   Telophase     0.2822    0.9836    0.4386      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2805      3872
   macro avg     0.3741    0.6568    0.3565      3872
weighted avg     0.2940    0.2805    0.1310      3872

INFO:root:Accuracy of the network on the 3872 validation images: 28 %
INFO:root:epoch54
INFO:root:[55,    50] training loss: 0.02669207
INFO:root:[55,   100] training loss: 0.01522005
INFO:root:[55,   150] training loss: 0.01734797
INFO:root:[55,   200] training loss: 0.01393498
INFO:root:[55,   250] training loss: 0.01469335
INFO:root:[55,   300] training loss: 0.01548757
INFO:root:[55,   350] training loss: 0.01521711
INFO:root:[55,   400] training loss: 0.00014581
INFO:root:[55,   450] training loss: 0.00011898
INFO:root:[55,   500] training loss: 0.00229963
INFO:root:[55,   550] training loss: 0.00235500
INFO:root:[55,   600] training loss: 0.01304453
INFO:root:[55,   650] training loss: 0.00072750
INFO:root:[55,   700] training loss: 0.00040026
INFO:root:[55,   750] training loss: 0.00044800
INFO:root:[55,   800] training loss: 0.00029677
INFO:root:[55,   850] training loss: 0.00026621
INFO:root:[55,   900] training loss: 0.02437989
INFO:root:[55,   950] training loss: 0.01614805
INFO:root:[55,  1000] training loss: 0.00022556
INFO:root:[55,  1050] training loss: 0.00014394
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.8511    0.0388    0.0741      1032
          G2     0.1389    0.6250    0.2273         8
   Metaphase     0.3415    0.7671    0.4726        73
   Telophase     0.2828    0.9894    0.4399      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2916      3872
   macro avg     0.4092    0.6315    0.3911      3872
weighted avg     0.3099    0.2916    0.1476      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch55
INFO:root:[56,    50] training loss: 0.02514352
INFO:root:[56,   100] training loss: 0.01486642
INFO:root:[56,   150] training loss: 0.01673671
INFO:root:[56,   200] training loss: 0.01500141
INFO:root:[56,   250] training loss: 0.01436665
INFO:root:[56,   300] training loss: 0.01570155
INFO:root:[56,   350] training loss: 0.01310277
INFO:root:[56,   400] training loss: 0.00016074
INFO:root:[56,   450] training loss: 0.00015792
INFO:root:[56,   500] training loss: 0.00225009
INFO:root:[56,   550] training loss: 0.00211265
INFO:root:[56,   600] training loss: 0.01070784
INFO:root:[56,   650] training loss: 0.00058047
INFO:root:[56,   700] training loss: 0.00035374
INFO:root:[56,   750] training loss: 0.00041031
INFO:root:[56,   800] training loss: 0.00027915
INFO:root:[56,   850] training loss: 0.00020113
INFO:root:[56,   900] training loss: 0.02292193
INFO:root:[56,   950] training loss: 0.01660568
INFO:root:[56,  1000] training loss: 0.00017949
INFO:root:[56,  1050] training loss: 0.00010931
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
    Anaphase     0.9194    0.0552    0.1042      1032
          G2     0.1200    0.7500    0.2069         8
   Metaphase     0.2232    0.7123    0.3399        73
   Telophase     0.2873    0.9778    0.4441      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2921      3872
   macro avg     0.4000    0.6422    0.3741      3872
weighted avg     0.3271    0.2921    0.1542      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch56
INFO:root:[57,    50] training loss: 0.02702940
INFO:root:[57,   100] training loss: 0.01939860
INFO:root:[57,   150] training loss: 0.01644572
INFO:root:[57,   200] training loss: 0.01521527
INFO:root:[57,   250] training loss: 0.01452613
INFO:root:[57,   300] training loss: 0.01511744
INFO:root:[57,   350] training loss: 0.01378958
INFO:root:[57,   400] training loss: 0.00015888
INFO:root:[57,   450] training loss: 0.00009024
INFO:root:[57,   500] training loss: 0.00210613
INFO:root:[57,   550] training loss: 0.00191119
INFO:root:[57,   600] training loss: 0.00893318
INFO:root:[57,   650] training loss: 0.00047093
INFO:root:[57,   700] training loss: 0.00028466
INFO:root:[57,   750] training loss: 0.00050476
INFO:root:[57,   800] training loss: 0.00028182
INFO:root:[57,   850] training loss: 0.00021967
INFO:root:[57,   900] training loss: 0.02232224
INFO:root:[57,   950] training loss: 0.01349860
INFO:root:[57,  1000] training loss: 0.00011783
INFO:root:[57,  1050] training loss: 0.00009696
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     1.0000    0.0012    0.0023      1720
    Anaphase     0.9186    0.0766    0.1413      1032
          G2     0.1786    0.6250    0.2778         8
   Metaphase     0.1920    0.8493    0.3131        73
   Telophase     0.2933    0.9720    0.4506      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2988      3872
   macro avg     0.5475    0.5749    0.3632      3872
weighted avg     0.7722    0.2988    0.1664      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch57
INFO:root:[58,    50] training loss: 0.02431172
INFO:root:[58,   100] training loss: 0.01821112
INFO:root:[58,   150] training loss: 0.01538113
INFO:root:[58,   200] training loss: 0.01335887
INFO:root:[58,   250] training loss: 0.01480798
INFO:root:[58,   300] training loss: 0.01640880
INFO:root:[58,   350] training loss: 0.01382870
INFO:root:[58,   400] training loss: 0.00010771
INFO:root:[58,   450] training loss: 0.00012134
INFO:root:[58,   500] training loss: 0.00173954
INFO:root:[58,   550] training loss: 0.00155398
INFO:root:[58,   600] training loss: 0.00875062
INFO:root:[58,   650] training loss: 0.00044712
INFO:root:[58,   700] training loss: 0.00028240
INFO:root:[58,   750] training loss: 0.00054056
INFO:root:[58,   800] training loss: 0.00032732
INFO:root:[58,   850] training loss: 0.00023125
INFO:root:[58,   900] training loss: 0.02343358
INFO:root:[58,   950] training loss: 0.01220780
INFO:root:[58,  1000] training loss: 0.00010321
INFO:root:[58,  1050] training loss: 0.00007656
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     1.0000    0.0012    0.0023      1720
    Anaphase     0.9444    0.1483    0.2563      1032
          G2     0.1875    0.7500    0.3000         8
   Metaphase     0.1390    0.7671    0.2353        73
   Telophase     0.3019    0.9536    0.4586      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.3120      3872
   macro avg     0.5699    0.6600    0.4157      3872
weighted avg     0.7805    0.3120    0.1979      3872

INFO:root:Accuracy of the network on the 3872 validation images: 31 %
INFO:root:epoch58
INFO:root:[59,    50] training loss: 0.02236176
INFO:root:[59,   100] training loss: 0.01390548
INFO:root:[59,   150] training loss: 0.01446313
INFO:root:[59,   200] training loss: 0.01347188
INFO:root:[59,   250] training loss: 0.01336331
INFO:root:[59,   300] training loss: 0.01676068
INFO:root:[59,   350] training loss: 0.01319745
INFO:root:[59,   400] training loss: 0.00014279
INFO:root:[59,   450] training loss: 0.00007386
INFO:root:[59,   500] training loss: 0.00158586
INFO:root:[59,   550] training loss: 0.00129890
INFO:root:[59,   600] training loss: 0.00639964
INFO:root:[59,   650] training loss: 0.00033515
INFO:root:[59,   700] training loss: 0.00022175
INFO:root:[59,   750] training loss: 0.00051122
INFO:root:[59,   800] training loss: 0.00026242
INFO:root:[59,   850] training loss: 0.00020391
INFO:root:[59,   900] training loss: 0.02023999
INFO:root:[59,   950] training loss: 0.01025006
INFO:root:[59,  1000] training loss: 0.00012786
INFO:root:[59,  1050] training loss: 0.00007655
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     1.0000    0.0006    0.0012      1720
    Anaphase     0.9364    0.0998    0.1804      1032
          G2     0.2143    0.7500    0.3333         8
   Metaphase     0.1362    0.9178    0.2372        73
   Telophase     0.3023    0.9449    0.4580      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.2993      3872
   macro avg     0.5342    0.6733    0.3770      3872
weighted avg     0.7783    0.2993    0.1770      3872

INFO:root:Accuracy of the network on the 3872 validation images: 29 %
INFO:root:epoch59
INFO:root:[60,    50] training loss: 0.02188137
INFO:root:[60,   100] training loss: 0.01375746
INFO:root:[60,   150] training loss: 0.01564247
INFO:root:[60,   200] training loss: 0.01326478
INFO:root:[60,   250] training loss: 0.01410566
INFO:root:[60,   300] training loss: 0.01482272
INFO:root:[60,   350] training loss: 0.01676307
INFO:root:[60,   400] training loss: 0.00009943
INFO:root:[60,   450] training loss: 0.00017633
INFO:root:[60,   500] training loss: 0.00148829
INFO:root:[60,   550] training loss: 0.00127835
INFO:root:[60,   600] training loss: 0.00544946
INFO:root:[60,   650] training loss: 0.00031523
INFO:root:[60,   700] training loss: 0.00020966
INFO:root:[60,   750] training loss: 0.00053484
INFO:root:[60,   800] training loss: 0.00025313
INFO:root:[60,   850] training loss: 0.00019982
INFO:root:[60,   900] training loss: 0.01957335
INFO:root:[60,   950] training loss: 0.01011805
INFO:root:[60,  1000] training loss: 0.00008668
INFO:root:[60,  1050] training loss: 0.00005231
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2857    1.0000    0.4444         2
           S     1.0000    0.0006    0.0012      1720
    Anaphase     0.9175    0.1831    0.3053      1032
          G2     0.2222    0.7500    0.3429         8
   Metaphase     0.1242    0.7808    0.2143        73
   Telophase     0.3018    0.9255    0.4552      1034
          G1     1.0000    0.3333    0.5000         3

    accuracy                         0.3133      3872
   macro avg     0.5502    0.5676    0.3233      3872
weighted avg     0.7731    0.3133    0.2088      3872

INFO:root:Accuracy of the network on the 3872 validation images: 31 %
INFO:root:epoch60
INFO:root:[61,    50] training loss: 0.02153334
INFO:root:[61,   100] training loss: 0.01461296
INFO:root:[61,   150] training loss: 0.01531085
INFO:root:[61,   200] training loss: 0.01261795
INFO:root:[61,   250] training loss: 0.01429789
INFO:root:[61,   300] training loss: 0.01565275
INFO:root:[61,   350] training loss: 0.01357582
INFO:root:[61,   400] training loss: 0.00006326
INFO:root:[61,   450] training loss: 0.00007493
INFO:root:[61,   500] training loss: 0.00107936
INFO:root:[61,   550] training loss: 0.00128527
INFO:root:[61,   600] training loss: 0.00480646
INFO:root:[61,   650] training loss: 0.00028133
INFO:root:[61,   700] training loss: 0.00017059
INFO:root:[61,   750] training loss: 0.00057569
INFO:root:[61,   800] training loss: 0.00023505
INFO:root:[61,   850] training loss: 0.00014369
INFO:root:[61,   900] training loss: 0.01891359
INFO:root:[61,   950] training loss: 0.00837489
INFO:root:[61,  1000] training loss: 0.00005468
INFO:root:[61,  1050] training loss: 0.00003340
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     1.0000    0.0081    0.0161      1720
    Anaphase     0.8017    0.2742    0.4087      1032
          G2     0.5000    0.6250    0.5556         8
   Metaphase     0.1078    0.9315    0.1932        73
   Telophase     0.3065    0.8462    0.4500      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.3228      3872
   macro avg     0.5451    0.6693    0.4343      3872
weighted avg     0.7435    0.3228    0.2420      3872

INFO:root:Accuracy of the network on the 3872 validation images: 32 %
INFO:root:epoch61
INFO:root:[62,    50] training loss: 0.02050954
INFO:root:[62,   100] training loss: 0.01397469
INFO:root:[62,   150] training loss: 0.01440950
INFO:root:[62,   200] training loss: 0.01301911
INFO:root:[62,   250] training loss: 0.01413301
INFO:root:[62,   300] training loss: 0.01564602
INFO:root:[62,   350] training loss: 0.01250057
INFO:root:[62,   400] training loss: 0.00012371
INFO:root:[62,   450] training loss: 0.00005675
INFO:root:[62,   500] training loss: 0.00078807
INFO:root:[62,   550] training loss: 0.00111004
INFO:root:[62,   600] training loss: 0.00389057
INFO:root:[62,   650] training loss: 0.00021508
INFO:root:[62,   700] training loss: 0.00014819
INFO:root:[62,   750] training loss: 0.00068509
INFO:root:[62,   800] training loss: 0.00019079
INFO:root:[62,   850] training loss: 0.00013915
INFO:root:[62,   900] training loss: 0.01739190
INFO:root:[62,   950] training loss: 0.00747007
INFO:root:[62,  1000] training loss: 0.00007139
INFO:root:[62,  1050] training loss: 0.00004873
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9474    0.0209    0.0410      1720
    Anaphase     0.7921    0.4060    0.5368      1032
          G2     0.3750    0.7500    0.5000         8
   Metaphase     0.1213    0.9041    0.2139        73
   Telophase     0.3112    0.8240    0.4517      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.3574      3872
   macro avg     0.5662    0.7007    0.4858      3872
weighted avg     0.7190    0.3574    0.2881      3872

INFO:root:Accuracy of the network on the 3872 validation images: 35 %
INFO:root:epoch62
INFO:root:[63,    50] training loss: 0.01823062
INFO:root:[63,   100] training loss: 0.01440265
INFO:root:[63,   150] training loss: 0.01622398
INFO:root:[63,   200] training loss: 0.01409384
INFO:root:[63,   250] training loss: 0.01430115
INFO:root:[63,   300] training loss: 0.01509597
INFO:root:[63,   350] training loss: 0.01226607
INFO:root:[63,   400] training loss: 0.00004395
INFO:root:[63,   450] training loss: 0.00005584
INFO:root:[63,   500] training loss: 0.00087784
INFO:root:[63,   550] training loss: 0.00090576
INFO:root:[63,   600] training loss: 0.00360520
INFO:root:[63,   650] training loss: 0.00023659
INFO:root:[63,   700] training loss: 0.00015149
INFO:root:[63,   750] training loss: 0.00056640
INFO:root:[63,   800] training loss: 0.00017039
INFO:root:[63,   850] training loss: 0.00013550
INFO:root:[63,   900] training loss: 0.01620675
INFO:root:[63,   950] training loss: 0.00618639
INFO:root:[63,  1000] training loss: 0.00008306
INFO:root:[63,  1050] training loss: 0.00004903
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9636    0.0616    0.1158      1720
    Anaphase     0.6717    0.5630    0.6125      1032
          G2     0.4000    0.7500    0.5217         8
   Metaphase     0.1299    0.9041    0.2272        73
   Telophase     0.2904    0.6644    0.4041      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.3747      3872
   macro avg     0.5318    0.7062    0.4902      3872
weighted avg     0.6887    0.3747    0.3290      3872

INFO:root:Accuracy of the network on the 3872 validation images: 37 %
INFO:root:epoch63
INFO:root:[64,    50] training loss: 0.01601249
INFO:root:[64,   100] training loss: 0.01335156
INFO:root:[64,   150] training loss: 0.01513434
INFO:root:[64,   200] training loss: 0.01526579
INFO:root:[64,   250] training loss: 0.01339324
INFO:root:[64,   300] training loss: 0.01503907
INFO:root:[64,   350] training loss: 0.01274385
INFO:root:[64,   400] training loss: 0.00017359
INFO:root:[64,   450] training loss: 0.00004362
INFO:root:[64,   500] training loss: 0.00080864
INFO:root:[64,   550] training loss: 0.00091281
INFO:root:[64,   600] training loss: 0.00302393
INFO:root:[64,   650] training loss: 0.00022300
INFO:root:[64,   700] training loss: 0.00014239
INFO:root:[64,   750] training loss: 0.00063578
INFO:root:[64,   800] training loss: 0.00017030
INFO:root:[64,   850] training loss: 0.00013786
INFO:root:[64,   900] training loss: 0.01826121
INFO:root:[64,   950] training loss: 0.00643404
INFO:root:[64,  1000] training loss: 0.00003598
INFO:root:[64,  1050] training loss: 0.00002753
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9609    0.1000    0.1811      1720
    Anaphase     0.7323    0.4612    0.5660      1032
          G2     0.3333    0.5000    0.4000         8
   Metaphase     0.1266    0.9589    0.2236        73
   Telophase     0.3154    0.7544    0.4448      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.3887      3872
   macro avg     0.4598    0.5392    0.3818      3872
weighted avg     0.7099    0.3887    0.3558      3872

INFO:root:Accuracy of the network on the 3872 validation images: 38 %
INFO:root:epoch64
INFO:root:[65,    50] training loss: 0.01673676
INFO:root:[65,   100] training loss: 0.01323185
INFO:root:[65,   150] training loss: 0.01477009
INFO:root:[65,   200] training loss: 0.01340466
INFO:root:[65,   250] training loss: 0.01414384
INFO:root:[65,   300] training loss: 0.01414892
INFO:root:[65,   350] training loss: 0.01443763
INFO:root:[65,   400] training loss: 0.00004331
INFO:root:[65,   450] training loss: 0.00003968
INFO:root:[65,   500] training loss: 0.00058771
INFO:root:[65,   550] training loss: 0.00099500
INFO:root:[65,   600] training loss: 0.00340533
INFO:root:[65,   650] training loss: 0.00020458
INFO:root:[65,   700] training loss: 0.00012417
INFO:root:[65,   750] training loss: 0.00043131
INFO:root:[65,   800] training loss: 0.00016695
INFO:root:[65,   850] training loss: 0.00011201
INFO:root:[65,   900] training loss: 0.01649121
INFO:root:[65,   950] training loss: 0.00533123
INFO:root:[65,  1000] training loss: 0.00003957
INFO:root:[65,  1050] training loss: 0.00003324
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9457    0.0506    0.0960      1720
    Anaphase     0.6999    0.5242    0.5994      1032
          G2     0.2333    0.8750    0.3684         8
   Metaphase     0.1281    0.9178    0.2248        73
   Telophase     0.2959    0.7012    0.4162      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.3693      3872
   macro avg     0.4718    0.5813    0.3864      3872
weighted avg     0.6893    0.3693    0.3193      3872

INFO:root:Accuracy of the network on the 3872 validation images: 36 %
INFO:root:epoch65
INFO:root:[66,    50] training loss: 0.01681051
INFO:root:[66,   100] training loss: 0.01337202
INFO:root:[66,   150] training loss: 0.01465796
INFO:root:[66,   200] training loss: 0.01306269
INFO:root:[66,   250] training loss: 0.01389447
INFO:root:[66,   300] training loss: 0.01622702
INFO:root:[66,   350] training loss: 0.01270814
INFO:root:[66,   400] training loss: 0.00012536
INFO:root:[66,   450] training loss: 0.00007009
INFO:root:[66,   500] training loss: 0.00065542
INFO:root:[66,   550] training loss: 0.00083071
INFO:root:[66,   600] training loss: 0.00247438
INFO:root:[66,   650] training loss: 0.00022175
INFO:root:[66,   700] training loss: 0.00014453
INFO:root:[66,   750] training loss: 0.00066454
INFO:root:[66,   800] training loss: 0.00014840
INFO:root:[66,   850] training loss: 0.00010053
INFO:root:[66,   900] training loss: 0.01613555
INFO:root:[66,   950] training loss: 0.00469259
INFO:root:[66,  1000] training loss: 0.00006578
INFO:root:[66,  1050] training loss: 0.00004826
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9440    0.0686    0.1279      1720
    Anaphase     0.6395    0.6085    0.6236      1032
          G2     0.2308    0.7500    0.3529         8
   Metaphase     0.1382    0.8767    0.2388        73
   Telophase     0.2770    0.6083    0.3806      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.3740      3872
   macro avg     0.4614    0.5589    0.3891      3872
weighted avg     0.6676    0.3740    0.3307      3872

INFO:root:Accuracy of the network on the 3872 validation images: 37 %
INFO:root:epoch66
INFO:root:[67,    50] training loss: 0.01638343
INFO:root:[67,   100] training loss: 0.01516271
INFO:root:[67,   150] training loss: 0.01430184
INFO:root:[67,   200] training loss: 0.01637217
INFO:root:[67,   250] training loss: 0.01312325
INFO:root:[67,   300] training loss: 0.01432254
INFO:root:[67,   350] training loss: 0.01286128
INFO:root:[67,   400] training loss: 0.00007132
INFO:root:[67,   450] training loss: 0.00004359
INFO:root:[67,   500] training loss: 0.00063310
INFO:root:[67,   550] training loss: 0.00071390
INFO:root:[67,   600] training loss: 0.00209910
INFO:root:[67,   650] training loss: 0.00016060
INFO:root:[67,   700] training loss: 0.00013260
INFO:root:[67,   750] training loss: 0.00054901
INFO:root:[67,   800] training loss: 0.00015518
INFO:root:[67,   850] training loss: 0.00009783
INFO:root:[67,   900] training loss: 0.01414797
INFO:root:[67,   950] training loss: 0.00426827
INFO:root:[67,  1000] training loss: 0.00006315
INFO:root:[67,  1050] training loss: 0.00004212
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9580    0.2651    0.4153      1720
    Anaphase     0.6545    0.6444    0.6494      1032
          G2     0.1818    0.5000    0.2667         8
   Metaphase     0.1408    0.8082    0.2398        73
   Telophase     0.3230    0.6044    0.4210      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.4680      3872
   macro avg     0.4654    0.5460    0.4275      3872
weighted avg     0.6901    0.4680    0.4758      3872

INFO:root:Accuracy of the network on the 3872 validation images: 46 %
INFO:root:epoch67
INFO:root:[68,    50] training loss: 0.01574962
INFO:root:[68,   100] training loss: 0.01506271
INFO:root:[68,   150] training loss: 0.01848803
INFO:root:[68,   200] training loss: 0.01303455
INFO:root:[68,   250] training loss: 0.01238708
INFO:root:[68,   300] training loss: 0.01445091
INFO:root:[68,   350] training loss: 0.01280416
INFO:root:[68,   400] training loss: 0.00005060
INFO:root:[68,   450] training loss: 0.00004301
INFO:root:[68,   500] training loss: 0.00051037
INFO:root:[68,   550] training loss: 0.00071182
INFO:root:[68,   600] training loss: 0.00173495
INFO:root:[68,   650] training loss: 0.00016776
INFO:root:[68,   700] training loss: 0.00010928
INFO:root:[68,   750] training loss: 0.00062481
INFO:root:[68,   800] training loss: 0.00013445
INFO:root:[68,   850] training loss: 0.00008720
INFO:root:[68,   900] training loss: 0.01528631
INFO:root:[68,   950] training loss: 0.00349948
INFO:root:[68,  1000] training loss: 0.00007758
INFO:root:[68,  1050] training loss: 0.00005841
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9572    0.3384    0.5000      1720
    Anaphase     0.5690    0.6831    0.6209      1032
          G2     0.4000    0.5000    0.4444         8
   Metaphase     0.1597    0.8904    0.2708        73
   Telophase     0.2953    0.4574    0.3589      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.4731      3872
   macro avg     0.4473    0.5528    0.4360      3872
weighted avg     0.6601    0.4731    0.4901      3872

INFO:root:Accuracy of the network on the 3872 validation images: 47 %
INFO:root:epoch68
INFO:root:[69,    50] training loss: 0.01457021
INFO:root:[69,   100] training loss: 0.01601123
INFO:root:[69,   150] training loss: 0.01389255
INFO:root:[69,   200] training loss: 0.01282517
INFO:root:[69,   250] training loss: 0.01289225
INFO:root:[69,   300] training loss: 0.01389887
INFO:root:[69,   350] training loss: 0.01140747
INFO:root:[69,   400] training loss: 0.00003657
INFO:root:[69,   450] training loss: 0.00005899
INFO:root:[69,   500] training loss: 0.00047939
INFO:root:[69,   550] training loss: 0.00061950
INFO:root:[69,   600] training loss: 0.00142403
INFO:root:[69,   650] training loss: 0.00014481
INFO:root:[69,   700] training loss: 0.00010639
INFO:root:[69,   750] training loss: 0.00063383
INFO:root:[69,   800] training loss: 0.00009712
INFO:root:[69,   850] training loss: 0.00007261
INFO:root:[69,   900] training loss: 0.01274515
INFO:root:[69,   950] training loss: 0.00501724
INFO:root:[69,  1000] training loss: 0.00008132
INFO:root:[69,  1050] training loss: 0.00005488
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.9462    0.4087    0.5708      1720
    Anaphase     0.5606    0.7083    0.6259      1032
          G2     0.2857    0.7500    0.4138         8
   Metaphase     0.1658    0.8493    0.2774        73
   Telophase     0.3069    0.4226    0.3556      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.5018      3872
   macro avg     0.5022    0.6627    0.5144      3872
weighted avg     0.6562    0.5018    0.5223      3872

INFO:root:Accuracy of the network on the 3872 validation images: 50 %
INFO:root:epoch69
INFO:root:[70,    50] training loss: 0.01420604
INFO:root:[70,   100] training loss: 0.01303685
INFO:root:[70,   150] training loss: 0.01419928
INFO:root:[70,   200] training loss: 0.01236750
INFO:root:[70,   250] training loss: 0.01231962
INFO:root:[70,   300] training loss: 0.01399801
INFO:root:[70,   350] training loss: 0.01202809
INFO:root:[70,   400] training loss: 0.00003906
INFO:root:[70,   450] training loss: 0.00002645
INFO:root:[70,   500] training loss: 0.00035739
INFO:root:[70,   550] training loss: 0.00064394
INFO:root:[70,   600] training loss: 0.00131214
INFO:root:[70,   650] training loss: 0.00012582
INFO:root:[70,   700] training loss: 0.00007839
INFO:root:[70,   750] training loss: 0.00083945
INFO:root:[70,   800] training loss: 0.00011895
INFO:root:[70,   850] training loss: 0.00008136
INFO:root:[70,   900] training loss: 0.01415853
INFO:root:[70,   950] training loss: 0.00393854
INFO:root:[70,  1000] training loss: 0.00006929
INFO:root:[70,  1050] training loss: 0.00006026
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.9534    0.4047    0.5682      1720
    Anaphase     0.5956    0.7393    0.6597      1032
          G2     0.2121    0.8750    0.3415         8
   Metaphase     0.1827    0.7534    0.2941        73
   Telophase     0.3261    0.4797    0.3883      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.5220      3872
   macro avg     0.5029    0.6789    0.5156      3872
weighted avg     0.6741    0.5220    0.5391      3872

INFO:root:Accuracy of the network on the 3872 validation images: 52 %
INFO:root:epoch70
INFO:root:[71,    50] training loss: 0.01380833
INFO:root:[71,   100] training loss: 0.01445947
INFO:root:[71,   150] training loss: 0.01383217
INFO:root:[71,   200] training loss: 0.01267727
INFO:root:[71,   250] training loss: 0.01224848
INFO:root:[71,   300] training loss: 0.01412976
INFO:root:[71,   350] training loss: 0.01250166
INFO:root:[71,   400] training loss: 0.00002164
INFO:root:[71,   450] training loss: 0.00011711
INFO:root:[71,   500] training loss: 0.00032179
INFO:root:[71,   550] training loss: 0.00054377
INFO:root:[71,   600] training loss: 0.00113296
INFO:root:[71,   650] training loss: 0.00014049
INFO:root:[71,   700] training loss: 0.00008380
INFO:root:[71,   750] training loss: 0.00070769
INFO:root:[71,   800] training loss: 0.00008197
INFO:root:[71,   850] training loss: 0.00007324
INFO:root:[71,   900] training loss: 0.01234166
INFO:root:[71,   950] training loss: 0.00314094
INFO:root:[71,  1000] training loss: 0.00008762
INFO:root:[71,  1050] training loss: 0.00005840
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9333    0.5453    0.6884      1720
    Anaphase     0.5849    0.7074    0.6404      1032
          G2     0.5000    0.5000    0.5000         8
   Metaphase     0.1667    0.8356    0.2779        73
   Telophase     0.3777    0.4526    0.4118      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.5697      3872
   macro avg     0.6042    0.7201    0.6169      3872
weighted avg     0.6767    0.5697    0.5939      3872

INFO:root:Accuracy of the network on the 3872 validation images: 56 %
INFO:root:epoch71
INFO:root:[72,    50] training loss: 0.01297517
INFO:root:[72,   100] training loss: 0.01313152
INFO:root:[72,   150] training loss: 0.01287720
INFO:root:[72,   200] training loss: 0.01241368
INFO:root:[72,   250] training loss: 0.01210430
INFO:root:[72,   300] training loss: 0.01431537
INFO:root:[72,   350] training loss: 0.01153911
INFO:root:[72,   400] training loss: 0.00002954
INFO:root:[72,   450] training loss: 0.00003032
INFO:root:[72,   500] training loss: 0.00032214
INFO:root:[72,   550] training loss: 0.00049351
INFO:root:[72,   600] training loss: 0.00095049
INFO:root:[72,   650] training loss: 0.00014298
INFO:root:[72,   700] training loss: 0.00008577
INFO:root:[72,   750] training loss: 0.00085748
INFO:root:[72,   800] training loss: 0.00004812
INFO:root:[72,   850] training loss: 0.00006474
INFO:root:[72,   900] training loss: 0.01429567
INFO:root:[72,   950] training loss: 0.00353741
INFO:root:[72,  1000] training loss: 0.00006087
INFO:root:[72,  1050] training loss: 0.00004674
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9310    0.5494    0.6910      1720
    Anaphase     0.5789    0.7035    0.6352      1032
          G2     0.2500    0.3750    0.3000         8
   Metaphase     0.1841    0.9178    0.3066        73
   Telophase     0.3869    0.4565    0.4188      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.5728      3872
   macro avg     0.5354    0.7146    0.5727      3872
weighted avg     0.6761    0.5728    0.5956      3872

INFO:root:Accuracy of the network on the 3872 validation images: 57 %
INFO:root:epoch72
INFO:root:[73,    50] training loss: 0.01287849
INFO:root:[73,   100] training loss: 0.01253261
INFO:root:[73,   150] training loss: 0.01261107
INFO:root:[73,   200] training loss: 0.01336155
INFO:root:[73,   250] training loss: 0.01536059
INFO:root:[73,   300] training loss: 0.01346551
INFO:root:[73,   350] training loss: 0.01168494
INFO:root:[73,   400] training loss: 0.00007266
INFO:root:[73,   450] training loss: 0.00003683
INFO:root:[73,   500] training loss: 0.00034521
INFO:root:[73,   550] training loss: 0.00051446
INFO:root:[73,   600] training loss: 0.00109081
INFO:root:[73,   650] training loss: 0.00014800
INFO:root:[73,   700] training loss: 0.00006866
INFO:root:[73,   750] training loss: 0.00055992
INFO:root:[73,   800] training loss: 0.00006631
INFO:root:[73,   850] training loss: 0.00006795
INFO:root:[73,   900] training loss: 0.01321052
INFO:root:[73,   950] training loss: 0.00281766
INFO:root:[73,  1000] training loss: 0.00007446
INFO:root:[73,  1050] training loss: 0.00005422
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.9232    0.6360    0.7532      1720
    Anaphase     0.5785    0.7781    0.6636      1032
          G2     0.3158    0.7500    0.4444         8
   Metaphase     0.2184    0.7808    0.3413        73
   Telophase     0.4154    0.4062    0.4108      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.6160      3872
   macro avg     0.5288    0.7645    0.5910      3872
weighted avg     0.6808    0.6160    0.6295      3872

INFO:root:Accuracy of the network on the 3872 validation images: 61 %
INFO:root:epoch73
INFO:root:[74,    50] training loss: 0.01401630
INFO:root:[74,   100] training loss: 0.01241785
INFO:root:[74,   150] training loss: 0.01295385
INFO:root:[74,   200] training loss: 0.01292053
INFO:root:[74,   250] training loss: 0.01332113
INFO:root:[74,   300] training loss: 0.01361159
INFO:root:[74,   350] training loss: 0.01402076
INFO:root:[74,   400] training loss: 0.00004461
INFO:root:[74,   450] training loss: 0.00004215
INFO:root:[74,   500] training loss: 0.00033157
INFO:root:[74,   550] training loss: 0.00048512
INFO:root:[74,   600] training loss: 0.00097537
INFO:root:[74,   650] training loss: 0.00012336
INFO:root:[74,   700] training loss: 0.00007929
INFO:root:[74,   750] training loss: 0.00073091
INFO:root:[74,   800] training loss: 0.00007036
INFO:root:[74,   850] training loss: 0.00006594
INFO:root:[74,   900] training loss: 0.01238723
INFO:root:[74,   950] training loss: 0.00269509
INFO:root:[74,  1000] training loss: 0.00007099
INFO:root:[74,  1050] training loss: 0.00004855
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9171    0.6756    0.7780      1720
    Anaphase     0.5615    0.8004    0.6600      1032
          G2     0.4000    0.5000    0.4444         8
   Metaphase     0.2151    0.7808    0.3373        73
   Telophase     0.4094    0.3385    0.3706      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.6204      3872
   macro avg     0.5004    0.5850    0.5129      3872
weighted avg     0.6720    0.6204    0.6285      3872

INFO:root:Accuracy of the network on the 3872 validation images: 62 %
INFO:root:epoch74
INFO:root:[75,    50] training loss: 0.01283682
INFO:root:[75,   100] training loss: 0.01350324
INFO:root:[75,   150] training loss: 0.01275434
INFO:root:[75,   200] training loss: 0.01160352
INFO:root:[75,   250] training loss: 0.01154090
INFO:root:[75,   300] training loss: 0.01502914
INFO:root:[75,   350] training loss: 0.01192038
INFO:root:[75,   400] training loss: 0.00003040
INFO:root:[75,   450] training loss: 0.00004520
INFO:root:[75,   500] training loss: 0.00028716
INFO:root:[75,   550] training loss: 0.00046064
INFO:root:[75,   600] training loss: 0.00099888
INFO:root:[75,   650] training loss: 0.00013382
INFO:root:[75,   700] training loss: 0.00007336
INFO:root:[75,   750] training loss: 0.00070453
INFO:root:[75,   800] training loss: 0.00008479
INFO:root:[75,   850] training loss: 0.00005717
INFO:root:[75,   900] training loss: 0.01232428
INFO:root:[75,   950] training loss: 0.00313727
INFO:root:[75,  1000] training loss: 0.00006260
INFO:root:[75,  1050] training loss: 0.00004092
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9240    0.6221    0.7436      1720
    Anaphase     0.5890    0.7984    0.6779      1032
          G2     0.3077    0.5000    0.3810         8
   Metaphase     0.2344    0.8219    0.3647        73
   Telophase     0.3983    0.4014    0.3998      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.6136      3872
   macro avg     0.4933    0.5920    0.5096      3872
weighted avg     0.6796    0.6136    0.6262      3872

INFO:root:Accuracy of the network on the 3872 validation images: 61 %
INFO:root:epoch75
INFO:root:[76,    50] training loss: 0.01306223
INFO:root:[76,   100] training loss: 0.01180606
INFO:root:[76,   150] training loss: 0.01230564
INFO:root:[76,   200] training loss: 0.01151519
INFO:root:[76,   250] training loss: 0.01291138
INFO:root:[76,   300] training loss: 0.01445042
INFO:root:[76,   350] training loss: 0.01150650
INFO:root:[76,   400] training loss: 0.00002567
INFO:root:[76,   450] training loss: 0.00003874
INFO:root:[76,   500] training loss: 0.00035686
INFO:root:[76,   550] training loss: 0.00043441
INFO:root:[76,   600] training loss: 0.00069176
INFO:root:[76,   650] training loss: 0.00012191
INFO:root:[76,   700] training loss: 0.00006752
INFO:root:[76,   750] training loss: 0.00095462
INFO:root:[76,   800] training loss: 0.00007950
INFO:root:[76,   850] training loss: 0.00005245
INFO:root:[76,   900] training loss: 0.01143972
INFO:root:[76,   950] training loss: 0.00265707
INFO:root:[76,  1000] training loss: 0.00008294
INFO:root:[76,  1050] training loss: 0.00004287
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9178    0.7140    0.8031      1720
    Anaphase     0.5915    0.7452    0.6595      1032
          G2     0.6000    0.3750    0.4615         8
   Metaphase     0.2104    0.8904    0.3403        73
   Telophase     0.4770    0.4217    0.4476      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.6472      3872
   macro avg     0.6376    0.7352    0.6446      3872
weighted avg     0.6991    0.6472    0.6606      3872

INFO:root:Accuracy of the network on the 3872 validation images: 64 %
INFO:root:epoch76
INFO:root:[77,    50] training loss: 0.01185183
INFO:root:[77,   100] training loss: 0.01211791
INFO:root:[77,   150] training loss: 0.01318189
INFO:root:[77,   200] training loss: 0.01224377
INFO:root:[77,   250] training loss: 0.01331233
INFO:root:[77,   300] training loss: 0.01376329
INFO:root:[77,   350] training loss: 0.01169138
INFO:root:[77,   400] training loss: 0.00002654
INFO:root:[77,   450] training loss: 0.00002952
INFO:root:[77,   500] training loss: 0.00019888
INFO:root:[77,   550] training loss: 0.00051309
INFO:root:[77,   600] training loss: 0.00095857
INFO:root:[77,   650] training loss: 0.00009104
INFO:root:[77,   700] training loss: 0.00006717
INFO:root:[77,   750] training loss: 0.00087541
INFO:root:[77,   800] training loss: 0.00006200
INFO:root:[77,   850] training loss: 0.00005481
INFO:root:[77,   900] training loss: 0.01319532
INFO:root:[77,   950] training loss: 0.00291853
INFO:root:[77,  1000] training loss: 0.00006342
INFO:root:[77,  1050] training loss: 0.00003365
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9204    0.6721    0.7769      1720
    Anaphase     0.5742    0.7500    0.6504      1032
          G2     0.3750    0.7500    0.5000         8
   Metaphase     0.2013    0.8493    0.3255        73
   Telophase     0.4274    0.3868    0.4061      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.6206      3872
   macro avg     0.5378    0.7726    0.6013      3872
weighted avg     0.6814    0.6206    0.6351      3872

INFO:root:Accuracy of the network on the 3872 validation images: 62 %
INFO:root:epoch77
INFO:root:[78,    50] training loss: 0.01226654
INFO:root:[78,   100] training loss: 0.01216842
INFO:root:[78,   150] training loss: 0.01230296
INFO:root:[78,   200] training loss: 0.01401703
INFO:root:[78,   250] training loss: 0.01254927
INFO:root:[78,   300] training loss: 0.01368508
INFO:root:[78,   350] training loss: 0.01215908
INFO:root:[78,   400] training loss: 0.00002082
INFO:root:[78,   450] training loss: 0.00002076
INFO:root:[78,   500] training loss: 0.00024432
INFO:root:[78,   550] training loss: 0.00045981
INFO:root:[78,   600] training loss: 0.00065558
INFO:root:[78,   650] training loss: 0.00009575
INFO:root:[78,   700] training loss: 0.00006084
INFO:root:[78,   750] training loss: 0.00078366
INFO:root:[78,   800] training loss: 0.00004991
INFO:root:[78,   850] training loss: 0.00006151
INFO:root:[78,   900] training loss: 0.01092330
INFO:root:[78,   950] training loss: 0.00254330
INFO:root:[78,  1000] training loss: 0.00006901
INFO:root:[78,  1050] training loss: 0.00004738
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8996    0.7657    0.8273      1720
    Anaphase     0.6246    0.7578    0.6848      1032
          G2     0.5000    0.3750    0.4286         8
   Metaphase     0.2338    0.8904    0.3704        73
   Telophase     0.5364    0.4487    0.4887      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.6808      3872
   macro avg     0.6016    0.7482    0.6367      3872
weighted avg     0.7157    0.6808    0.6894      3872

INFO:root:Accuracy of the network on the 3872 validation images: 68 %
INFO:root:epoch78
INFO:root:[79,    50] training loss: 0.01206300
INFO:root:[79,   100] training loss: 0.01190352
INFO:root:[79,   150] training loss: 0.01356448
INFO:root:[79,   200] training loss: 0.01400804
INFO:root:[79,   250] training loss: 0.01247733
INFO:root:[79,   300] training loss: 0.01337870
INFO:root:[79,   350] training loss: 0.01148749
INFO:root:[79,   400] training loss: 0.00009006
INFO:root:[79,   450] training loss: 0.00002609
INFO:root:[79,   500] training loss: 0.00021357
INFO:root:[79,   550] training loss: 0.00048613
INFO:root:[79,   600] training loss: 0.00064934
INFO:root:[79,   650] training loss: 0.00008522
INFO:root:[79,   700] training loss: 0.00006487
INFO:root:[79,   750] training loss: 0.00092195
INFO:root:[79,   800] training loss: 0.00004638
INFO:root:[79,   850] training loss: 0.00004286
INFO:root:[79,   900] training loss: 0.01070581
INFO:root:[79,   950] training loss: 0.00228337
INFO:root:[79,  1000] training loss: 0.00006239
INFO:root:[79,  1050] training loss: 0.00004321
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.9025    0.7587    0.8244      1720
    Anaphase     0.5891    0.8362    0.6912      1032
          G2     0.5000    0.6250    0.5556         8
   Metaphase     0.3046    0.8219    0.4444        73
   Telophase     0.5374    0.3888    0.4512      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.6816      3872
   macro avg     0.5834    0.7044    0.6177      3872
weighted avg     0.7090    0.6816    0.6814      3872

INFO:root:Accuracy of the network on the 3872 validation images: 68 %
INFO:root:epoch79
INFO:root:[80,    50] training loss: 0.01151422
INFO:root:[80,   100] training loss: 0.01249632
INFO:root:[80,   150] training loss: 0.01234953
INFO:root:[80,   200] training loss: 0.01109845
INFO:root:[80,   250] training loss: 0.01094551
INFO:root:[80,   300] training loss: 0.01316771
INFO:root:[80,   350] training loss: 0.01251258
INFO:root:[80,   400] training loss: 0.00003029
INFO:root:[80,   450] training loss: 0.00003989
INFO:root:[80,   500] training loss: 0.00030579
INFO:root:[80,   550] training loss: 0.00041310
INFO:root:[80,   600] training loss: 0.00051902
INFO:root:[80,   650] training loss: 0.00008543
INFO:root:[80,   700] training loss: 0.00005759
INFO:root:[80,   750] training loss: 0.00076890
INFO:root:[80,   800] training loss: 0.00004498
INFO:root:[80,   850] training loss: 0.00004416
INFO:root:[80,   900] training loss: 0.01012579
INFO:root:[80,   950] training loss: 0.00281303
INFO:root:[80,  1000] training loss: 0.00006592
INFO:root:[80,  1050] training loss: 0.00005108
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.9153    0.7041    0.7959      1720
    Anaphase     0.6080    0.8130    0.6957      1032
          G2     0.2222    0.7500    0.3429         8
   Metaphase     0.2250    0.6164    0.3297        73
   Telophase     0.4691    0.4255    0.4462      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.6570      3872
   macro avg     0.4914    0.6156    0.5158      3872
weighted avg     0.6994    0.6570    0.6658      3872

INFO:root:Accuracy of the network on the 3872 validation images: 65 %
INFO:root:epoch80
INFO:root:[81,    50] training loss: 0.01240081
INFO:root:[81,   100] training loss: 0.01221275
INFO:root:[81,   150] training loss: 0.01164971
INFO:root:[81,   200] training loss: 0.01153847
INFO:root:[81,   250] training loss: 0.01072050
INFO:root:[81,   300] training loss: 0.01321175
INFO:root:[81,   350] training loss: 0.01245382
INFO:root:[81,   400] training loss: 0.00002321
INFO:root:[81,   450] training loss: 0.00002578
INFO:root:[81,   500] training loss: 0.00026614
INFO:root:[81,   550] training loss: 0.00045665
INFO:root:[81,   600] training loss: 0.00053661
INFO:root:[81,   650] training loss: 0.00007938
INFO:root:[81,   700] training loss: 0.00005475
INFO:root:[81,   750] training loss: 0.00080313
INFO:root:[81,   800] training loss: 0.00004232
INFO:root:[81,   850] training loss: 0.00003911
INFO:root:[81,   900] training loss: 0.01146058
INFO:root:[81,   950] training loss: 0.00260715
INFO:root:[81,  1000] training loss: 0.00005069
INFO:root:[81,  1050] training loss: 0.00003381
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9150    0.7076    0.7980      1720
    Anaphase     0.6214    0.8256    0.7091      1032
          G2     0.4615    0.7500    0.5714         8
   Metaphase     0.2821    0.7534    0.4104        73
   Telophase     0.4764    0.4400    0.4575      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.6689      3872
   macro avg     0.5747    0.7824    0.6424      3872
weighted avg     0.7064    0.6689    0.6756      3872

INFO:root:Accuracy of the network on the 3872 validation images: 66 %
INFO:root:epoch81
INFO:root:[82,    50] training loss: 0.01285458
INFO:root:[82,   100] training loss: 0.01211125
INFO:root:[82,   150] training loss: 0.01185590
INFO:root:[82,   200] training loss: 0.01068865
INFO:root:[82,   250] training loss: 0.01095438
INFO:root:[82,   300] training loss: 0.01236917
INFO:root:[82,   350] training loss: 0.01141129
INFO:root:[82,   400] training loss: 0.00002588
INFO:root:[82,   450] training loss: 0.00002419
INFO:root:[82,   500] training loss: 0.00015049
INFO:root:[82,   550] training loss: 0.00034556
INFO:root:[82,   600] training loss: 0.00055108
INFO:root:[82,   650] training loss: 0.00008704
INFO:root:[82,   700] training loss: 0.00006380
INFO:root:[82,   750] training loss: 0.00061650
INFO:root:[82,   800] training loss: 0.00005551
INFO:root:[82,   850] training loss: 0.00006719
INFO:root:[82,   900] training loss: 0.01049755
INFO:root:[82,   950] training loss: 0.00277558
INFO:root:[82,  1000] training loss: 0.00006910
INFO:root:[82,  1050] training loss: 0.00004737
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.8978    0.7715    0.8299      1720
    Anaphase     0.6018    0.7965    0.6856      1032
          G2     0.5556    0.6250    0.5882         8
   Metaphase     0.2377    0.7945    0.3659        73
   Telophase     0.5033    0.3743    0.4293      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.6723      3872
   macro avg     0.5780    0.6945    0.6080      3872
weighted avg     0.7001    0.6723    0.6751      3872

INFO:root:Accuracy of the network on the 3872 validation images: 67 %
INFO:root:epoch82
INFO:root:[83,    50] training loss: 0.01115569
INFO:root:[83,   100] training loss: 0.01143368
INFO:root:[83,   150] training loss: 0.01238536
INFO:root:[83,   200] training loss: 0.01034845
INFO:root:[83,   250] training loss: 0.01360003
INFO:root:[83,   300] training loss: 0.01419881
INFO:root:[83,   350] training loss: 0.01325122
INFO:root:[83,   400] training loss: 0.00003566
INFO:root:[83,   450] training loss: 0.00003056
INFO:root:[83,   500] training loss: 0.00020628
INFO:root:[83,   550] training loss: 0.00041064
INFO:root:[83,   600] training loss: 0.00081416
INFO:root:[83,   650] training loss: 0.00010447
INFO:root:[83,   700] training loss: 0.00005902
INFO:root:[83,   750] training loss: 0.00075916
INFO:root:[83,   800] training loss: 0.00008467
INFO:root:[83,   850] training loss: 0.00003961
INFO:root:[83,   900] training loss: 0.01128902
INFO:root:[83,   950] training loss: 0.00246939
INFO:root:[83,  1000] training loss: 0.00007620
INFO:root:[83,  1050] training loss: 0.00004514
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.9007    0.7808    0.8365      1720
    Anaphase     0.6076    0.8343    0.7031      1032
          G2     0.5000    0.7500    0.6000         8
   Metaphase     0.2979    0.7671    0.4291        73
   Telophase     0.5344    0.3907    0.4514      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.6909      3872
   macro avg     0.5844    0.7890    0.6491      3872
weighted avg     0.7123    0.6909    0.6899      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch83
INFO:root:[84,    50] training loss: 0.01224682
INFO:root:[84,   100] training loss: 0.01104473
INFO:root:[84,   150] training loss: 0.01192706
INFO:root:[84,   200] training loss: 0.01232065
INFO:root:[84,   250] training loss: 0.01112154
INFO:root:[84,   300] training loss: 0.01207568
INFO:root:[84,   350] training loss: 0.00979199
INFO:root:[84,   400] training loss: 0.00003058
INFO:root:[84,   450] training loss: 0.00002865
INFO:root:[84,   500] training loss: 0.00019560
INFO:root:[84,   550] training loss: 0.00028718
INFO:root:[84,   600] training loss: 0.00053794
INFO:root:[84,   650] training loss: 0.00006131
INFO:root:[84,   700] training loss: 0.00004789
INFO:root:[84,   750] training loss: 0.00085763
INFO:root:[84,   800] training loss: 0.00005092
INFO:root:[84,   850] training loss: 0.00002781
INFO:root:[84,   900] training loss: 0.00974888
INFO:root:[84,   950] training loss: 0.00211881
INFO:root:[84,  1000] training loss: 0.00008313
INFO:root:[84,  1050] training loss: 0.00004525
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8997    0.7930    0.8430      1720
    Anaphase     0.6238    0.8469    0.7185      1032
          G2     0.5455    0.7500    0.6316         8
   Metaphase     0.3140    0.7397    0.4408        73
   Telophase     0.5569    0.4120    0.4736      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.7048      3872
   macro avg     0.6224    0.7917    0.6807      3872
weighted avg     0.7226    0.7048    0.7031      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch84
INFO:root:[85,    50] training loss: 0.01061844
INFO:root:[85,   100] training loss: 0.01119753
INFO:root:[85,   150] training loss: 0.01322187
INFO:root:[85,   200] training loss: 0.01183434
INFO:root:[85,   250] training loss: 0.01344030
INFO:root:[85,   300] training loss: 0.01209489
INFO:root:[85,   350] training loss: 0.01096253
INFO:root:[85,   400] training loss: 0.00001538
INFO:root:[85,   450] training loss: 0.00004318
INFO:root:[85,   500] training loss: 0.00014216
INFO:root:[85,   550] training loss: 0.00033114
INFO:root:[85,   600] training loss: 0.00041264
INFO:root:[85,   650] training loss: 0.00006895
INFO:root:[85,   700] training loss: 0.00004373
INFO:root:[85,   750] training loss: 0.00070648
INFO:root:[85,   800] training loss: 0.00004415
INFO:root:[85,   850] training loss: 0.00003567
INFO:root:[85,   900] training loss: 0.00896742
INFO:root:[85,   950] training loss: 0.00221800
INFO:root:[85,  1000] training loss: 0.00005826
INFO:root:[85,  1050] training loss: 0.00003989
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9038    0.7703    0.8318      1720
    Anaphase     0.6087    0.8246    0.7004      1032
          G2     0.3333    0.5000    0.4000         8
   Metaphase     0.2624    0.7260    0.3855        73
   Telophase     0.5419    0.4130    0.4687      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.6883      3872
   macro avg     0.6167    0.7477    0.6552      3872
weighted avg     0.7152    0.6883    0.6906      3872

INFO:root:Accuracy of the network on the 3872 validation images: 68 %
INFO:root:epoch85
INFO:root:[86,    50] training loss: 0.01084360
INFO:root:[86,   100] training loss: 0.01081275
INFO:root:[86,   150] training loss: 0.01194256
INFO:root:[86,   200] training loss: 0.00977194
INFO:root:[86,   250] training loss: 0.01166637
INFO:root:[86,   300] training loss: 0.01180636
INFO:root:[86,   350] training loss: 0.01335632
INFO:root:[86,   400] training loss: 0.00001804
INFO:root:[86,   450] training loss: 0.00002451
INFO:root:[86,   500] training loss: 0.00017503
INFO:root:[86,   550] training loss: 0.00037994
INFO:root:[86,   600] training loss: 0.00039050
INFO:root:[86,   650] training loss: 0.00006331
INFO:root:[86,   700] training loss: 0.00005344
INFO:root:[86,   750] training loss: 0.00077256
INFO:root:[86,   800] training loss: 0.00003838
INFO:root:[86,   850] training loss: 0.00004898
INFO:root:[86,   900] training loss: 0.00988126
INFO:root:[86,   950] training loss: 0.00226897
INFO:root:[86,  1000] training loss: 0.00005097
INFO:root:[86,  1050] training loss: 0.00004022
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.8883    0.8279    0.8571      1720
    Anaphase     0.6390    0.8266    0.7207      1032
          G2     0.4444    0.5000    0.4706         8
   Metaphase     0.2917    0.7671    0.4226        73
   Telophase     0.5879    0.4139    0.4858      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7151      3872
   macro avg     0.6216    0.6908    0.6367      3872
weighted avg     0.7294    0.7151    0.7125      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch86
INFO:root:[87,    50] training loss: 0.01127923
INFO:root:[87,   100] training loss: 0.01088948
INFO:root:[87,   150] training loss: 0.01104020
INFO:root:[87,   200] training loss: 0.01131339
INFO:root:[87,   250] training loss: 0.01166333
INFO:root:[87,   300] training loss: 0.01487544
INFO:root:[87,   350] training loss: 0.01154456
INFO:root:[87,   400] training loss: 0.00002493
INFO:root:[87,   450] training loss: 0.00003123
INFO:root:[87,   500] training loss: 0.00021660
INFO:root:[87,   550] training loss: 0.00037790
INFO:root:[87,   600] training loss: 0.00062886
INFO:root:[87,   650] training loss: 0.00012636
INFO:root:[87,   700] training loss: 0.00005736
INFO:root:[87,   750] training loss: 0.00055834
INFO:root:[87,   800] training loss: 0.00003891
INFO:root:[87,   850] training loss: 0.00003523
INFO:root:[87,   900] training loss: 0.01069391
INFO:root:[87,   950] training loss: 0.00242942
INFO:root:[87,  1000] training loss: 0.00005182
INFO:root:[87,  1050] training loss: 0.00003290
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.8901    0.7866    0.8352      1720
    Anaphase     0.6565    0.7926    0.7182      1032
          G2     0.4000    0.5000    0.4444         8
   Metaphase     0.2547    0.7397    0.3789        73
   Telophase     0.5597    0.4758    0.5144      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7035      3872
   macro avg     0.5373    0.6135    0.5559      3872
weighted avg     0.7263    0.7035    0.7086      3872

INFO:root:Accuracy of the network on the 3872 validation images: 70 %
INFO:root:epoch87
INFO:root:[88,    50] training loss: 0.01165466
INFO:root:[88,   100] training loss: 0.01334008
INFO:root:[88,   150] training loss: 0.01209110
INFO:root:[88,   200] training loss: 0.01039914
INFO:root:[88,   250] training loss: 0.01061426
INFO:root:[88,   300] training loss: 0.01136039
INFO:root:[88,   350] training loss: 0.00955421
INFO:root:[88,   400] training loss: 0.00022239
INFO:root:[88,   450] training loss: 0.00002218
INFO:root:[88,   500] training loss: 0.00012000
INFO:root:[88,   550] training loss: 0.00031030
INFO:root:[88,   600] training loss: 0.00061924
INFO:root:[88,   650] training loss: 0.00005659
INFO:root:[88,   700] training loss: 0.00003893
INFO:root:[88,   750] training loss: 0.00082420
INFO:root:[88,   800] training loss: 0.00003462
INFO:root:[88,   850] training loss: 0.00003081
INFO:root:[88,   900] training loss: 0.00971501
INFO:root:[88,   950] training loss: 0.00226972
INFO:root:[88,  1000] training loss: 0.00007543
INFO:root:[88,  1050] training loss: 0.00003691
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.9099    0.7750    0.8370      1720
    Anaphase     0.5976    0.8188    0.6909      1032
          G2     0.4286    0.3750    0.4000         8
   Metaphase     0.2607    0.7534    0.3873        73
   Telophase     0.5450    0.4043    0.4642      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.6867      3872
   macro avg     0.5702    0.7324    0.6148      3872
weighted avg     0.7156    0.6867    0.6891      3872

INFO:root:Accuracy of the network on the 3872 validation images: 68 %
INFO:root:epoch88
INFO:root:[89,    50] training loss: 0.01057893
INFO:root:[89,   100] training loss: 0.01282742
INFO:root:[89,   150] training loss: 0.01159105
INFO:root:[89,   200] training loss: 0.01199888
INFO:root:[89,   250] training loss: 0.01078965
INFO:root:[89,   300] training loss: 0.01153188
INFO:root:[89,   350] training loss: 0.01092522
INFO:root:[89,   400] training loss: 0.00001516
INFO:root:[89,   450] training loss: 0.00001920
INFO:root:[89,   500] training loss: 0.00016049
INFO:root:[89,   550] training loss: 0.00024857
INFO:root:[89,   600] training loss: 0.00043625
INFO:root:[89,   650] training loss: 0.00005980
INFO:root:[89,   700] training loss: 0.00004890
INFO:root:[89,   750] training loss: 0.00076622
INFO:root:[89,   800] training loss: 0.00003262
INFO:root:[89,   850] training loss: 0.00002844
INFO:root:[89,   900] training loss: 0.00878433
INFO:root:[89,   950] training loss: 0.00204629
INFO:root:[89,  1000] training loss: 0.00005342
INFO:root:[89,  1050] training loss: 0.00003344
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8858    0.8523    0.8687      1720
    Anaphase     0.6222    0.7917    0.6968      1032
          G2     0.3846    0.6250    0.4762         8
   Metaphase     0.2466    0.7397    0.3699        73
   Telophase     0.6096    0.3926    0.4776      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7110      3872
   macro avg     0.6308    0.7716    0.6699      3872
weighted avg     0.7287    0.7110    0.7083      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch89
INFO:root:[90,    50] training loss: 0.01174032
INFO:root:[90,   100] training loss: 0.01163446
INFO:root:[90,   150] training loss: 0.01193552
INFO:root:[90,   200] training loss: 0.00982941
INFO:root:[90,   250] training loss: 0.01070675
INFO:root:[90,   300] training loss: 0.01186891
INFO:root:[90,   350] training loss: 0.01017131
INFO:root:[90,   400] training loss: 0.00003470
INFO:root:[90,   450] training loss: 0.00002286
INFO:root:[90,   500] training loss: 0.00015197
INFO:root:[90,   550] training loss: 0.00030114
INFO:root:[90,   600] training loss: 0.00040573
INFO:root:[90,   650] training loss: 0.00005875
INFO:root:[90,   700] training loss: 0.00003894
INFO:root:[90,   750] training loss: 0.00086091
INFO:root:[90,   800] training loss: 0.00003744
INFO:root:[90,   850] training loss: 0.00003989
INFO:root:[90,   900] training loss: 0.00854244
INFO:root:[90,   950] training loss: 0.00211964
INFO:root:[90,  1000] training loss: 0.00004699
INFO:root:[90,  1050] training loss: 0.00007891
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.8853    0.8390    0.8615      1720
    Anaphase     0.6717    0.8188    0.7380      1032
          G2     0.4167    0.6250    0.5000         8
   Metaphase     0.2905    0.7123    0.4127        73
   Telophase     0.5977    0.4555    0.5170      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7283      3872
   macro avg     0.6231    0.7072    0.6470      3872
weighted avg     0.7393    0.7283    0.7273      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch90
INFO:root:[91,    50] training loss: 0.01063669
INFO:root:[91,   100] training loss: 0.01066365
INFO:root:[91,   150] training loss: 0.01095397
INFO:root:[91,   200] training loss: 0.00972967
INFO:root:[91,   250] training loss: 0.00990816
INFO:root:[91,   300] training loss: 0.01166470
INFO:root:[91,   350] training loss: 0.00910646
INFO:root:[91,   400] training loss: 0.00001761
INFO:root:[91,   450] training loss: 0.00001820
INFO:root:[91,   500] training loss: 0.00015860
INFO:root:[91,   550] training loss: 0.00019866
INFO:root:[91,   600] training loss: 0.00049886
INFO:root:[91,   650] training loss: 0.00004985
INFO:root:[91,   700] training loss: 0.00003172
INFO:root:[91,   750] training loss: 0.00050798
INFO:root:[91,   800] training loss: 0.00003436
INFO:root:[91,   850] training loss: 0.00003413
INFO:root:[91,   900] training loss: 0.00870737
INFO:root:[91,   950] training loss: 0.00199616
INFO:root:[91,  1000] training loss: 0.00004869
INFO:root:[91,  1050] training loss: 0.00002962
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8937    0.8308    0.8611      1720
    Anaphase     0.6407    0.7965    0.7102      1032
          G2     0.5000    0.3750    0.4286         8
   Metaphase     0.2579    0.7808    0.3878        73
   Telophase     0.6011    0.4400    0.5081      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7157      3872
   macro avg     0.6514    0.7462    0.6708      3872
weighted avg     0.7353    0.7157    0.7169      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch91
INFO:root:[92,    50] training loss: 0.01118170
INFO:root:[92,   100] training loss: 0.01594050
INFO:root:[92,   150] training loss: 0.01141002
INFO:root:[92,   200] training loss: 0.01082127
INFO:root:[92,   250] training loss: 0.01010990
INFO:root:[92,   300] training loss: 0.01130054
INFO:root:[92,   350] training loss: 0.00934005
INFO:root:[92,   400] training loss: 0.00001977
INFO:root:[92,   450] training loss: 0.00001871
INFO:root:[92,   500] training loss: 0.00009637
INFO:root:[92,   550] training loss: 0.00028300
INFO:root:[92,   600] training loss: 0.00038974
INFO:root:[92,   650] training loss: 0.00005482
INFO:root:[92,   700] training loss: 0.00003898
INFO:root:[92,   750] training loss: 0.00083815
INFO:root:[92,   800] training loss: 0.00002666
INFO:root:[92,   850] training loss: 0.00002335
INFO:root:[92,   900] training loss: 0.00819743
INFO:root:[92,   950] training loss: 0.00264793
INFO:root:[92,  1000] training loss: 0.00004404
INFO:root:[92,  1050] training loss: 0.00003814
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8951    0.8331    0.8630      1720
    Anaphase     0.6431    0.8101    0.7170      1032
          G2     0.2059    0.8750    0.3333         8
   Metaphase     0.2707    0.6712    0.3858        73
   Telophase     0.5949    0.4304    0.4994      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.7167      3872
   macro avg     0.5538    0.8028    0.6212      3872
weighted avg     0.7342    0.7167    0.7168      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch92
INFO:root:[93,    50] training loss: 0.01177967
INFO:root:[93,   100] training loss: 0.01357061
INFO:root:[93,   150] training loss: 0.01134285
INFO:root:[93,   200] training loss: 0.00994487
INFO:root:[93,   250] training loss: 0.01038593
INFO:root:[93,   300] training loss: 0.01114535
INFO:root:[93,   350] training loss: 0.01109239
INFO:root:[93,   400] training loss: 0.00001019
INFO:root:[93,   450] training loss: 0.00001825
INFO:root:[93,   500] training loss: 0.00012606
INFO:root:[93,   550] training loss: 0.00021279
INFO:root:[93,   600] training loss: 0.00026751
INFO:root:[93,   650] training loss: 0.00004917
INFO:root:[93,   700] training loss: 0.00004650
INFO:root:[93,   750] training loss: 0.00076654
INFO:root:[93,   800] training loss: 0.00002626
INFO:root:[93,   850] training loss: 0.00004421
INFO:root:[93,   900] training loss: 0.00800929
INFO:root:[93,   950] training loss: 0.00194256
INFO:root:[93,  1000] training loss: 0.00003826
INFO:root:[93,  1050] training loss: 0.00002595
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.8857    0.8291    0.8565      1720
    Anaphase     0.6661    0.8101    0.7311      1032
          G2     0.5714    0.5000    0.5333         8
   Metaphase     0.2800    0.7671    0.4103        73
   Telophase     0.5919    0.4545    0.5142      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.7221      3872
   macro avg     0.6065    0.6944    0.6289      3872
weighted avg     0.7364    0.7221    0.7224      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch93
INFO:root:[94,    50] training loss: 0.00973873
INFO:root:[94,   100] training loss: 0.01065547
INFO:root:[94,   150] training loss: 0.01011222
INFO:root:[94,   200] training loss: 0.00950448
INFO:root:[94,   250] training loss: 0.00978199
INFO:root:[94,   300] training loss: 0.01228500
INFO:root:[94,   350] training loss: 0.01012022
INFO:root:[94,   400] training loss: 0.00001326
INFO:root:[94,   450] training loss: 0.00002873
INFO:root:[94,   500] training loss: 0.00012153
INFO:root:[94,   550] training loss: 0.00029343
INFO:root:[94,   600] training loss: 0.00042616
INFO:root:[94,   650] training loss: 0.00004075
INFO:root:[94,   700] training loss: 0.00005189
INFO:root:[94,   750] training loss: 0.00060628
INFO:root:[94,   800] training loss: 0.00005498
INFO:root:[94,   850] training loss: 0.00002691
INFO:root:[94,   900] training loss: 0.00793457
INFO:root:[94,   950] training loss: 0.00192388
INFO:root:[94,  1000] training loss: 0.00004211
INFO:root:[94,  1050] training loss: 0.00002878
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     0.8759    0.8785    0.8772      1720
    Anaphase     0.6826    0.8295    0.7489      1032
          G2     0.4444    0.5000    0.4706         8
   Metaphase     0.3158    0.7397    0.4426        73
   Telophase     0.6615    0.4497    0.5354      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.7477      3872
   macro avg     0.5686    0.7711    0.6280      3872
weighted avg     0.7552    0.7477    0.7424      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch94
INFO:root:[95,    50] training loss: 0.01163462
INFO:root:[95,   100] training loss: 0.01197055
INFO:root:[95,   150] training loss: 0.01073110
INFO:root:[95,   200] training loss: 0.00952883
INFO:root:[95,   250] training loss: 0.00966245
INFO:root:[95,   300] training loss: 0.01118910
INFO:root:[95,   350] training loss: 0.00951897
INFO:root:[95,   400] training loss: 0.00002356
INFO:root:[95,   450] training loss: 0.00001390
INFO:root:[95,   500] training loss: 0.00007776
INFO:root:[95,   550] training loss: 0.00023725
INFO:root:[95,   600] training loss: 0.00025556
INFO:root:[95,   650] training loss: 0.00006690
INFO:root:[95,   700] training loss: 0.00003144
INFO:root:[95,   750] training loss: 0.00071199
INFO:root:[95,   800] training loss: 0.00002553
INFO:root:[95,   850] training loss: 0.00003053
INFO:root:[95,   900] training loss: 0.00771366
INFO:root:[95,   950] training loss: 0.00162811
INFO:root:[95,  1000] training loss: 0.00004044
INFO:root:[95,  1050] training loss: 0.00002669
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8899    0.8413    0.8649      1720
    Anaphase     0.6864    0.8527    0.7606      1032
          G2     0.5385    0.8750    0.6667         8
   Metaphase     0.3731    0.6849    0.4831        73
   Telophase     0.6178    0.4845    0.5431      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7464      3872
   macro avg     0.6818    0.8198    0.7312      3872
weighted avg     0.7525    0.7464    0.7436      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch95
INFO:root:[96,    50] training loss: 0.00941994
INFO:root:[96,   100] training loss: 0.01090089
INFO:root:[96,   150] training loss: 0.01056248
INFO:root:[96,   200] training loss: 0.00972841
INFO:root:[96,   250] training loss: 0.00990206
INFO:root:[96,   300] training loss: 0.01133807
INFO:root:[96,   350] training loss: 0.00895602
INFO:root:[96,   400] training loss: 0.00001601
INFO:root:[96,   450] training loss: 0.00001604
INFO:root:[96,   500] training loss: 0.00007500
INFO:root:[96,   550] training loss: 0.00022624
INFO:root:[96,   600] training loss: 0.00026440
INFO:root:[96,   650] training loss: 0.00005051
INFO:root:[96,   700] training loss: 0.00003277
INFO:root:[96,   750] training loss: 0.00065056
INFO:root:[96,   800] training loss: 0.00002208
INFO:root:[96,   850] training loss: 0.00004558
INFO:root:[96,   900] training loss: 0.00719177
INFO:root:[96,   950] training loss: 0.00237125
INFO:root:[96,  1000] training loss: 0.00004092
INFO:root:[96,  1050] training loss: 0.00003535
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8745    0.8750    0.8747      1720
    Anaphase     0.6664    0.8227    0.7363      1032
          G2     0.4444    0.5000    0.4706         8
   Metaphase     0.3053    0.7945    0.4411        73
   Telophase     0.6537    0.4236    0.5141      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.7384      3872
   macro avg     0.6016    0.7737    0.6553      3872
weighted avg     0.7481    0.7384    0.7324      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch96
INFO:root:[97,    50] training loss: 0.01070079
INFO:root:[97,   100] training loss: 0.01376054
INFO:root:[97,   150] training loss: 0.01024783
INFO:root:[97,   200] training loss: 0.01123358
INFO:root:[97,   250] training loss: 0.01173103
INFO:root:[97,   300] training loss: 0.01193283
INFO:root:[97,   350] training loss: 0.00910888
INFO:root:[97,   400] training loss: 0.00002360
INFO:root:[97,   450] training loss: 0.00001010
INFO:root:[97,   500] training loss: 0.00009455
INFO:root:[97,   550] training loss: 0.00023022
INFO:root:[97,   600] training loss: 0.00030325
INFO:root:[97,   650] training loss: 0.00004951
INFO:root:[97,   700] training loss: 0.00003559
INFO:root:[97,   750] training loss: 0.00063732
INFO:root:[97,   800] training loss: 0.00002811
INFO:root:[97,   850] training loss: 0.00003181
INFO:root:[97,   900] training loss: 0.00732060
INFO:root:[97,   950] training loss: 0.00186924
INFO:root:[97,  1000] training loss: 0.00003948
INFO:root:[97,  1050] training loss: 0.00002468
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8667    0.8884    0.8774      1720
    Anaphase     0.6793    0.8004    0.7349      1032
          G2     0.4545    0.6250    0.5263         8
   Metaphase     0.2585    0.7260    0.3813        73
   Telophase     0.6677    0.4333    0.5255      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7399      3872
   macro avg     0.6562    0.7819    0.6922      3872
weighted avg     0.7513    0.7399    0.7354      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch97
INFO:root:[98,    50] training loss: 0.01014938
INFO:root:[98,   100] training loss: 0.00950829
INFO:root:[98,   150] training loss: 0.01185261
INFO:root:[98,   200] training loss: 0.00947482
INFO:root:[98,   250] training loss: 0.01025992
INFO:root:[98,   300] training loss: 0.01249924
INFO:root:[98,   350] training loss: 0.01213171
INFO:root:[98,   400] training loss: 0.00001469
INFO:root:[98,   450] training loss: 0.00001804
INFO:root:[98,   500] training loss: 0.00009270
INFO:root:[98,   550] training loss: 0.00025688
INFO:root:[98,   600] training loss: 0.00043404
INFO:root:[98,   650] training loss: 0.00003393
INFO:root:[98,   700] training loss: 0.00002442
INFO:root:[98,   750] training loss: 0.00035635
INFO:root:[98,   800] training loss: 0.00004479
INFO:root:[98,   850] training loss: 0.00003236
INFO:root:[98,   900] training loss: 0.00779380
INFO:root:[98,   950] training loss: 0.00215620
INFO:root:[98,  1000] training loss: 0.00003922
INFO:root:[98,  1050] training loss: 0.00002549
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.8797    0.8244    0.8511      1720
    Anaphase     0.6576    0.7984    0.7212      1032
          G2     0.2800    0.8750    0.4242         8
   Metaphase     0.2350    0.5890    0.3359        73
   Telophase     0.6071    0.4662    0.5274      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7175      3872
   macro avg     0.5942    0.7219    0.6228      3872
weighted avg     0.7342    0.7175    0.7194      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch98
INFO:root:[99,    50] training loss: 0.01096050
INFO:root:[99,   100] training loss: 0.01111291
INFO:root:[99,   150] training loss: 0.01030220
INFO:root:[99,   200] training loss: 0.00962360
INFO:root:[99,   250] training loss: 0.00948757
INFO:root:[99,   300] training loss: 0.01008149
INFO:root:[99,   350] training loss: 0.00924150
INFO:root:[99,   400] training loss: 0.00001291
INFO:root:[99,   450] training loss: 0.00001290
INFO:root:[99,   500] training loss: 0.00008032
INFO:root:[99,   550] training loss: 0.00018723
INFO:root:[99,   600] training loss: 0.00030054
INFO:root:[99,   650] training loss: 0.00004112
INFO:root:[99,   700] training loss: 0.00002976
INFO:root:[99,   750] training loss: 0.00075263
INFO:root:[99,   800] training loss: 0.00001687
INFO:root:[99,   850] training loss: 0.00001958
INFO:root:[99,   900] training loss: 0.00600990
INFO:root:[99,   950] training loss: 0.00169472
INFO:root:[99,  1000] training loss: 0.00004647
INFO:root:[99,  1050] training loss: 0.00003445
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8681    0.8762    0.8721      1720
    Anaphase     0.7095    0.8072    0.7552      1032
          G2     0.5000    0.5000    0.5000         8
   Metaphase     0.3155    0.7260    0.4398        73
   Telophase     0.6465    0.4865    0.5552      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.7503      3872
   macro avg     0.6152    0.7708    0.6675      3872
weighted avg     0.7552    0.7503    0.7473      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch99
INFO:root:[100,    50] training loss: 0.00926206
INFO:root:[100,   100] training loss: 0.01181926
INFO:root:[100,   150] training loss: 0.01012092
INFO:root:[100,   200] training loss: 0.00943154
INFO:root:[100,   250] training loss: 0.00975475
INFO:root:[100,   300] training loss: 0.01118018
INFO:root:[100,   350] training loss: 0.00918927
INFO:root:[100,   400] training loss: 0.00002064
INFO:root:[100,   450] training loss: 0.00001593
INFO:root:[100,   500] training loss: 0.00038773
INFO:root:[100,   550] training loss: 0.00019872
INFO:root:[100,   600] training loss: 0.00028278
INFO:root:[100,   650] training loss: 0.00003112
INFO:root:[100,   700] training loss: 0.00003027
INFO:root:[100,   750] training loss: 0.00052340
INFO:root:[100,   800] training loss: 0.00004462
INFO:root:[100,   850] training loss: 0.00004752
INFO:root:[100,   900] training loss: 0.00767093
INFO:root:[100,   950] training loss: 0.00199737
INFO:root:[100,  1000] training loss: 0.00003843
INFO:root:[100,  1050] training loss: 0.00002875
INFO:root:              precision    recall  f1-score   support

    Prophase     0.3333    1.0000    0.5000         2
           S     0.8626    0.8942    0.8781      1720
    Anaphase     0.7101    0.8450    0.7717      1032
          G2     0.4167    0.6250    0.5000         8
   Metaphase     0.3594    0.6301    0.4577        73
   Telophase     0.6718    0.4613    0.5470      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.7601      3872
   macro avg     0.5648    0.7794    0.6292      3872
weighted avg     0.7601    0.7601    0.7523      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch100
INFO:root:[101,    50] training loss: 0.00976225
INFO:root:[101,   100] training loss: 0.00966107
INFO:root:[101,   150] training loss: 0.00937361
INFO:root:[101,   200] training loss: 0.00930412
INFO:root:[101,   250] training loss: 0.00916704
INFO:root:[101,   300] training loss: 0.00998658
INFO:root:[101,   350] training loss: 0.00910216
INFO:root:[101,   400] training loss: 0.00002461
INFO:root:[101,   450] training loss: 0.00001684
INFO:root:[101,   500] training loss: 0.00011621
INFO:root:[101,   550] training loss: 0.00013815
INFO:root:[101,   600] training loss: 0.00031624
INFO:root:[101,   650] training loss: 0.00003782
INFO:root:[101,   700] training loss: 0.00002227
INFO:root:[101,   750] training loss: 0.00064502
INFO:root:[101,   800] training loss: 0.00001814
INFO:root:[101,   850] training loss: 0.00001736
INFO:root:[101,   900] training loss: 0.00672852
INFO:root:[101,   950] training loss: 0.00229343
INFO:root:[101,  1000] training loss: 0.00003421
INFO:root:[101,  1050] training loss: 0.00002437
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8716    0.8802    0.8759      1720
    Anaphase     0.6854    0.8401    0.7549      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.3190    0.7123    0.4407        73
   Telophase     0.6566    0.4400    0.5269      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7485      3872
   macro avg     0.6892    0.7854    0.7176      3872
weighted avg     0.7536    0.7485    0.7418      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch101
INFO:root:[102,    50] training loss: 0.00907740
INFO:root:[102,   100] training loss: 0.01060833
INFO:root:[102,   150] training loss: 0.00957367
INFO:root:[102,   200] training loss: 0.00916611
INFO:root:[102,   250] training loss: 0.01130410
INFO:root:[102,   300] training loss: 0.01122350
INFO:root:[102,   350] training loss: 0.00854845
INFO:root:[102,   400] training loss: 0.00000891
INFO:root:[102,   450] training loss: 0.00000983
INFO:root:[102,   500] training loss: 0.00007404
INFO:root:[102,   550] training loss: 0.00016907
INFO:root:[102,   600] training loss: 0.00019771
INFO:root:[102,   650] training loss: 0.00004017
INFO:root:[102,   700] training loss: 0.00002921
INFO:root:[102,   750] training loss: 0.00076015
INFO:root:[102,   800] training loss: 0.00003218
INFO:root:[102,   850] training loss: 0.00002003
INFO:root:[102,   900] training loss: 0.00710066
INFO:root:[102,   950] training loss: 0.00196948
INFO:root:[102,  1000] training loss: 0.00005784
INFO:root:[102,  1050] training loss: 0.00003077
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.8583    0.9052    0.8812      1720
    Anaphase     0.7035    0.8023    0.7497      1032
          G2     0.5000    0.8750    0.6364         8
   Metaphase     0.2798    0.7397    0.4060        73
   Telophase     0.6927    0.4468    0.5432      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7523      3872
   macro avg     0.6478    0.8242    0.6976      3872
weighted avg     0.7611    0.7523    0.7464      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch102
INFO:root:[103,    50] training loss: 0.00948315
INFO:root:[103,   100] training loss: 0.00889384
INFO:root:[103,   150] training loss: 0.00924804
INFO:root:[103,   200] training loss: 0.00845967
INFO:root:[103,   250] training loss: 0.00912334
INFO:root:[103,   300] training loss: 0.01039250
INFO:root:[103,   350] training loss: 0.00856615
INFO:root:[103,   400] training loss: 0.00000872
INFO:root:[103,   450] training loss: 0.00001093
INFO:root:[103,   500] training loss: 0.00005648
INFO:root:[103,   550] training loss: 0.00018996
INFO:root:[103,   600] training loss: 0.00022346
INFO:root:[103,   650] training loss: 0.00003056
INFO:root:[103,   700] training loss: 0.00003487
INFO:root:[103,   750] training loss: 0.00061839
INFO:root:[103,   800] training loss: 0.00002179
INFO:root:[103,   850] training loss: 0.00001818
INFO:root:[103,   900] training loss: 0.00573578
INFO:root:[103,   950] training loss: 0.00173196
INFO:root:[103,  1000] training loss: 0.00003210
INFO:root:[103,  1050] training loss: 0.00002540
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8566    0.8581    0.8574      1720
    Anaphase     0.7059    0.7839    0.7429      1032
          G2     0.5000    0.2500    0.3333         8
   Metaphase     0.2663    0.6712    0.3813        73
   Telophase     0.6242    0.4884    0.5480      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7350      3872
   macro avg     0.6600    0.7217    0.6661      3872
weighted avg     0.7426    0.7350    0.7343      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch103
INFO:root:[104,    50] training loss: 0.01045561
INFO:root:[104,   100] training loss: 0.00957002
INFO:root:[104,   150] training loss: 0.00936569
INFO:root:[104,   200] training loss: 0.00827972
INFO:root:[104,   250] training loss: 0.00920762
INFO:root:[104,   300] training loss: 0.00973618
INFO:root:[104,   350] training loss: 0.00821297
INFO:root:[104,   400] training loss: 0.00001489
INFO:root:[104,   450] training loss: 0.00004099
INFO:root:[104,   500] training loss: 0.00007182
INFO:root:[104,   550] training loss: 0.00019242
INFO:root:[104,   600] training loss: 0.00022770
INFO:root:[104,   650] training loss: 0.00002625
INFO:root:[104,   700] training loss: 0.00002847
INFO:root:[104,   750] training loss: 0.00047164
INFO:root:[104,   800] training loss: 0.00002864
INFO:root:[104,   850] training loss: 0.00002424
INFO:root:[104,   900] training loss: 0.00681396
INFO:root:[104,   950] training loss: 0.00186414
INFO:root:[104,  1000] training loss: 0.00002453
INFO:root:[104,  1050] training loss: 0.00002460
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8810    0.8605    0.8706      1720
    Anaphase     0.6944    0.7994    0.7432      1032
          G2     0.4286    0.3750    0.4000         8
   Metaphase     0.2737    0.6712    0.3889        73
   Telophase     0.6416    0.5039    0.5645      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7446      3872
   macro avg     0.6551    0.7443    0.6810      3872
weighted avg     0.7549    0.7446    0.7449      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch104
INFO:root:[105,    50] training loss: 0.00919479
INFO:root:[105,   100] training loss: 0.01031209
INFO:root:[105,   150] training loss: 0.01009173
INFO:root:[105,   200] training loss: 0.00857764
INFO:root:[105,   250] training loss: 0.00957665
INFO:root:[105,   300] training loss: 0.00995519
INFO:root:[105,   350] training loss: 0.01016937
INFO:root:[105,   400] training loss: 0.00002011
INFO:root:[105,   450] training loss: 0.00002532
INFO:root:[105,   500] training loss: 0.00007674
INFO:root:[105,   550] training loss: 0.00018632
INFO:root:[105,   600] training loss: 0.00033538
INFO:root:[105,   650] training loss: 0.00003238
INFO:root:[105,   700] training loss: 0.00002652
INFO:root:[105,   750] training loss: 0.00057818
INFO:root:[105,   800] training loss: 0.00003154
INFO:root:[105,   850] training loss: 0.00002042
INFO:root:[105,   900] training loss: 0.00658861
INFO:root:[105,   950] training loss: 0.00159726
INFO:root:[105,  1000] training loss: 0.00003378
INFO:root:[105,  1050] training loss: 0.00002611
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.8742    0.8808    0.8775      1720
    Anaphase     0.7005    0.8750    0.7781      1032
          G2     0.3077    0.5000    0.3810         8
   Metaphase     0.4138    0.6575    0.5079        73
   Telophase     0.6634    0.4594    0.5429      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7616      3872
   macro avg     0.6371    0.6961    0.6553      3872
weighted avg     0.7617    0.7616    0.7536      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch105
INFO:root:[106,    50] training loss: 0.00983559
INFO:root:[106,   100] training loss: 0.00912151
INFO:root:[106,   150] training loss: 0.00970371
INFO:root:[106,   200] training loss: 0.00958338
INFO:root:[106,   250] training loss: 0.00883503
INFO:root:[106,   300] training loss: 0.00980510
INFO:root:[106,   350] training loss: 0.00853996
INFO:root:[106,   400] training loss: 0.00001002
INFO:root:[106,   450] training loss: 0.00001427
INFO:root:[106,   500] training loss: 0.00011316
INFO:root:[106,   550] training loss: 0.00024224
INFO:root:[106,   600] training loss: 0.00015683
INFO:root:[106,   650] training loss: 0.00004924
INFO:root:[106,   700] training loss: 0.00002158
INFO:root:[106,   750] training loss: 0.00045517
INFO:root:[106,   800] training loss: 0.00004826
INFO:root:[106,   850] training loss: 0.00002486
INFO:root:[106,   900] training loss: 0.00780596
INFO:root:[106,   950] training loss: 0.00197151
INFO:root:[106,  1000] training loss: 0.00003854
INFO:root:[106,  1050] training loss: 0.00002240
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8751    0.8884    0.8817      1720
    Anaphase     0.7048    0.8304    0.7625      1032
          G2     0.3333    0.5000    0.4000         8
   Metaphase     0.3205    0.6849    0.4367        73
   Telophase     0.6780    0.4826    0.5638      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7601      3872
   macro avg     0.6541    0.7695    0.6921      3872
weighted avg     0.7655    0.7601    0.7557      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch106
INFO:root:[107,    50] training loss: 0.01132981
INFO:root:[107,   100] training loss: 0.01044029
INFO:root:[107,   150] training loss: 0.00994523
INFO:root:[107,   200] training loss: 0.00996627
INFO:root:[107,   250] training loss: 0.00938797
INFO:root:[107,   300] training loss: 0.00945299
INFO:root:[107,   350] training loss: 0.00922489
INFO:root:[107,   400] training loss: 0.00001039
INFO:root:[107,   450] training loss: 0.00000965
INFO:root:[107,   500] training loss: 0.00006140
INFO:root:[107,   550] training loss: 0.00016146
INFO:root:[107,   600] training loss: 0.00025070
INFO:root:[107,   650] training loss: 0.00008581
INFO:root:[107,   700] training loss: 0.00002934
INFO:root:[107,   750] training loss: 0.00047984
INFO:root:[107,   800] training loss: 0.00003241
INFO:root:[107,   850] training loss: 0.00003273
INFO:root:[107,   900] training loss: 0.00625776
INFO:root:[107,   950] training loss: 0.00199236
INFO:root:[107,  1000] training loss: 0.00004016
INFO:root:[107,  1050] training loss: 0.00002295
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8711    0.8843    0.8777      1720
    Anaphase     0.6759    0.8285    0.7444      1032
          G2     0.5556    0.6250    0.5882         8
   Metaphase     0.2732    0.6849    0.3906        73
   Telophase     0.6641    0.4246    0.5180      1034
          G1     0.6000    1.0000    0.7500         3

    accuracy                         0.7425      3872
   macro avg     0.6152    0.7782    0.6670      3872
weighted avg     0.7516    0.7425    0.7362      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch107
INFO:root:[108,    50] training loss: 0.00867967
INFO:root:[108,   100] training loss: 0.00914163
INFO:root:[108,   150] training loss: 0.00895571
INFO:root:[108,   200] training loss: 0.00873771
INFO:root:[108,   250] training loss: 0.00925968
INFO:root:[108,   300] training loss: 0.00938462
INFO:root:[108,   350] training loss: 0.00818589
INFO:root:[108,   400] training loss: 0.00002858
INFO:root:[108,   450] training loss: 0.00008063
INFO:root:[108,   500] training loss: 0.00004919
INFO:root:[108,   550] training loss: 0.00014520
INFO:root:[108,   600] training loss: 0.00014997
INFO:root:[108,   650] training loss: 0.00004327
INFO:root:[108,   700] training loss: 0.00003812
INFO:root:[108,   750] training loss: 0.00061936
INFO:root:[108,   800] training loss: 0.00002011
INFO:root:[108,   850] training loss: 0.00002219
INFO:root:[108,   900] training loss: 0.00599138
INFO:root:[108,   950] training loss: 0.00124368
INFO:root:[108,  1000] training loss: 0.00003130
INFO:root:[108,  1050] training loss: 0.00002666
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8723    0.8895    0.8808      1720
    Anaphase     0.6961    0.8479    0.7645      1032
          G2     0.5000    0.5000    0.5000         8
   Metaphase     0.3712    0.6712    0.4780        73
   Telophase     0.6625    0.4574    0.5412      1034
          G1     0.7500    1.0000    0.8571         3

    accuracy                         0.7583      3872
   macro avg     0.6455    0.7666    0.6888      3872
weighted avg     0.7589    0.7583    0.7507      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch108
INFO:root:[109,    50] training loss: 0.00877848
INFO:root:[109,   100] training loss: 0.01246238
INFO:root:[109,   150] training loss: 0.00996804
INFO:root:[109,   200] training loss: 0.01236069
INFO:root:[109,   250] training loss: 0.01096690
INFO:root:[109,   300] training loss: 0.00987373
INFO:root:[109,   350] training loss: 0.00991948
INFO:root:[109,   400] training loss: 0.00012289
INFO:root:[109,   450] training loss: 0.00009856
INFO:root:[109,   500] training loss: 0.00016633
INFO:root:[109,   550] training loss: 0.00031369
INFO:root:[109,   600] training loss: 0.00028014
INFO:root:[109,   650] training loss: 0.00003823
INFO:root:[109,   700] training loss: 0.00002547
INFO:root:[109,   750] training loss: 0.00043792
INFO:root:[109,   800] training loss: 0.00003226
INFO:root:[109,   850] training loss: 0.00002362
INFO:root:[109,   900] training loss: 0.00595652
INFO:root:[109,   950] training loss: 0.00189977
INFO:root:[109,  1000] training loss: 0.00003114
INFO:root:[109,  1050] training loss: 0.00002032
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.8572    0.8657    0.8614      1720
    Anaphase     0.7049    0.7568    0.7299      1032
          G2     0.2222    0.2500    0.2353         8
   Metaphase     0.2318    0.6986    0.3481        73
   Telophase     0.6259    0.4807    0.5438      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7291      3872
   macro avg     0.5203    0.5788    0.5312      3872
weighted avg     0.7414    0.7291    0.7302      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch109
INFO:root:[110,    50] training loss: 0.01039206
INFO:root:[110,   100] training loss: 0.00990972
INFO:root:[110,   150] training loss: 0.00952709
INFO:root:[110,   200] training loss: 0.00819734
INFO:root:[110,   250] training loss: 0.00924261
INFO:root:[110,   300] training loss: 0.00951806
INFO:root:[110,   350] training loss: 0.00855866
INFO:root:[110,   400] training loss: 0.00001137
INFO:root:[110,   450] training loss: 0.00001185
INFO:root:[110,   500] training loss: 0.00004942
INFO:root:[110,   550] training loss: 0.00011063
INFO:root:[110,   600] training loss: 0.00028335
INFO:root:[110,   650] training loss: 0.00002376
INFO:root:[110,   700] training loss: 0.00002375
INFO:root:[110,   750] training loss: 0.00055934
INFO:root:[110,   800] training loss: 0.00002670
INFO:root:[110,   850] training loss: 0.00002669
INFO:root:[110,   900] training loss: 0.00544221
INFO:root:[110,   950] training loss: 0.00151300
INFO:root:[110,  1000] training loss: 0.00002668
INFO:root:[110,  1050] training loss: 0.00001861
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8683    0.8738    0.8711      1720
    Anaphase     0.6843    0.8169    0.7447      1032
          G2     0.5000    0.5000    0.5000         8
   Metaphase     0.2807    0.6575    0.3934        73
   Telophase     0.6464    0.4526    0.5324      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7415      3872
   macro avg     0.6638    0.7573    0.6917      3872
weighted avg     0.7481    0.7415    0.7372      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch110
INFO:root:[111,    50] training loss: 0.00916625
INFO:root:[111,   100] training loss: 0.01025127
INFO:root:[111,   150] training loss: 0.00941696
INFO:root:[111,   200] training loss: 0.00873706
INFO:root:[111,   250] training loss: 0.00905779
INFO:root:[111,   300] training loss: 0.01038993
INFO:root:[111,   350] training loss: 0.01056127
INFO:root:[111,   400] training loss: 0.00001949
INFO:root:[111,   450] training loss: 0.00001520
INFO:root:[111,   500] training loss: 0.00008554
INFO:root:[111,   550] training loss: 0.00022763
INFO:root:[111,   600] training loss: 0.00022008
INFO:root:[111,   650] training loss: 0.00003779
INFO:root:[111,   700] training loss: 0.00004230
INFO:root:[111,   750] training loss: 0.00046475
INFO:root:[111,   800] training loss: 0.00001993
INFO:root:[111,   850] training loss: 0.00002628
INFO:root:[111,   900] training loss: 0.00728168
INFO:root:[111,   950] training loss: 0.00160168
INFO:root:[111,  1000] training loss: 0.00004361
INFO:root:[111,  1050] training loss: 0.00002490
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.8800    0.8872    0.8836      1720
    Anaphase     0.6938    0.8430    0.7612      1032
          G2     0.4167    0.6250    0.5000         8
   Metaphase     0.3311    0.6712    0.4434        73
   Telophase     0.6722    0.4662    0.5505      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7585      3872
   macro avg     0.6420    0.7847    0.6865      3872
weighted avg     0.7635    0.7585    0.7529      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch111
INFO:root:[112,    50] training loss: 0.00902128
INFO:root:[112,   100] training loss: 0.00970507
INFO:root:[112,   150] training loss: 0.01048848
INFO:root:[112,   200] training loss: 0.01065213
INFO:root:[112,   250] training loss: 0.01070132
INFO:root:[112,   300] training loss: 0.00905856
INFO:root:[112,   350] training loss: 0.00875202
INFO:root:[112,   400] training loss: 0.00005468
INFO:root:[112,   450] training loss: 0.00002462
INFO:root:[112,   500] training loss: 0.00006357
INFO:root:[112,   550] training loss: 0.00020205
INFO:root:[112,   600] training loss: 0.00027364
INFO:root:[112,   650] training loss: 0.00001850
INFO:root:[112,   700] training loss: 0.00002937
INFO:root:[112,   750] training loss: 0.00045751
INFO:root:[112,   800] training loss: 0.00002330
INFO:root:[112,   850] training loss: 0.00002431
INFO:root:[112,   900] training loss: 0.00652799
INFO:root:[112,   950] training loss: 0.00177513
INFO:root:[112,  1000] training loss: 0.00002348
INFO:root:[112,  1050] training loss: 0.00001589
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8766    0.8552    0.8658      1720
    Anaphase     0.6834    0.8178    0.7446      1032
          G2     0.4286    0.3750    0.4000         8
   Metaphase     0.2802    0.6986    0.4000        73
   Telophase     0.6126    0.4526    0.5206      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7340      3872
   macro avg     0.6497    0.7428    0.6759      3872
weighted avg     0.7424    0.7340    0.7316      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch112
INFO:root:[113,    50] training loss: 0.00921774
INFO:root:[113,   100] training loss: 0.00901898
INFO:root:[113,   150] training loss: 0.00971109
INFO:root:[113,   200] training loss: 0.00873463
INFO:root:[113,   250] training loss: 0.01070840
INFO:root:[113,   300] training loss: 0.01003085
INFO:root:[113,   350] training loss: 0.00958412
INFO:root:[113,   400] training loss: 0.00005222
INFO:root:[113,   450] training loss: 0.00001452
INFO:root:[113,   500] training loss: 0.00008651
INFO:root:[113,   550] training loss: 0.00021992
INFO:root:[113,   600] training loss: 0.00023047
INFO:root:[113,   650] training loss: 0.00003389
INFO:root:[113,   700] training loss: 0.00005516
INFO:root:[113,   750] training loss: 0.00060482
INFO:root:[113,   800] training loss: 0.00004008
INFO:root:[113,   850] training loss: 0.00002866
INFO:root:[113,   900] training loss: 0.00598106
INFO:root:[113,   950] training loss: 0.00183492
INFO:root:[113,  1000] training loss: 0.00003675
INFO:root:[113,  1050] training loss: 0.00002376
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8718    0.8581    0.8649      1720
    Anaphase     0.6976    0.8091    0.7492      1032
          G2     0.3333    0.6250    0.4348         8
   Metaphase     0.2930    0.6301    0.4000        73
   Telophase     0.6182    0.4807    0.5408      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7397      3872
   macro avg     0.6401    0.7719    0.6842      3872
weighted avg     0.7456    0.7397    0.7379      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch113
INFO:root:[114,    50] training loss: 0.00917805
INFO:root:[114,   100] training loss: 0.00874733
INFO:root:[114,   150] training loss: 0.01151302
INFO:root:[114,   200] training loss: 0.00778405
INFO:root:[114,   250] training loss: 0.00833878
INFO:root:[114,   300] training loss: 0.00839876
INFO:root:[114,   350] training loss: 0.00692590
INFO:root:[114,   400] training loss: 0.00000796
INFO:root:[114,   450] training loss: 0.00014736
INFO:root:[114,   500] training loss: 0.00006126
INFO:root:[114,   550] training loss: 0.00022262
INFO:root:[114,   600] training loss: 0.00040171
INFO:root:[114,   650] training loss: 0.00005014
INFO:root:[114,   700] training loss: 0.00006858
INFO:root:[114,   750] training loss: 0.00181945
INFO:root:[114,   800] training loss: 0.00057777
INFO:root:[114,   850] training loss: 0.00045808
INFO:root:[114,   900] training loss: 0.00530511
INFO:root:[114,   950] training loss: 0.00123125
INFO:root:[114,  1000] training loss: 0.00001472
INFO:root:[114,  1050] training loss: 0.00001712
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8859    0.8622    0.8739      1720
    Anaphase     0.7707    0.8304    0.7994      1032
          G2     0.5000    0.5000    0.5000         8
   Metaphase     0.4500    0.6164    0.5202        73
   Telophase     0.6481    0.6093    0.6281      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7810      3872
   macro avg     0.7031    0.7741    0.7317      3872
weighted avg     0.7827    0.7810    0.7810      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch114
INFO:root:[115,    50] training loss: 0.00873315
INFO:root:[115,   100] training loss: 0.00819652
INFO:root:[115,   150] training loss: 0.00916119
INFO:root:[115,   200] training loss: 0.00745981
INFO:root:[115,   250] training loss: 0.00775375
INFO:root:[115,   300] training loss: 0.00917411
INFO:root:[115,   350] training loss: 0.00721222
INFO:root:[115,   400] training loss: 0.00000786
INFO:root:[115,   450] training loss: 0.00000825
INFO:root:[115,   500] training loss: 0.00002459
INFO:root:[115,   550] training loss: 0.00023743
INFO:root:[115,   600] training loss: 0.00030631
INFO:root:[115,   650] training loss: 0.00003140
INFO:root:[115,   700] training loss: 0.00003207
INFO:root:[115,   750] training loss: 0.00106058
INFO:root:[115,   800] training loss: 0.00028950
INFO:root:[115,   850] training loss: 0.00041954
INFO:root:[115,   900] training loss: 0.00418589
INFO:root:[115,   950] training loss: 0.00111192
INFO:root:[115,  1000] training loss: 0.00001760
INFO:root:[115,  1050] training loss: 0.00002121
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8816    0.8703    0.8760      1720
    Anaphase     0.7745    0.8256    0.7992      1032
          G2     0.4286    0.3750    0.4000         8
   Metaphase     0.4340    0.6301    0.5140        73
   Telophase     0.6534    0.6035    0.6275      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7818      3872
   macro avg     0.6913    0.7578    0.7167      3872
weighted avg     0.7827    0.7818    0.7814      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch115
INFO:root:[116,    50] training loss: 0.00802295
INFO:root:[116,   100] training loss: 0.00784744
INFO:root:[116,   150] training loss: 0.00762441
INFO:root:[116,   200] training loss: 0.00740870
INFO:root:[116,   250] training loss: 0.00729133
INFO:root:[116,   300] training loss: 0.00814794
INFO:root:[116,   350] training loss: 0.00721994
INFO:root:[116,   400] training loss: 0.00000559
INFO:root:[116,   450] training loss: 0.00000720
INFO:root:[116,   500] training loss: 0.00004825
INFO:root:[116,   550] training loss: 0.00019854
INFO:root:[116,   600] training loss: 0.00024110
INFO:root:[116,   650] training loss: 0.00002506
INFO:root:[116,   700] training loss: 0.00002042
INFO:root:[116,   750] training loss: 0.00073766
INFO:root:[116,   800] training loss: 0.00021326
INFO:root:[116,   850] training loss: 0.00024792
INFO:root:[116,   900] training loss: 0.00419196
INFO:root:[116,   950] training loss: 0.00118103
INFO:root:[116,  1000] training loss: 0.00003737
INFO:root:[116,  1050] training loss: 0.00003583
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8809    0.8727    0.8768      1720
    Anaphase     0.7847    0.8159    0.8000      1032
          G2     0.5000    0.3750    0.4286         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6581    0.6180    0.6374      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7846      3872
   macro avg     0.7027    0.7627    0.7231      3872
weighted avg     0.7864    0.7846    0.7848      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch116
INFO:root:[117,    50] training loss: 0.00808278
INFO:root:[117,   100] training loss: 0.00790985
INFO:root:[117,   150] training loss: 0.00822249
INFO:root:[117,   200] training loss: 0.00734264
INFO:root:[117,   250] training loss: 0.00780583
INFO:root:[117,   300] training loss: 0.00806841
INFO:root:[117,   350] training loss: 0.00668195
INFO:root:[117,   400] training loss: 0.00000647
INFO:root:[117,   450] training loss: 0.00000713
INFO:root:[117,   500] training loss: 0.00003840
INFO:root:[117,   550] training loss: 0.00018362
INFO:root:[117,   600] training loss: 0.00026418
INFO:root:[117,   650] training loss: 0.00001942
INFO:root:[117,   700] training loss: 0.00001991
INFO:root:[117,   750] training loss: 0.00059496
INFO:root:[117,   800] training loss: 0.00025238
INFO:root:[117,   850] training loss: 0.00024895
INFO:root:[117,   900] training loss: 0.00413393
INFO:root:[117,   950] training loss: 0.00117773
INFO:root:[117,  1000] training loss: 0.00001525
INFO:root:[117,  1050] training loss: 0.00001642
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8828    0.8587    0.8706      1720
    Anaphase     0.7799    0.8140    0.7966      1032
          G2     0.5714    0.5000    0.5333         8
   Metaphase     0.4375    0.6712    0.5297        73
   Telophase     0.6409    0.6180    0.6292      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7784      3872
   macro avg     0.7113    0.7803    0.7371      3872
weighted avg     0.7818    0.7784    0.7794      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch117
INFO:root:[118,    50] training loss: 0.00794500
INFO:root:[118,   100] training loss: 0.00806807
INFO:root:[118,   150] training loss: 0.00755754
INFO:root:[118,   200] training loss: 0.00728199
INFO:root:[118,   250] training loss: 0.00690167
INFO:root:[118,   300] training loss: 0.00800780
INFO:root:[118,   350] training loss: 0.00694390
INFO:root:[118,   400] training loss: 0.00000602
INFO:root:[118,   450] training loss: 0.00000764
INFO:root:[118,   500] training loss: 0.00002911
INFO:root:[118,   550] training loss: 0.00018347
INFO:root:[118,   600] training loss: 0.00028410
INFO:root:[118,   650] training loss: 0.00002007
INFO:root:[118,   700] training loss: 0.00001825
INFO:root:[118,   750] training loss: 0.00060651
INFO:root:[118,   800] training loss: 0.00023390
INFO:root:[118,   850] training loss: 0.00022053
INFO:root:[118,   900] training loss: 0.00433455
INFO:root:[118,   950] training loss: 0.00186728
INFO:root:[118,  1000] training loss: 0.00001589
INFO:root:[118,  1050] training loss: 0.00001975
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8801    0.8750    0.8776      1720
    Anaphase     0.7869    0.8014    0.7940      1032
          G2     0.5714    0.5000    0.5333         8
   Metaphase     0.4537    0.6712    0.5414        73
   Telophase     0.6505    0.6228    0.6364      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7836      3872
   macro avg     0.7156    0.7815    0.7404      3872
weighted avg     0.7853    0.7836    0.7839      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch118
INFO:root:[119,    50] training loss: 0.00781476
INFO:root:[119,   100] training loss: 0.00823135
INFO:root:[119,   150] training loss: 0.00811823
INFO:root:[119,   200] training loss: 0.00692565
INFO:root:[119,   250] training loss: 0.00716504
INFO:root:[119,   300] training loss: 0.00770954
INFO:root:[119,   350] training loss: 0.00670852
INFO:root:[119,   400] training loss: 0.00000550
INFO:root:[119,   450] training loss: 0.00000708
INFO:root:[119,   500] training loss: 0.00004196
INFO:root:[119,   550] training loss: 0.00021165
INFO:root:[119,   600] training loss: 0.00019541
INFO:root:[119,   650] training loss: 0.00001681
INFO:root:[119,   700] training loss: 0.00001841
INFO:root:[119,   750] training loss: 0.00043284
INFO:root:[119,   800] training loss: 0.00026102
INFO:root:[119,   850] training loss: 0.00023439
INFO:root:[119,   900] training loss: 0.00462755
INFO:root:[119,   950] training loss: 0.00127854
INFO:root:[119,  1000] training loss: 0.00002041
INFO:root:[119,  1050] training loss: 0.00001633
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8806    0.8616    0.8710      1720
    Anaphase     0.7850    0.8033    0.7941      1032
          G2     0.5714    0.5000    0.5333         8
   Metaphase     0.4364    0.6575    0.5246        73
   Telophase     0.6386    0.6238    0.6311      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7782      3872
   macro avg     0.7112    0.7780    0.7363      3872
weighted avg     0.7815    0.7782    0.7793      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch119
INFO:root:[120,    50] training loss: 0.00764407
INFO:root:[120,   100] training loss: 0.00750730
INFO:root:[120,   150] training loss: 0.00749482
INFO:root:[120,   200] training loss: 0.00689361
INFO:root:[120,   250] training loss: 0.00707660
INFO:root:[120,   300] training loss: 0.00968919
INFO:root:[120,   350] training loss: 0.00633334
INFO:root:[120,   400] training loss: 0.00000550
INFO:root:[120,   450] training loss: 0.00000636
INFO:root:[120,   500] training loss: 0.00006034
INFO:root:[120,   550] training loss: 0.00019286
INFO:root:[120,   600] training loss: 0.00018929
INFO:root:[120,   650] training loss: 0.00001602
INFO:root:[120,   700] training loss: 0.00001500
INFO:root:[120,   750] training loss: 0.00037153
INFO:root:[120,   800] training loss: 0.00025298
INFO:root:[120,   850] training loss: 0.00016703
INFO:root:[120,   900] training loss: 0.00371117
INFO:root:[120,   950] training loss: 0.00156739
INFO:root:[120,  1000] training loss: 0.00001659
INFO:root:[120,  1050] training loss: 0.00001676
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8811    0.8657    0.8733      1720
    Anaphase     0.7891    0.8014    0.7952      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4103    0.6575    0.5053        73
   Telophase     0.6520    0.6325    0.6421      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7820      3872
   macro avg     0.7177    0.7974    0.7487      3872
weighted avg     0.7860    0.7820    0.7834      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch120
INFO:root:[121,    50] training loss: 0.00746785
INFO:root:[121,   100] training loss: 0.00758988
INFO:root:[121,   150] training loss: 0.00802332
INFO:root:[121,   200] training loss: 0.00756069
INFO:root:[121,   250] training loss: 0.00708785
INFO:root:[121,   300] training loss: 0.00763502
INFO:root:[121,   350] training loss: 0.00628474
INFO:root:[121,   400] training loss: 0.00000605
INFO:root:[121,   450] training loss: 0.00000710
INFO:root:[121,   500] training loss: 0.00004966
INFO:root:[121,   550] training loss: 0.00019798
INFO:root:[121,   600] training loss: 0.00017965
INFO:root:[121,   650] training loss: 0.00001601
INFO:root:[121,   700] training loss: 0.00001632
INFO:root:[121,   750] training loss: 0.00043870
INFO:root:[121,   800] training loss: 0.00023297
INFO:root:[121,   850] training loss: 0.00016379
INFO:root:[121,   900] training loss: 0.00411168
INFO:root:[121,   950] training loss: 0.00171307
INFO:root:[121,  1000] training loss: 0.00001625
INFO:root:[121,  1050] training loss: 0.00001876
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8793    0.8552    0.8671      1720
    Anaphase     0.7839    0.7907    0.7873      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4087    0.6438    0.5000        73
   Telophase     0.6288    0.6257    0.6272      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7725      3872
   macro avg     0.7132    0.7915    0.7438      3872
weighted avg     0.7775    0.7725    0.7744      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch121
INFO:root:[122,    50] training loss: 0.00761066
INFO:root:[122,   100] training loss: 0.00771235
INFO:root:[122,   150] training loss: 0.00756643
INFO:root:[122,   200] training loss: 0.00669229
INFO:root:[122,   250] training loss: 0.00688608
INFO:root:[122,   300] training loss: 0.00816891
INFO:root:[122,   350] training loss: 0.00682268
INFO:root:[122,   400] training loss: 0.00000561
INFO:root:[122,   450] training loss: 0.00000748
INFO:root:[122,   500] training loss: 0.00002304
INFO:root:[122,   550] training loss: 0.00017690
INFO:root:[122,   600] training loss: 0.00017531
INFO:root:[122,   650] training loss: 0.00001913
INFO:root:[122,   700] training loss: 0.00001312
INFO:root:[122,   750] training loss: 0.00039786
INFO:root:[122,   800] training loss: 0.00017934
INFO:root:[122,   850] training loss: 0.00020354
INFO:root:[122,   900] training loss: 0.00367871
INFO:root:[122,   950] training loss: 0.00187057
INFO:root:[122,  1000] training loss: 0.00002091
INFO:root:[122,  1050] training loss: 0.00002486
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8788    0.8727    0.8757      1720
    Anaphase     0.7998    0.7897    0.7947      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4444    0.6575    0.5304        73
   Telophase     0.6471    0.6402    0.6437      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7841      3872
   macro avg     0.7231    0.7979    0.7528      3872
weighted avg     0.7871    0.7841    0.7852      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch122
INFO:root:[123,    50] training loss: 0.00751769
INFO:root:[123,   100] training loss: 0.00803180
INFO:root:[123,   150] training loss: 0.00745242
INFO:root:[123,   200] training loss: 0.00741406
INFO:root:[123,   250] training loss: 0.00797562
INFO:root:[123,   300] training loss: 0.00769490
INFO:root:[123,   350] training loss: 0.00704023
INFO:root:[123,   400] training loss: 0.00000634
INFO:root:[123,   450] training loss: 0.00000876
INFO:root:[123,   500] training loss: 0.00002426
INFO:root:[123,   550] training loss: 0.00016969
INFO:root:[123,   600] training loss: 0.00013818
INFO:root:[123,   650] training loss: 0.00001526
INFO:root:[123,   700] training loss: 0.00001639
INFO:root:[123,   750] training loss: 0.00056015
INFO:root:[123,   800] training loss: 0.00025773
INFO:root:[123,   850] training loss: 0.00014570
INFO:root:[123,   900] training loss: 0.00489141
INFO:root:[123,   950] training loss: 0.00123101
INFO:root:[123,  1000] training loss: 0.00001718
INFO:root:[123,  1050] training loss: 0.00002529
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8832    0.8488    0.8657      1720
    Anaphase     0.7834    0.8062    0.7947      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4103    0.6575    0.5053        73
   Telophase     0.6306    0.6257    0.6282      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7740      3872
   macro avg     0.7142    0.7948    0.7455      3872
weighted avg     0.7797    0.7740    0.7761      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch123
INFO:root:[124,    50] training loss: 0.00794866
INFO:root:[124,   100] training loss: 0.00751368
INFO:root:[124,   150] training loss: 0.00720343
INFO:root:[124,   200] training loss: 0.00697759
INFO:root:[124,   250] training loss: 0.00699442
INFO:root:[124,   300] training loss: 0.00770800
INFO:root:[124,   350] training loss: 0.00626233
INFO:root:[124,   400] training loss: 0.00000639
INFO:root:[124,   450] training loss: 0.00000729
INFO:root:[124,   500] training loss: 0.00005889
INFO:root:[124,   550] training loss: 0.00017195
INFO:root:[124,   600] training loss: 0.00018430
INFO:root:[124,   650] training loss: 0.00001505
INFO:root:[124,   700] training loss: 0.00001330
INFO:root:[124,   750] training loss: 0.00050286
INFO:root:[124,   800] training loss: 0.00016991
INFO:root:[124,   850] training loss: 0.00011744
INFO:root:[124,   900] training loss: 0.00385789
INFO:root:[124,   950] training loss: 0.00084525
INFO:root:[124,  1000] training loss: 0.00001964
INFO:root:[124,  1050] training loss: 0.00001572
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8824    0.8552    0.8686      1720
    Anaphase     0.7840    0.7984    0.7912      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4098    0.6849    0.5128        73
   Telophase     0.6356    0.6257    0.6306      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7753      3872
   macro avg     0.7148    0.7985    0.7469      3872
weighted avg     0.7808    0.7753    0.7773      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch124
INFO:root:[125,    50] training loss: 0.00780592
INFO:root:[125,   100] training loss: 0.00728962
INFO:root:[125,   150] training loss: 0.00776893
INFO:root:[125,   200] training loss: 0.00689188
INFO:root:[125,   250] training loss: 0.00814281
INFO:root:[125,   300] training loss: 0.00822120
INFO:root:[125,   350] training loss: 0.00591162
INFO:root:[125,   400] training loss: 0.00000675
INFO:root:[125,   450] training loss: 0.00000808
INFO:root:[125,   500] training loss: 0.00001880
INFO:root:[125,   550] training loss: 0.00017789
INFO:root:[125,   600] training loss: 0.00020292
INFO:root:[125,   650] training loss: 0.00001553
INFO:root:[125,   700] training loss: 0.00001573
INFO:root:[125,   750] training loss: 0.00037112
INFO:root:[125,   800] training loss: 0.00048537
INFO:root:[125,   850] training loss: 0.00051763
INFO:root:[125,   900] training loss: 0.00333112
INFO:root:[125,   950] training loss: 0.00108966
INFO:root:[125,  1000] training loss: 0.00001595
INFO:root:[125,  1050] training loss: 0.00001559
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8905    0.8320    0.8602      1720
    Anaphase     0.7857    0.7994    0.7925      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4202    0.6849    0.5208        73
   Telophase     0.6155    0.6441    0.6295      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7148    0.7979    0.7469      3872
weighted avg     0.7797    0.7701    0.7738      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch125
INFO:root:[126,    50] training loss: 0.00835241
INFO:root:[126,   100] training loss: 0.00762103
INFO:root:[126,   150] training loss: 0.00726985
INFO:root:[126,   200] training loss: 0.00723809
INFO:root:[126,   250] training loss: 0.00683054
INFO:root:[126,   300] training loss: 0.00829902
INFO:root:[126,   350] training loss: 0.00635189
INFO:root:[126,   400] training loss: 0.00000627
INFO:root:[126,   450] training loss: 0.00000955
INFO:root:[126,   500] training loss: 0.00002966
INFO:root:[126,   550] training loss: 0.00015114
INFO:root:[126,   600] training loss: 0.00020914
INFO:root:[126,   650] training loss: 0.00001480
INFO:root:[126,   700] training loss: 0.00001614
INFO:root:[126,   750] training loss: 0.00031178
INFO:root:[126,   800] training loss: 0.00058158
INFO:root:[126,   850] training loss: 0.00036686
INFO:root:[126,   900] training loss: 0.00327828
INFO:root:[126,   950] training loss: 0.00113360
INFO:root:[126,  1000] training loss: 0.00001658
INFO:root:[126,  1050] training loss: 0.00001566
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8930    0.8297    0.8602      1720
    Anaphase     0.7886    0.8023    0.7954      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4138    0.6575    0.5079        73
   Telophase     0.6170    0.6528    0.6344      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7717      3872
   macro avg     0.7149    0.7953    0.7461      3872
weighted avg     0.7818    0.7717    0.7756      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch126
INFO:root:[127,    50] training loss: 0.00726956
INFO:root:[127,   100] training loss: 0.00749325
INFO:root:[127,   150] training loss: 0.00722203
INFO:root:[127,   200] training loss: 0.00692479
INFO:root:[127,   250] training loss: 0.00742697
INFO:root:[127,   300] training loss: 0.00734488
INFO:root:[127,   350] training loss: 0.00572356
INFO:root:[127,   400] training loss: 0.00000647
INFO:root:[127,   450] training loss: 0.00000771
INFO:root:[127,   500] training loss: 0.00003697
INFO:root:[127,   550] training loss: 0.00015786
INFO:root:[127,   600] training loss: 0.00014814
INFO:root:[127,   650] training loss: 0.00001482
INFO:root:[127,   700] training loss: 0.00001549
INFO:root:[127,   750] training loss: 0.00043199
INFO:root:[127,   800] training loss: 0.00027700
INFO:root:[127,   850] training loss: 0.00032801
INFO:root:[127,   900] training loss: 0.00381864
INFO:root:[127,   950] training loss: 0.00125981
INFO:root:[127,  1000] training loss: 0.00001594
INFO:root:[127,  1050] training loss: 0.00001510
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8925    0.8250    0.8574      1720
    Anaphase     0.7888    0.8033    0.7960      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4248    0.6575    0.5161        73
   Telophase     0.6114    0.6528    0.6314      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7156    0.7948    0.7466      3872
weighted avg     0.7804    0.7699    0.7738      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch127
INFO:root:[128,    50] training loss: 0.00695231
INFO:root:[128,   100] training loss: 0.00746473
INFO:root:[128,   150] training loss: 0.00723682
INFO:root:[128,   200] training loss: 0.00697737
INFO:root:[128,   250] training loss: 0.00688359
INFO:root:[128,   300] training loss: 0.00765692
INFO:root:[128,   350] training loss: 0.00649087
INFO:root:[128,   400] training loss: 0.00000658
INFO:root:[128,   450] training loss: 0.00000795
INFO:root:[128,   500] training loss: 0.00002052
INFO:root:[128,   550] training loss: 0.00015819
INFO:root:[128,   600] training loss: 0.00010472
INFO:root:[128,   650] training loss: 0.00001417
INFO:root:[128,   700] training loss: 0.00001378
INFO:root:[128,   750] training loss: 0.00019217
INFO:root:[128,   800] training loss: 0.00025646
INFO:root:[128,   850] training loss: 0.00028151
INFO:root:[128,   900] training loss: 0.00364837
INFO:root:[128,   950] training loss: 0.00100598
INFO:root:[128,  1000] training loss: 0.00001719
INFO:root:[128,  1050] training loss: 0.00001945
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8914    0.8256    0.8572      1720
    Anaphase     0.7919    0.8004    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4211    0.6575    0.5134        73
   Telophase     0.6119    0.6557    0.6331      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7154    0.7949    0.7464      3872
weighted avg     0.7808    0.7701    0.7742      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch128
INFO:root:[129,    50] training loss: 0.00725604
INFO:root:[129,   100] training loss: 0.00705747
INFO:root:[129,   150] training loss: 0.00684036
INFO:root:[129,   200] training loss: 0.00676109
INFO:root:[129,   250] training loss: 0.00735215
INFO:root:[129,   300] training loss: 0.00726093
INFO:root:[129,   350] training loss: 0.00611328
INFO:root:[129,   400] training loss: 0.00000595
INFO:root:[129,   450] training loss: 0.00000844
INFO:root:[129,   500] training loss: 0.00011704
INFO:root:[129,   550] training loss: 0.00016793
INFO:root:[129,   600] training loss: 0.00013309
INFO:root:[129,   650] training loss: 0.00001560
INFO:root:[129,   700] training loss: 0.00001596
INFO:root:[129,   750] training loss: 0.00035135
INFO:root:[129,   800] training loss: 0.00033838
INFO:root:[129,   850] training loss: 0.00025444
INFO:root:[129,   900] training loss: 0.00381747
INFO:root:[129,   950] training loss: 0.00094183
INFO:root:[129,  1000] training loss: 0.00001615
INFO:root:[129,  1050] training loss: 0.00001826
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8931    0.8256    0.8580      1720
    Anaphase     0.7894    0.7955    0.7925      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4174    0.6575    0.5106        73
   Telophase     0.6101    0.6567    0.6325      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7691      3872
   macro avg     0.7145    0.7943    0.7455      3872
weighted avg     0.7803    0.7691    0.7734      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch129
INFO:root:[130,    50] training loss: 0.00725985
INFO:root:[130,   100] training loss: 0.00741057
INFO:root:[130,   150] training loss: 0.00665445
INFO:root:[130,   200] training loss: 0.00692499
INFO:root:[130,   250] training loss: 0.00701259
INFO:root:[130,   300] training loss: 0.00748264
INFO:root:[130,   350] training loss: 0.00629035
INFO:root:[130,   400] training loss: 0.00000604
INFO:root:[130,   450] training loss: 0.00000836
INFO:root:[130,   500] training loss: 0.00004040
INFO:root:[130,   550] training loss: 0.00016344
INFO:root:[130,   600] training loss: 0.00014440
INFO:root:[130,   650] training loss: 0.00001442
INFO:root:[130,   700] training loss: 0.00001375
INFO:root:[130,   750] training loss: 0.00027369
INFO:root:[130,   800] training loss: 0.00022465
INFO:root:[130,   850] training loss: 0.00027935
INFO:root:[130,   900] training loss: 0.00367007
INFO:root:[130,   950] training loss: 0.00106271
INFO:root:[130,  1000] training loss: 0.00001984
INFO:root:[130,  1050] training loss: 0.00001651
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8921    0.8267    0.8582      1720
    Anaphase     0.7921    0.7975    0.7948      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4211    0.6575    0.5134        73
   Telophase     0.6121    0.6576    0.6340      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7704      3872
   macro avg     0.7156    0.7949    0.7465      3872
weighted avg     0.7812    0.7704    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch130
INFO:root:[131,    50] training loss: 0.00806095
INFO:root:[131,   100] training loss: 0.00732526
INFO:root:[131,   150] training loss: 0.00685142
INFO:root:[131,   200] training loss: 0.00676345
INFO:root:[131,   250] training loss: 0.00721713
INFO:root:[131,   300] training loss: 0.00722875
INFO:root:[131,   350] training loss: 0.00640000
INFO:root:[131,   400] training loss: 0.00000748
INFO:root:[131,   450] training loss: 0.00000665
INFO:root:[131,   500] training loss: 0.00003369
INFO:root:[131,   550] training loss: 0.00021453
INFO:root:[131,   600] training loss: 0.00016852
INFO:root:[131,   650] training loss: 0.00001636
INFO:root:[131,   700] training loss: 0.00001536
INFO:root:[131,   750] training loss: 0.00027008
INFO:root:[131,   800] training loss: 0.00029018
INFO:root:[131,   850] training loss: 0.00022760
INFO:root:[131,   900] training loss: 0.00367173
INFO:root:[131,   950] training loss: 0.00106102
INFO:root:[131,  1000] training loss: 0.00001525
INFO:root:[131,  1050] training loss: 0.00001560
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8908    0.8297    0.8591      1720
    Anaphase     0.7938    0.7984    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6139    0.6567    0.6346      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7717      3872
   macro avg     0.7170    0.7953    0.7477      3872
weighted avg     0.7817    0.7717    0.7756      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch131
INFO:root:[132,    50] training loss: 0.00782179
INFO:root:[132,   100] training loss: 0.00731661
INFO:root:[132,   150] training loss: 0.00664753
INFO:root:[132,   200] training loss: 0.00651699
INFO:root:[132,   250] training loss: 0.00825685
INFO:root:[132,   300] training loss: 0.00727857
INFO:root:[132,   350] training loss: 0.00616418
INFO:root:[132,   400] training loss: 0.00000556
INFO:root:[132,   450] training loss: 0.00000770
INFO:root:[132,   500] training loss: 0.00002269
INFO:root:[132,   550] training loss: 0.00021895
INFO:root:[132,   600] training loss: 0.00015857
INFO:root:[132,   650] training loss: 0.00001452
INFO:root:[132,   700] training loss: 0.00001444
INFO:root:[132,   750] training loss: 0.00029324
INFO:root:[132,   800] training loss: 0.00028114
INFO:root:[132,   850] training loss: 0.00035963
INFO:root:[132,   900] training loss: 0.00320834
INFO:root:[132,   950] training loss: 0.00146643
INFO:root:[132,  1000] training loss: 0.00001415
INFO:root:[132,  1050] training loss: 0.00001499
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8917    0.8279    0.8586      1720
    Anaphase     0.7927    0.8004    0.7965      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4248    0.6575    0.5161        73
   Telophase     0.6139    0.6567    0.6346      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7714      3872
   macro avg     0.7164    0.7954    0.7473      3872
weighted avg     0.7817    0.7714    0.7754      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch132
INFO:root:[133,    50] training loss: 0.00756797
INFO:root:[133,   100] training loss: 0.00735925
INFO:root:[133,   150] training loss: 0.00703615
INFO:root:[133,   200] training loss: 0.00669776
INFO:root:[133,   250] training loss: 0.00693079
INFO:root:[133,   300] training loss: 0.00726027
INFO:root:[133,   350] training loss: 0.00628301
INFO:root:[133,   400] training loss: 0.00000654
INFO:root:[133,   450] training loss: 0.00000698
INFO:root:[133,   500] training loss: 0.00003812
INFO:root:[133,   550] training loss: 0.00015643
INFO:root:[133,   600] training loss: 0.00014444
INFO:root:[133,   650] training loss: 0.00001411
INFO:root:[133,   700] training loss: 0.00001419
INFO:root:[133,   750] training loss: 0.00029276
INFO:root:[133,   800] training loss: 0.00020537
INFO:root:[133,   850] training loss: 0.00033664
INFO:root:[133,   900] training loss: 0.00348331
INFO:root:[133,   950] training loss: 0.00138966
INFO:root:[133,  1000] training loss: 0.00001526
INFO:root:[133,  1050] training loss: 0.00002179
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8903    0.8302    0.8592      1720
    Anaphase     0.7963    0.7955    0.7959      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6139    0.6596    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7720      3872
   macro avg     0.7172    0.7954    0.7479      3872
weighted avg     0.7821    0.7720    0.7759      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch133
INFO:root:[134,    50] training loss: 0.00724039
INFO:root:[134,   100] training loss: 0.00702387
INFO:root:[134,   150] training loss: 0.00766171
INFO:root:[134,   200] training loss: 0.00677080
INFO:root:[134,   250] training loss: 0.00688699
INFO:root:[134,   300] training loss: 0.00725397
INFO:root:[134,   350] training loss: 0.00671931
INFO:root:[134,   400] training loss: 0.00000605
INFO:root:[134,   450] training loss: 0.00000781
INFO:root:[134,   500] training loss: 0.00002740
INFO:root:[134,   550] training loss: 0.00016202
INFO:root:[134,   600] training loss: 0.00021539
INFO:root:[134,   650] training loss: 0.00001289
INFO:root:[134,   700] training loss: 0.00001355
INFO:root:[134,   750] training loss: 0.00018754
INFO:root:[134,   800] training loss: 0.00027695
INFO:root:[134,   850] training loss: 0.00028914
INFO:root:[134,   900] training loss: 0.00311522
INFO:root:[134,   950] training loss: 0.00127163
INFO:root:[134,  1000] training loss: 0.00001678
INFO:root:[134,  1050] training loss: 0.00001875
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8924    0.8244    0.8571      1720
    Anaphase     0.7929    0.7975    0.7952      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6095    0.6596    0.6335      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7164    0.7949    0.7471      3872
weighted avg     0.7810    0.7699    0.7741      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch134
INFO:root:[135,    50] training loss: 0.00679395
INFO:root:[135,   100] training loss: 0.00770242
INFO:root:[135,   150] training loss: 0.00721323
INFO:root:[135,   200] training loss: 0.00643085
INFO:root:[135,   250] training loss: 0.00690961
INFO:root:[135,   300] training loss: 0.00710880
INFO:root:[135,   350] training loss: 0.00631721
INFO:root:[135,   400] training loss: 0.00000593
INFO:root:[135,   450] training loss: 0.00000981
INFO:root:[135,   500] training loss: 0.00002620
INFO:root:[135,   550] training loss: 0.00018332
INFO:root:[135,   600] training loss: 0.00023329
INFO:root:[135,   650] training loss: 0.00001418
INFO:root:[135,   700] training loss: 0.00001421
INFO:root:[135,   750] training loss: 0.00032779
INFO:root:[135,   800] training loss: 0.00025509
INFO:root:[135,   850] training loss: 0.00021124
INFO:root:[135,   900] training loss: 0.00399188
INFO:root:[135,   950] training loss: 0.00172463
INFO:root:[135,  1000] training loss: 0.00001724
INFO:root:[135,  1050] training loss: 0.00001791
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8919    0.8250    0.8571      1720
    Anaphase     0.7925    0.7955    0.7940      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6086    0.6586    0.6326      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7694      3872
   macro avg     0.7162    0.7945    0.7468      3872
weighted avg     0.7804    0.7694    0.7736      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch135
INFO:root:[136,    50] training loss: 0.00745450
INFO:root:[136,   100] training loss: 0.00705125
INFO:root:[136,   150] training loss: 0.00717686
INFO:root:[136,   200] training loss: 0.00668283
INFO:root:[136,   250] training loss: 0.00690069
INFO:root:[136,   300] training loss: 0.00685409
INFO:root:[136,   350] training loss: 0.00615786
INFO:root:[136,   400] training loss: 0.00000599
INFO:root:[136,   450] training loss: 0.00000673
INFO:root:[136,   500] training loss: 0.00002416
INFO:root:[136,   550] training loss: 0.00022096
INFO:root:[136,   600] training loss: 0.00017751
INFO:root:[136,   650] training loss: 0.00001176
INFO:root:[136,   700] training loss: 0.00001347
INFO:root:[136,   750] training loss: 0.00020283
INFO:root:[136,   800] training loss: 0.00027949
INFO:root:[136,   850] training loss: 0.00026301
INFO:root:[136,   900] training loss: 0.00366696
INFO:root:[136,   950] training loss: 0.00117544
INFO:root:[136,  1000] training loss: 0.00002186
INFO:root:[136,  1050] training loss: 0.00001684
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8918    0.8244    0.8568      1720
    Anaphase     0.7925    0.7955    0.7940      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6080    0.6586    0.6323      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7691      3872
   macro avg     0.7161    0.7944    0.7467      3872
weighted avg     0.7802    0.7691    0.7733      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch136
INFO:root:[137,    50] training loss: 0.00730960
INFO:root:[137,   100] training loss: 0.00693764
INFO:root:[137,   150] training loss: 0.00702911
INFO:root:[137,   200] training loss: 0.00648360
INFO:root:[137,   250] training loss: 0.00686455
INFO:root:[137,   300] training loss: 0.00723048
INFO:root:[137,   350] training loss: 0.00619707
INFO:root:[137,   400] training loss: 0.00000747
INFO:root:[137,   450] training loss: 0.00000744
INFO:root:[137,   500] training loss: 0.00001962
INFO:root:[137,   550] training loss: 0.00020251
INFO:root:[137,   600] training loss: 0.00018294
INFO:root:[137,   650] training loss: 0.00001376
INFO:root:[137,   700] training loss: 0.00001643
INFO:root:[137,   750] training loss: 0.00014817
INFO:root:[137,   800] training loss: 0.00027370
INFO:root:[137,   850] training loss: 0.00030153
INFO:root:[137,   900] training loss: 0.00313350
INFO:root:[137,   950] training loss: 0.00104750
INFO:root:[137,  1000] training loss: 0.00002282
INFO:root:[137,  1050] training loss: 0.00001700
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8922    0.8233    0.8564      1720
    Anaphase     0.7934    0.7965    0.7950      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6082    0.6605    0.6333      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7694      3872
   macro avg     0.7163    0.7947    0.7469      3872
weighted avg     0.7807    0.7694    0.7737      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch137
INFO:root:[138,    50] training loss: 0.00780467
INFO:root:[138,   100] training loss: 0.00735663
INFO:root:[138,   150] training loss: 0.00681425
INFO:root:[138,   200] training loss: 0.00661873
INFO:root:[138,   250] training loss: 0.00787513
INFO:root:[138,   300] training loss: 0.00718828
INFO:root:[138,   350] training loss: 0.00589674
INFO:root:[138,   400] training loss: 0.00000545
INFO:root:[138,   450] training loss: 0.00000905
INFO:root:[138,   500] training loss: 0.00002488
INFO:root:[138,   550] training loss: 0.00014265
INFO:root:[138,   600] training loss: 0.00016261
INFO:root:[138,   650] training loss: 0.00001593
INFO:root:[138,   700] training loss: 0.00001649
INFO:root:[138,   750] training loss: 0.00018251
INFO:root:[138,   800] training loss: 0.00027871
INFO:root:[138,   850] training loss: 0.00029022
INFO:root:[138,   900] training loss: 0.00377096
INFO:root:[138,   950] training loss: 0.00139214
INFO:root:[138,  1000] training loss: 0.00001536
INFO:root:[138,  1050] training loss: 0.00001787
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8917    0.8233    0.8561      1720
    Anaphase     0.7934    0.7965    0.7950      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6078    0.6596    0.6327      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7691      3872
   macro avg     0.7162    0.7946    0.7468      3872
weighted avg     0.7804    0.7691    0.7734      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch138
INFO:root:[139,    50] training loss: 0.00704447
INFO:root:[139,   100] training loss: 0.00723135
INFO:root:[139,   150] training loss: 0.00695600
INFO:root:[139,   200] training loss: 0.00667084
INFO:root:[139,   250] training loss: 0.00653717
INFO:root:[139,   300] training loss: 0.00737138
INFO:root:[139,   350] training loss: 0.00633668
INFO:root:[139,   400] training loss: 0.00000696
INFO:root:[139,   450] training loss: 0.00000719
INFO:root:[139,   500] training loss: 0.00002838
INFO:root:[139,   550] training loss: 0.00015713
INFO:root:[139,   600] training loss: 0.00024795
INFO:root:[139,   650] training loss: 0.00001223
INFO:root:[139,   700] training loss: 0.00001385
INFO:root:[139,   750] training loss: 0.00023352
INFO:root:[139,   800] training loss: 0.00019687
INFO:root:[139,   850] training loss: 0.00024790
INFO:root:[139,   900] training loss: 0.00392291
INFO:root:[139,   950] training loss: 0.00109173
INFO:root:[139,  1000] training loss: 0.00001742
INFO:root:[139,  1050] training loss: 0.00002575
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8924    0.8244    0.8571      1720
    Anaphase     0.7942    0.7965    0.7954      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6096    0.6615    0.6345      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7166    0.7950    0.7473      3872
weighted avg     0.7814    0.7701    0.7744      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch139
INFO:root:[140,    50] training loss: 0.00696736
INFO:root:[140,   100] training loss: 0.00713246
INFO:root:[140,   150] training loss: 0.00689241
INFO:root:[140,   200] training loss: 0.00663730
INFO:root:[140,   250] training loss: 0.00712522
INFO:root:[140,   300] training loss: 0.00720694
INFO:root:[140,   350] training loss: 0.00624840
INFO:root:[140,   400] training loss: 0.00000565
INFO:root:[140,   450] training loss: 0.00000649
INFO:root:[140,   500] training loss: 0.00004029
INFO:root:[140,   550] training loss: 0.00016243
INFO:root:[140,   600] training loss: 0.00018098
INFO:root:[140,   650] training loss: 0.00001701
INFO:root:[140,   700] training loss: 0.00001415
INFO:root:[140,   750] training loss: 0.00028264
INFO:root:[140,   800] training loss: 0.00021012
INFO:root:[140,   850] training loss: 0.00030917
INFO:root:[140,   900] training loss: 0.00334688
INFO:root:[140,   950] training loss: 0.00112209
INFO:root:[140,  1000] training loss: 0.00002208
INFO:root:[140,  1050] training loss: 0.00002162
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8918    0.8238    0.8565      1720
    Anaphase     0.7950    0.7965    0.7957      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6091    0.6615    0.6342      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7166    0.7949    0.7472      3872
weighted avg     0.7812    0.7699    0.7742      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch140
INFO:root:[141,    50] training loss: 0.00714878
INFO:root:[141,   100] training loss: 0.00753613
INFO:root:[141,   150] training loss: 0.00770360
INFO:root:[141,   200] training loss: 0.00680300
INFO:root:[141,   250] training loss: 0.00661926
INFO:root:[141,   300] training loss: 0.00726428
INFO:root:[141,   350] training loss: 0.00680782
INFO:root:[141,   400] training loss: 0.00000711
INFO:root:[141,   450] training loss: 0.00000730
INFO:root:[141,   500] training loss: 0.00002715
INFO:root:[141,   550] training loss: 0.00014908
INFO:root:[141,   600] training loss: 0.00017432
INFO:root:[141,   650] training loss: 0.00001330
INFO:root:[141,   700] training loss: 0.00001457
INFO:root:[141,   750] training loss: 0.00024837
INFO:root:[141,   800] training loss: 0.00019814
INFO:root:[141,   850] training loss: 0.00028396
INFO:root:[141,   900] training loss: 0.00300553
INFO:root:[141,   950] training loss: 0.00098122
INFO:root:[141,  1000] training loss: 0.00001719
INFO:root:[141,  1050] training loss: 0.00001603
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8929    0.8238    0.8570      1720
    Anaphase     0.7950    0.7965    0.7957      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6098    0.6634    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7704      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7704    0.7747      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch141
INFO:root:[142,    50] training loss: 0.00753898
INFO:root:[142,   100] training loss: 0.00694370
INFO:root:[142,   150] training loss: 0.00702611
INFO:root:[142,   200] training loss: 0.00738085
INFO:root:[142,   250] training loss: 0.00659902
INFO:root:[142,   300] training loss: 0.00725541
INFO:root:[142,   350] training loss: 0.00602236
INFO:root:[142,   400] training loss: 0.00000640
INFO:root:[142,   450] training loss: 0.00000854
INFO:root:[142,   500] training loss: 0.00002511
INFO:root:[142,   550] training loss: 0.00014737
INFO:root:[142,   600] training loss: 0.00012990
INFO:root:[142,   650] training loss: 0.00001351
INFO:root:[142,   700] training loss: 0.00001295
INFO:root:[142,   750] training loss: 0.00023025
INFO:root:[142,   800] training loss: 0.00023151
INFO:root:[142,   850] training loss: 0.00033234
INFO:root:[142,   900] training loss: 0.00334118
INFO:root:[142,   950] training loss: 0.00148683
INFO:root:[142,  1000] training loss: 0.00001859
INFO:root:[142,  1050] training loss: 0.00001804
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8922    0.8227    0.8560      1720
    Anaphase     0.7965    0.7965    0.7965      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7817    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch142
INFO:root:[143,    50] training loss: 0.00733498
INFO:root:[143,   100] training loss: 0.00719425
INFO:root:[143,   150] training loss: 0.00721426
INFO:root:[143,   200] training loss: 0.00675981
INFO:root:[143,   250] training loss: 0.00716108
INFO:root:[143,   300] training loss: 0.00738015
INFO:root:[143,   350] training loss: 0.00582351
INFO:root:[143,   400] training loss: 0.00000693
INFO:root:[143,   450] training loss: 0.00000845
INFO:root:[143,   500] training loss: 0.00003694
INFO:root:[143,   550] training loss: 0.00019822
INFO:root:[143,   600] training loss: 0.00011668
INFO:root:[143,   650] training loss: 0.00001257
INFO:root:[143,   700] training loss: 0.00001179
INFO:root:[143,   750] training loss: 0.00021681
INFO:root:[143,   800] training loss: 0.00021107
INFO:root:[143,   850] training loss: 0.00028935
INFO:root:[143,   900] training loss: 0.00333146
INFO:root:[143,   950] training loss: 0.00104514
INFO:root:[143,  1000] training loss: 0.00001497
INFO:root:[143,  1050] training loss: 0.00001772
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8933    0.8227    0.8565      1720
    Anaphase     0.7950    0.7965    0.7957      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch143
INFO:root:[144,    50] training loss: 0.00737368
INFO:root:[144,   100] training loss: 0.00731082
INFO:root:[144,   150] training loss: 0.00716092
INFO:root:[144,   200] training loss: 0.00641662
INFO:root:[144,   250] training loss: 0.00726362
INFO:root:[144,   300] training loss: 0.00714145
INFO:root:[144,   350] training loss: 0.00591559
INFO:root:[144,   400] training loss: 0.00000825
INFO:root:[144,   450] training loss: 0.00000641
INFO:root:[144,   500] training loss: 0.00003721
INFO:root:[144,   550] training loss: 0.00018688
INFO:root:[144,   600] training loss: 0.00013341
INFO:root:[144,   650] training loss: 0.00001423
INFO:root:[144,   700] training loss: 0.00001333
INFO:root:[144,   750] training loss: 0.00022036
INFO:root:[144,   800] training loss: 0.00026202
INFO:root:[144,   850] training loss: 0.00028806
INFO:root:[144,   900] training loss: 0.00371642
INFO:root:[144,   950] training loss: 0.00121700
INFO:root:[144,  1000] training loss: 0.00001779
INFO:root:[144,  1050] training loss: 0.00001666
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8933    0.8227    0.8565      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6094    0.6654    0.6362      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7704      3872
   macro avg     0.7170    0.7953    0.7475      3872
weighted avg     0.7821    0.7704    0.7748      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch144
INFO:root:[145,    50] training loss: 0.00704655
INFO:root:[145,   100] training loss: 0.00706534
INFO:root:[145,   150] training loss: 0.00718748
INFO:root:[145,   200] training loss: 0.00682293
INFO:root:[145,   250] training loss: 0.00658341
INFO:root:[145,   300] training loss: 0.00721594
INFO:root:[145,   350] training loss: 0.00627692
INFO:root:[145,   400] training loss: 0.00000646
INFO:root:[145,   450] training loss: 0.00001005
INFO:root:[145,   500] training loss: 0.00002537
INFO:root:[145,   550] training loss: 0.00017246
INFO:root:[145,   600] training loss: 0.00019702
INFO:root:[145,   650] training loss: 0.00001283
INFO:root:[145,   700] training loss: 0.00001451
INFO:root:[145,   750] training loss: 0.00029230
INFO:root:[145,   800] training loss: 0.00021928
INFO:root:[145,   850] training loss: 0.00036344
INFO:root:[145,   900] training loss: 0.00321570
INFO:root:[145,   950] training loss: 0.00105034
INFO:root:[145,  1000] training loss: 0.00001862
INFO:root:[145,  1050] training loss: 0.00001650
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8933    0.8227    0.8565      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6094    0.6654    0.6362      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7704      3872
   macro avg     0.7170    0.7953    0.7475      3872
weighted avg     0.7821    0.7704    0.7748      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch145
INFO:root:[146,    50] training loss: 0.00717845
INFO:root:[146,   100] training loss: 0.00726924
INFO:root:[146,   150] training loss: 0.00707614
INFO:root:[146,   200] training loss: 0.00646962
INFO:root:[146,   250] training loss: 0.00661388
INFO:root:[146,   300] training loss: 0.00737174
INFO:root:[146,   350] training loss: 0.00599279
INFO:root:[146,   400] training loss: 0.00000599
INFO:root:[146,   450] training loss: 0.00000803
INFO:root:[146,   500] training loss: 0.00003111
INFO:root:[146,   550] training loss: 0.00014637
INFO:root:[146,   600] training loss: 0.00017326
INFO:root:[146,   650] training loss: 0.00001307
INFO:root:[146,   700] training loss: 0.00001349
INFO:root:[146,   750] training loss: 0.00026283
INFO:root:[146,   800] training loss: 0.00025778
INFO:root:[146,   850] training loss: 0.00018936
INFO:root:[146,   900] training loss: 0.00363176
INFO:root:[146,   950] training loss: 0.00095938
INFO:root:[146,  1000] training loss: 0.00001448
INFO:root:[146,  1050] training loss: 0.00002274
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch146
INFO:root:[147,    50] training loss: 0.00749087
INFO:root:[147,   100] training loss: 0.00729205
INFO:root:[147,   150] training loss: 0.00715474
INFO:root:[147,   200] training loss: 0.00670555
INFO:root:[147,   250] training loss: 0.00686955
INFO:root:[147,   300] training loss: 0.00717267
INFO:root:[147,   350] training loss: 0.00680346
INFO:root:[147,   400] training loss: 0.00000693
INFO:root:[147,   450] training loss: 0.00000787
INFO:root:[147,   500] training loss: 0.00002233
INFO:root:[147,   550] training loss: 0.00023104
INFO:root:[147,   600] training loss: 0.00011983
INFO:root:[147,   650] training loss: 0.00001319
INFO:root:[147,   700] training loss: 0.00001369
INFO:root:[147,   750] training loss: 0.00019689
INFO:root:[147,   800] training loss: 0.00028195
INFO:root:[147,   850] training loss: 0.00029254
INFO:root:[147,   900] training loss: 0.00323649
INFO:root:[147,   950] training loss: 0.00116331
INFO:root:[147,  1000] training loss: 0.00001675
INFO:root:[147,  1050] training loss: 0.00001653
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch147
INFO:root:[148,    50] training loss: 0.00699467
INFO:root:[148,   100] training loss: 0.00709854
INFO:root:[148,   150] training loss: 0.00724375
INFO:root:[148,   200] training loss: 0.00700432
INFO:root:[148,   250] training loss: 0.00697500
INFO:root:[148,   300] training loss: 0.00746273
INFO:root:[148,   350] training loss: 0.00603486
INFO:root:[148,   400] training loss: 0.00000678
INFO:root:[148,   450] training loss: 0.00000801
INFO:root:[148,   500] training loss: 0.00002709
INFO:root:[148,   550] training loss: 0.00017632
INFO:root:[148,   600] training loss: 0.00018453
INFO:root:[148,   650] training loss: 0.00001336
INFO:root:[148,   700] training loss: 0.00001330
INFO:root:[148,   750] training loss: 0.00019056
INFO:root:[148,   800] training loss: 0.00037031
INFO:root:[148,   850] training loss: 0.00025049
INFO:root:[148,   900] training loss: 0.00336574
INFO:root:[148,   950] training loss: 0.00100092
INFO:root:[148,  1000] training loss: 0.00001719
INFO:root:[148,  1050] training loss: 0.00007375
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch148
INFO:root:[149,    50] training loss: 0.00700784
INFO:root:[149,   100] training loss: 0.00726111
INFO:root:[149,   150] training loss: 0.00705673
INFO:root:[149,   200] training loss: 0.00638834
INFO:root:[149,   250] training loss: 0.00672271
INFO:root:[149,   300] training loss: 0.00820201
INFO:root:[149,   350] training loss: 0.00639925
INFO:root:[149,   400] training loss: 0.00000751
INFO:root:[149,   450] training loss: 0.00000678
INFO:root:[149,   500] training loss: 0.00003427
INFO:root:[149,   550] training loss: 0.00020148
INFO:root:[149,   600] training loss: 0.00014090
INFO:root:[149,   650] training loss: 0.00001219
INFO:root:[149,   700] training loss: 0.00001375
INFO:root:[149,   750] training loss: 0.00023076
INFO:root:[149,   800] training loss: 0.00023171
INFO:root:[149,   850] training loss: 0.00030645
INFO:root:[149,   900] training loss: 0.00354446
INFO:root:[149,   950] training loss: 0.00085417
INFO:root:[149,  1000] training loss: 0.00001470
INFO:root:[149,  1050] training loss: 0.00002193
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch149
INFO:root:[150,    50] training loss: 0.00700371
INFO:root:[150,   100] training loss: 0.00764267
INFO:root:[150,   150] training loss: 0.00726245
INFO:root:[150,   200] training loss: 0.00672537
INFO:root:[150,   250] training loss: 0.00683962
INFO:root:[150,   300] training loss: 0.00736883
INFO:root:[150,   350] training loss: 0.00604089
INFO:root:[150,   400] training loss: 0.00000671
INFO:root:[150,   450] training loss: 0.00000932
INFO:root:[150,   500] training loss: 0.00002708
INFO:root:[150,   550] training loss: 0.00016461
INFO:root:[150,   600] training loss: 0.00014738
INFO:root:[150,   650] training loss: 0.00001331
INFO:root:[150,   700] training loss: 0.00001280
INFO:root:[150,   750] training loss: 0.00019645
INFO:root:[150,   800] training loss: 0.00024954
INFO:root:[150,   850] training loss: 0.00032211
INFO:root:[150,   900] training loss: 0.00349389
INFO:root:[150,   950] training loss: 0.00099016
INFO:root:[150,  1000] training loss: 0.00005580
INFO:root:[150,  1050] training loss: 0.00001610
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch150
INFO:root:[151,    50] training loss: 0.00795147
INFO:root:[151,   100] training loss: 0.00680730
INFO:root:[151,   150] training loss: 0.00714443
INFO:root:[151,   200] training loss: 0.00625799
INFO:root:[151,   250] training loss: 0.00745298
INFO:root:[151,   300] training loss: 0.00722369
INFO:root:[151,   350] training loss: 0.00619122
INFO:root:[151,   400] training loss: 0.00000792
INFO:root:[151,   450] training loss: 0.00000846
INFO:root:[151,   500] training loss: 0.00004558
INFO:root:[151,   550] training loss: 0.00016516
INFO:root:[151,   600] training loss: 0.00014035
INFO:root:[151,   650] training loss: 0.00001250
INFO:root:[151,   700] training loss: 0.00001439
INFO:root:[151,   750] training loss: 0.00022464
INFO:root:[151,   800] training loss: 0.00022140
INFO:root:[151,   850] training loss: 0.00028847
INFO:root:[151,   900] training loss: 0.00309954
INFO:root:[151,   950] training loss: 0.00153015
INFO:root:[151,  1000] training loss: 0.00002541
INFO:root:[151,  1050] training loss: 0.00002988
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch151
INFO:root:[152,    50] training loss: 0.00804368
INFO:root:[152,   100] training loss: 0.00714141
INFO:root:[152,   150] training loss: 0.00697361
INFO:root:[152,   200] training loss: 0.00646924
INFO:root:[152,   250] training loss: 0.00691809
INFO:root:[152,   300] training loss: 0.00696548
INFO:root:[152,   350] training loss: 0.00632705
INFO:root:[152,   400] training loss: 0.00000559
INFO:root:[152,   450] training loss: 0.00000771
INFO:root:[152,   500] training loss: 0.00004258
INFO:root:[152,   550] training loss: 0.00014503
INFO:root:[152,   600] training loss: 0.00014342
INFO:root:[152,   650] training loss: 0.00001435
INFO:root:[152,   700] training loss: 0.00001431
INFO:root:[152,   750] training loss: 0.00020259
INFO:root:[152,   800] training loss: 0.00023178
INFO:root:[152,   850] training loss: 0.00029473
INFO:root:[152,   900] training loss: 0.00375590
INFO:root:[152,   950] training loss: 0.00131117
INFO:root:[152,  1000] training loss: 0.00002143
INFO:root:[152,  1050] training loss: 0.00002305
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch152
INFO:root:[153,    50] training loss: 0.00748997
INFO:root:[153,   100] training loss: 0.00746179
INFO:root:[153,   150] training loss: 0.00829198
INFO:root:[153,   200] training loss: 0.00670579
INFO:root:[153,   250] training loss: 0.00687631
INFO:root:[153,   300] training loss: 0.00719954
INFO:root:[153,   350] training loss: 0.00617021
INFO:root:[153,   400] training loss: 0.00000665
INFO:root:[153,   450] training loss: 0.00000735
INFO:root:[153,   500] training loss: 0.00004704
INFO:root:[153,   550] training loss: 0.00018008
INFO:root:[153,   600] training loss: 0.00011303
INFO:root:[153,   650] training loss: 0.00001175
INFO:root:[153,   700] training loss: 0.00001355
INFO:root:[153,   750] training loss: 0.00022786
INFO:root:[153,   800] training loss: 0.00022970
INFO:root:[153,   850] training loss: 0.00032085
INFO:root:[153,   900] training loss: 0.00297935
INFO:root:[153,   950] training loss: 0.00095894
INFO:root:[153,  1000] training loss: 0.00001374
INFO:root:[153,  1050] training loss: 0.00002270
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8227    0.8563      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6090    0.6644    0.6355      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7168    0.7952    0.7474      3872
weighted avg     0.7818    0.7701    0.7745      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch153
INFO:root:[154,    50] training loss: 0.00700096
INFO:root:[154,   100] training loss: 0.00773403
INFO:root:[154,   150] training loss: 0.00690459
INFO:root:[154,   200] training loss: 0.00670612
INFO:root:[154,   250] training loss: 0.00657513
INFO:root:[154,   300] training loss: 0.00759087
INFO:root:[154,   350] training loss: 0.00630659
INFO:root:[154,   400] training loss: 0.00000694
INFO:root:[154,   450] training loss: 0.00000738
INFO:root:[154,   500] training loss: 0.00002181
INFO:root:[154,   550] training loss: 0.00015072
INFO:root:[154,   600] training loss: 0.00016286
INFO:root:[154,   650] training loss: 0.00001435
INFO:root:[154,   700] training loss: 0.00001288
INFO:root:[154,   750] training loss: 0.00021133
INFO:root:[154,   800] training loss: 0.00020142
INFO:root:[154,   850] training loss: 0.00018531
INFO:root:[154,   900] training loss: 0.00340399
INFO:root:[154,   950] training loss: 0.00122258
INFO:root:[154,  1000] training loss: 0.00001619
INFO:root:[154,  1050] training loss: 0.00003415
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch154
INFO:root:[155,    50] training loss: 0.00696375
INFO:root:[155,   100] training loss: 0.00740630
INFO:root:[155,   150] training loss: 0.00687829
INFO:root:[155,   200] training loss: 0.00718382
INFO:root:[155,   250] training loss: 0.00697309
INFO:root:[155,   300] training loss: 0.00767319
INFO:root:[155,   350] training loss: 0.00698747
INFO:root:[155,   400] training loss: 0.00000670
INFO:root:[155,   450] training loss: 0.00000840
INFO:root:[155,   500] training loss: 0.00002424
INFO:root:[155,   550] training loss: 0.00016655
INFO:root:[155,   600] training loss: 0.00016467
INFO:root:[155,   650] training loss: 0.00001260
INFO:root:[155,   700] training loss: 0.00001757
INFO:root:[155,   750] training loss: 0.00014884
INFO:root:[155,   800] training loss: 0.00021590
INFO:root:[155,   850] training loss: 0.00027302
INFO:root:[155,   900] training loss: 0.00398101
INFO:root:[155,   950] training loss: 0.00110523
INFO:root:[155,  1000] training loss: 0.00001993
INFO:root:[155,  1050] training loss: 0.00002032
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch155
INFO:root:[156,    50] training loss: 0.00695617
INFO:root:[156,   100] training loss: 0.00751411
INFO:root:[156,   150] training loss: 0.00714884
INFO:root:[156,   200] training loss: 0.00692581
INFO:root:[156,   250] training loss: 0.00705420
INFO:root:[156,   300] training loss: 0.00713953
INFO:root:[156,   350] training loss: 0.00628163
INFO:root:[156,   400] training loss: 0.00000634
INFO:root:[156,   450] training loss: 0.00000775
INFO:root:[156,   500] training loss: 0.00005233
INFO:root:[156,   550] training loss: 0.00016113
INFO:root:[156,   600] training loss: 0.00022143
INFO:root:[156,   650] training loss: 0.00001287
INFO:root:[156,   700] training loss: 0.00001419
INFO:root:[156,   750] training loss: 0.00025066
INFO:root:[156,   800] training loss: 0.00026778
INFO:root:[156,   850] training loss: 0.00020985
INFO:root:[156,   900] training loss: 0.00355688
INFO:root:[156,   950] training loss: 0.00098712
INFO:root:[156,  1000] training loss: 0.00001589
INFO:root:[156,  1050] training loss: 0.00001672
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch156
INFO:root:[157,    50] training loss: 0.00727510
INFO:root:[157,   100] training loss: 0.00702443
INFO:root:[157,   150] training loss: 0.00727119
INFO:root:[157,   200] training loss: 0.00674953
INFO:root:[157,   250] training loss: 0.00695164
INFO:root:[157,   300] training loss: 0.00755330
INFO:root:[157,   350] training loss: 0.00615845
INFO:root:[157,   400] training loss: 0.00000751
INFO:root:[157,   450] training loss: 0.00000735
INFO:root:[157,   500] training loss: 0.00002486
INFO:root:[157,   550] training loss: 0.00019537
INFO:root:[157,   600] training loss: 0.00015476
INFO:root:[157,   650] training loss: 0.00001391
INFO:root:[157,   700] training loss: 0.00001459
INFO:root:[157,   750] training loss: 0.00021425
INFO:root:[157,   800] training loss: 0.00024311
INFO:root:[157,   850] training loss: 0.00018115
INFO:root:[157,   900] training loss: 0.00377268
INFO:root:[157,   950] training loss: 0.00107179
INFO:root:[157,  1000] training loss: 0.00001725
INFO:root:[157,  1050] training loss: 0.00001779
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch157
INFO:root:[158,    50] training loss: 0.00698318
INFO:root:[158,   100] training loss: 0.00708154
INFO:root:[158,   150] training loss: 0.00678666
INFO:root:[158,   200] training loss: 0.00675491
INFO:root:[158,   250] training loss: 0.00626392
INFO:root:[158,   300] training loss: 0.00733201
INFO:root:[158,   350] training loss: 0.00632494
INFO:root:[158,   400] training loss: 0.00000598
INFO:root:[158,   450] training loss: 0.00000741
INFO:root:[158,   500] training loss: 0.00002354
INFO:root:[158,   550] training loss: 0.00018602
INFO:root:[158,   600] training loss: 0.00012219
INFO:root:[158,   650] training loss: 0.00001279
INFO:root:[158,   700] training loss: 0.00001384
INFO:root:[158,   750] training loss: 0.00022387
INFO:root:[158,   800] training loss: 0.00022407
INFO:root:[158,   850] training loss: 0.00026797
INFO:root:[158,   900] training loss: 0.00322966
INFO:root:[158,   950] training loss: 0.00114094
INFO:root:[158,  1000] training loss: 0.00001476
INFO:root:[158,  1050] training loss: 0.00003124
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch158
INFO:root:[159,    50] training loss: 0.00720979
INFO:root:[159,   100] training loss: 0.00723605
INFO:root:[159,   150] training loss: 0.00711632
INFO:root:[159,   200] training loss: 0.00700387
INFO:root:[159,   250] training loss: 0.00672754
INFO:root:[159,   300] training loss: 0.00730165
INFO:root:[159,   350] training loss: 0.00609207
INFO:root:[159,   400] training loss: 0.00000550
INFO:root:[159,   450] training loss: 0.00000856
INFO:root:[159,   500] training loss: 0.00003792
INFO:root:[159,   550] training loss: 0.00016249
INFO:root:[159,   600] training loss: 0.00014536
INFO:root:[159,   650] training loss: 0.00001330
INFO:root:[159,   700] training loss: 0.00001318
INFO:root:[159,   750] training loss: 0.00022625
INFO:root:[159,   800] training loss: 0.00019940
INFO:root:[159,   850] training loss: 0.00027972
INFO:root:[159,   900] training loss: 0.00317371
INFO:root:[159,   950] training loss: 0.00121779
INFO:root:[159,  1000] training loss: 0.00001566
INFO:root:[159,  1050] training loss: 0.00002176
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch159
INFO:root:[160,    50] training loss: 0.00693307
INFO:root:[160,   100] training loss: 0.00709961
INFO:root:[160,   150] training loss: 0.00694934
INFO:root:[160,   200] training loss: 0.00684794
INFO:root:[160,   250] training loss: 0.00708910
INFO:root:[160,   300] training loss: 0.00731401
INFO:root:[160,   350] training loss: 0.00628353
INFO:root:[160,   400] training loss: 0.00000644
INFO:root:[160,   450] training loss: 0.00000828
INFO:root:[160,   500] training loss: 0.00002816
INFO:root:[160,   550] training loss: 0.00014888
INFO:root:[160,   600] training loss: 0.00013825
INFO:root:[160,   650] training loss: 0.00001297
INFO:root:[160,   700] training loss: 0.00001292
INFO:root:[160,   750] training loss: 0.00020212
INFO:root:[160,   800] training loss: 0.00023993
INFO:root:[160,   850] training loss: 0.00029505
INFO:root:[160,   900] training loss: 0.00319450
INFO:root:[160,   950] training loss: 0.00122365
INFO:root:[160,  1000] training loss: 0.00001764
INFO:root:[160,  1050] training loss: 0.00002238
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch160
INFO:root:[161,    50] training loss: 0.00742985
INFO:root:[161,   100] training loss: 0.00722553
INFO:root:[161,   150] training loss: 0.00699926
INFO:root:[161,   200] training loss: 0.00679398
INFO:root:[161,   250] training loss: 0.00703807
INFO:root:[161,   300] training loss: 0.00739642
INFO:root:[161,   350] training loss: 0.00644494
INFO:root:[161,   400] training loss: 0.00000604
INFO:root:[161,   450] training loss: 0.00000768
INFO:root:[161,   500] training loss: 0.00007171
INFO:root:[161,   550] training loss: 0.00017958
INFO:root:[161,   600] training loss: 0.00016417
INFO:root:[161,   650] training loss: 0.00001553
INFO:root:[161,   700] training loss: 0.00001467
INFO:root:[161,   750] training loss: 0.00023896
INFO:root:[161,   800] training loss: 0.00019251
INFO:root:[161,   850] training loss: 0.00022304
INFO:root:[161,   900] training loss: 0.00353452
INFO:root:[161,   950] training loss: 0.00110446
INFO:root:[161,  1000] training loss: 0.00001697
INFO:root:[161,  1050] training loss: 0.00001730
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch161
INFO:root:[162,    50] training loss: 0.00738700
INFO:root:[162,   100] training loss: 0.00702889
INFO:root:[162,   150] training loss: 0.00669021
INFO:root:[162,   200] training loss: 0.00651993
INFO:root:[162,   250] training loss: 0.00678198
INFO:root:[162,   300] training loss: 0.00722224
INFO:root:[162,   350] training loss: 0.00609568
INFO:root:[162,   400] training loss: 0.00000639
INFO:root:[162,   450] training loss: 0.00000772
INFO:root:[162,   500] training loss: 0.00009824
INFO:root:[162,   550] training loss: 0.00016959
INFO:root:[162,   600] training loss: 0.00017501
INFO:root:[162,   650] training loss: 0.00001251
INFO:root:[162,   700] training loss: 0.00001422
INFO:root:[162,   750] training loss: 0.00022761
INFO:root:[162,   800] training loss: 0.00023426
INFO:root:[162,   850] training loss: 0.00033565
INFO:root:[162,   900] training loss: 0.00335775
INFO:root:[162,   950] training loss: 0.00111485
INFO:root:[162,  1000] training loss: 0.00001747
INFO:root:[162,  1050] training loss: 0.00002401
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch162
INFO:root:[163,    50] training loss: 0.00710192
INFO:root:[163,   100] training loss: 0.00725713
INFO:root:[163,   150] training loss: 0.00732218
INFO:root:[163,   200] training loss: 0.00711099
INFO:root:[163,   250] training loss: 0.00694837
INFO:root:[163,   300] training loss: 0.00699308
INFO:root:[163,   350] training loss: 0.00603402
INFO:root:[163,   400] training loss: 0.00000618
INFO:root:[163,   450] training loss: 0.00000776
INFO:root:[163,   500] training loss: 0.00003084
INFO:root:[163,   550] training loss: 0.00019206
INFO:root:[163,   600] training loss: 0.00015266
INFO:root:[163,   650] training loss: 0.00001445
INFO:root:[163,   700] training loss: 0.00001442
INFO:root:[163,   750] training loss: 0.00020784
INFO:root:[163,   800] training loss: 0.00020850
INFO:root:[163,   850] training loss: 0.00022401
INFO:root:[163,   900] training loss: 0.00365793
INFO:root:[163,   950] training loss: 0.00095108
INFO:root:[163,  1000] training loss: 0.00001673
INFO:root:[163,  1050] training loss: 0.00001647
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch163
INFO:root:[164,    50] training loss: 0.00693480
INFO:root:[164,   100] training loss: 0.00697878
INFO:root:[164,   150] training loss: 0.00691373
INFO:root:[164,   200] training loss: 0.00672634
INFO:root:[164,   250] training loss: 0.00686860
INFO:root:[164,   300] training loss: 0.00743292
INFO:root:[164,   350] training loss: 0.00659839
INFO:root:[164,   400] training loss: 0.00000559
INFO:root:[164,   450] training loss: 0.00000788
INFO:root:[164,   500] training loss: 0.00002261
INFO:root:[164,   550] training loss: 0.00017097
INFO:root:[164,   600] training loss: 0.00011972
INFO:root:[164,   650] training loss: 0.00001299
INFO:root:[164,   700] training loss: 0.00001277
INFO:root:[164,   750] training loss: 0.00019209
INFO:root:[164,   800] training loss: 0.00029605
INFO:root:[164,   850] training loss: 0.00026767
INFO:root:[164,   900] training loss: 0.00331797
INFO:root:[164,   950] training loss: 0.00143991
INFO:root:[164,  1000] training loss: 0.00001799
INFO:root:[164,  1050] training loss: 0.00001491
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch164
INFO:root:[165,    50] training loss: 0.00726949
INFO:root:[165,   100] training loss: 0.00693898
INFO:root:[165,   150] training loss: 0.00747411
INFO:root:[165,   200] training loss: 0.00629902
INFO:root:[165,   250] training loss: 0.00753230
INFO:root:[165,   300] training loss: 0.00707231
INFO:root:[165,   350] training loss: 0.00585497
INFO:root:[165,   400] training loss: 0.00000669
INFO:root:[165,   450] training loss: 0.00000682
INFO:root:[165,   500] training loss: 0.00002670
INFO:root:[165,   550] training loss: 0.00016376
INFO:root:[165,   600] training loss: 0.00020877
INFO:root:[165,   650] training loss: 0.00001129
INFO:root:[165,   700] training loss: 0.00001228
INFO:root:[165,   750] training loss: 0.00024485
INFO:root:[165,   800] training loss: 0.00025312
INFO:root:[165,   850] training loss: 0.00024662
INFO:root:[165,   900] training loss: 0.00339639
INFO:root:[165,   950] training loss: 0.00103217
INFO:root:[165,  1000] training loss: 0.00001539
INFO:root:[165,  1050] training loss: 0.00002352
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch165
INFO:root:[166,    50] training loss: 0.00739881
INFO:root:[166,   100] training loss: 0.00774856
INFO:root:[166,   150] training loss: 0.00694656
INFO:root:[166,   200] training loss: 0.00681097
INFO:root:[166,   250] training loss: 0.00660447
INFO:root:[166,   300] training loss: 0.00901669
INFO:root:[166,   350] training loss: 0.00647078
INFO:root:[166,   400] training loss: 0.00000644
INFO:root:[166,   450] training loss: 0.00000841
INFO:root:[166,   500] training loss: 0.00003765
INFO:root:[166,   550] training loss: 0.00021397
INFO:root:[166,   600] training loss: 0.00016022
INFO:root:[166,   650] training loss: 0.00001385
INFO:root:[166,   700] training loss: 0.00001409
INFO:root:[166,   750] training loss: 0.00023758
INFO:root:[166,   800] training loss: 0.00022200
INFO:root:[166,   850] training loss: 0.00028706
INFO:root:[166,   900] training loss: 0.00321728
INFO:root:[166,   950] training loss: 0.00103702
INFO:root:[166,  1000] training loss: 0.00001693
INFO:root:[166,  1050] training loss: 0.00004277
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch166
INFO:root:[167,    50] training loss: 0.00709588
INFO:root:[167,   100] training loss: 0.00690131
INFO:root:[167,   150] training loss: 0.00663036
INFO:root:[167,   200] training loss: 0.00700680
INFO:root:[167,   250] training loss: 0.00664237
INFO:root:[167,   300] training loss: 0.00759946
INFO:root:[167,   350] training loss: 0.00583119
INFO:root:[167,   400] training loss: 0.00000527
INFO:root:[167,   450] training loss: 0.00000779
INFO:root:[167,   500] training loss: 0.00002345
INFO:root:[167,   550] training loss: 0.00015494
INFO:root:[167,   600] training loss: 0.00023341
INFO:root:[167,   650] training loss: 0.00001187
INFO:root:[167,   700] training loss: 0.00001266
INFO:root:[167,   750] training loss: 0.00020321
INFO:root:[167,   800] training loss: 0.00023240
INFO:root:[167,   850] training loss: 0.00029618
INFO:root:[167,   900] training loss: 0.00364839
INFO:root:[167,   950] training loss: 0.00107159
INFO:root:[167,  1000] training loss: 0.00001629
INFO:root:[167,  1050] training loss: 0.00001613
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch167
INFO:root:[168,    50] training loss: 0.00705376
INFO:root:[168,   100] training loss: 0.00743049
INFO:root:[168,   150] training loss: 0.00682150
INFO:root:[168,   200] training loss: 0.00662072
INFO:root:[168,   250] training loss: 0.00730014
INFO:root:[168,   300] training loss: 0.00734022
INFO:root:[168,   350] training loss: 0.00621310
INFO:root:[168,   400] training loss: 0.00000649
INFO:root:[168,   450] training loss: 0.00000755
INFO:root:[168,   500] training loss: 0.00002201
INFO:root:[168,   550] training loss: 0.00014735
INFO:root:[168,   600] training loss: 0.00022380
INFO:root:[168,   650] training loss: 0.00001400
INFO:root:[168,   700] training loss: 0.00001757
INFO:root:[168,   750] training loss: 0.00022970
INFO:root:[168,   800] training loss: 0.00021313
INFO:root:[168,   850] training loss: 0.00032355
INFO:root:[168,   900] training loss: 0.00393587
INFO:root:[168,   950] training loss: 0.00198586
INFO:root:[168,  1000] training loss: 0.00001567
INFO:root:[168,  1050] training loss: 0.00001808
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch168
INFO:root:[169,    50] training loss: 0.00720734
INFO:root:[169,   100] training loss: 0.00717808
INFO:root:[169,   150] training loss: 0.00691763
INFO:root:[169,   200] training loss: 0.00741346
INFO:root:[169,   250] training loss: 0.00663942
INFO:root:[169,   300] training loss: 0.00743895
INFO:root:[169,   350] training loss: 0.00604079
INFO:root:[169,   400] training loss: 0.00000663
INFO:root:[169,   450] training loss: 0.00000792
INFO:root:[169,   500] training loss: 0.00002399
INFO:root:[169,   550] training loss: 0.00015604
INFO:root:[169,   600] training loss: 0.00019224
INFO:root:[169,   650] training loss: 0.00001367
INFO:root:[169,   700] training loss: 0.00001449
INFO:root:[169,   750] training loss: 0.00025708
INFO:root:[169,   800] training loss: 0.00030148
INFO:root:[169,   850] training loss: 0.00039030
INFO:root:[169,   900] training loss: 0.00362770
INFO:root:[169,   950] training loss: 0.00126554
INFO:root:[169,  1000] training loss: 0.00001765
INFO:root:[169,  1050] training loss: 0.00003742
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch169
INFO:root:[170,    50] training loss: 0.00726853
INFO:root:[170,   100] training loss: 0.00700725
INFO:root:[170,   150] training loss: 0.00709572
INFO:root:[170,   200] training loss: 0.00812003
INFO:root:[170,   250] training loss: 0.00741547
INFO:root:[170,   300] training loss: 0.00735104
INFO:root:[170,   350] training loss: 0.00620669
INFO:root:[170,   400] training loss: 0.00000706
INFO:root:[170,   450] training loss: 0.00000772
INFO:root:[170,   500] training loss: 0.00005247
INFO:root:[170,   550] training loss: 0.00013937
INFO:root:[170,   600] training loss: 0.00016870
INFO:root:[170,   650] training loss: 0.00001442
INFO:root:[170,   700] training loss: 0.00001373
INFO:root:[170,   750] training loss: 0.00013407
INFO:root:[170,   800] training loss: 0.00026606
INFO:root:[170,   850] training loss: 0.00031911
INFO:root:[170,   900] training loss: 0.00320918
INFO:root:[170,   950] training loss: 0.00130327
INFO:root:[170,  1000] training loss: 0.00002119
INFO:root:[170,  1050] training loss: 0.00002763
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch170
INFO:root:[171,    50] training loss: 0.00726262
INFO:root:[171,   100] training loss: 0.00710305
INFO:root:[171,   150] training loss: 0.00661263
INFO:root:[171,   200] training loss: 0.00668175
INFO:root:[171,   250] training loss: 0.00742138
INFO:root:[171,   300] training loss: 0.00778872
INFO:root:[171,   350] training loss: 0.00592334
INFO:root:[171,   400] training loss: 0.00000550
INFO:root:[171,   450] training loss: 0.00000788
INFO:root:[171,   500] training loss: 0.00004929
INFO:root:[171,   550] training loss: 0.00016334
INFO:root:[171,   600] training loss: 0.00014552
INFO:root:[171,   650] training loss: 0.00001472
INFO:root:[171,   700] training loss: 0.00001413
INFO:root:[171,   750] training loss: 0.00018356
INFO:root:[171,   800] training loss: 0.00021084
INFO:root:[171,   850] training loss: 0.00024152
INFO:root:[171,   900] training loss: 0.00335134
INFO:root:[171,   950] training loss: 0.00128740
INFO:root:[171,  1000] training loss: 0.00001594
INFO:root:[171,  1050] training loss: 0.00001643
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch171
INFO:root:[172,    50] training loss: 0.00721495
INFO:root:[172,   100] training loss: 0.00689797
INFO:root:[172,   150] training loss: 0.00752337
INFO:root:[172,   200] training loss: 0.00681784
INFO:root:[172,   250] training loss: 0.00753643
INFO:root:[172,   300] training loss: 0.00720759
INFO:root:[172,   350] training loss: 0.00606362
INFO:root:[172,   400] training loss: 0.00000591
INFO:root:[172,   450] training loss: 0.00000691
INFO:root:[172,   500] training loss: 0.00005203
INFO:root:[172,   550] training loss: 0.00017419
INFO:root:[172,   600] training loss: 0.00019584
INFO:root:[172,   650] training loss: 0.00001180
INFO:root:[172,   700] training loss: 0.00001219
INFO:root:[172,   750] training loss: 0.00023803
INFO:root:[172,   800] training loss: 0.00028620
INFO:root:[172,   850] training loss: 0.00028196
INFO:root:[172,   900] training loss: 0.00433336
INFO:root:[172,   950] training loss: 0.00150751
INFO:root:[172,  1000] training loss: 0.00001558
INFO:root:[172,  1050] training loss: 0.00002222
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch172
INFO:root:[173,    50] training loss: 0.00723738
INFO:root:[173,   100] training loss: 0.00702462
INFO:root:[173,   150] training loss: 0.00739088
INFO:root:[173,   200] training loss: 0.00686858
INFO:root:[173,   250] training loss: 0.00661355
INFO:root:[173,   300] training loss: 0.00762272
INFO:root:[173,   350] training loss: 0.00589696
INFO:root:[173,   400] training loss: 0.00000519
INFO:root:[173,   450] training loss: 0.00000848
INFO:root:[173,   500] training loss: 0.00002497
INFO:root:[173,   550] training loss: 0.00016452
INFO:root:[173,   600] training loss: 0.00016157
INFO:root:[173,   650] training loss: 0.00001327
INFO:root:[173,   700] training loss: 0.00001427
INFO:root:[173,   750] training loss: 0.00018899
INFO:root:[173,   800] training loss: 0.00024105
INFO:root:[173,   850] training loss: 0.00033417
INFO:root:[173,   900] training loss: 0.00344930
INFO:root:[173,   950] training loss: 0.00085766
INFO:root:[173,  1000] training loss: 0.00001471
INFO:root:[173,  1050] training loss: 0.00001908
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch173
INFO:root:[174,    50] training loss: 0.00739718
INFO:root:[174,   100] training loss: 0.00714179
INFO:root:[174,   150] training loss: 0.00731500
INFO:root:[174,   200] training loss: 0.00658182
INFO:root:[174,   250] training loss: 0.00656950
INFO:root:[174,   300] training loss: 0.00728243
INFO:root:[174,   350] training loss: 0.00619136
INFO:root:[174,   400] training loss: 0.00000595
INFO:root:[174,   450] training loss: 0.00000836
INFO:root:[174,   500] training loss: 0.00004415
INFO:root:[174,   550] training loss: 0.00016484
INFO:root:[174,   600] training loss: 0.00019292
INFO:root:[174,   650] training loss: 0.00001293
INFO:root:[174,   700] training loss: 0.00001218
INFO:root:[174,   750] training loss: 0.00019971
INFO:root:[174,   800] training loss: 0.00020600
INFO:root:[174,   850] training loss: 0.00028097
INFO:root:[174,   900] training loss: 0.00329245
INFO:root:[174,   950] training loss: 0.00131508
INFO:root:[174,  1000] training loss: 0.00001436
INFO:root:[174,  1050] training loss: 0.00001739
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch174
INFO:root:[175,    50] training loss: 0.00715684
INFO:root:[175,   100] training loss: 0.00727192
INFO:root:[175,   150] training loss: 0.00699211
INFO:root:[175,   200] training loss: 0.00641502
INFO:root:[175,   250] training loss: 0.00670590
INFO:root:[175,   300] training loss: 0.00742716
INFO:root:[175,   350] training loss: 0.00618725
INFO:root:[175,   400] training loss: 0.00000593
INFO:root:[175,   450] training loss: 0.00000718
INFO:root:[175,   500] training loss: 0.00002180
INFO:root:[175,   550] training loss: 0.00019493
INFO:root:[175,   600] training loss: 0.00016955
INFO:root:[175,   650] training loss: 0.00001263
INFO:root:[175,   700] training loss: 0.00001288
INFO:root:[175,   750] training loss: 0.00018724
INFO:root:[175,   800] training loss: 0.00031035
INFO:root:[175,   850] training loss: 0.00026191
INFO:root:[175,   900] training loss: 0.00384799
INFO:root:[175,   950] training loss: 0.00118863
INFO:root:[175,  1000] training loss: 0.00001607
INFO:root:[175,  1050] training loss: 0.00005117
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch175
INFO:root:[176,    50] training loss: 0.00738667
INFO:root:[176,   100] training loss: 0.00732331
INFO:root:[176,   150] training loss: 0.00711105
INFO:root:[176,   200] training loss: 0.00647478
INFO:root:[176,   250] training loss: 0.00679096
INFO:root:[176,   300] training loss: 0.00707275
INFO:root:[176,   350] training loss: 0.00598537
INFO:root:[176,   400] training loss: 0.00000603
INFO:root:[176,   450] training loss: 0.00000825
INFO:root:[176,   500] training loss: 0.00004186
INFO:root:[176,   550] training loss: 0.00019694
INFO:root:[176,   600] training loss: 0.00016945
INFO:root:[176,   650] training loss: 0.00001281
INFO:root:[176,   700] training loss: 0.00001418
INFO:root:[176,   750] training loss: 0.00027277
INFO:root:[176,   800] training loss: 0.00024202
INFO:root:[176,   850] training loss: 0.00023057
INFO:root:[176,   900] training loss: 0.00352845
INFO:root:[176,   950] training loss: 0.00118604
INFO:root:[176,  1000] training loss: 0.00001510
INFO:root:[176,  1050] training loss: 0.00001906
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch176
INFO:root:[177,    50] training loss: 0.00713824
INFO:root:[177,   100] training loss: 0.00674896
INFO:root:[177,   150] training loss: 0.00762812
INFO:root:[177,   200] training loss: 0.00667361
INFO:root:[177,   250] training loss: 0.00684169
INFO:root:[177,   300] training loss: 0.00746228
INFO:root:[177,   350] training loss: 0.00657824
INFO:root:[177,   400] training loss: 0.00000577
INFO:root:[177,   450] training loss: 0.00000967
INFO:root:[177,   500] training loss: 0.00002558
INFO:root:[177,   550] training loss: 0.00021563
INFO:root:[177,   600] training loss: 0.00020115
INFO:root:[177,   650] training loss: 0.00001495
INFO:root:[177,   700] training loss: 0.00001378
INFO:root:[177,   750] training loss: 0.00022498
INFO:root:[177,   800] training loss: 0.00024440
INFO:root:[177,   850] training loss: 0.00029186
INFO:root:[177,   900] training loss: 0.00354376
INFO:root:[177,   950] training loss: 0.00116695
INFO:root:[177,  1000] training loss: 0.00001563
INFO:root:[177,  1050] training loss: 0.00001891
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch177
INFO:root:[178,    50] training loss: 0.00734120
INFO:root:[178,   100] training loss: 0.00729036
INFO:root:[178,   150] training loss: 0.00684570
INFO:root:[178,   200] training loss: 0.00658415
INFO:root:[178,   250] training loss: 0.00673589
INFO:root:[178,   300] training loss: 0.00747097
INFO:root:[178,   350] training loss: 0.00584036
INFO:root:[178,   400] training loss: 0.00000647
INFO:root:[178,   450] training loss: 0.00000741
INFO:root:[178,   500] training loss: 0.00002753
INFO:root:[178,   550] training loss: 0.00020704
INFO:root:[178,   600] training loss: 0.00022661
INFO:root:[178,   650] training loss: 0.00001233
INFO:root:[178,   700] training loss: 0.00001359
INFO:root:[178,   750] training loss: 0.00014641
INFO:root:[178,   800] training loss: 0.00024649
INFO:root:[178,   850] training loss: 0.00025636
INFO:root:[178,   900] training loss: 0.00395184
INFO:root:[178,   950] training loss: 0.00121999
INFO:root:[178,  1000] training loss: 0.00001958
INFO:root:[178,  1050] training loss: 0.00001521
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch178
INFO:root:[179,    50] training loss: 0.00767919
INFO:root:[179,   100] training loss: 0.00793956
INFO:root:[179,   150] training loss: 0.00701122
INFO:root:[179,   200] training loss: 0.00685534
INFO:root:[179,   250] training loss: 0.00759012
INFO:root:[179,   300] training loss: 0.00730891
INFO:root:[179,   350] training loss: 0.00620846
INFO:root:[179,   400] training loss: 0.00000639
INFO:root:[179,   450] training loss: 0.00000730
INFO:root:[179,   500] training loss: 0.00003150
INFO:root:[179,   550] training loss: 0.00016970
INFO:root:[179,   600] training loss: 0.00017319
INFO:root:[179,   650] training loss: 0.00001234
INFO:root:[179,   700] training loss: 0.00001304
INFO:root:[179,   750] training loss: 0.00013294
INFO:root:[179,   800] training loss: 0.00021274
INFO:root:[179,   850] training loss: 0.00029248
INFO:root:[179,   900] training loss: 0.00364680
INFO:root:[179,   950] training loss: 0.00139161
INFO:root:[179,  1000] training loss: 0.00001425
INFO:root:[179,  1050] training loss: 0.00001946
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch179
INFO:root:[180,    50] training loss: 0.00707265
INFO:root:[180,   100] training loss: 0.00760428
INFO:root:[180,   150] training loss: 0.00806846
INFO:root:[180,   200] training loss: 0.00662526
INFO:root:[180,   250] training loss: 0.00677749
INFO:root:[180,   300] training loss: 0.00750727
INFO:root:[180,   350] training loss: 0.00605824
INFO:root:[180,   400] training loss: 0.00000624
INFO:root:[180,   450] training loss: 0.00000819
INFO:root:[180,   500] training loss: 0.00004443
INFO:root:[180,   550] training loss: 0.00014694
INFO:root:[180,   600] training loss: 0.00013538
INFO:root:[180,   650] training loss: 0.00001546
INFO:root:[180,   700] training loss: 0.00001385
INFO:root:[180,   750] training loss: 0.00029848
INFO:root:[180,   800] training loss: 0.00022764
INFO:root:[180,   850] training loss: 0.00024872
INFO:root:[180,   900] training loss: 0.00352763
INFO:root:[180,   950] training loss: 0.00161689
INFO:root:[180,  1000] training loss: 0.00001786
INFO:root:[180,  1050] training loss: 0.00001672
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch180
INFO:root:[181,    50] training loss: 0.00828061
INFO:root:[181,   100] training loss: 0.00737953
INFO:root:[181,   150] training loss: 0.00738053
INFO:root:[181,   200] training loss: 0.00699477
INFO:root:[181,   250] training loss: 0.00691249
INFO:root:[181,   300] training loss: 0.00725859
INFO:root:[181,   350] training loss: 0.00622621
INFO:root:[181,   400] training loss: 0.00000523
INFO:root:[181,   450] training loss: 0.00000727
INFO:root:[181,   500] training loss: 0.00002933
INFO:root:[181,   550] training loss: 0.00018416
INFO:root:[181,   600] training loss: 0.00015400
INFO:root:[181,   650] training loss: 0.00001434
INFO:root:[181,   700] training loss: 0.00001481
INFO:root:[181,   750] training loss: 0.00021471
INFO:root:[181,   800] training loss: 0.00019089
INFO:root:[181,   850] training loss: 0.00022196
INFO:root:[181,   900] training loss: 0.00375792
INFO:root:[181,   950] training loss: 0.00132712
INFO:root:[181,  1000] training loss: 0.00001397
INFO:root:[181,  1050] training loss: 0.00002341
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch181
INFO:root:[182,    50] training loss: 0.00696029
INFO:root:[182,   100] training loss: 0.00775161
INFO:root:[182,   150] training loss: 0.00736286
INFO:root:[182,   200] training loss: 0.00668944
INFO:root:[182,   250] training loss: 0.00689478
INFO:root:[182,   300] training loss: 0.00748778
INFO:root:[182,   350] training loss: 0.00650241
INFO:root:[182,   400] training loss: 0.00000639
INFO:root:[182,   450] training loss: 0.00000712
INFO:root:[182,   500] training loss: 0.00002911
INFO:root:[182,   550] training loss: 0.00016822
INFO:root:[182,   600] training loss: 0.00016107
INFO:root:[182,   650] training loss: 0.00001104
INFO:root:[182,   700] training loss: 0.00001289
INFO:root:[182,   750] training loss: 0.00018868
INFO:root:[182,   800] training loss: 0.00024033
INFO:root:[182,   850] training loss: 0.00018997
INFO:root:[182,   900] training loss: 0.00475579
INFO:root:[182,   950] training loss: 0.00122436
INFO:root:[182,  1000] training loss: 0.00001601
INFO:root:[182,  1050] training loss: 0.00001781
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch182
INFO:root:[183,    50] training loss: 0.00715722
INFO:root:[183,   100] training loss: 0.00714990
INFO:root:[183,   150] training loss: 0.00712133
INFO:root:[183,   200] training loss: 0.00666281
INFO:root:[183,   250] training loss: 0.00680940
INFO:root:[183,   300] training loss: 0.00737762
INFO:root:[183,   350] training loss: 0.00598477
INFO:root:[183,   400] training loss: 0.00000613
INFO:root:[183,   450] training loss: 0.00000887
INFO:root:[183,   500] training loss: 0.00002437
INFO:root:[183,   550] training loss: 0.00018887
INFO:root:[183,   600] training loss: 0.00020690
INFO:root:[183,   650] training loss: 0.00001335
INFO:root:[183,   700] training loss: 0.00001419
INFO:root:[183,   750] training loss: 0.00020348
INFO:root:[183,   800] training loss: 0.00019024
INFO:root:[183,   850] training loss: 0.00020134
INFO:root:[183,   900] training loss: 0.00359567
INFO:root:[183,   950] training loss: 0.00133784
INFO:root:[183,  1000] training loss: 0.00001553
INFO:root:[183,  1050] training loss: 0.00002702
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch183
INFO:root:[184,    50] training loss: 0.00708046
INFO:root:[184,   100] training loss: 0.00719872
INFO:root:[184,   150] training loss: 0.00718724
INFO:root:[184,   200] training loss: 0.00699297
INFO:root:[184,   250] training loss: 0.00690528
INFO:root:[184,   300] training loss: 0.00718587
INFO:root:[184,   350] training loss: 0.00614086
INFO:root:[184,   400] training loss: 0.00000628
INFO:root:[184,   450] training loss: 0.00000887
INFO:root:[184,   500] training loss: 0.00002513
INFO:root:[184,   550] training loss: 0.00014869
INFO:root:[184,   600] training loss: 0.00013113
INFO:root:[184,   650] training loss: 0.00001370
INFO:root:[184,   700] training loss: 0.00001369
INFO:root:[184,   750] training loss: 0.00020369
INFO:root:[184,   800] training loss: 0.00017973
INFO:root:[184,   850] training loss: 0.00038138
INFO:root:[184,   900] training loss: 0.00356002
INFO:root:[184,   950] training loss: 0.00118399
INFO:root:[184,  1000] training loss: 0.00001518
INFO:root:[184,  1050] training loss: 0.00001586
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch184
INFO:root:[185,    50] training loss: 0.00705355
INFO:root:[185,   100] training loss: 0.00706969
INFO:root:[185,   150] training loss: 0.00790393
INFO:root:[185,   200] training loss: 0.00733456
INFO:root:[185,   250] training loss: 0.00699256
INFO:root:[185,   300] training loss: 0.00714773
INFO:root:[185,   350] training loss: 0.00598704
INFO:root:[185,   400] training loss: 0.00000625
INFO:root:[185,   450] training loss: 0.00000715
INFO:root:[185,   500] training loss: 0.00003015
INFO:root:[185,   550] training loss: 0.00014989
INFO:root:[185,   600] training loss: 0.00015475
INFO:root:[185,   650] training loss: 0.00001367
INFO:root:[185,   700] training loss: 0.00001255
INFO:root:[185,   750] training loss: 0.00028984
INFO:root:[185,   800] training loss: 0.00026661
INFO:root:[185,   850] training loss: 0.00025140
INFO:root:[185,   900] training loss: 0.00378655
INFO:root:[185,   950] training loss: 0.00111171
INFO:root:[185,  1000] training loss: 0.00002270
INFO:root:[185,  1050] training loss: 0.00001636
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch185
INFO:root:[186,    50] training loss: 0.00703791
INFO:root:[186,   100] training loss: 0.00734571
INFO:root:[186,   150] training loss: 0.00687899
INFO:root:[186,   200] training loss: 0.00702696
INFO:root:[186,   250] training loss: 0.00646704
INFO:root:[186,   300] training loss: 0.00739385
INFO:root:[186,   350] training loss: 0.00588719
INFO:root:[186,   400] training loss: 0.00000671
INFO:root:[186,   450] training loss: 0.00000612
INFO:root:[186,   500] training loss: 0.00002327
INFO:root:[186,   550] training loss: 0.00014927
INFO:root:[186,   600] training loss: 0.00020832
INFO:root:[186,   650] training loss: 0.00001339
INFO:root:[186,   700] training loss: 0.00001363
INFO:root:[186,   750] training loss: 0.00019778
INFO:root:[186,   800] training loss: 0.00021755
INFO:root:[186,   850] training loss: 0.00023151
INFO:root:[186,   900] training loss: 0.00306087
INFO:root:[186,   950] training loss: 0.00107074
INFO:root:[186,  1000] training loss: 0.00001598
INFO:root:[186,  1050] training loss: 0.00005267
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch186
INFO:root:[187,    50] training loss: 0.00722160
INFO:root:[187,   100] training loss: 0.00728952
INFO:root:[187,   150] training loss: 0.00807394
INFO:root:[187,   200] training loss: 0.00649913
INFO:root:[187,   250] training loss: 0.00678731
INFO:root:[187,   300] training loss: 0.00721874
INFO:root:[187,   350] training loss: 0.00660983
INFO:root:[187,   400] training loss: 0.00000555
INFO:root:[187,   450] training loss: 0.00000839
INFO:root:[187,   500] training loss: 0.00002182
INFO:root:[187,   550] training loss: 0.00020227
INFO:root:[187,   600] training loss: 0.00014792
INFO:root:[187,   650] training loss: 0.00001464
INFO:root:[187,   700] training loss: 0.00001382
INFO:root:[187,   750] training loss: 0.00020794
INFO:root:[187,   800] training loss: 0.00020258
INFO:root:[187,   850] training loss: 0.00027846
INFO:root:[187,   900] training loss: 0.00352744
INFO:root:[187,   950] training loss: 0.00153673
INFO:root:[187,  1000] training loss: 0.00001648
INFO:root:[187,  1050] training loss: 0.00001794
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch187
INFO:root:[188,    50] training loss: 0.00702143
INFO:root:[188,   100] training loss: 0.00713165
INFO:root:[188,   150] training loss: 0.00692451
INFO:root:[188,   200] training loss: 0.00661717
INFO:root:[188,   250] training loss: 0.00729342
INFO:root:[188,   300] training loss: 0.00697275
INFO:root:[188,   350] training loss: 0.00608848
INFO:root:[188,   400] training loss: 0.00000624
INFO:root:[188,   450] training loss: 0.00000774
INFO:root:[188,   500] training loss: 0.00002849
INFO:root:[188,   550] training loss: 0.00016336
INFO:root:[188,   600] training loss: 0.00019179
INFO:root:[188,   650] training loss: 0.00001262
INFO:root:[188,   700] training loss: 0.00001220
INFO:root:[188,   750] training loss: 0.00016845
INFO:root:[188,   800] training loss: 0.00017628
INFO:root:[188,   850] training loss: 0.00027254
INFO:root:[188,   900] training loss: 0.00364740
INFO:root:[188,   950] training loss: 0.00116063
INFO:root:[188,  1000] training loss: 0.00001735
INFO:root:[188,  1050] training loss: 0.00002246
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch188
INFO:root:[189,    50] training loss: 0.00739856
INFO:root:[189,   100] training loss: 0.00727352
INFO:root:[189,   150] training loss: 0.00714499
INFO:root:[189,   200] training loss: 0.00662081
INFO:root:[189,   250] training loss: 0.00698968
INFO:root:[189,   300] training loss: 0.00737583
INFO:root:[189,   350] training loss: 0.00605615
INFO:root:[189,   400] training loss: 0.00000565
INFO:root:[189,   450] training loss: 0.00000916
INFO:root:[189,   500] training loss: 0.00002270
INFO:root:[189,   550] training loss: 0.00016478
INFO:root:[189,   600] training loss: 0.00013884
INFO:root:[189,   650] training loss: 0.00001302
INFO:root:[189,   700] training loss: 0.00001354
INFO:root:[189,   750] training loss: 0.00019662
INFO:root:[189,   800] training loss: 0.00028930
INFO:root:[189,   850] training loss: 0.00026316
INFO:root:[189,   900] training loss: 0.00405952
INFO:root:[189,   950] training loss: 0.00096967
INFO:root:[189,  1000] training loss: 0.00001744
INFO:root:[189,  1050] training loss: 0.00001886
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch189
INFO:root:[190,    50] training loss: 0.00740516
INFO:root:[190,   100] training loss: 0.00723394
INFO:root:[190,   150] training loss: 0.00709883
INFO:root:[190,   200] training loss: 0.00658088
INFO:root:[190,   250] training loss: 0.00736486
INFO:root:[190,   300] training loss: 0.00726208
INFO:root:[190,   350] training loss: 0.00645149
INFO:root:[190,   400] training loss: 0.00000633
INFO:root:[190,   450] training loss: 0.00000878
INFO:root:[190,   500] training loss: 0.00002501
INFO:root:[190,   550] training loss: 0.00017615
INFO:root:[190,   600] training loss: 0.00011869
INFO:root:[190,   650] training loss: 0.00001126
INFO:root:[190,   700] training loss: 0.00001432
INFO:root:[190,   750] training loss: 0.00020012
INFO:root:[190,   800] training loss: 0.00020178
INFO:root:[190,   850] training loss: 0.00029062
INFO:root:[190,   900] training loss: 0.00354050
INFO:root:[190,   950] training loss: 0.00119074
INFO:root:[190,  1000] training loss: 0.00001635
INFO:root:[190,  1050] training loss: 0.00001936
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch190
INFO:root:[191,    50] training loss: 0.00697180
INFO:root:[191,   100] training loss: 0.00711419
INFO:root:[191,   150] training loss: 0.00701870
INFO:root:[191,   200] training loss: 0.00697421
INFO:root:[191,   250] training loss: 0.00806524
INFO:root:[191,   300] training loss: 0.00798359
INFO:root:[191,   350] training loss: 0.00597879
INFO:root:[191,   400] training loss: 0.00000602
INFO:root:[191,   450] training loss: 0.00000938
INFO:root:[191,   500] training loss: 0.00002436
INFO:root:[191,   550] training loss: 0.00013519
INFO:root:[191,   600] training loss: 0.00016020
INFO:root:[191,   650] training loss: 0.00001309
INFO:root:[191,   700] training loss: 0.00001244
INFO:root:[191,   750] training loss: 0.00025164
INFO:root:[191,   800] training loss: 0.00020816
INFO:root:[191,   850] training loss: 0.00029329
INFO:root:[191,   900] training loss: 0.00312638
INFO:root:[191,   950] training loss: 0.00091870
INFO:root:[191,  1000] training loss: 0.00001710
INFO:root:[191,  1050] training loss: 0.00001881
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch191
INFO:root:[192,    50] training loss: 0.00724315
INFO:root:[192,   100] training loss: 0.00728085
INFO:root:[192,   150] training loss: 0.00827403
INFO:root:[192,   200] training loss: 0.00647714
INFO:root:[192,   250] training loss: 0.00691617
INFO:root:[192,   300] training loss: 0.00728239
INFO:root:[192,   350] training loss: 0.00618818
INFO:root:[192,   400] training loss: 0.00000622
INFO:root:[192,   450] training loss: 0.00000763
INFO:root:[192,   500] training loss: 0.00002804
INFO:root:[192,   550] training loss: 0.00015004
INFO:root:[192,   600] training loss: 0.00017489
INFO:root:[192,   650] training loss: 0.00001228
INFO:root:[192,   700] training loss: 0.00001366
INFO:root:[192,   750] training loss: 0.00018188
INFO:root:[192,   800] training loss: 0.00019855
INFO:root:[192,   850] training loss: 0.00032916
INFO:root:[192,   900] training loss: 0.00369113
INFO:root:[192,   950] training loss: 0.00109865
INFO:root:[192,  1000] training loss: 0.00001708
INFO:root:[192,  1050] training loss: 0.00001768
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch192
INFO:root:[193,    50] training loss: 0.00738941
INFO:root:[193,   100] training loss: 0.00757897
INFO:root:[193,   150] training loss: 0.00739400
INFO:root:[193,   200] training loss: 0.00660450
INFO:root:[193,   250] training loss: 0.00666608
INFO:root:[193,   300] training loss: 0.00698530
INFO:root:[193,   350] training loss: 0.00634180
INFO:root:[193,   400] training loss: 0.00000505
INFO:root:[193,   450] training loss: 0.00000636
INFO:root:[193,   500] training loss: 0.00002773
INFO:root:[193,   550] training loss: 0.00018310
INFO:root:[193,   600] training loss: 0.00015178
INFO:root:[193,   650] training loss: 0.00001370
INFO:root:[193,   700] training loss: 0.00001483
INFO:root:[193,   750] training loss: 0.00021884
INFO:root:[193,   800] training loss: 0.00022515
INFO:root:[193,   850] training loss: 0.00025794
INFO:root:[193,   900] training loss: 0.00338881
INFO:root:[193,   950] training loss: 0.00095461
INFO:root:[193,  1000] training loss: 0.00001602
INFO:root:[193,  1050] training loss: 0.00001732
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch193
INFO:root:[194,    50] training loss: 0.00735705
INFO:root:[194,   100] training loss: 0.00732374
INFO:root:[194,   150] training loss: 0.00730157
INFO:root:[194,   200] training loss: 0.00637487
INFO:root:[194,   250] training loss: 0.00733037
INFO:root:[194,   300] training loss: 0.00704378
INFO:root:[194,   350] training loss: 0.00624229
INFO:root:[194,   400] training loss: 0.00000546
INFO:root:[194,   450] training loss: 0.00000728
INFO:root:[194,   500] training loss: 0.00002810
INFO:root:[194,   550] training loss: 0.00019696
INFO:root:[194,   600] training loss: 0.00020351
INFO:root:[194,   650] training loss: 0.00001308
INFO:root:[194,   700] training loss: 0.00001429
INFO:root:[194,   750] training loss: 0.00022651
INFO:root:[194,   800] training loss: 0.00016651
INFO:root:[194,   850] training loss: 0.00024283
INFO:root:[194,   900] training loss: 0.00382153
INFO:root:[194,   950] training loss: 0.00089609
INFO:root:[194,  1000] training loss: 0.00001546
INFO:root:[194,  1050] training loss: 0.00001933
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch194
INFO:root:[195,    50] training loss: 0.00761594
INFO:root:[195,   100] training loss: 0.00717058
INFO:root:[195,   150] training loss: 0.00723001
INFO:root:[195,   200] training loss: 0.00733946
INFO:root:[195,   250] training loss: 0.00755630
INFO:root:[195,   300] training loss: 0.00728717
INFO:root:[195,   350] training loss: 0.00634052
INFO:root:[195,   400] training loss: 0.00000637
INFO:root:[195,   450] training loss: 0.00000797
INFO:root:[195,   500] training loss: 0.00002057
INFO:root:[195,   550] training loss: 0.00015051
INFO:root:[195,   600] training loss: 0.00015716
INFO:root:[195,   650] training loss: 0.00001139
INFO:root:[195,   700] training loss: 0.00001350
INFO:root:[195,   750] training loss: 0.00028938
INFO:root:[195,   800] training loss: 0.00022760
INFO:root:[195,   850] training loss: 0.00019478
INFO:root:[195,   900] training loss: 0.00388573
INFO:root:[195,   950] training loss: 0.00108417
INFO:root:[195,  1000] training loss: 0.00001739
INFO:root:[195,  1050] training loss: 0.00001597
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch195
INFO:root:[196,    50] training loss: 0.00745630
INFO:root:[196,   100] training loss: 0.00686799
INFO:root:[196,   150] training loss: 0.00899490
INFO:root:[196,   200] training loss: 0.00694743
INFO:root:[196,   250] training loss: 0.00698218
INFO:root:[196,   300] training loss: 0.00745315
INFO:root:[196,   350] training loss: 0.00583710
INFO:root:[196,   400] training loss: 0.00000806
INFO:root:[196,   450] training loss: 0.00001016
INFO:root:[196,   500] training loss: 0.00004032
INFO:root:[196,   550] training loss: 0.00022443
INFO:root:[196,   600] training loss: 0.00019773
INFO:root:[196,   650] training loss: 0.00001446
INFO:root:[196,   700] training loss: 0.00001456
INFO:root:[196,   750] training loss: 0.00024933
INFO:root:[196,   800] training loss: 0.00023245
INFO:root:[196,   850] training loss: 0.00024129
INFO:root:[196,   900] training loss: 0.00334838
INFO:root:[196,   950] training loss: 0.00110453
INFO:root:[196,  1000] training loss: 0.00002446
INFO:root:[196,  1050] training loss: 0.00001846
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch196
INFO:root:[197,    50] training loss: 0.00688197
INFO:root:[197,   100] training loss: 0.00722008
INFO:root:[197,   150] training loss: 0.00672432
INFO:root:[197,   200] training loss: 0.00671348
INFO:root:[197,   250] training loss: 0.00803446
INFO:root:[197,   300] training loss: 0.00749087
INFO:root:[197,   350] training loss: 0.00627329
INFO:root:[197,   400] training loss: 0.00000621
INFO:root:[197,   450] training loss: 0.00000846
INFO:root:[197,   500] training loss: 0.00002616
INFO:root:[197,   550] training loss: 0.00014037
INFO:root:[197,   600] training loss: 0.00017141
INFO:root:[197,   650] training loss: 0.00001386
INFO:root:[197,   700] training loss: 0.00001418
INFO:root:[197,   750] training loss: 0.00026928
INFO:root:[197,   800] training loss: 0.00024871
INFO:root:[197,   850] training loss: 0.00023297
INFO:root:[197,   900] training loss: 0.00350969
INFO:root:[197,   950] training loss: 0.00099900
INFO:root:[197,  1000] training loss: 0.00001671
INFO:root:[197,  1050] training loss: 0.00001665
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch197
INFO:root:[198,    50] training loss: 0.00723045
INFO:root:[198,   100] training loss: 0.00744908
INFO:root:[198,   150] training loss: 0.00692805
INFO:root:[198,   200] training loss: 0.00752007
INFO:root:[198,   250] training loss: 0.00702796
INFO:root:[198,   300] training loss: 0.00732460
INFO:root:[198,   350] training loss: 0.00660997
INFO:root:[198,   400] training loss: 0.00000717
INFO:root:[198,   450] training loss: 0.00000887
INFO:root:[198,   500] training loss: 0.00002243
INFO:root:[198,   550] training loss: 0.00015282
INFO:root:[198,   600] training loss: 0.00018847
INFO:root:[198,   650] training loss: 0.00001437
INFO:root:[198,   700] training loss: 0.00001253
INFO:root:[198,   750] training loss: 0.00014496
INFO:root:[198,   800] training loss: 0.00022220
INFO:root:[198,   850] training loss: 0.00022434
INFO:root:[198,   900] training loss: 0.00355912
INFO:root:[198,   950] training loss: 0.00123788
INFO:root:[198,  1000] training loss: 0.00001911
INFO:root:[198,  1050] training loss: 0.00001805
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch198
INFO:root:[199,    50] training loss: 0.00721993
INFO:root:[199,   100] training loss: 0.00739684
INFO:root:[199,   150] training loss: 0.00718011
INFO:root:[199,   200] training loss: 0.00642211
INFO:root:[199,   250] training loss: 0.00697675
INFO:root:[199,   300] training loss: 0.00737728
INFO:root:[199,   350] training loss: 0.00651370
INFO:root:[199,   400] training loss: 0.00000821
INFO:root:[199,   450] training loss: 0.00000876
INFO:root:[199,   500] training loss: 0.00003104
INFO:root:[199,   550] training loss: 0.00017585
INFO:root:[199,   600] training loss: 0.00016416
INFO:root:[199,   650] training loss: 0.00001322
INFO:root:[199,   700] training loss: 0.00001318
INFO:root:[199,   750] training loss: 0.00021351
INFO:root:[199,   800] training loss: 0.00017905
INFO:root:[199,   850] training loss: 0.00027618
INFO:root:[199,   900] training loss: 0.00405494
INFO:root:[199,   950] training loss: 0.00086672
INFO:root:[199,  1000] training loss: 0.00001700
INFO:root:[199,  1050] training loss: 0.00003344
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch199
INFO:root:[200,    50] training loss: 0.00692235
INFO:root:[200,   100] training loss: 0.00697515
INFO:root:[200,   150] training loss: 0.00710760
INFO:root:[200,   200] training loss: 0.00671764
INFO:root:[200,   250] training loss: 0.00672650
INFO:root:[200,   300] training loss: 0.00727147
INFO:root:[200,   350] training loss: 0.00582181
INFO:root:[200,   400] training loss: 0.00000652
INFO:root:[200,   450] training loss: 0.00000818
INFO:root:[200,   500] training loss: 0.00002727
INFO:root:[200,   550] training loss: 0.00016441
INFO:root:[200,   600] training loss: 0.00017203
INFO:root:[200,   650] training loss: 0.00001683
INFO:root:[200,   700] training loss: 0.00001201
INFO:root:[200,   750] training loss: 0.00021164
INFO:root:[200,   800] training loss: 0.00021649
INFO:root:[200,   850] training loss: 0.00025411
INFO:root:[200,   900] training loss: 0.00375908
INFO:root:[200,   950] training loss: 0.00111176
INFO:root:[200,  1000] training loss: 0.00001816
INFO:root:[200,  1050] training loss: 0.00001838
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch200
INFO:root:[201,    50] training loss: 0.00716383
INFO:root:[201,   100] training loss: 0.00710385
INFO:root:[201,   150] training loss: 0.00688438
INFO:root:[201,   200] training loss: 0.00643361
INFO:root:[201,   250] training loss: 0.00666113
INFO:root:[201,   300] training loss: 0.00747866
INFO:root:[201,   350] training loss: 0.00611500
INFO:root:[201,   400] training loss: 0.00000514
INFO:root:[201,   450] training loss: 0.00000797
INFO:root:[201,   500] training loss: 0.00003272
INFO:root:[201,   550] training loss: 0.00015363
INFO:root:[201,   600] training loss: 0.00012951
INFO:root:[201,   650] training loss: 0.00001251
INFO:root:[201,   700] training loss: 0.00001458
INFO:root:[201,   750] training loss: 0.00022795
INFO:root:[201,   800] training loss: 0.00022532
INFO:root:[201,   850] training loss: 0.00027007
INFO:root:[201,   900] training loss: 0.00452593
INFO:root:[201,   950] training loss: 0.00117917
INFO:root:[201,  1000] training loss: 0.00001664
INFO:root:[201,  1050] training loss: 0.00001573
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch201
INFO:root:[202,    50] training loss: 0.00716818
INFO:root:[202,   100] training loss: 0.00747342
INFO:root:[202,   150] training loss: 0.00727983
INFO:root:[202,   200] training loss: 0.00710294
INFO:root:[202,   250] training loss: 0.00662092
INFO:root:[202,   300] training loss: 0.00754340
INFO:root:[202,   350] training loss: 0.00607455
INFO:root:[202,   400] training loss: 0.00000563
INFO:root:[202,   450] training loss: 0.00000903
INFO:root:[202,   500] training loss: 0.00002889
INFO:root:[202,   550] training loss: 0.00016227
INFO:root:[202,   600] training loss: 0.00014715
INFO:root:[202,   650] training loss: 0.00001440
INFO:root:[202,   700] training loss: 0.00001313
INFO:root:[202,   750] training loss: 0.00022167
INFO:root:[202,   800] training loss: 0.00039096
INFO:root:[202,   850] training loss: 0.00028943
INFO:root:[202,   900] training loss: 0.00399120
INFO:root:[202,   950] training loss: 0.00090703
INFO:root:[202,  1000] training loss: 0.00002158
INFO:root:[202,  1050] training loss: 0.00001680
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch202
INFO:root:[203,    50] training loss: 0.00743212
INFO:root:[203,   100] training loss: 0.00709228
INFO:root:[203,   150] training loss: 0.00685303
INFO:root:[203,   200] training loss: 0.00699070
INFO:root:[203,   250] training loss: 0.00657062
INFO:root:[203,   300] training loss: 0.00746348
INFO:root:[203,   350] training loss: 0.00586716
INFO:root:[203,   400] training loss: 0.00000604
INFO:root:[203,   450] training loss: 0.00001037
INFO:root:[203,   500] training loss: 0.00002474
INFO:root:[203,   550] training loss: 0.00018424
INFO:root:[203,   600] training loss: 0.00020045
INFO:root:[203,   650] training loss: 0.00001453
INFO:root:[203,   700] training loss: 0.00001471
INFO:root:[203,   750] training loss: 0.00025791
INFO:root:[203,   800] training loss: 0.00027879
INFO:root:[203,   850] training loss: 0.00026602
INFO:root:[203,   900] training loss: 0.00304181
INFO:root:[203,   950] training loss: 0.00112496
INFO:root:[203,  1000] training loss: 0.00001608
INFO:root:[203,  1050] training loss: 0.00001666
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch203
INFO:root:[204,    50] training loss: 0.00741786
INFO:root:[204,   100] training loss: 0.00758253
INFO:root:[204,   150] training loss: 0.00667325
INFO:root:[204,   200] training loss: 0.00671549
INFO:root:[204,   250] training loss: 0.00719330
INFO:root:[204,   300] training loss: 0.00726314
INFO:root:[204,   350] training loss: 0.00602556
INFO:root:[204,   400] training loss: 0.00000622
INFO:root:[204,   450] training loss: 0.00000990
INFO:root:[204,   500] training loss: 0.00004274
INFO:root:[204,   550] training loss: 0.00015313
INFO:root:[204,   600] training loss: 0.00016742
INFO:root:[204,   650] training loss: 0.00001343
INFO:root:[204,   700] training loss: 0.00001499
INFO:root:[204,   750] training loss: 0.00024763
INFO:root:[204,   800] training loss: 0.00023540
INFO:root:[204,   850] training loss: 0.00027408
INFO:root:[204,   900] training loss: 0.00424466
INFO:root:[204,   950] training loss: 0.00113384
INFO:root:[204,  1000] training loss: 0.00001598
INFO:root:[204,  1050] training loss: 0.00001933
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8932    0.8221    0.8562      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6088    0.6654    0.6359      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7701      3872
   macro avg     0.7169    0.7952    0.7474      3872
weighted avg     0.7820    0.7701    0.7746      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch204
INFO:root:[205,    50] training loss: 0.00734647
INFO:root:[205,   100] training loss: 0.00714925
INFO:root:[205,   150] training loss: 0.00717020
INFO:root:[205,   200] training loss: 0.00663309
INFO:root:[205,   250] training loss: 0.00704559
INFO:root:[205,   300] training loss: 0.00859180
INFO:root:[205,   350] training loss: 0.00607924
INFO:root:[205,   400] training loss: 0.00000602
INFO:root:[205,   450] training loss: 0.00000694
INFO:root:[205,   500] training loss: 0.00002659
INFO:root:[205,   550] training loss: 0.00019133
INFO:root:[205,   600] training loss: 0.00016951
INFO:root:[205,   650] training loss: 0.00001244
INFO:root:[205,   700] training loss: 0.00001399
INFO:root:[205,   750] training loss: 0.00021252
INFO:root:[205,   800] training loss: 0.00015576
INFO:root:[205,   850] training loss: 0.00030291
INFO:root:[205,   900] training loss: 0.00356089
INFO:root:[205,   950] training loss: 0.00099261
INFO:root:[205,  1000] training loss: 0.00001867
INFO:root:[205,  1050] training loss: 0.00001702
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch205
INFO:root:[206,    50] training loss: 0.00714234
INFO:root:[206,   100] training loss: 0.00700458
INFO:root:[206,   150] training loss: 0.00677247
INFO:root:[206,   200] training loss: 0.00633875
INFO:root:[206,   250] training loss: 0.00717167
INFO:root:[206,   300] training loss: 0.00740778
INFO:root:[206,   350] training loss: 0.00613657
INFO:root:[206,   400] training loss: 0.00000587
INFO:root:[206,   450] training loss: 0.00000637
INFO:root:[206,   500] training loss: 0.00002862
INFO:root:[206,   550] training loss: 0.00019051
INFO:root:[206,   600] training loss: 0.00015611
INFO:root:[206,   650] training loss: 0.00001526
INFO:root:[206,   700] training loss: 0.00001481
INFO:root:[206,   750] training loss: 0.00029624
INFO:root:[206,   800] training loss: 0.00022086
INFO:root:[206,   850] training loss: 0.00027019
INFO:root:[206,   900] training loss: 0.00337536
INFO:root:[206,   950] training loss: 0.00097291
INFO:root:[206,  1000] training loss: 0.00001471
INFO:root:[206,  1050] training loss: 0.00001458
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch206
INFO:root:[207,    50] training loss: 0.00732960
INFO:root:[207,   100] training loss: 0.00711859
INFO:root:[207,   150] training loss: 0.00693599
INFO:root:[207,   200] training loss: 0.00660385
INFO:root:[207,   250] training loss: 0.00675241
INFO:root:[207,   300] training loss: 0.00716867
INFO:root:[207,   350] training loss: 0.00620219
INFO:root:[207,   400] training loss: 0.00000654
INFO:root:[207,   450] training loss: 0.00000846
INFO:root:[207,   500] training loss: 0.00003346
INFO:root:[207,   550] training loss: 0.00015612
INFO:root:[207,   600] training loss: 0.00013038
INFO:root:[207,   650] training loss: 0.00001474
INFO:root:[207,   700] training loss: 0.00001256
INFO:root:[207,   750] training loss: 0.00019448
INFO:root:[207,   800] training loss: 0.00014809
INFO:root:[207,   850] training loss: 0.00026012
INFO:root:[207,   900] training loss: 0.00386060
INFO:root:[207,   950] training loss: 0.00088372
INFO:root:[207,  1000] training loss: 0.00001399
INFO:root:[207,  1050] training loss: 0.00002091
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch207
INFO:root:[208,    50] training loss: 0.00733390
INFO:root:[208,   100] training loss: 0.00700088
INFO:root:[208,   150] training loss: 0.00702493
INFO:root:[208,   200] training loss: 0.00651553
INFO:root:[208,   250] training loss: 0.00675087
INFO:root:[208,   300] training loss: 0.00693412
INFO:root:[208,   350] training loss: 0.00628786
INFO:root:[208,   400] training loss: 0.00000595
INFO:root:[208,   450] training loss: 0.00000693
INFO:root:[208,   500] training loss: 0.00002138
INFO:root:[208,   550] training loss: 0.00023138
INFO:root:[208,   600] training loss: 0.00017883
INFO:root:[208,   650] training loss: 0.00001147
INFO:root:[208,   700] training loss: 0.00001224
INFO:root:[208,   750] training loss: 0.00016018
INFO:root:[208,   800] training loss: 0.00022708
INFO:root:[208,   850] training loss: 0.00024804
INFO:root:[208,   900] training loss: 0.00338161
INFO:root:[208,   950] training loss: 0.00101033
INFO:root:[208,  1000] training loss: 0.00002034
INFO:root:[208,  1050] training loss: 0.00001267
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch208
INFO:root:[209,    50] training loss: 0.00790809
INFO:root:[209,   100] training loss: 0.00702382
INFO:root:[209,   150] training loss: 0.00694805
INFO:root:[209,   200] training loss: 0.00666451
INFO:root:[209,   250] training loss: 0.00706299
INFO:root:[209,   300] training loss: 0.00716686
INFO:root:[209,   350] training loss: 0.00588272
INFO:root:[209,   400] training loss: 0.00000666
INFO:root:[209,   450] training loss: 0.00000803
INFO:root:[209,   500] training loss: 0.00003131
INFO:root:[209,   550] training loss: 0.00015050
INFO:root:[209,   600] training loss: 0.00022283
INFO:root:[209,   650] training loss: 0.00001140
INFO:root:[209,   700] training loss: 0.00001456
INFO:root:[209,   750] training loss: 0.00028713
INFO:root:[209,   800] training loss: 0.00022489
INFO:root:[209,   850] training loss: 0.00026081
INFO:root:[209,   900] training loss: 0.00317504
INFO:root:[209,   950] training loss: 0.00094455
INFO:root:[209,  1000] training loss: 0.00001830
INFO:root:[209,  1050] training loss: 0.00002184
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch209
INFO:root:[210,    50] training loss: 0.00705805
INFO:root:[210,   100] training loss: 0.00704469
INFO:root:[210,   150] training loss: 0.00706450
INFO:root:[210,   200] training loss: 0.00663131
INFO:root:[210,   250] training loss: 0.00672806
INFO:root:[210,   300] training loss: 0.00778699
INFO:root:[210,   350] training loss: 0.00718246
INFO:root:[210,   400] training loss: 0.00000751
INFO:root:[210,   450] training loss: 0.00000890
INFO:root:[210,   500] training loss: 0.00003387
INFO:root:[210,   550] training loss: 0.00017782
INFO:root:[210,   600] training loss: 0.00013812
INFO:root:[210,   650] training loss: 0.00001353
INFO:root:[210,   700] training loss: 0.00001441
INFO:root:[210,   750] training loss: 0.00025753
INFO:root:[210,   800] training loss: 0.00024672
INFO:root:[210,   850] training loss: 0.00026106
INFO:root:[210,   900] training loss: 0.00344526
INFO:root:[210,   950] training loss: 0.00134739
INFO:root:[210,  1000] training loss: 0.00001493
INFO:root:[210,  1050] training loss: 0.00002481
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch210
INFO:root:[211,    50] training loss: 0.00691482
INFO:root:[211,   100] training loss: 0.00702863
INFO:root:[211,   150] training loss: 0.00745214
INFO:root:[211,   200] training loss: 0.00683979
INFO:root:[211,   250] training loss: 0.00660330
INFO:root:[211,   300] training loss: 0.00726352
INFO:root:[211,   350] training loss: 0.00623330
INFO:root:[211,   400] training loss: 0.00000534
INFO:root:[211,   450] training loss: 0.00000922
INFO:root:[211,   500] training loss: 0.00002416
INFO:root:[211,   550] training loss: 0.00016133
INFO:root:[211,   600] training loss: 0.00012361
INFO:root:[211,   650] training loss: 0.00001482
INFO:root:[211,   700] training loss: 0.00001489
INFO:root:[211,   750] training loss: 0.00020724
INFO:root:[211,   800] training loss: 0.00026090
INFO:root:[211,   850] training loss: 0.00034360
INFO:root:[211,   900] training loss: 0.00341257
INFO:root:[211,   950] training loss: 0.00099067
INFO:root:[211,  1000] training loss: 0.00001544
INFO:root:[211,  1050] training loss: 0.00001409
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch211
INFO:root:[212,    50] training loss: 0.00708233
INFO:root:[212,   100] training loss: 0.00718984
INFO:root:[212,   150] training loss: 0.00697324
INFO:root:[212,   200] training loss: 0.00688855
INFO:root:[212,   250] training loss: 0.00683899
INFO:root:[212,   300] training loss: 0.00727315
INFO:root:[212,   350] training loss: 0.00593402
INFO:root:[212,   400] training loss: 0.00000659
INFO:root:[212,   450] training loss: 0.00000705
INFO:root:[212,   500] training loss: 0.00002739
INFO:root:[212,   550] training loss: 0.00015431
INFO:root:[212,   600] training loss: 0.00016655
INFO:root:[212,   650] training loss: 0.00001353
INFO:root:[212,   700] training loss: 0.00001253
INFO:root:[212,   750] training loss: 0.00020837
INFO:root:[212,   800] training loss: 0.00020243
INFO:root:[212,   850] training loss: 0.00031888
INFO:root:[212,   900] training loss: 0.00309375
INFO:root:[212,   950] training loss: 0.00151702
INFO:root:[212,  1000] training loss: 0.00001806
INFO:root:[212,  1050] training loss: 0.00006334
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch212
INFO:root:[213,    50] training loss: 0.00743460
INFO:root:[213,   100] training loss: 0.00693512
INFO:root:[213,   150] training loss: 0.00686289
INFO:root:[213,   200] training loss: 0.00682787
INFO:root:[213,   250] training loss: 0.00705285
INFO:root:[213,   300] training loss: 0.00743918
INFO:root:[213,   350] training loss: 0.00591597
INFO:root:[213,   400] training loss: 0.00000546
INFO:root:[213,   450] training loss: 0.00000799
INFO:root:[213,   500] training loss: 0.00002438
INFO:root:[213,   550] training loss: 0.00017532
INFO:root:[213,   600] training loss: 0.00013466
INFO:root:[213,   650] training loss: 0.00001330
INFO:root:[213,   700] training loss: 0.00001423
INFO:root:[213,   750] training loss: 0.00024495
INFO:root:[213,   800] training loss: 0.00017641
INFO:root:[213,   850] training loss: 0.00024714
INFO:root:[213,   900] training loss: 0.00330266
INFO:root:[213,   950] training loss: 0.00110078
INFO:root:[213,  1000] training loss: 0.00001705
INFO:root:[213,  1050] training loss: 0.00011350
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch213
INFO:root:[214,    50] training loss: 0.00722668
INFO:root:[214,   100] training loss: 0.00711766
INFO:root:[214,   150] training loss: 0.00707197
INFO:root:[214,   200] training loss: 0.00675950
INFO:root:[214,   250] training loss: 0.00669718
INFO:root:[214,   300] training loss: 0.00716543
INFO:root:[214,   350] training loss: 0.00631600
INFO:root:[214,   400] training loss: 0.00000630
INFO:root:[214,   450] training loss: 0.00000700
INFO:root:[214,   500] training loss: 0.00002667
INFO:root:[214,   550] training loss: 0.00014663
INFO:root:[214,   600] training loss: 0.00011572
INFO:root:[214,   650] training loss: 0.00001302
INFO:root:[214,   700] training loss: 0.00001567
INFO:root:[214,   750] training loss: 0.00015919
INFO:root:[214,   800] training loss: 0.00025849
INFO:root:[214,   850] training loss: 0.00022674
INFO:root:[214,   900] training loss: 0.00327073
INFO:root:[214,   950] training loss: 0.00094026
INFO:root:[214,  1000] training loss: 0.00001406
INFO:root:[214,  1050] training loss: 0.00002227
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch214
INFO:root:[215,    50] training loss: 0.00698350
INFO:root:[215,   100] training loss: 0.00755553
INFO:root:[215,   150] training loss: 0.00781080
INFO:root:[215,   200] training loss: 0.00648873
INFO:root:[215,   250] training loss: 0.00692053
INFO:root:[215,   300] training loss: 0.00735456
INFO:root:[215,   350] training loss: 0.00626044
INFO:root:[215,   400] training loss: 0.00000573
INFO:root:[215,   450] training loss: 0.00000932
INFO:root:[215,   500] training loss: 0.00003403
INFO:root:[215,   550] training loss: 0.00014589
INFO:root:[215,   600] training loss: 0.00025858
INFO:root:[215,   650] training loss: 0.00001269
INFO:root:[215,   700] training loss: 0.00001424
INFO:root:[215,   750] training loss: 0.00024253
INFO:root:[215,   800] training loss: 0.00022844
INFO:root:[215,   850] training loss: 0.00022721
INFO:root:[215,   900] training loss: 0.00331373
INFO:root:[215,   950] training loss: 0.00125408
INFO:root:[215,  1000] training loss: 0.00002304
INFO:root:[215,  1050] training loss: 0.00002010
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch215
INFO:root:[216,    50] training loss: 0.00738733
INFO:root:[216,   100] training loss: 0.00727179
INFO:root:[216,   150] training loss: 0.00707039
INFO:root:[216,   200] training loss: 0.00648582
INFO:root:[216,   250] training loss: 0.00673301
INFO:root:[216,   300] training loss: 0.00741669
INFO:root:[216,   350] training loss: 0.00628557
INFO:root:[216,   400] training loss: 0.00000692
INFO:root:[216,   450] training loss: 0.00000767
INFO:root:[216,   500] training loss: 0.00003450
INFO:root:[216,   550] training loss: 0.00013959
INFO:root:[216,   600] training loss: 0.00015072
INFO:root:[216,   650] training loss: 0.00001149
INFO:root:[216,   700] training loss: 0.00001304
INFO:root:[216,   750] training loss: 0.00024517
INFO:root:[216,   800] training loss: 0.00019369
INFO:root:[216,   850] training loss: 0.00028477
INFO:root:[216,   900] training loss: 0.00336831
INFO:root:[216,   950] training loss: 0.00121371
INFO:root:[216,  1000] training loss: 0.00001844
INFO:root:[216,  1050] training loss: 0.00002192
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch216
INFO:root:[217,    50] training loss: 0.00695805
INFO:root:[217,   100] training loss: 0.00727071
INFO:root:[217,   150] training loss: 0.00716959
INFO:root:[217,   200] training loss: 0.00674069
INFO:root:[217,   250] training loss: 0.00658102
INFO:root:[217,   300] training loss: 0.00722700
INFO:root:[217,   350] training loss: 0.00610524
INFO:root:[217,   400] training loss: 0.00000639
INFO:root:[217,   450] training loss: 0.00000821
INFO:root:[217,   500] training loss: 0.00003125
INFO:root:[217,   550] training loss: 0.00020032
INFO:root:[217,   600] training loss: 0.00020823
INFO:root:[217,   650] training loss: 0.00001320
INFO:root:[217,   700] training loss: 0.00001376
INFO:root:[217,   750] training loss: 0.00020526
INFO:root:[217,   800] training loss: 0.00027203
INFO:root:[217,   850] training loss: 0.00022898
INFO:root:[217,   900] training loss: 0.00403535
INFO:root:[217,   950] training loss: 0.00105286
INFO:root:[217,  1000] training loss: 0.00001677
INFO:root:[217,  1050] training loss: 0.00001665
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch217
INFO:root:[218,    50] training loss: 0.00776524
INFO:root:[218,   100] training loss: 0.00722532
INFO:root:[218,   150] training loss: 0.00733240
INFO:root:[218,   200] training loss: 0.00662740
INFO:root:[218,   250] training loss: 0.00677136
INFO:root:[218,   300] training loss: 0.00705151
INFO:root:[218,   350] training loss: 0.00670628
INFO:root:[218,   400] training loss: 0.00000661
INFO:root:[218,   450] training loss: 0.00000864
INFO:root:[218,   500] training loss: 0.00003026
INFO:root:[218,   550] training loss: 0.00018105
INFO:root:[218,   600] training loss: 0.00019990
INFO:root:[218,   650] training loss: 0.00001157
INFO:root:[218,   700] training loss: 0.00001342
INFO:root:[218,   750] training loss: 0.00016500
INFO:root:[218,   800] training loss: 0.00022660
INFO:root:[218,   850] training loss: 0.00022084
INFO:root:[218,   900] training loss: 0.00367530
INFO:root:[218,   950] training loss: 0.00129533
INFO:root:[218,  1000] training loss: 0.00001724
INFO:root:[218,  1050] training loss: 0.00001779
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch218
INFO:root:[219,    50] training loss: 0.00694476
INFO:root:[219,   100] training loss: 0.00722967
INFO:root:[219,   150] training loss: 0.00690443
INFO:root:[219,   200] training loss: 0.00683789
INFO:root:[219,   250] training loss: 0.00651574
INFO:root:[219,   300] training loss: 0.00717167
INFO:root:[219,   350] training loss: 0.00609816
INFO:root:[219,   400] training loss: 0.00000617
INFO:root:[219,   450] training loss: 0.00000614
INFO:root:[219,   500] training loss: 0.00004095
INFO:root:[219,   550] training loss: 0.00020468
INFO:root:[219,   600] training loss: 0.00012010
INFO:root:[219,   650] training loss: 0.00001409
INFO:root:[219,   700] training loss: 0.00001266
INFO:root:[219,   750] training loss: 0.00022201
INFO:root:[219,   800] training loss: 0.00022000
INFO:root:[219,   850] training loss: 0.00022494
INFO:root:[219,   900] training loss: 0.00343826
INFO:root:[219,   950] training loss: 0.00112096
INFO:root:[219,  1000] training loss: 0.00001641
INFO:root:[219,  1050] training loss: 0.00001664
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch219
INFO:root:[220,    50] training loss: 0.00711369
INFO:root:[220,   100] training loss: 0.00749972
INFO:root:[220,   150] training loss: 0.00722274
INFO:root:[220,   200] training loss: 0.00651817
INFO:root:[220,   250] training loss: 0.00690684
INFO:root:[220,   300] training loss: 0.00752707
INFO:root:[220,   350] training loss: 0.00605200
INFO:root:[220,   400] training loss: 0.00000637
INFO:root:[220,   450] training loss: 0.00000935
INFO:root:[220,   500] training loss: 0.00002714
INFO:root:[220,   550] training loss: 0.00022888
INFO:root:[220,   600] training loss: 0.00016844
INFO:root:[220,   650] training loss: 0.00001309
INFO:root:[220,   700] training loss: 0.00001349
INFO:root:[220,   750] training loss: 0.00024574
INFO:root:[220,   800] training loss: 0.00021816
INFO:root:[220,   850] training loss: 0.00027256
INFO:root:[220,   900] training loss: 0.00338988
INFO:root:[220,   950] training loss: 0.00155585
INFO:root:[220,  1000] training loss: 0.00002183
INFO:root:[220,  1050] training loss: 0.00001468
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch220
INFO:root:[221,    50] training loss: 0.00709384
INFO:root:[221,   100] training loss: 0.00729280
INFO:root:[221,   150] training loss: 0.00674283
INFO:root:[221,   200] training loss: 0.00621807
INFO:root:[221,   250] training loss: 0.00670723
INFO:root:[221,   300] training loss: 0.00699795
INFO:root:[221,   350] training loss: 0.00642983
INFO:root:[221,   400] training loss: 0.00000556
INFO:root:[221,   450] training loss: 0.00000624
INFO:root:[221,   500] training loss: 0.00004778
INFO:root:[221,   550] training loss: 0.00017193
INFO:root:[221,   600] training loss: 0.00016099
INFO:root:[221,   650] training loss: 0.00001311
INFO:root:[221,   700] training loss: 0.00001235
INFO:root:[221,   750] training loss: 0.00019516
INFO:root:[221,   800] training loss: 0.00028577
INFO:root:[221,   850] training loss: 0.00028545
INFO:root:[221,   900] training loss: 0.00356523
INFO:root:[221,   950] training loss: 0.00095288
INFO:root:[221,  1000] training loss: 0.00002016
INFO:root:[221,  1050] training loss: 0.00002833
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch221
INFO:root:[222,    50] training loss: 0.00759334
INFO:root:[222,   100] training loss: 0.00687002
INFO:root:[222,   150] training loss: 0.00684811
INFO:root:[222,   200] training loss: 0.00739307
INFO:root:[222,   250] training loss: 0.00674935
INFO:root:[222,   300] training loss: 0.00721723
INFO:root:[222,   350] training loss: 0.00603926
INFO:root:[222,   400] training loss: 0.00000526
INFO:root:[222,   450] training loss: 0.00000747
INFO:root:[222,   500] training loss: 0.00002519
INFO:root:[222,   550] training loss: 0.00016225
INFO:root:[222,   600] training loss: 0.00012466
INFO:root:[222,   650] training loss: 0.00001334
INFO:root:[222,   700] training loss: 0.00001274
INFO:root:[222,   750] training loss: 0.00024190
INFO:root:[222,   800] training loss: 0.00023412
INFO:root:[222,   850] training loss: 0.00031679
INFO:root:[222,   900] training loss: 0.00371645
INFO:root:[222,   950] training loss: 0.00108388
INFO:root:[222,  1000] training loss: 0.00001516
INFO:root:[222,  1050] training loss: 0.00001711
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch222
INFO:root:[223,    50] training loss: 0.00709063
INFO:root:[223,   100] training loss: 0.00731584
INFO:root:[223,   150] training loss: 0.00719772
INFO:root:[223,   200] training loss: 0.00705921
INFO:root:[223,   250] training loss: 0.00669736
INFO:root:[223,   300] training loss: 0.00717377
INFO:root:[223,   350] training loss: 0.00650930
INFO:root:[223,   400] training loss: 0.00000601
INFO:root:[223,   450] training loss: 0.00000785
INFO:root:[223,   500] training loss: 0.00002880
INFO:root:[223,   550] training loss: 0.00016378
INFO:root:[223,   600] training loss: 0.00012934
INFO:root:[223,   650] training loss: 0.00001261
INFO:root:[223,   700] training loss: 0.00001275
INFO:root:[223,   750] training loss: 0.00021698
INFO:root:[223,   800] training loss: 0.00028960
INFO:root:[223,   850] training loss: 0.00026093
INFO:root:[223,   900] training loss: 0.00360075
INFO:root:[223,   950] training loss: 0.00118481
INFO:root:[223,  1000] training loss: 0.00001484
INFO:root:[223,  1050] training loss: 0.00006180
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch223
INFO:root:[224,    50] training loss: 0.00851003
INFO:root:[224,   100] training loss: 0.00794971
INFO:root:[224,   150] training loss: 0.00738479
INFO:root:[224,   200] training loss: 0.00699902
INFO:root:[224,   250] training loss: 0.00677640
INFO:root:[224,   300] training loss: 0.00776351
INFO:root:[224,   350] training loss: 0.00652882
INFO:root:[224,   400] training loss: 0.00000588
INFO:root:[224,   450] training loss: 0.00000928
INFO:root:[224,   500] training loss: 0.00002690
INFO:root:[224,   550] training loss: 0.00018662
INFO:root:[224,   600] training loss: 0.00015194
INFO:root:[224,   650] training loss: 0.00001235
INFO:root:[224,   700] training loss: 0.00001653
INFO:root:[224,   750] training loss: 0.00021353
INFO:root:[224,   800] training loss: 0.00029629
INFO:root:[224,   850] training loss: 0.00029936
INFO:root:[224,   900] training loss: 0.00343971
INFO:root:[224,   950] training loss: 0.00109438
INFO:root:[224,  1000] training loss: 0.00001681
INFO:root:[224,  1050] training loss: 0.00001853
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch224
INFO:root:[225,    50] training loss: 0.00711200
INFO:root:[225,   100] training loss: 0.00672032
INFO:root:[225,   150] training loss: 0.00690069
INFO:root:[225,   200] training loss: 0.00666916
INFO:root:[225,   250] training loss: 0.00706938
INFO:root:[225,   300] training loss: 0.00703948
INFO:root:[225,   350] training loss: 0.00619118
INFO:root:[225,   400] training loss: 0.00000675
INFO:root:[225,   450] training loss: 0.00000859
INFO:root:[225,   500] training loss: 0.00002437
INFO:root:[225,   550] training loss: 0.00016523
INFO:root:[225,   600] training loss: 0.00016177
INFO:root:[225,   650] training loss: 0.00001147
INFO:root:[225,   700] training loss: 0.00001377
INFO:root:[225,   750] training loss: 0.00024458
INFO:root:[225,   800] training loss: 0.00016100
INFO:root:[225,   850] training loss: 0.00035271
INFO:root:[225,   900] training loss: 0.00384657
INFO:root:[225,   950] training loss: 0.00105113
INFO:root:[225,  1000] training loss: 0.00002009
INFO:root:[225,  1050] training loss: 0.00002147
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch225
INFO:root:[226,    50] training loss: 0.00703136
INFO:root:[226,   100] training loss: 0.00694704
INFO:root:[226,   150] training loss: 0.00707088
INFO:root:[226,   200] training loss: 0.00680977
INFO:root:[226,   250] training loss: 0.00738012
INFO:root:[226,   300] training loss: 0.00743017
INFO:root:[226,   350] training loss: 0.00618394
INFO:root:[226,   400] training loss: 0.00000682
INFO:root:[226,   450] training loss: 0.00000733
INFO:root:[226,   500] training loss: 0.00003263
INFO:root:[226,   550] training loss: 0.00015788
INFO:root:[226,   600] training loss: 0.00015707
INFO:root:[226,   650] training loss: 0.00001160
INFO:root:[226,   700] training loss: 0.00001329
INFO:root:[226,   750] training loss: 0.00020700
INFO:root:[226,   800] training loss: 0.00022922
INFO:root:[226,   850] training loss: 0.00020998
INFO:root:[226,   900] training loss: 0.00401648
INFO:root:[226,   950] training loss: 0.00101229
INFO:root:[226,  1000] training loss: 0.00001860
INFO:root:[226,  1050] training loss: 0.00001940
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch226
INFO:root:[227,    50] training loss: 0.00735545
INFO:root:[227,   100] training loss: 0.00711949
INFO:root:[227,   150] training loss: 0.00706300
INFO:root:[227,   200] training loss: 0.00640024
INFO:root:[227,   250] training loss: 0.00664424
INFO:root:[227,   300] training loss: 0.00708706
INFO:root:[227,   350] training loss: 0.00603736
INFO:root:[227,   400] training loss: 0.00000604
INFO:root:[227,   450] training loss: 0.00000925
INFO:root:[227,   500] training loss: 0.00002264
INFO:root:[227,   550] training loss: 0.00016285
INFO:root:[227,   600] training loss: 0.00021307
INFO:root:[227,   650] training loss: 0.00001343
INFO:root:[227,   700] training loss: 0.00001149
INFO:root:[227,   750] training loss: 0.00021726
INFO:root:[227,   800] training loss: 0.00021059
INFO:root:[227,   850] training loss: 0.00031935
INFO:root:[227,   900] training loss: 0.00342090
INFO:root:[227,   950] training loss: 0.00107378
INFO:root:[227,  1000] training loss: 0.00001682
INFO:root:[227,  1050] training loss: 0.00001528
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch227
INFO:root:[228,    50] training loss: 0.00750583
INFO:root:[228,   100] training loss: 0.00717404
INFO:root:[228,   150] training loss: 0.00695933
INFO:root:[228,   200] training loss: 0.00688747
INFO:root:[228,   250] training loss: 0.00839588
INFO:root:[228,   300] training loss: 0.00702310
INFO:root:[228,   350] training loss: 0.00599525
INFO:root:[228,   400] training loss: 0.00000674
INFO:root:[228,   450] training loss: 0.00000768
INFO:root:[228,   500] training loss: 0.00003658
INFO:root:[228,   550] training loss: 0.00017067
INFO:root:[228,   600] training loss: 0.00013911
INFO:root:[228,   650] training loss: 0.00001220
INFO:root:[228,   700] training loss: 0.00001309
INFO:root:[228,   750] training loss: 0.00026287
INFO:root:[228,   800] training loss: 0.00018372
INFO:root:[228,   850] training loss: 0.00025504
INFO:root:[228,   900] training loss: 0.00324530
INFO:root:[228,   950] training loss: 0.00125008
INFO:root:[228,  1000] training loss: 0.00001707
INFO:root:[228,  1050] training loss: 0.00001739
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch228
INFO:root:[229,    50] training loss: 0.00731413
INFO:root:[229,   100] training loss: 0.00731514
INFO:root:[229,   150] training loss: 0.00708767
INFO:root:[229,   200] training loss: 0.00690933
INFO:root:[229,   250] training loss: 0.00727244
INFO:root:[229,   300] training loss: 0.00709642
INFO:root:[229,   350] training loss: 0.00896972
INFO:root:[229,   400] training loss: 0.00000557
INFO:root:[229,   450] training loss: 0.00000945
INFO:root:[229,   500] training loss: 0.00002143
INFO:root:[229,   550] training loss: 0.00016255
INFO:root:[229,   600] training loss: 0.00014086
INFO:root:[229,   650] training loss: 0.00001323
INFO:root:[229,   700] training loss: 0.00001305
INFO:root:[229,   750] training loss: 0.00022849
INFO:root:[229,   800] training loss: 0.00026049
INFO:root:[229,   850] training loss: 0.00032034
INFO:root:[229,   900] training loss: 0.00404041
INFO:root:[229,   950] training loss: 0.00113471
INFO:root:[229,  1000] training loss: 0.00001336
INFO:root:[229,  1050] training loss: 0.00001531
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch229
INFO:root:[230,    50] training loss: 0.00716344
INFO:root:[230,   100] training loss: 0.00704217
INFO:root:[230,   150] training loss: 0.00717659
INFO:root:[230,   200] training loss: 0.00646022
INFO:root:[230,   250] training loss: 0.00677502
INFO:root:[230,   300] training loss: 0.00724911
INFO:root:[230,   350] training loss: 0.00706058
INFO:root:[230,   400] training loss: 0.00000577
INFO:root:[230,   450] training loss: 0.00000852
INFO:root:[230,   500] training loss: 0.00004754
INFO:root:[230,   550] training loss: 0.00018766
INFO:root:[230,   600] training loss: 0.00016663
INFO:root:[230,   650] training loss: 0.00001259
INFO:root:[230,   700] training loss: 0.00001398
INFO:root:[230,   750] training loss: 0.00018932
INFO:root:[230,   800] training loss: 0.00023966
INFO:root:[230,   850] training loss: 0.00024620
INFO:root:[230,   900] training loss: 0.00396948
INFO:root:[230,   950] training loss: 0.00123844
INFO:root:[230,  1000] training loss: 0.00001810
INFO:root:[230,  1050] training loss: 0.00003068
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch230
INFO:root:[231,    50] training loss: 0.00711627
INFO:root:[231,   100] training loss: 0.00695312
INFO:root:[231,   150] training loss: 0.00716423
INFO:root:[231,   200] training loss: 0.00718954
INFO:root:[231,   250] training loss: 0.00723650
INFO:root:[231,   300] training loss: 0.00687200
INFO:root:[231,   350] training loss: 0.00660765
INFO:root:[231,   400] training loss: 0.00000624
INFO:root:[231,   450] training loss: 0.00000690
INFO:root:[231,   500] training loss: 0.00002855
INFO:root:[231,   550] training loss: 0.00020909
INFO:root:[231,   600] training loss: 0.00025825
INFO:root:[231,   650] training loss: 0.00001180
INFO:root:[231,   700] training loss: 0.00001403
INFO:root:[231,   750] training loss: 0.00018388
INFO:root:[231,   800] training loss: 0.00018216
INFO:root:[231,   850] training loss: 0.00023696
INFO:root:[231,   900] training loss: 0.00373032
INFO:root:[231,   950] training loss: 0.00106600
INFO:root:[231,  1000] training loss: 0.00004942
INFO:root:[231,  1050] training loss: 0.00001719
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch231
INFO:root:[232,    50] training loss: 0.00880253
INFO:root:[232,   100] training loss: 0.00702270
INFO:root:[232,   150] training loss: 0.00730232
INFO:root:[232,   200] training loss: 0.00645805
INFO:root:[232,   250] training loss: 0.00690161
INFO:root:[232,   300] training loss: 0.00742785
INFO:root:[232,   350] training loss: 0.00581088
INFO:root:[232,   400] training loss: 0.00000657
INFO:root:[232,   450] training loss: 0.00000687
INFO:root:[232,   500] training loss: 0.00002755
INFO:root:[232,   550] training loss: 0.00013710
INFO:root:[232,   600] training loss: 0.00016019
INFO:root:[232,   650] training loss: 0.00001265
INFO:root:[232,   700] training loss: 0.00001269
INFO:root:[232,   750] training loss: 0.00021433
INFO:root:[232,   800] training loss: 0.00026424
INFO:root:[232,   850] training loss: 0.00022576
INFO:root:[232,   900] training loss: 0.00311187
INFO:root:[232,   950] training loss: 0.00160590
INFO:root:[232,  1000] training loss: 0.00001783
INFO:root:[232,  1050] training loss: 0.00002429
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch232
INFO:root:[233,    50] training loss: 0.00694845
INFO:root:[233,   100] training loss: 0.00696040
INFO:root:[233,   150] training loss: 0.00741578
INFO:root:[233,   200] training loss: 0.00686409
INFO:root:[233,   250] training loss: 0.00690684
INFO:root:[233,   300] training loss: 0.00737433
INFO:root:[233,   350] training loss: 0.00607095
INFO:root:[233,   400] training loss: 0.00000702
INFO:root:[233,   450] training loss: 0.00000939
INFO:root:[233,   500] training loss: 0.00002567
INFO:root:[233,   550] training loss: 0.00016697
INFO:root:[233,   600] training loss: 0.00022093
INFO:root:[233,   650] training loss: 0.00001219
INFO:root:[233,   700] training loss: 0.00001336
INFO:root:[233,   750] training loss: 0.00022858
INFO:root:[233,   800] training loss: 0.00030226
INFO:root:[233,   850] training loss: 0.00026027
INFO:root:[233,   900] training loss: 0.00411115
INFO:root:[233,   950] training loss: 0.00096729
INFO:root:[233,  1000] training loss: 0.00002296
INFO:root:[233,  1050] training loss: 0.00001448
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch233
INFO:root:[234,    50] training loss: 0.00735167
INFO:root:[234,   100] training loss: 0.00698858
INFO:root:[234,   150] training loss: 0.00677139
INFO:root:[234,   200] training loss: 0.00714400
INFO:root:[234,   250] training loss: 0.00700050
INFO:root:[234,   300] training loss: 0.00750796
INFO:root:[234,   350] training loss: 0.00589530
INFO:root:[234,   400] training loss: 0.00000592
INFO:root:[234,   450] training loss: 0.00000905
INFO:root:[234,   500] training loss: 0.00008016
INFO:root:[234,   550] training loss: 0.00019216
INFO:root:[234,   600] training loss: 0.00016981
INFO:root:[234,   650] training loss: 0.00001503
INFO:root:[234,   700] training loss: 0.00001270
INFO:root:[234,   750] training loss: 0.00020291
INFO:root:[234,   800] training loss: 0.00026006
INFO:root:[234,   850] training loss: 0.00024491
INFO:root:[234,   900] training loss: 0.00315874
INFO:root:[234,   950] training loss: 0.00111755
INFO:root:[234,  1000] training loss: 0.00001687
INFO:root:[234,  1050] training loss: 0.00002280
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch234
INFO:root:[235,    50] training loss: 0.00727726
INFO:root:[235,   100] training loss: 0.00739383
INFO:root:[235,   150] training loss: 0.00727105
INFO:root:[235,   200] training loss: 0.00678813
INFO:root:[235,   250] training loss: 0.00681621
INFO:root:[235,   300] training loss: 0.00719847
INFO:root:[235,   350] training loss: 0.00643253
INFO:root:[235,   400] training loss: 0.00000667
INFO:root:[235,   450] training loss: 0.00000732
INFO:root:[235,   500] training loss: 0.00003191
INFO:root:[235,   550] training loss: 0.00014056
INFO:root:[235,   600] training loss: 0.00013216
INFO:root:[235,   650] training loss: 0.00001211
INFO:root:[235,   700] training loss: 0.00001277
INFO:root:[235,   750] training loss: 0.00017796
INFO:root:[235,   800] training loss: 0.00026827
INFO:root:[235,   850] training loss: 0.00029651
INFO:root:[235,   900] training loss: 0.00553702
INFO:root:[235,   950] training loss: 0.00140322
INFO:root:[235,  1000] training loss: 0.00001789
INFO:root:[235,  1050] training loss: 0.00002329
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch235
INFO:root:[236,    50] training loss: 0.00708381
INFO:root:[236,   100] training loss: 0.00685168
INFO:root:[236,   150] training loss: 0.00708561
INFO:root:[236,   200] training loss: 0.00671439
INFO:root:[236,   250] training loss: 0.00684817
INFO:root:[236,   300] training loss: 0.00768814
INFO:root:[236,   350] training loss: 0.00752437
INFO:root:[236,   400] training loss: 0.00000592
INFO:root:[236,   450] training loss: 0.00000735
INFO:root:[236,   500] training loss: 0.00002648
INFO:root:[236,   550] training loss: 0.00016483
INFO:root:[236,   600] training loss: 0.00022223
INFO:root:[236,   650] training loss: 0.00001522
INFO:root:[236,   700] training loss: 0.00001396
INFO:root:[236,   750] training loss: 0.00019217
INFO:root:[236,   800] training loss: 0.00017485
INFO:root:[236,   850] training loss: 0.00021491
INFO:root:[236,   900] training loss: 0.00357863
INFO:root:[236,   950] training loss: 0.00131121
INFO:root:[236,  1000] training loss: 0.00001591
INFO:root:[236,  1050] training loss: 0.00001726
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch236
INFO:root:[237,    50] training loss: 0.00747115
INFO:root:[237,   100] training loss: 0.00713624
INFO:root:[237,   150] training loss: 0.00700093
INFO:root:[237,   200] training loss: 0.00654801
INFO:root:[237,   250] training loss: 0.00704115
INFO:root:[237,   300] training loss: 0.00735961
INFO:root:[237,   350] training loss: 0.00660533
INFO:root:[237,   400] training loss: 0.00000683
INFO:root:[237,   450] training loss: 0.00000793
INFO:root:[237,   500] training loss: 0.00003826
INFO:root:[237,   550] training loss: 0.00015541
INFO:root:[237,   600] training loss: 0.00019205
INFO:root:[237,   650] training loss: 0.00001385
INFO:root:[237,   700] training loss: 0.00001329
INFO:root:[237,   750] training loss: 0.00018523
INFO:root:[237,   800] training loss: 0.00028326
INFO:root:[237,   850] training loss: 0.00033239
INFO:root:[237,   900] training loss: 0.00344662
INFO:root:[237,   950] training loss: 0.00133502
INFO:root:[237,  1000] training loss: 0.00001575
INFO:root:[237,  1050] training loss: 0.00002489
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch237
INFO:root:[238,    50] training loss: 0.00691507
INFO:root:[238,   100] training loss: 0.00776194
INFO:root:[238,   150] training loss: 0.00708666
INFO:root:[238,   200] training loss: 0.00680299
INFO:root:[238,   250] training loss: 0.00716924
INFO:root:[238,   300] training loss: 0.00715166
INFO:root:[238,   350] training loss: 0.00624557
INFO:root:[238,   400] training loss: 0.00000558
INFO:root:[238,   450] training loss: 0.00000700
INFO:root:[238,   500] training loss: 0.00002583
INFO:root:[238,   550] training loss: 0.00015770
INFO:root:[238,   600] training loss: 0.00015402
INFO:root:[238,   650] training loss: 0.00001293
INFO:root:[238,   700] training loss: 0.00001544
INFO:root:[238,   750] training loss: 0.00023232
INFO:root:[238,   800] training loss: 0.00026456
INFO:root:[238,   850] training loss: 0.00021773
INFO:root:[238,   900] training loss: 0.00342152
INFO:root:[238,   950] training loss: 0.00125014
INFO:root:[238,  1000] training loss: 0.00001916
INFO:root:[238,  1050] training loss: 0.00001841
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch238
INFO:root:[239,    50] training loss: 0.00765324
INFO:root:[239,   100] training loss: 0.00691986
INFO:root:[239,   150] training loss: 0.00733108
INFO:root:[239,   200] training loss: 0.00677994
INFO:root:[239,   250] training loss: 0.00727927
INFO:root:[239,   300] training loss: 0.00722556
INFO:root:[239,   350] training loss: 0.00649564
INFO:root:[239,   400] training loss: 0.00000572
INFO:root:[239,   450] training loss: 0.00000876
INFO:root:[239,   500] training loss: 0.00002686
INFO:root:[239,   550] training loss: 0.00016595
INFO:root:[239,   600] training loss: 0.00017593
INFO:root:[239,   650] training loss: 0.00001273
INFO:root:[239,   700] training loss: 0.00001321
INFO:root:[239,   750] training loss: 0.00023824
INFO:root:[239,   800] training loss: 0.00019820
INFO:root:[239,   850] training loss: 0.00025717
INFO:root:[239,   900] training loss: 0.00367286
INFO:root:[239,   950] training loss: 0.00111104
INFO:root:[239,  1000] training loss: 0.00001604
INFO:root:[239,  1050] training loss: 0.00001605
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch239
INFO:root:[240,    50] training loss: 0.00794348
INFO:root:[240,   100] training loss: 0.00748129
INFO:root:[240,   150] training loss: 0.00675786
INFO:root:[240,   200] training loss: 0.00665775
INFO:root:[240,   250] training loss: 0.00695614
INFO:root:[240,   300] training loss: 0.00721291
INFO:root:[240,   350] training loss: 0.00620689
INFO:root:[240,   400] training loss: 0.00000731
INFO:root:[240,   450] training loss: 0.00000806
INFO:root:[240,   500] training loss: 0.00002728
INFO:root:[240,   550] training loss: 0.00016974
INFO:root:[240,   600] training loss: 0.00015292
INFO:root:[240,   650] training loss: 0.00001172
INFO:root:[240,   700] training loss: 0.00001575
INFO:root:[240,   750] training loss: 0.00023806
INFO:root:[240,   800] training loss: 0.00026243
INFO:root:[240,   850] training loss: 0.00019631
INFO:root:[240,   900] training loss: 0.00339800
INFO:root:[240,   950] training loss: 0.00107019
INFO:root:[240,  1000] training loss: 0.00001418
INFO:root:[240,  1050] training loss: 0.00004328
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch240
INFO:root:[241,    50] training loss: 0.00766667
INFO:root:[241,   100] training loss: 0.00698817
INFO:root:[241,   150] training loss: 0.00714755
INFO:root:[241,   200] training loss: 0.00669629
INFO:root:[241,   250] training loss: 0.00684773
INFO:root:[241,   300] training loss: 0.00721173
INFO:root:[241,   350] training loss: 0.00611428
INFO:root:[241,   400] training loss: 0.00000694
INFO:root:[241,   450] training loss: 0.00000702
INFO:root:[241,   500] training loss: 0.00006668
INFO:root:[241,   550] training loss: 0.00014666
INFO:root:[241,   600] training loss: 0.00021428
INFO:root:[241,   650] training loss: 0.00001464
INFO:root:[241,   700] training loss: 0.00001475
INFO:root:[241,   750] training loss: 0.00029692
INFO:root:[241,   800] training loss: 0.00017579
INFO:root:[241,   850] training loss: 0.00026223
INFO:root:[241,   900] training loss: 0.00328235
INFO:root:[241,   950] training loss: 0.00105205
INFO:root:[241,  1000] training loss: 0.00001705
INFO:root:[241,  1050] training loss: 0.00001661
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch241
INFO:root:[242,    50] training loss: 0.00735529
INFO:root:[242,   100] training loss: 0.00724464
INFO:root:[242,   150] training loss: 0.00729629
INFO:root:[242,   200] training loss: 0.00667426
INFO:root:[242,   250] training loss: 0.00688253
INFO:root:[242,   300] training loss: 0.00822924
INFO:root:[242,   350] training loss: 0.00650984
INFO:root:[242,   400] training loss: 0.00000599
INFO:root:[242,   450] training loss: 0.00000936
INFO:root:[242,   500] training loss: 0.00004224
INFO:root:[242,   550] training loss: 0.00015624
INFO:root:[242,   600] training loss: 0.00020174
INFO:root:[242,   650] training loss: 0.00001314
INFO:root:[242,   700] training loss: 0.00001292
INFO:root:[242,   750] training loss: 0.00021068
INFO:root:[242,   800] training loss: 0.00021742
INFO:root:[242,   850] training loss: 0.00029243
INFO:root:[242,   900] training loss: 0.00335236
INFO:root:[242,   950] training loss: 0.00118038
INFO:root:[242,  1000] training loss: 0.00001694
INFO:root:[242,  1050] training loss: 0.00001981
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch242
INFO:root:[243,    50] training loss: 0.00755955
INFO:root:[243,   100] training loss: 0.00673778
INFO:root:[243,   150] training loss: 0.00762975
INFO:root:[243,   200] training loss: 0.00772190
INFO:root:[243,   250] training loss: 0.00668451
INFO:root:[243,   300] training loss: 0.00755245
INFO:root:[243,   350] training loss: 0.00604061
INFO:root:[243,   400] training loss: 0.00000572
INFO:root:[243,   450] training loss: 0.00000944
INFO:root:[243,   500] training loss: 0.00002573
INFO:root:[243,   550] training loss: 0.00015395
INFO:root:[243,   600] training loss: 0.00021874
INFO:root:[243,   650] training loss: 0.00001454
INFO:root:[243,   700] training loss: 0.00001278
INFO:root:[243,   750] training loss: 0.00025324
INFO:root:[243,   800] training loss: 0.00019140
INFO:root:[243,   850] training loss: 0.00026095
INFO:root:[243,   900] training loss: 0.00385159
INFO:root:[243,   950] training loss: 0.00130209
INFO:root:[243,  1000] training loss: 0.00001414
INFO:root:[243,  1050] training loss: 0.00002850
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch243
INFO:root:[244,    50] training loss: 0.00710894
INFO:root:[244,   100] training loss: 0.00712077
INFO:root:[244,   150] training loss: 0.00685979
INFO:root:[244,   200] training loss: 0.00645539
INFO:root:[244,   250] training loss: 0.00724137
INFO:root:[244,   300] training loss: 0.00881466
INFO:root:[244,   350] training loss: 0.00586595
INFO:root:[244,   400] training loss: 0.00000736
INFO:root:[244,   450] training loss: 0.00000794
INFO:root:[244,   500] training loss: 0.00003350
INFO:root:[244,   550] training loss: 0.00014443
INFO:root:[244,   600] training loss: 0.00016217
INFO:root:[244,   650] training loss: 0.00001599
INFO:root:[244,   700] training loss: 0.00001517
INFO:root:[244,   750] training loss: 0.00020471
INFO:root:[244,   800] training loss: 0.00020670
INFO:root:[244,   850] training loss: 0.00025554
INFO:root:[244,   900] training loss: 0.00369350
INFO:root:[244,   950] training loss: 0.00119796
INFO:root:[244,  1000] training loss: 0.00001445
INFO:root:[244,  1050] training loss: 0.00001786
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch244
INFO:root:[245,    50] training loss: 0.00735518
INFO:root:[245,   100] training loss: 0.00778392
INFO:root:[245,   150] training loss: 0.00762984
INFO:root:[245,   200] training loss: 0.00671834
INFO:root:[245,   250] training loss: 0.00658963
INFO:root:[245,   300] training loss: 0.00830453
INFO:root:[245,   350] training loss: 0.00597989
INFO:root:[245,   400] training loss: 0.00000656
INFO:root:[245,   450] training loss: 0.00000827
INFO:root:[245,   500] training loss: 0.00003040
INFO:root:[245,   550] training loss: 0.00017091
INFO:root:[245,   600] training loss: 0.00017227
INFO:root:[245,   650] training loss: 0.00001394
INFO:root:[245,   700] training loss: 0.00001334
INFO:root:[245,   750] training loss: 0.00017533
INFO:root:[245,   800] training loss: 0.00025450
INFO:root:[245,   850] training loss: 0.00024039
INFO:root:[245,   900] training loss: 0.00441986
INFO:root:[245,   950] training loss: 0.00102968
INFO:root:[245,  1000] training loss: 0.00002403
INFO:root:[245,  1050] training loss: 0.00001777
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch245
INFO:root:[246,    50] training loss: 0.00740317
INFO:root:[246,   100] training loss: 0.00703370
INFO:root:[246,   150] training loss: 0.00688030
INFO:root:[246,   200] training loss: 0.00663407
INFO:root:[246,   250] training loss: 0.00673224
INFO:root:[246,   300] training loss: 0.00718368
INFO:root:[246,   350] training loss: 0.00599830
INFO:root:[246,   400] training loss: 0.00000575
INFO:root:[246,   450] training loss: 0.00000757
INFO:root:[246,   500] training loss: 0.00010457
INFO:root:[246,   550] training loss: 0.00016068
INFO:root:[246,   600] training loss: 0.00016268
INFO:root:[246,   650] training loss: 0.00001414
INFO:root:[246,   700] training loss: 0.00001415
INFO:root:[246,   750] training loss: 0.00020602
INFO:root:[246,   800] training loss: 0.00029239
INFO:root:[246,   850] training loss: 0.00037447
INFO:root:[246,   900] training loss: 0.00383374
INFO:root:[246,   950] training loss: 0.00137646
INFO:root:[246,  1000] training loss: 0.00001855
INFO:root:[246,  1050] training loss: 0.00003846
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch246
INFO:root:[247,    50] training loss: 0.00736863
INFO:root:[247,   100] training loss: 0.00684318
INFO:root:[247,   150] training loss: 0.00713887
INFO:root:[247,   200] training loss: 0.00713635
INFO:root:[247,   250] training loss: 0.00690874
INFO:root:[247,   300] training loss: 0.00740941
INFO:root:[247,   350] training loss: 0.00641179
INFO:root:[247,   400] training loss: 0.00000732
INFO:root:[247,   450] training loss: 0.00000797
INFO:root:[247,   500] training loss: 0.00002375
INFO:root:[247,   550] training loss: 0.00019140
INFO:root:[247,   600] training loss: 0.00015562
INFO:root:[247,   650] training loss: 0.00001447
INFO:root:[247,   700] training loss: 0.00001288
INFO:root:[247,   750] training loss: 0.00021849
INFO:root:[247,   800] training loss: 0.00019152
INFO:root:[247,   850] training loss: 0.00024601
INFO:root:[247,   900] training loss: 0.00345269
INFO:root:[247,   950] training loss: 0.00131452
INFO:root:[247,  1000] training loss: 0.00001468
INFO:root:[247,  1050] training loss: 0.00001588
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch247
INFO:root:[248,    50] training loss: 0.00742122
INFO:root:[248,   100] training loss: 0.00748672
INFO:root:[248,   150] training loss: 0.00731070
INFO:root:[248,   200] training loss: 0.00674053
INFO:root:[248,   250] training loss: 0.00696389
INFO:root:[248,   300] training loss: 0.00739646
INFO:root:[248,   350] training loss: 0.00618488
INFO:root:[248,   400] training loss: 0.00000618
INFO:root:[248,   450] training loss: 0.00000752
INFO:root:[248,   500] training loss: 0.00002046
INFO:root:[248,   550] training loss: 0.00014974
INFO:root:[248,   600] training loss: 0.00018160
INFO:root:[248,   650] training loss: 0.00001389
INFO:root:[248,   700] training loss: 0.00001193
INFO:root:[248,   750] training loss: 0.00020144
INFO:root:[248,   800] training loss: 0.00017944
INFO:root:[248,   850] training loss: 0.00028792
INFO:root:[248,   900] training loss: 0.00321753
INFO:root:[248,   950] training loss: 0.00148671
INFO:root:[248,  1000] training loss: 0.00001433
INFO:root:[248,  1050] training loss: 0.00002061
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch248
INFO:root:[249,    50] training loss: 0.00703296
INFO:root:[249,   100] training loss: 0.00688357
INFO:root:[249,   150] training loss: 0.00686539
INFO:root:[249,   200] training loss: 0.00650827
INFO:root:[249,   250] training loss: 0.00680279
INFO:root:[249,   300] training loss: 0.00846827
INFO:root:[249,   350] training loss: 0.00626124
INFO:root:[249,   400] training loss: 0.00000571
INFO:root:[249,   450] training loss: 0.00000826
INFO:root:[249,   500] training loss: 0.00002809
INFO:root:[249,   550] training loss: 0.00021848
INFO:root:[249,   600] training loss: 0.00014494
INFO:root:[249,   650] training loss: 0.00001263
INFO:root:[249,   700] training loss: 0.00001398
INFO:root:[249,   750] training loss: 0.00024299
INFO:root:[249,   800] training loss: 0.00026876
INFO:root:[249,   850] training loss: 0.00034988
INFO:root:[249,   900] training loss: 0.00339988
INFO:root:[249,   950] training loss: 0.00104195
INFO:root:[249,  1000] training loss: 0.00001603
INFO:root:[249,  1050] training loss: 0.00001738
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch249
INFO:root:[250,    50] training loss: 0.00752228
INFO:root:[250,   100] training loss: 0.00739216
INFO:root:[250,   150] training loss: 0.00670727
INFO:root:[250,   200] training loss: 0.00684177
INFO:root:[250,   250] training loss: 0.00747989
INFO:root:[250,   300] training loss: 0.00753357
INFO:root:[250,   350] training loss: 0.00654866
INFO:root:[250,   400] training loss: 0.00000505
INFO:root:[250,   450] training loss: 0.00000767
INFO:root:[250,   500] training loss: 0.00003041
INFO:root:[250,   550] training loss: 0.00015712
INFO:root:[250,   600] training loss: 0.00020290
INFO:root:[250,   650] training loss: 0.00001376
INFO:root:[250,   700] training loss: 0.00001342
INFO:root:[250,   750] training loss: 0.00015690
INFO:root:[250,   800] training loss: 0.00019672
INFO:root:[250,   850] training loss: 0.00021146
INFO:root:[250,   900] training loss: 0.00324417
INFO:root:[250,   950] training loss: 0.00185613
INFO:root:[250,  1000] training loss: 0.00002001
INFO:root:[250,  1050] training loss: 0.00001588
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch250
INFO:root:[251,    50] training loss: 0.00746480
INFO:root:[251,   100] training loss: 0.00731936
INFO:root:[251,   150] training loss: 0.00741085
INFO:root:[251,   200] training loss: 0.00654830
INFO:root:[251,   250] training loss: 0.00734165
INFO:root:[251,   300] training loss: 0.00749974
INFO:root:[251,   350] training loss: 0.00615316
INFO:root:[251,   400] training loss: 0.00000596
INFO:root:[251,   450] training loss: 0.00000774
INFO:root:[251,   500] training loss: 0.00003103
INFO:root:[251,   550] training loss: 0.00018384
INFO:root:[251,   600] training loss: 0.00019518
INFO:root:[251,   650] training loss: 0.00001267
INFO:root:[251,   700] training loss: 0.00001345
INFO:root:[251,   750] training loss: 0.00021818
INFO:root:[251,   800] training loss: 0.00019115
INFO:root:[251,   850] training loss: 0.00028646
INFO:root:[251,   900] training loss: 0.00364954
INFO:root:[251,   950] training loss: 0.00122429
INFO:root:[251,  1000] training loss: 0.00002300
INFO:root:[251,  1050] training loss: 0.00002183
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch251
INFO:root:[252,    50] training loss: 0.00709972
INFO:root:[252,   100] training loss: 0.00739846
INFO:root:[252,   150] training loss: 0.00776858
INFO:root:[252,   200] training loss: 0.00702330
INFO:root:[252,   250] training loss: 0.00676267
INFO:root:[252,   300] training loss: 0.00730589
INFO:root:[252,   350] training loss: 0.00604978
INFO:root:[252,   400] training loss: 0.00000538
INFO:root:[252,   450] training loss: 0.00000802
INFO:root:[252,   500] training loss: 0.00002469
INFO:root:[252,   550] training loss: 0.00016060
INFO:root:[252,   600] training loss: 0.00016891
INFO:root:[252,   650] training loss: 0.00001412
INFO:root:[252,   700] training loss: 0.00001461
INFO:root:[252,   750] training loss: 0.00030640
INFO:root:[252,   800] training loss: 0.00023399
INFO:root:[252,   850] training loss: 0.00019955
INFO:root:[252,   900] training loss: 0.00354181
INFO:root:[252,   950] training loss: 0.00120827
INFO:root:[252,  1000] training loss: 0.00001761
INFO:root:[252,  1050] training loss: 0.00003113
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch252
INFO:root:[253,    50] training loss: 0.00733451
INFO:root:[253,   100] training loss: 0.00764227
INFO:root:[253,   150] training loss: 0.00704251
INFO:root:[253,   200] training loss: 0.00698993
INFO:root:[253,   250] training loss: 0.00693157
INFO:root:[253,   300] training loss: 0.00744693
INFO:root:[253,   350] training loss: 0.00613530
INFO:root:[253,   400] training loss: 0.00000740
INFO:root:[253,   450] training loss: 0.00000672
INFO:root:[253,   500] training loss: 0.00003002
INFO:root:[253,   550] training loss: 0.00017578
INFO:root:[253,   600] training loss: 0.00020230
INFO:root:[253,   650] training loss: 0.00001365
INFO:root:[253,   700] training loss: 0.00001280
INFO:root:[253,   750] training loss: 0.00023224
INFO:root:[253,   800] training loss: 0.00020930
INFO:root:[253,   850] training loss: 0.00027851
INFO:root:[253,   900] training loss: 0.00358249
INFO:root:[253,   950] training loss: 0.00125171
INFO:root:[253,  1000] training loss: 0.00003256
INFO:root:[253,  1050] training loss: 0.00001553
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch253
INFO:root:[254,    50] training loss: 0.00772963
INFO:root:[254,   100] training loss: 0.00717952
INFO:root:[254,   150] training loss: 0.00683464
INFO:root:[254,   200] training loss: 0.00959107
INFO:root:[254,   250] training loss: 0.00723106
INFO:root:[254,   300] training loss: 0.00774762
INFO:root:[254,   350] training loss: 0.00601408
INFO:root:[254,   400] training loss: 0.00000658
INFO:root:[254,   450] training loss: 0.00000726
INFO:root:[254,   500] training loss: 0.00002771
INFO:root:[254,   550] training loss: 0.00017464
INFO:root:[254,   600] training loss: 0.00017865
INFO:root:[254,   650] training loss: 0.00001369
INFO:root:[254,   700] training loss: 0.00001439
INFO:root:[254,   750] training loss: 0.00036702
INFO:root:[254,   800] training loss: 0.00025924
INFO:root:[254,   850] training loss: 0.00027204
INFO:root:[254,   900] training loss: 0.00361217
INFO:root:[254,   950] training loss: 0.00104871
INFO:root:[254,  1000] training loss: 0.00001424
INFO:root:[254,  1050] training loss: 0.00002029
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch254
INFO:root:[255,    50] training loss: 0.00773439
INFO:root:[255,   100] training loss: 0.00693549
INFO:root:[255,   150] training loss: 0.00701014
INFO:root:[255,   200] training loss: 0.00651550
INFO:root:[255,   250] training loss: 0.00703316
INFO:root:[255,   300] training loss: 0.00706481
INFO:root:[255,   350] training loss: 0.00625072
INFO:root:[255,   400] training loss: 0.00000631
INFO:root:[255,   450] training loss: 0.00000740
INFO:root:[255,   500] training loss: 0.00002817
INFO:root:[255,   550] training loss: 0.00019677
INFO:root:[255,   600] training loss: 0.00021192
INFO:root:[255,   650] training loss: 0.00001353
INFO:root:[255,   700] training loss: 0.00001350
INFO:root:[255,   750] training loss: 0.00017483
INFO:root:[255,   800] training loss: 0.00021347
INFO:root:[255,   850] training loss: 0.00025469
INFO:root:[255,   900] training loss: 0.00362784
INFO:root:[255,   950] training loss: 0.00093075
INFO:root:[255,  1000] training loss: 0.00001748
INFO:root:[255,  1050] training loss: 0.00001793
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch255
INFO:root:[256,    50] training loss: 0.00735011
INFO:root:[256,   100] training loss: 0.00730441
INFO:root:[256,   150] training loss: 0.00694147
INFO:root:[256,   200] training loss: 0.00686575
INFO:root:[256,   250] training loss: 0.00687965
INFO:root:[256,   300] training loss: 0.00773208
INFO:root:[256,   350] training loss: 0.00636319
INFO:root:[256,   400] training loss: 0.00000660
INFO:root:[256,   450] training loss: 0.00000897
INFO:root:[256,   500] training loss: 0.00002663
INFO:root:[256,   550] training loss: 0.00015492
INFO:root:[256,   600] training loss: 0.00016127
INFO:root:[256,   650] training loss: 0.00001202
INFO:root:[256,   700] training loss: 0.00001396
INFO:root:[256,   750] training loss: 0.00023132
INFO:root:[256,   800] training loss: 0.00019265
INFO:root:[256,   850] training loss: 0.00033159
INFO:root:[256,   900] training loss: 0.00327424
INFO:root:[256,   950] training loss: 0.00113869
INFO:root:[256,  1000] training loss: 0.00001621
INFO:root:[256,  1050] training loss: 0.00001742
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch256
INFO:root:[257,    50] training loss: 0.00757235
INFO:root:[257,   100] training loss: 0.00691237
INFO:root:[257,   150] training loss: 0.00675150
INFO:root:[257,   200] training loss: 0.00679755
INFO:root:[257,   250] training loss: 0.00701492
INFO:root:[257,   300] training loss: 0.00743250
INFO:root:[257,   350] training loss: 0.00629906
INFO:root:[257,   400] training loss: 0.00000645
INFO:root:[257,   450] training loss: 0.00000822
INFO:root:[257,   500] training loss: 0.00003240
INFO:root:[257,   550] training loss: 0.00016313
INFO:root:[257,   600] training loss: 0.00012851
INFO:root:[257,   650] training loss: 0.00001403
INFO:root:[257,   700] training loss: 0.00001266
INFO:root:[257,   750] training loss: 0.00028409
INFO:root:[257,   800] training loss: 0.00020099
INFO:root:[257,   850] training loss: 0.00029806
INFO:root:[257,   900] training loss: 0.00386206
INFO:root:[257,   950] training loss: 0.00101979
INFO:root:[257,  1000] training loss: 0.00001755
INFO:root:[257,  1050] training loss: 0.00001730
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch257
INFO:root:[258,    50] training loss: 0.00835999
INFO:root:[258,   100] training loss: 0.00845956
INFO:root:[258,   150] training loss: 0.00666682
INFO:root:[258,   200] training loss: 0.00648596
INFO:root:[258,   250] training loss: 0.00654528
INFO:root:[258,   300] training loss: 0.00729434
INFO:root:[258,   350] training loss: 0.00682882
INFO:root:[258,   400] training loss: 0.00000641
INFO:root:[258,   450] training loss: 0.00000820
INFO:root:[258,   500] training loss: 0.00002467
INFO:root:[258,   550] training loss: 0.00021460
INFO:root:[258,   600] training loss: 0.00020954
INFO:root:[258,   650] training loss: 0.00001181
INFO:root:[258,   700] training loss: 0.00001366
INFO:root:[258,   750] training loss: 0.00017297
INFO:root:[258,   800] training loss: 0.00026700
INFO:root:[258,   850] training loss: 0.00022725
INFO:root:[258,   900] training loss: 0.00361291
INFO:root:[258,   950] training loss: 0.00115020
INFO:root:[258,  1000] training loss: 0.00001752
INFO:root:[258,  1050] training loss: 0.00001871
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch258
INFO:root:[259,    50] training loss: 0.00702109
INFO:root:[259,   100] training loss: 0.00707705
INFO:root:[259,   150] training loss: 0.00696627
INFO:root:[259,   200] training loss: 0.00643062
INFO:root:[259,   250] training loss: 0.00716264
INFO:root:[259,   300] training loss: 0.00703297
INFO:root:[259,   350] training loss: 0.00600501
INFO:root:[259,   400] training loss: 0.00000699
INFO:root:[259,   450] training loss: 0.00000742
INFO:root:[259,   500] training loss: 0.00002005
INFO:root:[259,   550] training loss: 0.00015774
INFO:root:[259,   600] training loss: 0.00019684
INFO:root:[259,   650] training loss: 0.00001422
INFO:root:[259,   700] training loss: 0.00001294
INFO:root:[259,   750] training loss: 0.00029516
INFO:root:[259,   800] training loss: 0.00021192
INFO:root:[259,   850] training loss: 0.00024820
INFO:root:[259,   900] training loss: 0.00416029
INFO:root:[259,   950] training loss: 0.00115719
INFO:root:[259,  1000] training loss: 0.00002065
INFO:root:[259,  1050] training loss: 0.00003777
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch259
INFO:root:[260,    50] training loss: 0.00720114
INFO:root:[260,   100] training loss: 0.00685257
INFO:root:[260,   150] training loss: 0.00820745
INFO:root:[260,   200] training loss: 0.00653124
INFO:root:[260,   250] training loss: 0.00694006
INFO:root:[260,   300] training loss: 0.00754362
INFO:root:[260,   350] training loss: 0.00633723
INFO:root:[260,   400] training loss: 0.00000548
INFO:root:[260,   450] training loss: 0.00000874
INFO:root:[260,   500] training loss: 0.00002497
INFO:root:[260,   550] training loss: 0.00020613
INFO:root:[260,   600] training loss: 0.00016939
INFO:root:[260,   650] training loss: 0.00001283
INFO:root:[260,   700] training loss: 0.00001357
INFO:root:[260,   750] training loss: 0.00021740
INFO:root:[260,   800] training loss: 0.00021026
INFO:root:[260,   850] training loss: 0.00031938
INFO:root:[260,   900] training loss: 0.00323727
INFO:root:[260,   950] training loss: 0.00105367
INFO:root:[260,  1000] training loss: 0.00001824
INFO:root:[260,  1050] training loss: 0.00003536
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch260
INFO:root:[261,    50] training loss: 0.00759718
INFO:root:[261,   100] training loss: 0.00722021
INFO:root:[261,   150] training loss: 0.00704923
INFO:root:[261,   200] training loss: 0.00645500
INFO:root:[261,   250] training loss: 0.00717003
INFO:root:[261,   300] training loss: 0.00735642
INFO:root:[261,   350] training loss: 0.00650577
INFO:root:[261,   400] training loss: 0.00000614
INFO:root:[261,   450] training loss: 0.00000885
INFO:root:[261,   500] training loss: 0.00002505
INFO:root:[261,   550] training loss: 0.00016609
INFO:root:[261,   600] training loss: 0.00012995
INFO:root:[261,   650] training loss: 0.00001532
INFO:root:[261,   700] training loss: 0.00001419
INFO:root:[261,   750] training loss: 0.00028260
INFO:root:[261,   800] training loss: 0.00024711
INFO:root:[261,   850] training loss: 0.00023000
INFO:root:[261,   900] training loss: 0.00369155
INFO:root:[261,   950] training loss: 0.00152945
INFO:root:[261,  1000] training loss: 0.00001289
INFO:root:[261,  1050] training loss: 0.00001742
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch261
INFO:root:[262,    50] training loss: 0.00746753
INFO:root:[262,   100] training loss: 0.00732638
INFO:root:[262,   150] training loss: 0.00685587
INFO:root:[262,   200] training loss: 0.00667498
INFO:root:[262,   250] training loss: 0.00665921
INFO:root:[262,   300] training loss: 0.00695235
INFO:root:[262,   350] training loss: 0.00608496
INFO:root:[262,   400] training loss: 0.00000556
INFO:root:[262,   450] training loss: 0.00000769
INFO:root:[262,   500] training loss: 0.00002842
INFO:root:[262,   550] training loss: 0.00017695
INFO:root:[262,   600] training loss: 0.00017175
INFO:root:[262,   650] training loss: 0.00001252
INFO:root:[262,   700] training loss: 0.00001372
INFO:root:[262,   750] training loss: 0.00029564
INFO:root:[262,   800] training loss: 0.00022221
INFO:root:[262,   850] training loss: 0.00023926
INFO:root:[262,   900] training loss: 0.00333492
INFO:root:[262,   950] training loss: 0.00122301
INFO:root:[262,  1000] training loss: 0.00002138
INFO:root:[262,  1050] training loss: 0.00002018
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch262
INFO:root:[263,    50] training loss: 0.00697397
INFO:root:[263,   100] training loss: 0.00795106
INFO:root:[263,   150] training loss: 0.00676838
INFO:root:[263,   200] training loss: 0.00703477
INFO:root:[263,   250] training loss: 0.00681522
INFO:root:[263,   300] training loss: 0.00743910
INFO:root:[263,   350] training loss: 0.00653848
INFO:root:[263,   400] training loss: 0.00000580
INFO:root:[263,   450] training loss: 0.00000883
INFO:root:[263,   500] training loss: 0.00003161
INFO:root:[263,   550] training loss: 0.00016230
INFO:root:[263,   600] training loss: 0.00015995
INFO:root:[263,   650] training loss: 0.00001351
INFO:root:[263,   700] training loss: 0.00001243
INFO:root:[263,   750] training loss: 0.00020412
INFO:root:[263,   800] training loss: 0.00016065
INFO:root:[263,   850] training loss: 0.00042068
INFO:root:[263,   900] training loss: 0.00372900
INFO:root:[263,   950] training loss: 0.00099050
INFO:root:[263,  1000] training loss: 0.00002526
INFO:root:[263,  1050] training loss: 0.00001779
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch263
INFO:root:[264,    50] training loss: 0.00694668
INFO:root:[264,   100] training loss: 0.00759384
INFO:root:[264,   150] training loss: 0.00758956
INFO:root:[264,   200] training loss: 0.00644735
INFO:root:[264,   250] training loss: 0.00696625
INFO:root:[264,   300] training loss: 0.00727651
INFO:root:[264,   350] training loss: 0.00600228
INFO:root:[264,   400] training loss: 0.00000578
INFO:root:[264,   450] training loss: 0.00000877
INFO:root:[264,   500] training loss: 0.00002300
INFO:root:[264,   550] training loss: 0.00016206
INFO:root:[264,   600] training loss: 0.00014035
INFO:root:[264,   650] training loss: 0.00001251
INFO:root:[264,   700] training loss: 0.00001593
INFO:root:[264,   750] training loss: 0.00024518
INFO:root:[264,   800] training loss: 0.00026242
INFO:root:[264,   850] training loss: 0.00020092
INFO:root:[264,   900] training loss: 0.00409360
INFO:root:[264,   950] training loss: 0.00124426
INFO:root:[264,  1000] training loss: 0.00001874
INFO:root:[264,  1050] training loss: 0.00001690
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch264
INFO:root:[265,    50] training loss: 0.00713420
INFO:root:[265,   100] training loss: 0.00697041
INFO:root:[265,   150] training loss: 0.00680605
INFO:root:[265,   200] training loss: 0.00688811
INFO:root:[265,   250] training loss: 0.00657093
INFO:root:[265,   300] training loss: 0.00709089
INFO:root:[265,   350] training loss: 0.00622655
INFO:root:[265,   400] training loss: 0.00000569
INFO:root:[265,   450] training loss: 0.00000749
INFO:root:[265,   500] training loss: 0.00002737
INFO:root:[265,   550] training loss: 0.00015623
INFO:root:[265,   600] training loss: 0.00013575
INFO:root:[265,   650] training loss: 0.00001292
INFO:root:[265,   700] training loss: 0.00001201
INFO:root:[265,   750] training loss: 0.00021206
INFO:root:[265,   800] training loss: 0.00015118
INFO:root:[265,   850] training loss: 0.00024418
INFO:root:[265,   900] training loss: 0.00331005
INFO:root:[265,   950] training loss: 0.00128747
INFO:root:[265,  1000] training loss: 0.00001757
INFO:root:[265,  1050] training loss: 0.00005239
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch265
INFO:root:[266,    50] training loss: 0.00700963
INFO:root:[266,   100] training loss: 0.00690395
INFO:root:[266,   150] training loss: 0.00692092
INFO:root:[266,   200] training loss: 0.00648305
INFO:root:[266,   250] training loss: 0.00752092
INFO:root:[266,   300] training loss: 0.00715325
INFO:root:[266,   350] training loss: 0.00670617
INFO:root:[266,   400] training loss: 0.00000666
INFO:root:[266,   450] training loss: 0.00000778
INFO:root:[266,   500] training loss: 0.00002316
INFO:root:[266,   550] training loss: 0.00016485
INFO:root:[266,   600] training loss: 0.00015063
INFO:root:[266,   650] training loss: 0.00001418
INFO:root:[266,   700] training loss: 0.00001270
INFO:root:[266,   750] training loss: 0.00018326
INFO:root:[266,   800] training loss: 0.00018920
INFO:root:[266,   850] training loss: 0.00028790
INFO:root:[266,   900] training loss: 0.00334974
INFO:root:[266,   950] training loss: 0.00124755
INFO:root:[266,  1000] training loss: 0.00001517
INFO:root:[266,  1050] training loss: 0.00001522
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch266
INFO:root:[267,    50] training loss: 0.00705548
INFO:root:[267,   100] training loss: 0.00755016
INFO:root:[267,   150] training loss: 0.00703564
INFO:root:[267,   200] training loss: 0.00646106
INFO:root:[267,   250] training loss: 0.00714046
INFO:root:[267,   300] training loss: 0.00725247
INFO:root:[267,   350] training loss: 0.00605415
INFO:root:[267,   400] training loss: 0.00000695
INFO:root:[267,   450] training loss: 0.00000621
INFO:root:[267,   500] training loss: 0.00002382
INFO:root:[267,   550] training loss: 0.00016777
INFO:root:[267,   600] training loss: 0.00024510
INFO:root:[267,   650] training loss: 0.00001591
INFO:root:[267,   700] training loss: 0.00002438
INFO:root:[267,   750] training loss: 0.00018885
INFO:root:[267,   800] training loss: 0.00020962
INFO:root:[267,   850] training loss: 0.00031334
INFO:root:[267,   900] training loss: 0.00361141
INFO:root:[267,   950] training loss: 0.00122440
INFO:root:[267,  1000] training loss: 0.00001922
INFO:root:[267,  1050] training loss: 0.00001846
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch267
INFO:root:[268,    50] training loss: 0.00740314
INFO:root:[268,   100] training loss: 0.00699521
INFO:root:[268,   150] training loss: 0.00678253
INFO:root:[268,   200] training loss: 0.00681318
INFO:root:[268,   250] training loss: 0.00678735
INFO:root:[268,   300] training loss: 0.00769791
INFO:root:[268,   350] training loss: 0.00613570
INFO:root:[268,   400] training loss: 0.00000722
INFO:root:[268,   450] training loss: 0.00000887
INFO:root:[268,   500] training loss: 0.00002478
INFO:root:[268,   550] training loss: 0.00015433
INFO:root:[268,   600] training loss: 0.00014658
INFO:root:[268,   650] training loss: 0.00001519
INFO:root:[268,   700] training loss: 0.00001252
INFO:root:[268,   750] training loss: 0.00018851
INFO:root:[268,   800] training loss: 0.00019124
INFO:root:[268,   850] training loss: 0.00028371
INFO:root:[268,   900] training loss: 0.00337401
INFO:root:[268,   950] training loss: 0.00293511
INFO:root:[268,  1000] training loss: 0.00001643
INFO:root:[268,  1050] training loss: 0.00002137
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch268
INFO:root:[269,    50] training loss: 0.00691477
INFO:root:[269,   100] training loss: 0.00709724
INFO:root:[269,   150] training loss: 0.00704515
INFO:root:[269,   200] training loss: 0.00694913
INFO:root:[269,   250] training loss: 0.00689722
INFO:root:[269,   300] training loss: 0.00757399
INFO:root:[269,   350] training loss: 0.00648224
INFO:root:[269,   400] training loss: 0.00000665
INFO:root:[269,   450] training loss: 0.00000719
INFO:root:[269,   500] training loss: 0.00003146
INFO:root:[269,   550] training loss: 0.00015219
INFO:root:[269,   600] training loss: 0.00016182
INFO:root:[269,   650] training loss: 0.00001351
INFO:root:[269,   700] training loss: 0.00001766
INFO:root:[269,   750] training loss: 0.00013750
INFO:root:[269,   800] training loss: 0.00022285
INFO:root:[269,   850] training loss: 0.00024628
INFO:root:[269,   900] training loss: 0.00344470
INFO:root:[269,   950] training loss: 0.00108732
INFO:root:[269,  1000] training loss: 0.00001641
INFO:root:[269,  1050] training loss: 0.00002369
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch269
INFO:root:[270,    50] training loss: 0.00767177
INFO:root:[270,   100] training loss: 0.00838418
INFO:root:[270,   150] training loss: 0.00710126
INFO:root:[270,   200] training loss: 0.00639255
INFO:root:[270,   250] training loss: 0.00679089
INFO:root:[270,   300] training loss: 0.00767728
INFO:root:[270,   350] training loss: 0.00641219
INFO:root:[270,   400] training loss: 0.00000595
INFO:root:[270,   450] training loss: 0.00000641
INFO:root:[270,   500] training loss: 0.00002809
INFO:root:[270,   550] training loss: 0.00017050
INFO:root:[270,   600] training loss: 0.00018732
INFO:root:[270,   650] training loss: 0.00001250
INFO:root:[270,   700] training loss: 0.00001480
INFO:root:[270,   750] training loss: 0.00017124
INFO:root:[270,   800] training loss: 0.00022167
INFO:root:[270,   850] training loss: 0.00024211
INFO:root:[270,   900] training loss: 0.00361203
INFO:root:[270,   950] training loss: 0.00113551
INFO:root:[270,  1000] training loss: 0.00001830
INFO:root:[270,  1050] training loss: 0.00002387
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch270
INFO:root:[271,    50] training loss: 0.00752375
INFO:root:[271,   100] training loss: 0.00718504
INFO:root:[271,   150] training loss: 0.00749295
INFO:root:[271,   200] training loss: 0.00686704
INFO:root:[271,   250] training loss: 0.00668658
INFO:root:[271,   300] training loss: 0.00719188
INFO:root:[271,   350] training loss: 0.00597881
INFO:root:[271,   400] training loss: 0.00000719
INFO:root:[271,   450] training loss: 0.00000889
INFO:root:[271,   500] training loss: 0.00005523
INFO:root:[271,   550] training loss: 0.00016151
INFO:root:[271,   600] training loss: 0.00016064
INFO:root:[271,   650] training loss: 0.00002654
INFO:root:[271,   700] training loss: 0.00001284
INFO:root:[271,   750] training loss: 0.00016415
INFO:root:[271,   800] training loss: 0.00019197
INFO:root:[271,   850] training loss: 0.00031773
INFO:root:[271,   900] training loss: 0.00398197
INFO:root:[271,   950] training loss: 0.00100980
INFO:root:[271,  1000] training loss: 0.00001732
INFO:root:[271,  1050] training loss: 0.00001851
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch271
INFO:root:[272,    50] training loss: 0.00728410
INFO:root:[272,   100] training loss: 0.00716730
INFO:root:[272,   150] training loss: 0.00753094
INFO:root:[272,   200] training loss: 0.00756923
INFO:root:[272,   250] training loss: 0.00642576
INFO:root:[272,   300] training loss: 0.00725333
INFO:root:[272,   350] training loss: 0.00626901
INFO:root:[272,   400] training loss: 0.00000645
INFO:root:[272,   450] training loss: 0.00000871
INFO:root:[272,   500] training loss: 0.00002760
INFO:root:[272,   550] training loss: 0.00019087
INFO:root:[272,   600] training loss: 0.00023936
INFO:root:[272,   650] training loss: 0.00001434
INFO:root:[272,   700] training loss: 0.00001322
INFO:root:[272,   750] training loss: 0.00019697
INFO:root:[272,   800] training loss: 0.00034742
INFO:root:[272,   850] training loss: 0.00024897
INFO:root:[272,   900] training loss: 0.00343847
INFO:root:[272,   950] training loss: 0.00119608
INFO:root:[272,  1000] training loss: 0.00001712
INFO:root:[272,  1050] training loss: 0.00002393
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch272
INFO:root:[273,    50] training loss: 0.00762202
INFO:root:[273,   100] training loss: 0.00748119
INFO:root:[273,   150] training loss: 0.00662803
INFO:root:[273,   200] training loss: 0.00653072
INFO:root:[273,   250] training loss: 0.00699229
INFO:root:[273,   300] training loss: 0.00715132
INFO:root:[273,   350] training loss: 0.00575015
INFO:root:[273,   400] training loss: 0.00000630
INFO:root:[273,   450] training loss: 0.00000692
INFO:root:[273,   500] training loss: 0.00002440
INFO:root:[273,   550] training loss: 0.00015202
INFO:root:[273,   600] training loss: 0.00016505
INFO:root:[273,   650] training loss: 0.00001403
INFO:root:[273,   700] training loss: 0.00001422
INFO:root:[273,   750] training loss: 0.00020312
INFO:root:[273,   800] training loss: 0.00021222
INFO:root:[273,   850] training loss: 0.00039018
INFO:root:[273,   900] training loss: 0.00364762
INFO:root:[273,   950] training loss: 0.00109814
INFO:root:[273,  1000] training loss: 0.00001507
INFO:root:[273,  1050] training loss: 0.00002462
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch273
INFO:root:[274,    50] training loss: 0.00689858
INFO:root:[274,   100] training loss: 0.00712112
INFO:root:[274,   150] training loss: 0.00692083
INFO:root:[274,   200] training loss: 0.00665362
INFO:root:[274,   250] training loss: 0.00663701
INFO:root:[274,   300] training loss: 0.00700508
INFO:root:[274,   350] training loss: 0.00644654
INFO:root:[274,   400] training loss: 0.00000669
INFO:root:[274,   450] training loss: 0.00000933
INFO:root:[274,   500] training loss: 0.00003461
INFO:root:[274,   550] training loss: 0.00019233
INFO:root:[274,   600] training loss: 0.00018675
INFO:root:[274,   650] training loss: 0.00001277
INFO:root:[274,   700] training loss: 0.00001233
INFO:root:[274,   750] training loss: 0.00017454
INFO:root:[274,   800] training loss: 0.00024477
INFO:root:[274,   850] training loss: 0.00030667
INFO:root:[274,   900] training loss: 0.00347813
INFO:root:[274,   950] training loss: 0.00121999
INFO:root:[274,  1000] training loss: 0.00001854
INFO:root:[274,  1050] training loss: 0.00001600
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch274
INFO:root:[275,    50] training loss: 0.00669595
INFO:root:[275,   100] training loss: 0.00788684
INFO:root:[275,   150] training loss: 0.00708068
INFO:root:[275,   200] training loss: 0.00664008
INFO:root:[275,   250] training loss: 0.00711357
INFO:root:[275,   300] training loss: 0.00743505
INFO:root:[275,   350] training loss: 0.00607589
INFO:root:[275,   400] training loss: 0.00000524
INFO:root:[275,   450] training loss: 0.00000770
INFO:root:[275,   500] training loss: 0.00002190
INFO:root:[275,   550] training loss: 0.00016257
INFO:root:[275,   600] training loss: 0.00015236
INFO:root:[275,   650] training loss: 0.00001374
INFO:root:[275,   700] training loss: 0.00001416
INFO:root:[275,   750] training loss: 0.00017168
INFO:root:[275,   800] training loss: 0.00024589
INFO:root:[275,   850] training loss: 0.00027614
INFO:root:[275,   900] training loss: 0.00328549
INFO:root:[275,   950] training loss: 0.00103159
INFO:root:[275,  1000] training loss: 0.00001747
INFO:root:[275,  1050] training loss: 0.00002834
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch275
INFO:root:[276,    50] training loss: 0.00728913
INFO:root:[276,   100] training loss: 0.00707676
INFO:root:[276,   150] training loss: 0.00679776
INFO:root:[276,   200] training loss: 0.00657770
INFO:root:[276,   250] training loss: 0.00660790
INFO:root:[276,   300] training loss: 0.00745001
INFO:root:[276,   350] training loss: 0.00612337
INFO:root:[276,   400] training loss: 0.00000627
INFO:root:[276,   450] training loss: 0.00000773
INFO:root:[276,   500] training loss: 0.00008843
INFO:root:[276,   550] training loss: 0.00019891
INFO:root:[276,   600] training loss: 0.00019243
INFO:root:[276,   650] training loss: 0.00001350
INFO:root:[276,   700] training loss: 0.00001379
INFO:root:[276,   750] training loss: 0.00022453
INFO:root:[276,   800] training loss: 0.00018467
INFO:root:[276,   850] training loss: 0.00021761
INFO:root:[276,   900] training loss: 0.00324807
INFO:root:[276,   950] training loss: 0.00138775
INFO:root:[276,  1000] training loss: 0.00002044
INFO:root:[276,  1050] training loss: 0.00001771
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch276
INFO:root:[277,    50] training loss: 0.00695233
INFO:root:[277,   100] training loss: 0.00688047
INFO:root:[277,   150] training loss: 0.00718211
INFO:root:[277,   200] training loss: 0.00724128
INFO:root:[277,   250] training loss: 0.00649266
INFO:root:[277,   300] training loss: 0.00747205
INFO:root:[277,   350] training loss: 0.00601616
INFO:root:[277,   400] training loss: 0.00000587
INFO:root:[277,   450] training loss: 0.00000775
INFO:root:[277,   500] training loss: 0.00003039
INFO:root:[277,   550] training loss: 0.00018296
INFO:root:[277,   600] training loss: 0.00012908
INFO:root:[277,   650] training loss: 0.00001272
INFO:root:[277,   700] training loss: 0.00001449
INFO:root:[277,   750] training loss: 0.00030786
INFO:root:[277,   800] training loss: 0.00020721
INFO:root:[277,   850] training loss: 0.00030124
INFO:root:[277,   900] training loss: 0.00348390
INFO:root:[277,   950] training loss: 0.00134219
INFO:root:[277,  1000] training loss: 0.00001345
INFO:root:[277,  1050] training loss: 0.00002924
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch277
INFO:root:[278,    50] training loss: 0.00793390
INFO:root:[278,   100] training loss: 0.00711568
INFO:root:[278,   150] training loss: 0.00704748
INFO:root:[278,   200] training loss: 0.00667769
INFO:root:[278,   250] training loss: 0.00712829
INFO:root:[278,   300] training loss: 0.00728766
INFO:root:[278,   350] training loss: 0.00600510
INFO:root:[278,   400] training loss: 0.00000630
INFO:root:[278,   450] training loss: 0.00000848
INFO:root:[278,   500] training loss: 0.00003362
INFO:root:[278,   550] training loss: 0.00016637
INFO:root:[278,   600] training loss: 0.00018165
INFO:root:[278,   650] training loss: 0.00001242
INFO:root:[278,   700] training loss: 0.00001358
INFO:root:[278,   750] training loss: 0.00012931
INFO:root:[278,   800] training loss: 0.00022558
INFO:root:[278,   850] training loss: 0.00025285
INFO:root:[278,   900] training loss: 0.00379843
INFO:root:[278,   950] training loss: 0.00114997
INFO:root:[278,  1000] training loss: 0.00001733
INFO:root:[278,  1050] training loss: 0.00001571
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch278
INFO:root:[279,    50] training loss: 0.00800779
INFO:root:[279,   100] training loss: 0.00705902
INFO:root:[279,   150] training loss: 0.00722056
INFO:root:[279,   200] training loss: 0.00661628
INFO:root:[279,   250] training loss: 0.00659656
INFO:root:[279,   300] training loss: 0.00740543
INFO:root:[279,   350] training loss: 0.00638988
INFO:root:[279,   400] training loss: 0.00000725
INFO:root:[279,   450] training loss: 0.00000815
INFO:root:[279,   500] training loss: 0.00002703
INFO:root:[279,   550] training loss: 0.00016883
INFO:root:[279,   600] training loss: 0.00011321
INFO:root:[279,   650] training loss: 0.00001334
INFO:root:[279,   700] training loss: 0.00001384
INFO:root:[279,   750] training loss: 0.00023697
INFO:root:[279,   800] training loss: 0.00021796
INFO:root:[279,   850] training loss: 0.00024812
INFO:root:[279,   900] training loss: 0.00352896
INFO:root:[279,   950] training loss: 0.00119516
INFO:root:[279,  1000] training loss: 0.00001629
INFO:root:[279,  1050] training loss: 0.00001666
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch279
INFO:root:[280,    50] training loss: 0.00710841
INFO:root:[280,   100] training loss: 0.00705085
INFO:root:[280,   150] training loss: 0.00723294
INFO:root:[280,   200] training loss: 0.00666719
INFO:root:[280,   250] training loss: 0.00703248
INFO:root:[280,   300] training loss: 0.00740078
INFO:root:[280,   350] training loss: 0.00572107
INFO:root:[280,   400] training loss: 0.00000538
INFO:root:[280,   450] training loss: 0.00000631
INFO:root:[280,   500] training loss: 0.00010400
INFO:root:[280,   550] training loss: 0.00013506
INFO:root:[280,   600] training loss: 0.00013399
INFO:root:[280,   650] training loss: 0.00001266
INFO:root:[280,   700] training loss: 0.00001329
INFO:root:[280,   750] training loss: 0.00015758
INFO:root:[280,   800] training loss: 0.00027737
INFO:root:[280,   850] training loss: 0.00027386
INFO:root:[280,   900] training loss: 0.00433272
INFO:root:[280,   950] training loss: 0.00103801
INFO:root:[280,  1000] training loss: 0.00002327
INFO:root:[280,  1050] training loss: 0.00001751
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch280
INFO:root:[281,    50] training loss: 0.00727987
INFO:root:[281,   100] training loss: 0.00721021
INFO:root:[281,   150] training loss: 0.00653052
INFO:root:[281,   200] training loss: 0.00702711
INFO:root:[281,   250] training loss: 0.00680889
INFO:root:[281,   300] training loss: 0.00764228
INFO:root:[281,   350] training loss: 0.00599110
INFO:root:[281,   400] training loss: 0.00000630
INFO:root:[281,   450] training loss: 0.00000777
INFO:root:[281,   500] training loss: 0.00002385
INFO:root:[281,   550] training loss: 0.00014363
INFO:root:[281,   600] training loss: 0.00018308
INFO:root:[281,   650] training loss: 0.00001423
INFO:root:[281,   700] training loss: 0.00001558
INFO:root:[281,   750] training loss: 0.00021661
INFO:root:[281,   800] training loss: 0.00028444
INFO:root:[281,   850] training loss: 0.00017248
INFO:root:[281,   900] training loss: 0.00359520
INFO:root:[281,   950] training loss: 0.00103483
INFO:root:[281,  1000] training loss: 0.00001472
INFO:root:[281,  1050] training loss: 0.00001484
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch281
INFO:root:[282,    50] training loss: 0.00718744
INFO:root:[282,   100] training loss: 0.00739213
INFO:root:[282,   150] training loss: 0.00720129
INFO:root:[282,   200] training loss: 0.00781508
INFO:root:[282,   250] training loss: 0.00722518
INFO:root:[282,   300] training loss: 0.00781242
INFO:root:[282,   350] training loss: 0.00604206
INFO:root:[282,   400] training loss: 0.00000644
INFO:root:[282,   450] training loss: 0.00000855
INFO:root:[282,   500] training loss: 0.00002557
INFO:root:[282,   550] training loss: 0.00017207
INFO:root:[282,   600] training loss: 0.00014511
INFO:root:[282,   650] training loss: 0.00001349
INFO:root:[282,   700] training loss: 0.00001415
INFO:root:[282,   750] training loss: 0.00015725
INFO:root:[282,   800] training loss: 0.00029435
INFO:root:[282,   850] training loss: 0.00025536
INFO:root:[282,   900] training loss: 0.00353625
INFO:root:[282,   950] training loss: 0.00125677
INFO:root:[282,  1000] training loss: 0.00001800
INFO:root:[282,  1050] training loss: 0.00002232
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch282
INFO:root:[283,    50] training loss: 0.00712547
INFO:root:[283,   100] training loss: 0.00720196
INFO:root:[283,   150] training loss: 0.00714399
INFO:root:[283,   200] training loss: 0.00696861
INFO:root:[283,   250] training loss: 0.00691489
INFO:root:[283,   300] training loss: 0.00730683
INFO:root:[283,   350] training loss: 0.00615701
INFO:root:[283,   400] training loss: 0.00000541
INFO:root:[283,   450] training loss: 0.00000768
INFO:root:[283,   500] training loss: 0.00002650
INFO:root:[283,   550] training loss: 0.00015603
INFO:root:[283,   600] training loss: 0.00014250
INFO:root:[283,   650] training loss: 0.00001367
INFO:root:[283,   700] training loss: 0.00001833
INFO:root:[283,   750] training loss: 0.00022903
INFO:root:[283,   800] training loss: 0.00019402
INFO:root:[283,   850] training loss: 0.00024979
INFO:root:[283,   900] training loss: 0.00325474
INFO:root:[283,   950] training loss: 0.00128312
INFO:root:[283,  1000] training loss: 0.00001552
INFO:root:[283,  1050] training loss: 0.00001713
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch283
INFO:root:[284,    50] training loss: 0.00742532
INFO:root:[284,   100] training loss: 0.00691306
INFO:root:[284,   150] training loss: 0.00726777
INFO:root:[284,   200] training loss: 0.00712823
INFO:root:[284,   250] training loss: 0.00653102
INFO:root:[284,   300] training loss: 0.00738340
INFO:root:[284,   350] training loss: 0.00584026
INFO:root:[284,   400] training loss: 0.00000583
INFO:root:[284,   450] training loss: 0.00000808
INFO:root:[284,   500] training loss: 0.00002817
INFO:root:[284,   550] training loss: 0.00015776
INFO:root:[284,   600] training loss: 0.00013426
INFO:root:[284,   650] training loss: 0.00001255
INFO:root:[284,   700] training loss: 0.00001272
INFO:root:[284,   750] training loss: 0.00026818
INFO:root:[284,   800] training loss: 0.00021089
INFO:root:[284,   850] training loss: 0.00024371
INFO:root:[284,   900] training loss: 0.00344443
INFO:root:[284,   950] training loss: 0.00182608
INFO:root:[284,  1000] training loss: 0.00001734
INFO:root:[284,  1050] training loss: 0.00001745
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch284
INFO:root:[285,    50] training loss: 0.00726485
INFO:root:[285,   100] training loss: 0.00731871
INFO:root:[285,   150] training loss: 0.00700890
INFO:root:[285,   200] training loss: 0.00695840
INFO:root:[285,   250] training loss: 0.00741702
INFO:root:[285,   300] training loss: 0.00700646
INFO:root:[285,   350] training loss: 0.00615091
INFO:root:[285,   400] training loss: 0.00000538
INFO:root:[285,   450] training loss: 0.00000760
INFO:root:[285,   500] training loss: 0.00003331
INFO:root:[285,   550] training loss: 0.00015901
INFO:root:[285,   600] training loss: 0.00021429
INFO:root:[285,   650] training loss: 0.00001234
INFO:root:[285,   700] training loss: 0.00001394
INFO:root:[285,   750] training loss: 0.00022210
INFO:root:[285,   800] training loss: 0.00023430
INFO:root:[285,   850] training loss: 0.00031435
INFO:root:[285,   900] training loss: 0.00375602
INFO:root:[285,   950] training loss: 0.00116276
INFO:root:[285,  1000] training loss: 0.00001804
INFO:root:[285,  1050] training loss: 0.00001635
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch285
INFO:root:[286,    50] training loss: 0.00720970
INFO:root:[286,   100] training loss: 0.00709742
INFO:root:[286,   150] training loss: 0.00731725
INFO:root:[286,   200] training loss: 0.00676851
INFO:root:[286,   250] training loss: 0.00691768
INFO:root:[286,   300] training loss: 0.00690298
INFO:root:[286,   350] training loss: 0.00629633
INFO:root:[286,   400] training loss: 0.00000565
INFO:root:[286,   450] training loss: 0.00001055
INFO:root:[286,   500] training loss: 0.00003268
INFO:root:[286,   550] training loss: 0.00017340
INFO:root:[286,   600] training loss: 0.00014477
INFO:root:[286,   650] training loss: 0.00001567
INFO:root:[286,   700] training loss: 0.00001331
INFO:root:[286,   750] training loss: 0.00022850
INFO:root:[286,   800] training loss: 0.00021269
INFO:root:[286,   850] training loss: 0.00026517
INFO:root:[286,   900] training loss: 0.00332760
INFO:root:[286,   950] training loss: 0.00112570
INFO:root:[286,  1000] training loss: 0.00001708
INFO:root:[286,  1050] training loss: 0.00002281
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch286
INFO:root:[287,    50] training loss: 0.00720114
INFO:root:[287,   100] training loss: 0.00669134
INFO:root:[287,   150] training loss: 0.00704881
INFO:root:[287,   200] training loss: 0.00675813
INFO:root:[287,   250] training loss: 0.00689906
INFO:root:[287,   300] training loss: 0.00745308
INFO:root:[287,   350] training loss: 0.00626510
INFO:root:[287,   400] training loss: 0.00000564
INFO:root:[287,   450] training loss: 0.00000829
INFO:root:[287,   500] training loss: 0.00002376
INFO:root:[287,   550] training loss: 0.00018391
INFO:root:[287,   600] training loss: 0.00016019
INFO:root:[287,   650] training loss: 0.00001334
INFO:root:[287,   700] training loss: 0.00001278
INFO:root:[287,   750] training loss: 0.00022031
INFO:root:[287,   800] training loss: 0.00017812
INFO:root:[287,   850] training loss: 0.00023872
INFO:root:[287,   900] training loss: 0.00336030
INFO:root:[287,   950] training loss: 0.00127872
INFO:root:[287,  1000] training loss: 0.00001699
INFO:root:[287,  1050] training loss: 0.00001768
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch287
INFO:root:[288,    50] training loss: 0.00710100
INFO:root:[288,   100] training loss: 0.00704228
INFO:root:[288,   150] training loss: 0.00724450
INFO:root:[288,   200] training loss: 0.00683807
INFO:root:[288,   250] training loss: 0.00732822
INFO:root:[288,   300] training loss: 0.00728169
INFO:root:[288,   350] training loss: 0.00633760
INFO:root:[288,   400] training loss: 0.00000655
INFO:root:[288,   450] training loss: 0.00000688
INFO:root:[288,   500] training loss: 0.00003738
INFO:root:[288,   550] training loss: 0.00015644
INFO:root:[288,   600] training loss: 0.00016843
INFO:root:[288,   650] training loss: 0.00001161
INFO:root:[288,   700] training loss: 0.00001341
INFO:root:[288,   750] training loss: 0.00020628
INFO:root:[288,   800] training loss: 0.00016859
INFO:root:[288,   850] training loss: 0.00029367
INFO:root:[288,   900] training loss: 0.00418211
INFO:root:[288,   950] training loss: 0.00108491
INFO:root:[288,  1000] training loss: 0.00001547
INFO:root:[288,  1050] training loss: 0.00001670
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch288
INFO:root:[289,    50] training loss: 0.00703499
INFO:root:[289,   100] training loss: 0.00715563
INFO:root:[289,   150] training loss: 0.00702195
INFO:root:[289,   200] training loss: 0.00692310
INFO:root:[289,   250] training loss: 0.00684465
INFO:root:[289,   300] training loss: 0.00729414
INFO:root:[289,   350] training loss: 0.00724657
INFO:root:[289,   400] training loss: 0.00000610
INFO:root:[289,   450] training loss: 0.00000797
INFO:root:[289,   500] training loss: 0.00002582
INFO:root:[289,   550] training loss: 0.00017700
INFO:root:[289,   600] training loss: 0.00020261
INFO:root:[289,   650] training loss: 0.00001191
INFO:root:[289,   700] training loss: 0.00001303
INFO:root:[289,   750] training loss: 0.00022053
INFO:root:[289,   800] training loss: 0.00028406
INFO:root:[289,   850] training loss: 0.00020398
INFO:root:[289,   900] training loss: 0.00327329
INFO:root:[289,   950] training loss: 0.00108303
INFO:root:[289,  1000] training loss: 0.00001605
INFO:root:[289,  1050] training loss: 0.00001658
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch289
INFO:root:[290,    50] training loss: 0.00721240
INFO:root:[290,   100] training loss: 0.00681039
INFO:root:[290,   150] training loss: 0.00834217
INFO:root:[290,   200] training loss: 0.00627009
INFO:root:[290,   250] training loss: 0.00650124
INFO:root:[290,   300] training loss: 0.00725701
INFO:root:[290,   350] training loss: 0.00638456
INFO:root:[290,   400] training loss: 0.00000573
INFO:root:[290,   450] training loss: 0.00000711
INFO:root:[290,   500] training loss: 0.00002926
INFO:root:[290,   550] training loss: 0.00014553
INFO:root:[290,   600] training loss: 0.00014299
INFO:root:[290,   650] training loss: 0.00001489
INFO:root:[290,   700] training loss: 0.00001237
INFO:root:[290,   750] training loss: 0.00016852
INFO:root:[290,   800] training loss: 0.00024383
INFO:root:[290,   850] training loss: 0.00031571
INFO:root:[290,   900] training loss: 0.00337067
INFO:root:[290,   950] training loss: 0.00111917
INFO:root:[290,  1000] training loss: 0.00001511
INFO:root:[290,  1050] training loss: 0.00001544
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch290
INFO:root:[291,    50] training loss: 0.00732724
INFO:root:[291,   100] training loss: 0.00731864
INFO:root:[291,   150] training loss: 0.00704901
INFO:root:[291,   200] training loss: 0.00660855
INFO:root:[291,   250] training loss: 0.00694921
INFO:root:[291,   300] training loss: 0.00713532
INFO:root:[291,   350] training loss: 0.00576731
INFO:root:[291,   400] training loss: 0.00000654
INFO:root:[291,   450] training loss: 0.00000764
INFO:root:[291,   500] training loss: 0.00002302
INFO:root:[291,   550] training loss: 0.00015153
INFO:root:[291,   600] training loss: 0.00012216
INFO:root:[291,   650] training loss: 0.00001283
INFO:root:[291,   700] training loss: 0.00001301
INFO:root:[291,   750] training loss: 0.00020557
INFO:root:[291,   800] training loss: 0.00017751
INFO:root:[291,   850] training loss: 0.00031801
INFO:root:[291,   900] training loss: 0.00367090
INFO:root:[291,   950] training loss: 0.00105437
INFO:root:[291,  1000] training loss: 0.00001531
INFO:root:[291,  1050] training loss: 0.00002003
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch291
INFO:root:[292,    50] training loss: 0.00667002
INFO:root:[292,   100] training loss: 0.00805190
INFO:root:[292,   150] training loss: 0.00673543
INFO:root:[292,   200] training loss: 0.00672217
INFO:root:[292,   250] training loss: 0.00682828
INFO:root:[292,   300] training loss: 0.00743806
INFO:root:[292,   350] training loss: 0.00674810
INFO:root:[292,   400] training loss: 0.00000728
INFO:root:[292,   450] training loss: 0.00000676
INFO:root:[292,   500] training loss: 0.00003638
INFO:root:[292,   550] training loss: 0.00016822
INFO:root:[292,   600] training loss: 0.00020780
INFO:root:[292,   650] training loss: 0.00001230
INFO:root:[292,   700] training loss: 0.00001373
INFO:root:[292,   750] training loss: 0.00022746
INFO:root:[292,   800] training loss: 0.00018828
INFO:root:[292,   850] training loss: 0.00025848
INFO:root:[292,   900] training loss: 0.00328975
INFO:root:[292,   950] training loss: 0.00117610
INFO:root:[292,  1000] training loss: 0.00001546
INFO:root:[292,  1050] training loss: 0.00001667
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch292
INFO:root:[293,    50] training loss: 0.00718907
INFO:root:[293,   100] training loss: 0.00742920
INFO:root:[293,   150] training loss: 0.00696458
INFO:root:[293,   200] training loss: 0.00692797
INFO:root:[293,   250] training loss: 0.00684767
INFO:root:[293,   300] training loss: 0.00774972
INFO:root:[293,   350] training loss: 0.00654236
INFO:root:[293,   400] training loss: 0.00000667
INFO:root:[293,   450] training loss: 0.00000722
INFO:root:[293,   500] training loss: 0.00005189
INFO:root:[293,   550] training loss: 0.00016965
INFO:root:[293,   600] training loss: 0.00016794
INFO:root:[293,   650] training loss: 0.00001476
INFO:root:[293,   700] training loss: 0.00001344
INFO:root:[293,   750] training loss: 0.00023375
INFO:root:[293,   800] training loss: 0.00021215
INFO:root:[293,   850] training loss: 0.00023954
INFO:root:[293,   900] training loss: 0.00338159
INFO:root:[293,   950] training loss: 0.00094342
INFO:root:[293,  1000] training loss: 0.00001648
INFO:root:[293,  1050] training loss: 0.00003199
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch293
INFO:root:[294,    50] training loss: 0.00789641
INFO:root:[294,   100] training loss: 0.00776170
INFO:root:[294,   150] training loss: 0.00713156
INFO:root:[294,   200] training loss: 0.00677843
INFO:root:[294,   250] training loss: 0.00692751
INFO:root:[294,   300] training loss: 0.00708859
INFO:root:[294,   350] training loss: 0.00602208
INFO:root:[294,   400] training loss: 0.00000713
INFO:root:[294,   450] training loss: 0.00000939
INFO:root:[294,   500] training loss: 0.00002199
INFO:root:[294,   550] training loss: 0.00017007
INFO:root:[294,   600] training loss: 0.00027840
INFO:root:[294,   650] training loss: 0.00001312
INFO:root:[294,   700] training loss: 0.00001381
INFO:root:[294,   750] training loss: 0.00023726
INFO:root:[294,   800] training loss: 0.00029774
INFO:root:[294,   850] training loss: 0.00029913
INFO:root:[294,   900] training loss: 0.00325298
INFO:root:[294,   950] training loss: 0.00158854
INFO:root:[294,  1000] training loss: 0.00001667
INFO:root:[294,  1050] training loss: 0.00001928
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch294
INFO:root:[295,    50] training loss: 0.00690601
INFO:root:[295,   100] training loss: 0.00724975
INFO:root:[295,   150] training loss: 0.00818466
INFO:root:[295,   200] training loss: 0.00672775
INFO:root:[295,   250] training loss: 0.00647314
INFO:root:[295,   300] training loss: 0.00716668
INFO:root:[295,   350] training loss: 0.00631262
INFO:root:[295,   400] training loss: 0.00000526
INFO:root:[295,   450] training loss: 0.00000800
INFO:root:[295,   500] training loss: 0.00002130
INFO:root:[295,   550] training loss: 0.00013707
INFO:root:[295,   600] training loss: 0.00014470
INFO:root:[295,   650] training loss: 0.00001369
INFO:root:[295,   700] training loss: 0.00001419
INFO:root:[295,   750] training loss: 0.00024937
INFO:root:[295,   800] training loss: 0.00025190
INFO:root:[295,   850] training loss: 0.00026179
INFO:root:[295,   900] training loss: 0.00320535
INFO:root:[295,   950] training loss: 0.00100593
INFO:root:[295,  1000] training loss: 0.00001683
INFO:root:[295,  1050] training loss: 0.00002998
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch295
INFO:root:[296,    50] training loss: 0.00761022
INFO:root:[296,   100] training loss: 0.00698330
INFO:root:[296,   150] training loss: 0.00676041
INFO:root:[296,   200] training loss: 0.00637840
INFO:root:[296,   250] training loss: 0.00644926
INFO:root:[296,   300] training loss: 0.00780885
INFO:root:[296,   350] training loss: 0.00616874
INFO:root:[296,   400] training loss: 0.00000737
INFO:root:[296,   450] training loss: 0.00000886
INFO:root:[296,   500] training loss: 0.00002349
INFO:root:[296,   550] training loss: 0.00018186
INFO:root:[296,   600] training loss: 0.00015515
INFO:root:[296,   650] training loss: 0.00001230
INFO:root:[296,   700] training loss: 0.00001471
INFO:root:[296,   750] training loss: 0.00026212
INFO:root:[296,   800] training loss: 0.00034072
INFO:root:[296,   850] training loss: 0.00022093
INFO:root:[296,   900] training loss: 0.00369203
INFO:root:[296,   950] training loss: 0.00102292
INFO:root:[296,  1000] training loss: 0.00001842
INFO:root:[296,  1050] training loss: 0.00002173
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch296
INFO:root:[297,    50] training loss: 0.00683497
INFO:root:[297,   100] training loss: 0.00690575
INFO:root:[297,   150] training loss: 0.00767606
INFO:root:[297,   200] training loss: 0.00667119
INFO:root:[297,   250] training loss: 0.00684475
INFO:root:[297,   300] training loss: 0.00727435
INFO:root:[297,   350] training loss: 0.00599266
INFO:root:[297,   400] training loss: 0.00000621
INFO:root:[297,   450] training loss: 0.00000878
INFO:root:[297,   500] training loss: 0.00004058
INFO:root:[297,   550] training loss: 0.00015660
INFO:root:[297,   600] training loss: 0.00015307
INFO:root:[297,   650] training loss: 0.00001335
INFO:root:[297,   700] training loss: 0.00001336
INFO:root:[297,   750] training loss: 0.00026102
INFO:root:[297,   800] training loss: 0.00028121
INFO:root:[297,   850] training loss: 0.00025405
INFO:root:[297,   900] training loss: 0.00355870
INFO:root:[297,   950] training loss: 0.00113586
INFO:root:[297,  1000] training loss: 0.00001862
INFO:root:[297,  1050] training loss: 0.00001847
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch297
INFO:root:[298,    50] training loss: 0.00701293
INFO:root:[298,   100] training loss: 0.00724260
INFO:root:[298,   150] training loss: 0.00707058
INFO:root:[298,   200] training loss: 0.00684035
INFO:root:[298,   250] training loss: 0.00749078
INFO:root:[298,   300] training loss: 0.00729100
INFO:root:[298,   350] training loss: 0.00590950
INFO:root:[298,   400] training loss: 0.00000559
INFO:root:[298,   450] training loss: 0.00000796
INFO:root:[298,   500] training loss: 0.00003175
INFO:root:[298,   550] training loss: 0.00016351
INFO:root:[298,   600] training loss: 0.00013102
INFO:root:[298,   650] training loss: 0.00001365
INFO:root:[298,   700] training loss: 0.00001421
INFO:root:[298,   750] training loss: 0.00028746
INFO:root:[298,   800] training loss: 0.00019468
INFO:root:[298,   850] training loss: 0.00025774
INFO:root:[298,   900] training loss: 0.00339244
INFO:root:[298,   950] training loss: 0.00109432
INFO:root:[298,  1000] training loss: 0.00002001
INFO:root:[298,  1050] training loss: 0.00001756
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch298
INFO:root:[299,    50] training loss: 0.00743161
INFO:root:[299,   100] training loss: 0.00712060
INFO:root:[299,   150] training loss: 0.00690474
INFO:root:[299,   200] training loss: 0.00653539
INFO:root:[299,   250] training loss: 0.00681844
INFO:root:[299,   300] training loss: 0.00716507
INFO:root:[299,   350] training loss: 0.00633995
INFO:root:[299,   400] training loss: 0.00000619
INFO:root:[299,   450] training loss: 0.00000758
INFO:root:[299,   500] training loss: 0.00003689
INFO:root:[299,   550] training loss: 0.00014974
INFO:root:[299,   600] training loss: 0.00019019
INFO:root:[299,   650] training loss: 0.00001127
INFO:root:[299,   700] training loss: 0.00001273
INFO:root:[299,   750] training loss: 0.00018439
INFO:root:[299,   800] training loss: 0.00019862
INFO:root:[299,   850] training loss: 0.00031532
INFO:root:[299,   900] training loss: 0.00379374
INFO:root:[299,   950] training loss: 0.00117124
INFO:root:[299,  1000] training loss: 0.00001856
INFO:root:[299,  1050] training loss: 0.00001558
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch299
INFO:root:[300,    50] training loss: 0.00745827
INFO:root:[300,   100] training loss: 0.00720800
INFO:root:[300,   150] training loss: 0.00774651
INFO:root:[300,   200] training loss: 0.00661456
INFO:root:[300,   250] training loss: 0.00663094
INFO:root:[300,   300] training loss: 0.00744404
INFO:root:[300,   350] training loss: 0.00606419
INFO:root:[300,   400] training loss: 0.00000611
INFO:root:[300,   450] training loss: 0.00000897
INFO:root:[300,   500] training loss: 0.00003198
INFO:root:[300,   550] training loss: 0.00016680
INFO:root:[300,   600] training loss: 0.00018873
INFO:root:[300,   650] training loss: 0.00001217
INFO:root:[300,   700] training loss: 0.00001659
INFO:root:[300,   750] training loss: 0.00016480
INFO:root:[300,   800] training loss: 0.00030763
INFO:root:[300,   850] training loss: 0.00020313
INFO:root:[300,   900] training loss: 0.00382697
INFO:root:[300,   950] training loss: 0.00100817
INFO:root:[300,  1000] training loss: 0.00002410
INFO:root:[300,  1050] training loss: 0.00001796
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8927    0.8221    0.8559      1720
    Anaphase     0.7957    0.7965    0.7961      1032
          G2     0.6250    0.6250    0.6250         8
   Metaphase     0.4286    0.6575    0.5189        73
   Telophase     0.6085    0.6644    0.6352      1034
          G1     1.0000    1.0000    1.0000         3

    accuracy                         0.7699      3872
   macro avg     0.7167    0.7951    0.7473      3872
weighted avg     0.7816    0.7699    0.7743      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6454 test images: 77 %
INFO:root:The model saved: final_model_dict_jcd_h5_reshape.pth
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.3333    0.4000         3
           S     0.8910    0.8294    0.8591      2867
    Anaphase     0.7949    0.8047    0.7998      1720
          G2     0.4444    0.5714    0.5000        14
   Metaphase     0.4346    0.6860    0.5321       121
   Telophase     0.6190    0.6560    0.6370      1724
          G1     0.8333    1.0000    0.9091         5

    accuracy                         0.7732      6454
   macro avg     0.6453    0.6973    0.6624      6454
weighted avg     0.7830    0.7732    0.7769      6454

INFO:root:   Prophase         S  Anaphase   G2  Metaphase  Telophase        G1
0       0.4  0.859104  0.799769  0.5   0.532051   0.637004  0.909091
