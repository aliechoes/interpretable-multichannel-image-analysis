INFO:root:the deviced being used is cpu
INFO:root:statistics used: {'mean': tensor([0.3079, 0.0614, 0.1428]), 'std': tensor([0.1656, 0.1625, 0.1261])}
INFO:root:test_indx used: 8237, 3382, 2361, 23748, 26770, 23949, 26217, 2657, 12907, 12557, 9901, 28753, 26388, 18315, 9953, 1279, 483, 29762, 10375, 15787, 19051, 2360, 15455, 3587, 18292, 15161, 23610, 3242, 14355, 6639, 26804, 8859, 23863, 8840, 14873, 7827, 20791, 4885, 26928, 3376, 13621, 29907, 25215, 22651, 14878, 23525, 26595, 3688, 17113, 26824, 25818, 5062, 30105, 24690, 3709, 28211, 21721, 2321, 25599, 29410, 21245, 31452, 4282, 29187, 24573, 9878, 8000, 3446, 644, 22650, 1335, 13040, 19767, 26185, 16244, 31665, 21214, 13237, 3835, 11641, 4531, 24304, 184, 32152, 2830, 3798, 2016, 5724, 14967, 23031, 4668, 19491, 8718, 24518, 18181, 24615, 24372, 6955, 25187, 19658, 14280, 11520, 7434, 23161, 18419, 9989, 7944, 1516, 13962, 25255, 494, 26071, 15251, 26837, 28784, 9727, 17183, 9126, 18414, 4571, 17614, 3525, 28278, 25052, 1204, 18733, 4201, 22394, 18005, 19869, 4714, 374, 10896, 13991, 20660, 22152, 18343, 5290, 16743, 8031, 16729, 3130, 821, 19211, 17013, 21072, 7150, 7269, 31594, 26072, 21791, 27380, 28244, 3787, 19620, 9722, 14850, 27137, 13317, 5825, 31670, 2478, 12442, 12667, 26485, 605, 15491, 28725, 10831, 22164, 4042, 31518, 20299, 10842, 20721, 23386, 24865, 29958, 6284, 16696, 7578, 7340, 15998, 3155, 281, 2502, 11972, 25068, 18715, 17557, 4092, 27294, 29398, 8727, 24955, 23843, 19948, 25833, 11, 7339, 6752, 26351, 7581, 28703, 22672, 16917, 23766, 10170, 21968, 14618, 23652, 30304, 19502, 6349, 9981, 6105, 29284, 31383, 11484, 723, 17148, 22157, 20793, 30586, 26887, 30567, 16194, 9103, 22575, 31661, 8018, 17678, 31432, 12527, 3405, 17967, 23714, 15446, 11855, 27814, 3005, 29645, 15198, 20116, 13329, 31738, 5200, 14352, 28782, 26009, 32106, 23850, 31657, 21179, 1524, 8133, 8033, 6404, 21969, 21166, 9264, 7751, 17431, 20037, 4184, 27590, 1097, 10211, 18290, 19859, 4984, 18502, 31241, 18262, 9229, 27825, 27387, 7263, 4955, 870, 21805, 15786, 30979, 20794, 639, 26601, 5265, 26069, 2545, 21116, 21041, 25149, 5844, 17633, 31103, 3494, 28466, 27043, 23506, 28407, 17139, 24015, 7542, 10597, 18466, 22357, 2967, 25492, 18219, 27109, 10483, 11859, 14654, 17022, 13340, 31428, 27430, 25244, 5593, 28534, 7121, 4296, 15091, 16119, 3550, 8274, 26397, 11655, 1666, 31688, 18596, 2524, 2381, 719, 26498, 9079, 9534, 28754, 22026, 16144, 11773, 17925, 24116, 1760, 25519, 12858, 29525, 8790, 2742, 19270, 8262, 6767, 2069, 15253, 22758, 11963, 19194, 24101, 1978, 3412, 15526, 14121, 7466, 31993, 16457, 26057, 28962, 20946, 27213, 137, 17838, 12030, 28502, 2225, 1183, 14440, 17182, 19985, 30974, 11158, 16765, 1567, 400, 25547, 7360, 14374, 5812, 2914, 21588, 16245, 12471, 4755, 6323, 2215, 7327, 29560, 17720, 16609, 19360, 11207, 5681, 20109, 5744, 140, 11868, 26510, 27553, 7433, 16271, 2243, 26212, 10574, 22537, 26935, 3485, 18131, 21135, 25744, 3613, 26242, 26295, 31987, 10943, 25884, 22205, 18910, 29941, 28069, 15292, 8037, 26146, 23384, 31834, 20731, 24913, 23944, 5049, 9159, 19341, 23958, 9661, 16330, 26324, 9548, 31580, 12232, 30522, 18473, 17061, 3048, 16233, 28617, 7647, 28866, 10111, 10229, 2701, 18109, 21319, 30064, 12051, 20733, 23915, 22478, 4290, 28408, 21310, 31275, 21329, 13159, 949, 8121, 29711, 10956, 9731, 19449, 12187, 27901, 28046, 3592, 3398, 29417, 956, 29536, 13459, 16834, 30927, 31161, 7440, 27701, 921, 10698, 9701, 8993, 20956, 6401, 30697, 30630, 24897, 11140, 25766, 25677, 18729, 677, 21785, 13228, 5650, 28779, 7529, 19577, 23857, 20048, 9699, 30863, 27881, 7276, 14153, 3045, 21274, 9030, 13789, 8633, 249, 30386, 29530, 4514, 13983, 5277, 29137, 25569, 22050, 25111, 4339, 20419, 2300, 671, 18565, 25020, 23791, 7428, 25437, 15064, 24799, 17860, 24662, 2986, 18849, 27083, 26632, 1184, 28469, 24777, 2955, 22692, 22281, 867, 9221, 9632, 12412, 30733, 14329, 21675, 20750, 8844, 11846, 7220, 30377, 24577, 10747, 23580, 27095, 12135, 27930, 24611, 28134, 22044, 20504, 17339, 12550, 28666, 10789, 25877, 31154, 19596, 6028, 3673, 9118, 23556, 14409, 26784, 24588, 1220, 28837, 10825, 29245, 10296, 9582, 8637, 31477, 9086, 28078, 31469, 2155, 4761, 18816, 28522, 30278, 18710, 975, 30354, 31948, 9149, 5293, 4789, 23950, 4827, 24961, 19281, 30465, 20730, 13300, 2601, 7379, 6820, 10741, 20136, 20663, 9184, 16769, 26328, 13772, 21302, 17365, 1342, 787, 29776, 27359, 31698, 7566, 4660, 4143, 19973, 17155, 6005, 24427, 16474, 1120, 764, 8480, 11008, 30742, 27745, 25212, 29715, 7783, 23804, 4864, 25556, 31339, 208, 21824, 9427, 4309, 521, 20044, 11974, 25074, 1339, 31437, 18033, 30773, 26059, 10655, 447, 18990, 9821, 28070, 28906, 29330, 24968, 7414, 9370, 31829, 25936, 6731, 14539, 13844, 9339, 27196, 16191, 19071, 10363, 10476, 19754, 15283, 14337, 10766, 339, 21477, 21173, 2448, 18339, 11244, 308, 15766, 765, 29901, 28077, 3535, 15338, 22828, 15578, 4500, 819, 18276, 3019, 19510, 26974, 7424, 19996, 19450, 672, 43, 2737, 13853, 13794, 31351, 9165, 9501, 20557, 18040, 1084, 2471, 19255, 22919, 23694, 13367, 8028, 3433, 30088, 26780, 15956, 21210, 21690, 12875, 31730, 10692, 5842, 9594, 12091, 25118, 18204, 28857, 30861, 21221, 11149, 26854, 21416, 28891, 25001, 31601, 31468, 25887, 26342, 25473, 6595, 7842, 3034, 26959, 17427, 8593, 11847, 19756, 24988, 4284, 16031, 8924, 17569, 31732, 10249, 14877, 29777, 17200, 31147, 22507, 15475, 9526, 24957, 3564, 26544, 31188, 12189, 21055, 2085, 14158, 7153, 22049, 6400, 15041, 4344, 6385, 16910, 25777, 25726, 890, 17541, 6539, 30984, 20756, 10749, 9016, 11511, 6930, 2572, 1062, 20790, 1246, 29106, 24920, 15457, 19599, 8776, 31516, 11902, 2124, 445, 8252, 4793, 16407, 32115, 15101, 7224, 14800, 2912, 14378, 25256, 11796, 31839, 3286, 29651, 26856, 21578, 20385, 11181, 14950, 23877, 18848, 17325, 11587, 27987, 17948, 12919, 9040, 21627, 1331, 10316, 11463, 1125, 8886, 10965, 29236, 16358, 26629, 12859, 30481, 26951, 20352, 7585, 23876, 6920, 29743, 7889, 28882, 14080, 6220, 2439, 24463, 30356, 13277, 24309, 23426, 11199, 19674, 21593, 1509, 10940, 19872, 14853, 16858, 7138, 11500, 11470, 26023, 18250, 18548, 18159, 25402, 14600, 29494, 22365, 12826, 12340, 29976, 14112, 19002, 31907, 16441, 23639, 1213, 12305, 7, 20588, 18855, 25038, 15940, 26752, 12096, 15716, 31376, 1648, 6844, 14495, 593, 15031, 12624, 264, 11085, 6709, 10009, 9651, 9122, 6317, 9643, 5309, 2858, 15148, 17961, 14855, 25309, 26257, 31964, 9074, 15236, 11635, 20994, 25121, 25448, 21684, 8631, 32221, 11789, 24459, 1405, 942, 12807, 31060, 16963, 26043, 30780, 30213, 25060, 1186, 15430, 1685, 29815, 5695, 27595, 4028, 11905, 27846, 16273, 26769, 9000, 14923, 5110, 17501, 4614, 30559, 5982, 17597, 10867, 28260, 15895, 26628, 26588, 15006, 4432, 280, 22748, 23038, 16655, 19538, 31861, 4118, 21664, 1455, 19048, 25137, 24894, 17897, 14266, 8191, 6086, 12903, 6366, 27914, 13223, 17081, 32233, 907, 28094, 2581, 15816, 22680, 22372, 10644, 24371, 876, 1529, 8873, 30242, 2077, 19889, 1259, 14545, 5499, 22765, 25642, 15702, 14433, 24972, 31041, 23218, 25082, 3506, 18869, 15137, 20966, 24675, 21209, 54, 18568, 25465, 8431, 6802, 10470, 15193, 30211, 25036, 2630, 7222, 12861, 5763, 9703, 25208, 1274, 882, 3324, 13022, 17172, 7164, 17128, 12687, 30678, 20257, 20881, 15808, 25580, 13952, 7331, 20182, 24107, 1114, 20957, 23824, 14647, 13805, 6109, 12976, 22501, 19992, 30887, 4037, 1140, 1308, 22894, 12148, 16016, 7574, 30023, 21162, 17184, 16651, 15051, 31527, 14714, 27288, 14784, 9589, 16579, 25911, 20414, 30367, 21013, 2740, 7501, 5371, 16490, 5440, 21841, 27838, 26325, 5250, 327, 6413, 7090, 29058, 24303, 3609, 14001, 21340, 32265, 25370, 19466, 24180, 29851, 4406, 6837, 24986, 10973, 16978, 20206, 14854, 13087, 20183, 4751, 15713, 20685, 22504, 13162, 226, 2262, 4404, 7296, 18388, 16644, 7936, 31369, 9573, 2627, 14429, 6344, 26129, 26656, 26038, 22103, 24625, 4508, 10138, 19991, 19402, 24815, 13118, 3760, 14096, 30541, 30017, 888, 2101, 31710, 23882, 32005, 5785, 22821, 29946, 884, 6883, 13857, 2506, 16062, 7375, 24457, 3674, 20917, 30384, 11830, 10693, 26688, 18089, 31439, 10742, 14649, 18612, 13615, 5319, 23928, 24438, 25451, 11072, 24395, 29881, 1719, 16738, 12439, 11049, 29027, 19633, 10953, 16930, 11423, 23983, 8719, 30056, 3336, 1245, 8452, 6535, 17655, 12229, 12584, 22363, 21265, 3911, 5624, 16276, 28825, 8444, 12566, 2008, 8657, 197, 21843, 17639, 23679, 17358, 9207, 6970, 8984, 10804, 1287, 3069, 1494, 15431, 29493, 18481, 22342, 12587, 22341, 11792, 12245, 22291, 14679, 7877, 6341, 4157, 1268, 19277, 31529, 6775, 19657, 19989, 30880, 27847, 1263, 4684, 7354, 15520, 23816, 19803, 22654, 25950, 13597, 10502, 3151, 31989, 6097, 4491, 14972, 11981, 3900, 20458, 7839, 18335, 21827, 11039, 2417, 15752, 15289, 15428, 2172, 26019, 9022, 16209, 29981, 23711, 29471, 32196, 7003, 4357, 23878, 9629, 28272, 23110, 14331, 9687, 23226, 8964, 6586, 16589, 11033, 2213, 4695, 22708, 16692, 15021, 16602, 10411, 11857, 1008, 20482, 169, 4079, 17645, 11130, 22697, 10936, 15233, 17438, 29473, 19417, 15931, 6974, 10270, 2982, 1452, 9474, 2276, 23343, 3620, 25913, 25819, 26457, 5980, 28201, 11376, 9174, 17464, 23196, 31930, 22732, 11209, 4504, 31209, 2120, 23137, 9900, 10208, 22448, 22881, 9347, 18141, 15473, 19815, 13992, 27280, 9434, 16952, 10186, 7870, 13734, 17849, 4393, 21718, 32133, 31471, 20122, 11840, 15648, 22845, 30126, 1537, 12603, 17770, 9664, 20736, 20275, 6650, 2419, 30285, 29721, 15103, 30123, 15965, 15901, 26934, 14777, 13780, 7111, 4685, 15708, 15217, 8130, 21409, 14081, 5345, 28328, 28307, 8740, 22611, 19490, 10365, 305, 18645, 19679, 1278, 8559, 17670, 31783, 23591, 2455, 17802, 27609, 17637, 14265, 13347, 2096, 12298, 19501, 15652, 1054, 13099, 21366, 9626, 27611, 14049, 27500, 24592, 23054, 5334, 27247, 29616, 7069, 1736, 8223, 11255, 14821, 23939, 27517, 6303, 17079, 10271, 8538, 10877, 30461, 27376, 15144, 9862, 20173, 16161, 28308, 26625, 27061, 20523, 18628, 21301, 16976, 23817, 30051, 4166, 23124, 2499, 899, 8503, 26910, 14024, 1089, 5075, 11050, 16518, 15516, 1823, 24143, 17932, 23311, 19800, 12682, 16059, 17271, 6636, 29948, 8685, 29865, 11147, 6507, 18340, 8699, 27835, 3191, 28654, 24357, 29565, 29729, 32173, 26381, 4259, 859, 21410, 4099, 27666, 4008, 8640, 6438, 17987, 19616, 25823, 26298, 1497, 27134, 5936, 18460, 10954, 10460, 5818, 8507, 1726, 32066, 3676, 7490, 8188, 20311, 25115, 31049, 22149, 21529, 7278, 14496, 3645, 1686, 14341, 31828, 5352, 31123, 22588, 1320, 28323, 1700, 9817, 18075, 30782, 24622, 20478, 22780, 31666, 21983, 21206, 3519, 28888, 12729, 25419, 19977, 28277, 29546, 26539, 5356, 23285, 4346, 15392, 16827, 20008, 19126, 26925, 511, 9223, 1348, 11251, 3213, 999, 31089, 25459, 10408, 18149, 8598, 6926, 6651, 16691, 16224, 15098, 20397, 4197, 21960, 18237, 27002, 12373, 12537, 23756, 20188, 6672, 28671, 10453, 29824, 23155, 10472, 5539, 10533, 16403, 2573, 20989, 18479, 1875, 6420, 31838, 5940, 14893, 6403, 4093, 15821, 13207, 18859, 8902, 21138, 25938, 11178, 6122, 13320, 31567, 3219, 18974, 12586, 29304, 15179, 12672, 10769, 22840, 30225, 15026, 30776, 31944, 21513, 29327, 30163, 21596, 10473, 17761, 29773, 26953, 14187, 16114, 18240, 2659, 14567, 15932, 18078, 23515, 26036, 2280, 19670, 20518, 31108, 11668, 23029, 12706, 22295, 31322, 216, 21984, 8330, 2888, 15948, 12509, 29692, 6626, 5688, 22477, 15048, 12287, 22570, 5311, 17419, 11022, 31733, 23337, 1495, 13333, 15227, 14446, 23961, 2458, 8627, 13895, 29778, 23096, 27863, 18238, 17455, 11913, 18213, 31668, 6255, 3729, 22045, 18947, 9237, 25326, 74, 16735, 30467, 32147, 12502, 29900, 27250, 630, 4526, 2513, 15728, 10521, 5141, 9255, 13619, 25487, 18592, 9317, 14479, 570, 31227, 22239, 11617, 11229, 23920, 17587, 17654, 13883, 12786, 19779, 30961, 7240, 10711, 27574, 3892, 3375, 17319, 7972, 11414, 28404, 7037, 31232, 26134, 13975, 7910, 14792, 3970, 29375, 18403, 18377, 15631, 9536, 16344, 26710, 15657, 15499, 15010, 8717, 3093, 27776, 22585, 21090, 12061, 19858, 28165, 21580, 23034, 4276, 10146, 959, 8187, 16082, 15335, 52, 29420, 26015, 30615, 20082, 1007, 24331, 10740, 3995, 27084, 30700, 31765, 25724, 6218, 14881, 18360, 19865, 17240, 30856, 28342, 778, 3431, 18563, 28532, 18202, 9825, 8663, 26386, 28836, 13463, 31412, 28509, 20761, 23237, 6083, 10761, 28817, 4240, 6503, 21736, 5943, 21819, 15037, 7230, 8417, 1908, 13707, 15605, 29001, 23051, 21204, 15426, 8609, 29975, 28313, 15921, 529, 28647, 17248, 25706, 31346, 26054, 21818, 23326, 30632, 27608, 16616, 12261, 3834, 21811, 3499, 30068, 1749, 7767, 798, 31750, 3419, 19110, 23405, 6804, 19293, 11097, 15421, 22126, 13033, 8275, 29730, 16645, 20374, 16552, 7097, 19615, 19956, 18172, 19480, 15820, 28928, 3921, 3393, 12169, 28974, 13750, 25701, 4196, 27099, 28935, 3300, 23310, 26265, 6197, 4502, 27026, 17680, 15237, 4999, 2870, 24077, 6684, 21018, 31082, 20462, 4341, 25312, 25509, 17432, 31484, 11738, 18654, 22921, 12464, 25254, 12474, 9697, 15302, 12841, 12408, 9719, 7306, 6725, 8085, 550, 27644, 10350, 25219, 15372, 9013, 8005, 28748, 3094, 2151, 3972, 8548, 24153, 1459, 8635, 21532, 18690, 13535, 16865, 16256, 27893, 10959, 27045, 10593, 19980, 14196, 23830, 5958, 27642, 3157, 24734, 15724, 5872, 22658, 26139, 15171, 18092, 30082, 5007, 20833, 15680, 27174, 18080, 27675, 7322, 27929, 27576, 18731, 30790, 11896, 24486, 6302, 5879, 24651, 19953, 18173, 343, 142, 27055, 3651, 18662, 10925, 15662, 17762, 23242, 19376, 26878, 9425, 6575, 22897, 18585, 858, 6965, 20555, 15813, 21283, 12777, 10200, 23754, 8746, 7163, 22936, 24339, 14097, 18137, 10580, 6673, 14680, 30237, 13020, 11524, 25644, 20824, 20466, 21577, 15867, 10094, 4046, 6838, 30542, 12529, 2979, 30346, 17605, 7503, 22211, 1340, 15564, 9782, 26300, 615, 646, 13927, 27248, 26542, 5231, 19418, 6191, 32071, 22717, 830, 918, 24052, 26533, 31873, 2854, 22767, 15399, 2777, 148, 18318, 14753, 2780, 12467, 21950, 30715, 22310, 13762, 23450, 14559, 13310, 1271, 20239, 12146, 4174, 25835, 12762, 750, 29217, 8378, 7682, 25695, 12226, 194, 19845, 31924, 21854, 1166, 6299, 357, 10116, 18933, 20914, 28757, 5283, 13722, 5279, 4004, 17449, 10503, 7038, 19287, 13471, 19247, 5153, 19649, 3531, 23581, 5511, 10003, 6616, 8695, 20408, 30628, 9974, 13997, 15740, 12863, 21999, 1221, 5662, 396, 1804, 2765, 24728, 26705, 3206, 15401, 29225, 19410, 26446, 13731, 8329, 27799, 12775, 20403, 5991, 10439, 8132, 21202, 9295, 22313, 10191, 27472, 24824, 16981, 748, 12748, 11875, 14973, 28439, 23333, 20106, 30335, 17276, 29850, 19612, 17429, 4712, 19748, 28246, 26560, 16685, 8875, 30477, 25563, 16639, 6777, 18441, 29594, 25144, 27433, 9604, 15109, 5995, 21348, 25453, 22012, 11481, 7730, 22877, 6409, 22700, 15733, 27076, 32042, 23803, 3714, 19580, 15477, 16225, 11082, 12739, 10485, 199, 16372, 29335, 28301, 11248, 14817, 9571, 23062, 13130, 10517, 8603, 31449, 3772, 190, 769, 30720, 17719, 30592, 31228, 32215, 14750, 3560, 5015, 31127, 11735, 23647, 3032, 7869, 27904, 2135, 18070, 11746, 25117, 26763, 20603, 4723, 1267, 10809, 31448, 12497, 27398, 30, 9084, 6139, 4264, 16318, 8567, 10760, 2984, 13760, 7216, 15699, 20906, 29866, 6776, 28058, 20715, 923, 8166, 15944, 6226, 4401, 7351, 12120, 26402, 40, 16666, 6842, 27710, 6206, 7016, 28724, 29596, 23348, 16763, 5180, 24, 118, 14452, 19877, 2148, 21153, 25817, 13149, 25456, 31669, 8457, 1751, 3041, 3091, 31012, 20795, 26106, 20317, 18935, 25405, 20604, 24784, 27983, 9806, 24912, 11518, 1446, 5391, 5273, 12158, 31336, 4939, 2815, 1565, 17090, 13242, 210, 23924, 26942, 16681, 19663, 27792, 21097, 17250, 20704, 20406, 19597, 1202, 12145, 2309, 2037, 594, 18437, 4302, 9218, 27241, 30124, 27848, 20404, 4692, 24991, 23838, 26263, 25838, 7248, 22246, 12734, 1261, 20639, 24355, 9653, 22679, 4878, 22252, 1444, 26756, 31910, 14305, 31796, 24204, 29591, 22506, 1761, 13925, 29099, 10241, 7894, 2767, 19757, 3180, 6015, 25653, 13044, 16730, 19512, 14652, 31584, 2980, 17865, 14309, 19622, 18490, 7557, 31005, 2074, 3708, 3218, 30328, 16453, 19613, 27720, 13945, 7820, 31848, 25645, 18815, 23345, 2704, 17471, 146, 2523, 28075, 18424, 17750, 17234, 24629, 16961, 25942, 16551, 7718, 21630, 26440, 15674, 6612, 24149, 18411, 30624, 9702, 23859, 16385, 21401, 25789, 13522, 16207, 19061, 28495, 13108, 30330, 31068, 14, 23043, 10122, 19887, 2269, 21461, 12248, 5145, 14050, 11562, 5292, 26535, 25989, 6452, 9847, 28065, 17843, 11865, 22104, 17370, 11151, 8094, 21010, 7745, 27916, 13143, 5834, 3566, 25890, 11477, 9923, 7076, 17992, 14614, 22480, 1750, 27667, 14333, 28412, 30310, 21536, 15106, 11897, 12493, 27053, 1240, 21350, 16949, 29441, 23757, 12462, 11739, 18409, 19155, 13811, 31318, 2103, 5126, 9794, 26151, 11314, 7811, 8721, 15968, 2597, 30371, 1779, 2526, 7661, 23484, 29402, 17033, 31895, 6863, 18436, 16915, 26897, 29713, 713, 1596, 12855, 3472, 185, 29397, 1309, 16994, 13995, 1995, 19310, 1661, 1924, 13376, 5165, 611, 6262, 31920, 1559, 11984, 3529, 13600, 15057, 2709, 5142, 12791, 12278, 1086, 6319, 11123, 15452, 31712, 12447, 3297, 6223, 29138, 2395, 30638, 14682, 9770, 29325, 31289, 29653, 1892, 4863, 26860, 32199, 16847, 16140, 7382, 30301, 1807, 50, 2610, 20889, 18902, 1463, 20595, 25691, 2019, 14262, 14686, 21043, 9954, 9251, 14302, 21782, 2390, 5326, 21894, 9959, 17623, 24800, 4176, 23126, 22125, 7497, 28011, 7632, 23462, 23774, 30654, 18429, 4926, 20574, 31559, 15329, 28222, 15258, 8492, 27682, 9105, 29745, 27290, 8095, 701, 5888, 23200, 19, 2050, 20270, 28911, 247, 29323, 15938, 24742, 8159, 365, 10595, 26020, 10345, 25012, 19018, 23283, 23763, 15332, 3000, 3655, 4209, 32256, 17157, 25486, 3424, 7132, 8110, 26290, 9637, 19550, 27686, 9739, 16132, 29884, 4142, 22178, 20249, 7071, 3008, 19204, 27344, 20203, 30291, 26492, 6482, 19629, 2466, 9771, 14515, 23175, 27781, 22961, 15991, 11825, 21189, 4888, 18919, 1448, 30999, 9222, 6331, 15519, 3953, 29443, 13049, 24082, 4877, 26987, 20307, 19294, 16436, 26364, 17629, 8244, 21831, 6058, 31966, 9217, 25601, 30871, 30257, 7707, 13054, 8212, 9160, 25986, 2757, 252, 24346, 17447, 31957, 20240, 3040, 24731, 11117, 19714, 5118, 5014, 5981, 31176, 7615, 27601, 19695, 31430, 16154, 5000, 20990, 26166, 15243, 11783, 2643, 28321, 8885, 28862, 31453, 30169, 26818, 22208, 2073, 4615, 7875, 22714, 14628, 20411, 12468, 31680, 23159, 3362, 21885, 7741, 10524, 8338, 24410, 1713, 5930, 17789, 1927, 11387, 11499, 18918, 22251, 29472, 14588, 27200, 7044, 24378, 8733, 4770, 3912, 10462, 3347, 26611, 20378, 11297, 19132, 26733, 22716, 29780, 2931, 5904, 26808, 20103, 30032, 30594, 23122, 7425, 11539, 9757, 31248, 26279, 8210, 14536, 13095, 32012, 16761, 11716, 985, 30004, 29332, 19879, 30235, 17586, 28961, 14691, 19994, 6877, 29016, 3601, 17377, 12705, 14052, 21272, 5649, 29334, 31748, 29404, 9422, 21865, 13953, 11582, 24112, 19130, 27797, 11372, 16954, 297, 14413, 16020, 8354, 15515, 6081, 23179, 13873, 27393, 28056, 4254, 678, 13127, 16373, 30719, 8176, 11586, 19473, 23374, 23017, 18800, 4333, 22218, 1354, 6908, 23511, 25314, 11765, 25893, 22174, 17894, 3195, 7668, 24758, 3497, 14580, 1464, 5295, 19906, 17044, 6379, 872, 9483, 29654, 17170, 26280, 2287, 26040, 9864, 3580, 31496, 27158, 8517, 5252, 10141, 15447, 11447, 6129, 9288, 16007, 19974, 16678, 7732, 23006, 8910, 26981, 11242, 27680, 11740, 15339, 24637, 4701, 19979, 2154, 6760, 16890, 5177, 2751, 18155, 18829, 5146, 30143, 20228, 11517, 22999, 23614, 24283, 30040, 2948, 364, 26427, 26035, 10451, 128, 27034, 8554, 5312, 31658, 7109, 22321, 12974, 22820, 20107, 28375, 21311, 22349, 14312, 7300, 22655, 13003, 9206, 25697, 6959, 26074, 8209, 17565, 25367, 24587, 4648, 28645, 7198, 27157, 4168, 25325, 30793, 28596, 30881, 5436, 25424, 19978, 25418, 19229, 1413, 18586, 28670, 24607, 10325, 21849, 17353, 21762, 10768, 27336, 17580, 28976, 10185, 13344, 19687, 24335, 26392, 23111, 31967, 22, 3307, 15984, 24943, 27022, 2181, 26285, 19691, 10103, 31380, 6417, 24614, 3367, 8907, 26990, 26975, 29867, 20015, 31314, 10275, 29366, 2182, 2505, 14250, 17300, 28304, 8380, 15538, 9982, 4441, 13684, 2747, 26453, 4239, 2987, 29078, 24760, 13080, 16236, 528, 9097, 13666, 17209, 6020, 22934, 6451, 29788, 12180, 20108, 6098, 17579, 4433, 13512, 17123, 8951, 602, 6562, 29083, 3552, 8313, 18527, 13343, 7711, 17064, 4158, 30976, 16795, 7527, 30593, 117, 29456, 9131, 19721, 28677, 350, 3853, 22324, 30308, 2748, 19241, 29025, 14075, 27480, 24061, 31931, 8622, 13039, 31479, 10628, 7962, 20431, 2336, 13468, 29833, 6254, 4833, 16054, 24092, 23297, 1178, 16878, 8039, 2079, 15493, 28903, 17813, 31233, 21386, 16267, 2916, 10305, 6954, 28942, 20931, 28319, 3397, 6696, 25343, 22933, 32183, 13433, 20297, 22707, 4036, 31189, 22860, 24964, 21954, 16266, 7495, 27015, 5975, 1013, 11161, 4835, 9373, 9278, 4687, 25286, 138, 17165, 9990, 11460, 24464, 14918, 10690, 1384, 6305, 30455, 29967, 14288, 20569, 11844, 20325, 26545, 22460, 29313, 21109, 24382, 30402, 18027, 25662, 8160, 4644, 352, 13700, 12813, 24044, 11941, 7564, 391, 13328, 24638, 27259, 16135, 9249, 5832, 19645, 21769, 26832, 10713, 27232, 3220, 29483, 16001, 20762, 8677, 23491, 22811, 28390, 1959, 19045, 1791, 25799, 13917, 17690, 6770, 1638, 7526, 4679, 6405, 27509, 14834, 29983, 12466, 727, 4855, 31778, 25288, 3198, 12286, 14945, 15803, 427, 28166, 30573, 7856, 21691, 14743, 26494, 2618, 16780, 27180, 18246, 5769, 13234, 2245, 13435, 22240, 2720, 4551, 15634, 18461, 27181, 19013, 17908, 15141, 21938, 25875, 30406, 17194, 1821, 10882, 12519, 8596, 23825, 24099, 23898, 4476, 15700, 31673, 5680, 1050, 6394, 27672, 29468, 4330, 15444, 30246, 7422, 24316, 9939, 22207, 26169, 14314, 18892, 6960, 30309, 21917, 3503, 10256, 18108, 30274, 19514, 5799, 20702, 4804, 8174, 6702, 28496, 30576, 17029, 18885, 29705, 13012, 11476, 22487, 11263, 24795, 7334, 21545, 24809, 31531, 14386, 15923, 28180, 16354, 29376, 8242, 25796, 5555, 1083, 10725, 8799, 248, 30067, 29545, 21962, 12312, 17945, 16987, 17242, 25004, 17672, 30820, 18726, 30202, 21468, 25031, 8773, 21563, 25661, 9835, 24858, 8250, 29899, 13291, 16049, 22074, 13813, 1314, 13161, 4492, 3150, 618, 17168, 11269, 1351, 19527, 4485, 8236, 7452, 21346, 14047, 27491, 26076, 31031, 21738, 17793, 23451, 10235, 18750, 11292, 27626, 14538, 17189, 15800, 7313, 26529, 27593, 31292, 31744, 28380, 31813, 10552, 22041, 4894, 31208, 26830, 26802, 23202, 932, 29119, 25017, 27841, 14172, 3701, 21369, 13674, 9958, 4415, 10137, 7544, 1952, 15594, 1866, 7486, 27834, 13928, 7131, 17917, 19311, 21944, 19626, 30434, 28437, 24903, 10053, 15412, 13658, 2032, 9018, 12653, 30933, 10049, 14092, 28786, 26606, 14846, 27912, 797, 5884, 4389, 26371, 17514, 20321, 9543, 19397, 22947, 9542, 1972, 15448, 17530, 12902, 29289, 11985, 32065, 9996, 26210, 28706, 26586, 21485, 7207, 4851, 2450, 26884, 29672, 18410, 26754, 21081, 106, 1987, 13282, 4620, 6145, 23373, 17944, 4010, 31976, 26228, 25257, 30326, 18307, 10223, 16703, 6367, 10636, 30440, 7963, 9488, 18773, 18201, 8710, 12581, 2446, 25462, 23976, 27448, 25227, 11249, 9468, 1090, 3748, 25120, 21082, 5464, 12941, 1311, 4821, 17485, 5488, 12443, 24697, 32021, 11658, 25452, 31092, 9520, 23759, 561, 31061, 20265, 19102, 25925, 14353, 2494, 22325, 30109, 18334, 15112, 3906, 3299, 31804, 14976, 180, 30862, 20722, 31406, 30053, 24019, 3342, 10516, 14400, 17369, 3885, 29156, 742, 5191, 3211, 31849, 13914, 30336, 1321, 8731, 1702, 9885, 20255, 20631, 16025, 20130, 29682, 6995, 29746, 10013, 29014, 6568, 8061, 28150, 10952, 21543, 430, 25204, 11872, 13202, 31358, 12461, 13213, 25279, 3224, 20101, 16237, 5589, 3186, 27124, 10088, 30468, 18907, 3699, 13372, 10433, 7113, 10264, 29748, 7627, 12664, 19261, 11722, 1805, 5109, 19267, 30315, 13402, 7367, 18299, 17930, 4831, 22599, 5028, 9714, 2921, 24882, 13969, 13057, 22112, 5073, 11619, 15545, 5272, 32254, 13240, 18044, 24627, 11510, 2641, 23888, 20613, 9054, 5508, 11924, 3126, 22215, 10617, 9749, 7595, 19609, 30251, 27277, 4808, 13103, 15717, 21759, 8564, 13356, 31356, 6119, 21882, 7396, 7474, 8126, 3851, 5781, 23776, 22411, 3828, 31144, 24177, 2408, 3166, 3073, 22959, 2706, 7699, 16122, 17034, 10132, 23014, 24792, 25171, 1168, 27419, 24055, 30232, 26489, 30572, 23627, 26999, 2415, 589, 22514, 9133, 25959, 28627, 10957, 28865, 8493, 20217, 11923, 5032, 16536, 6412, 361, 17884, 12909, 14593, 20312, 1879, 6088, 22525, 21498, 31674, 22533, 15424, 7350, 12434, 17445, 17403, 8170, 21644, 31, 18009, 12241, 18936, 23956, 19430, 10860, 15574, 16657, 31528, 15296, 12621, 10482, 20692, 24978, 22139, 29244, 10571, 31950, 14678, 20820, 22607, 6806, 28875, 2220, 30292, 6596, 20515, 26180, 27573, 6131, 26943, 22344, 23271, 10856, 5406, 28995, 14206, 21900, 7782, 18677, 23078, 14695, 18753, 16105, 14454, 8700, 1096, 11404, 9734, 27252, 7750, 15513, 9050, 15877, 25974, 3929, 18646, 18597, 29181, 25043, 12972, 30819, 14328, 1667, 10064, 10057, 29868, 4934, 30807, 7932, 25987, 29065, 23726, 27251, 11824, 8514, 4581, 28626, 16611, 19356, 23589, 685, 17293, 23113, 28858, 16659, 27994, 14327, 5382, 3833, 16781, 6705, 24141, 24334, 9401, 21361, 28760, 30777, 25643, 22786, 3830, 21168, 29864, 12479, 4289, 920, 23678, 29566, 25745, 27347, 298, 19181, 29671, 5122, 5735, 3979, 14162, 6011, 20195, 2461, 25100, 18618, 13503, 24387, 19854, 21328, 17159, 9308, 28577, 3824, 24640, 24804, 21773, 2029, 18963, 28127, 31971, 3141, 6689, 9212, 7187, 29998, 7120, 909, 24379, 8053, 23583, 24084, 1670, 17450, 22572, 24572, 27765, 16922, 4451, 28462, 7778, 30297, 3083, 15961, 10010, 29128, 11646, 30483, 4958, 23885, 28363, 9435, 4170, 22376, 9353, 6386, 5204, 3182, 31617, 22114, 9331, 30850, 23305, 9557, 30084, 20649, 22461, 22932, 3724, 13270, 288, 4018, 18637, 27309, 699, 7029, 23762, 3156, 19162, 20640, 31763, 29714, 16199, 18041, 16439, 4464, 9685, 2750, 14557, 30534, 6578, 7508, 27390, 10377, 7543, 722, 17740, 1945, 3735, 7622, 28861, 18650, 26343, 5517, 9480, 30012, 25590, 29753, 30229, 23986, 26089, 26883, 16313, 25855, 12926, 5615, 9121, 19098, 16622, 17251, 24170, 151, 4587, 23742, 9117, 13078, 6246, 5784, 12472, 22806, 24008, 16252, 14042, 1815, 253, 29147, 20204, 7249, 25006, 26487, 3337, 2184, 20087, 18175, 25594, 18926, 3444, 21859, 832, 11427, 27895, 681, 21459, 14948, 12917, 663, 14069, 23430, 17538, 5780, 18996, 19732, 1800, 21165, 17018, 26996, 3994, 5894, 10513, 7223, 29673, 7621, 19342, 9950, 25587, 29790, 21199, 15946, 7705, 5474, 9521, 25973, 12427, 24472, 12441, 9859, 14664, 15909, 15122, 23605, 7127, 22248, 16286, 9290, 9929, 31386, 2758, 9495, 24540, 31025, 14926, 14359, 24660, 737, 25104, 20461, 15206, 31579, 32239, 16523, 2375, 13038, 1944, 5765, 21457, 19063, 7516, 26709, 17267, 9227, 913, 13551, 18115, 29979, 27193, 24451, 27059, 29652, 21923, 20671, 13867, 18471, 310, 32181, 26437, 16939, 6056, 17266, 22419, 29219, 16635, 27255, 31328, 6280, 9019, 12561, 24698, 428, 26924, 31421, 7801, 30387, 14787, 31589, 4686, 28710, 15090, 24058, 1426, 10653, 6907, 28153, 20643, 15027, 21467, 11458, 6583, 22415, 13239, 26661, 22193, 14029, 17299, 4997, 24212, 29797, 15633, 5490, 2723, 19160, 5716, 23340, 7966, 7245, 5776, 26058, 30277, 9020, 30920, 17904, 6012, 8182, 881, 1167, 18688, 27207, 17259, 30028, 30395, 8777, 23145, 32052, 18701, 17619, 28275, 1264, 16073, 23076, 5881, 9779, 11706, 10144, 9781, 18779, 16264, 28483, 13275, 24095, 18737, 2250, 9726, 1617, 10303, 5910, 5690, 2296, 5577, 32014, 17069, 17487, 20158, 30250, 23241, 6318, 24041, 13821, 23981, 25122, 17292, 9992, 10511, 70, 18971, 17533, 14879, 10855, 26992, 21198, 10888, 14362, 12752, 22953, 16193, 31224, 29183, 30935, 5048, 31047, 7210, 22347, 26775, 3899, 3275, 17411, 19035, 17156, 12839, 8438, 26892, 6092, 27844, 16188, 17546, 10723, 20153, 8158, 15197, 8302, 16755, 19448, 27940, 738, 20904, 9355, 14046, 11975, 16770, 237, 19921, 17389, 6360, 7982, 19839, 6667, 30173, 16149, 11669, 32143, 17878, 26357, 4017, 15104, 4574, 25514, 21466, 1017, 18129, 17382, 30735, 20575, 17140, 22323, 31048, 601, 20180, 23633, 12632, 3496, 1272, 9554, 28735, 18474, 3395, 10629, 12115, 11012, 27883, 11250, 22849, 14865, 22261, 28081, 31002, 14176, 18493, 929, 5696, 27031, 28564, 18320, 21288, 16229, 3043, 30646, 9350, 31629, 10002, 6296, 15407, 15649, 3082, 18874, 19809, 23190, 20837, 7573, 23630, 26707, 14236, 7832, 22909, 3335, 27041, 1619, 1401, 22459, 31401, 31566, 14736, 3309, 3632, 6112, 21549, 17428, 11682, 6570, 6831, 17110, 21780, 18642, 5987, 21481, 11697, 21528, 17400, 30763, 8605, 20991, 6906, 13010, 26984, 1442, 695, 377, 28880, 31459, 7630, 4801, 18986, 344, 9475, 25758, 23854, 30831, 19008, 12449, 1211, 16901, 25670, 25152, 16841, 15727, 30110, 31856, 2308, 13461, 19208, 22184, 16838, 6969, 12834, 7404, 17863, 17824, 9127, 31623, 18054, 31694, 15586, 11845, 7380, 14875, 8485, 18349, 19966, 15751, 6046, 2968, 24851, 3481, 11622, 28358, 24677, 614, 14505, 15154, 31979, 29478, 28410, 5117, 7421, 2698, 19675, 6748, 30986, 9352, 20911, 8062, 5717, 6301, 13279, 3484, 21540, 20006, 31628, 19576, 22022, 28149, 26655, 12831, 20254, 27977, 18842, 7618, 4826, 14181, 17795, 24591, 17065, 20608, 21734, 4430, 9066, 23760, 24215, 24887, 4288, 25376, 7292, 16120, 7032, 1171, 1996, 28557, 15868, 15152, 19955, 37, 19056, 26360, 25461, 11432, 11395, 9587, 25180, 16178, 24460, 6304, 29287, 14561, 768, 2212, 14499, 9240, 23475, 20202, 30648, 26571, 5294, 25605, 27246, 20806, 12332, 19268, 16548, 23463, 29427, 10603, 19886, 19218, 13411, 30494, 29229, 1163, 10567, 31575, 17942, 3586, 6533, 9431, 7841, 19773, 17175, 3072, 18722, 9828, 31393, 14009, 16324, 9389, 941, 9665, 31447, 10632, 17352, 11116, 13863, 23811, 4930, 30527, 23716, 24152, 7110, 6740, 4151, 13395, 24120, 27004, 30463, 7341, 29980, 18176, 18598, 21429, 16029, 6259, 24632, 7301, 15298, 25336, 13807, 31199, 11333, 9819, 17379, 27542, 5360, 3761, 3183, 13197, 22756, 31833, 6864, 19265, 11373, 10355, 11171, 23066, 866, 20250, 31781, 24441, 2293, 19777, 22854, 2894, 28512, 25272, 2823, 2444, 4465, 2413, 28173, 29015, 23007, 12680, 17361, 25525, 31495, 23082, 19452, 11170, 1031, 5552, 9635, 13439, 31784, 8874, 4117, 10913, 15238, 23441, 457, 10828, 12253, 11350, 16338, 2267, 12531, 26562, 28337, 17499, 24779, 21874, 25185, 19870, 5854, 14577, 12401, 15190, 9116, 1349, 27733, 14783, 15834, 7887, 2826, 12065, 7169, 14003, 29112, 7174, 26969, 28112, 28573, 22766, 21713, 29584, 12657, 15914, 267, 2509, 26762, 4119, 29667, 15380, 18128, 23046, 4906, 30992, 24220, 25975, 19572, 3855, 13560, 12768, 13860, 1292, 31505, 6983, 11174, 10336, 30374, 28292, 4599, 10962, 15216, 928, 23980, 5493, 19107, 16418, 23385, 7882, 25982, 1106, 5002, 15370, 10691, 23146, 10181, 26012, 6320, 8327, 14525, 17286, 27104, 8857, 19436, 23442, 28230, 21196, 20581, 31297, 22918, 13491, 17435, 15825, 13602, 7643, 24926, 2566, 10790, 5595, 10125, 7748, 22308, 19444, 444, 468, 19070, 5495, 4849, 26753, 26363, 11336, 1855, 10210, 11909, 19363, 31259, 11799, 4769, 18943, 29926, 15123, 24258, 7664, 5563, 20209, 31253, 11726, 14859, 26296, 30418, 13757, 2303, 13383, 19788, 1087, 12223, 25879, 19925, 13168, 16411, 28711, 23787, 29135, 20176, 21904, 19394, 16581, 163, 25495, 22545, 29863, 7083, 10066, 26284, 1818, 21685, 24293, 14026, 5813, 1889, 18209, 4011, 8064, 28797, 30816, 31212, 5811, 3867, 30604, 17684, 12897, 21208, 4102, 19292, 15052, 14142, 5603, 26461, 11537, 13632, 4469, 19710, 20454, 27917, 25686, 12796, 26734, 13790, 12543, 13730, 4647, 30128, 2562, 2481, 13993, 4242, 14653, 26486, 25347, 5210, 29947, 8989, 8919, 16103, 25978, 17949, 30248, 24879, 26760, 23820, 9192, 8977, 4278, 24930, 9439, 22887, 19587, 23395, 16640, 19787, 8458, 1137, 27417, 5380, 31506, 11176, 23818, 24620, 31943, 1668, 7441, 2171, 26954, 12303, 29522, 19290, 27164, 30394, 20848, 23460, 19062, 1641, 1902, 29069, 27817, 5974, 20095, 31544, 8760, 18229, 28020, 19148, 5237, 9767, 24578, 9497, 883, 359, 2936, 8055, 6519, 15415, 28448, 6966, 9196, 21660, 3417, 12738, 6726, 22510, 10990, 17952, 30692, 6228, 30946, 10328, 22879, 6265, 28082, 25360, 31715, 25910, 3540, 19536, 6384, 8811, 27239, 18730, 6410, 24568, 18983, 2290, 21778, 631, 12579, 460, 13636, 23534, 17295, 31801, 3416, 5909, 26569, 19548, 15280, 11127, 19761, 11139, 29874, 25390, 6008, 8778, 20669, 16786, 2787, 8192, 11299, 12556, 2756, 3690, 25366, 4876, 20737, 25408, 6486, 24593, 19273, 15366, 11541, 25480, 149, 15753, 1485, 289, 26173, 2080, 18802, 13180, 20635, 22624, 28804, 22200, 31338, 566, 6830, 31585, 25848, 10801, 24096, 11230, 31095, 14527, 26553, 19214, 31532, 501, 31882, 29943, 6240, 14712, 11346, 18486, 20134, 20559, 30317, 24506, 1605, 12425, 23622, 5164, 17668, 21876, 588, 9300, 28803, 12302, 27299, 4842, 17994, 31357, 15270, 22542, 8526, 8035, 16960, 22058, 10569, 8269, 28982, 2683, 8201, 26055, 17270, 3287, 14439, 23847, 27702, 1657, 24716, 9924, 21977, 22623, 20624, 9418, 29241, 27110, 14734, 12246, 10490, 13884, 2402, 8802, 25947, 4138, 12414, 14519, 16746, 23093, 15769, 2398, 8001, 14668, 28416, 13827, 22356, 9948, 22117, 8550, 21356, 12948, 22132, 5381, 24308, 6961, 18060, 7218, 25625, 9944, 1318, 11498, 23540, 21303, 20785, 10889, 26132, 19355, 648, 5664, 22118, 624, 27341, 18804, 19813, 12023, 32023, 11774, 30305, 25960, 22973, 12103, 15772, 25246, 662, 28472, 13753, 5941, 27395, 31880, 5206, 13536, 2663, 9195, 31347, 10243, 20666, 24059, 30561, 10370, 20524, 5379, 4207, 13838, 5129, 17899, 1992, 4813, 20086, 16873, 27700, 20873, 8151, 23538, 879, 4204, 19655, 707, 22982, 491, 13269, 10351, 12370, 1711, 31274, 7915, 23042, 21394, 2382, 27742, 24270, 14531, 14267, 19221, 3501, 7052, 16412, 96, 11514, 8309, 26786, 11588, 15312, 18647, 27685, 8585, 30482, 5375, 24719, 13770, 27622, 10849, 11561, 3117, 22036, 15139, 13109, 1843, 17424, 20369, 9691, 3516, 11560, 11379, 13448, 32013, 29008, 13392, 4816, 4413, 30484, 25687, 26765, 8996, 1862, 22329, 15517, 3067, 1510, 27, 11624, 25968, 24458, 19993, 23987, 21435, 12124, 19935, 15175, 30115, 8664, 15709, 17716, 15667, 5667, 13591, 22105, 19715, 25920, 14586, 18587, 28377, 8077, 14115, 334, 22466, 29460, 27128, 2385, 12052, 22923, 21943, 12186, 14154, 25700, 7589, 3598, 18718, 22336, 27541, 28868, 15533, 14644, 4165, 4140, 27971, 20912, 5332, 4582, 24598, 29606, 30750, 28575, 24938, 2703, 6251, 8083, 11733, 23797, 2734, 18552, 16914, 965, 763, 14045, 12942, 31955, 5358, 16826, 7749, 25737, 3223, 15295, 10557, 27507, 7462, 30853, 25565, 5051, 22285, 7409, 21987, 30814, 2118, 26604, 8319, 23129, 23219, 17344, 2273, 23624, 24407, 762, 11576, 3443, 3910, 9659, 5330, 24271, 29755, 14136, 4275, 30410, 9676, 15262, 15892, 5476, 21628, 12382, 13738, 29760, 12674, 24069, 19133, 25631, 24822, 10914, 28896, 15646, 29122, 8195, 5133, 1573, 9822, 28831, 3504, 9262, 32184, 10104, 3860, 16998, 24706, 21681, 13091, 8097, 10119, 12155, 4973, 20525, 16406, 8181, 5713, 32041, 10732, 22014, 16129, 19517, 7143, 23319, 10018, 10069, 1965, 18015, 3746, 30408, 22454, 4610, 3449, 20489, 7549, 17198, 32208, 10835, 26407, 10177, 10432, 14285, 258, 4050, 12335, 28747, 20207, 31899, 17691, 11106, 9809, 12829, 1393, 15458, 4054, 31745, 14958, 30579, 21729, 16311, 22703, 29759, 10233, 14183, 24848, 8821, 29836, 6504, 157, 26243, 21661, 31888, 28199, 1857, 22928, 25430, 19307, 895, 9934, 13158, 21538, 27332, 4794, 30789, 24453, 12121, 25280, 5183, 23366, 25161, 27757, 3838, 16700, 21637, 26472, 20434, 23084, 21584, 7376, 4328, 5185, 19780, 3554, 8042, 14448, 14729, 676, 32046, 25648, 19096, 24650, 1193, 3770, 15880, 3455, 15941, 27898, 23777, 16821, 20971, 30382, 26739, 30228, 10906, 24242, 32171, 18387, 27878, 16819, 27176, 7597, 25772, 21052, 29050, 24740, 23120, 32085, 15675, 25218, 10645, 16417, 5486, 27423, 790, 25490, 32182, 10570, 24225, 28236, 23892, 26376, 8027, 22762, 12967, 25813, 13121, 4449, 20169, 27729, 15780, 19336, 6327, 30754, 15718, 27038, 3744, 9673, 14964, 8108, 24664, 2699, 17488, 11926, 586, 4322, 5613, 5264, 1936, 18337, 10285, 25449, 13251, 16159, 22950, 18475, 23413, 25166, 20822, 9253, 21453, 966, 30378, 8381, 17326, 9881, 10919, 31709, 1652, 24429, 19141, 28785, 14321, 15933, 5885, 17525, 2965, 1358, 3047, 27442, 26757, 21044, 17796, 22130, 20144, 22150, 10545, 26989, 24137, 5587, 25650, 21503, 27127, 7570, 13387, 25533, 22362, 14210, 23500, 16542, 17951, 11501, 28270, 25566, 13217, 597, 28682, 32192, 2903, 17378, 2928, 23004, 4747, 22052, 11718, 4499, 2517, 14177, 31084, 9695, 17588, 15855, 3357, 25088, 26896, 20360, 26662, 28460, 28039, 7010, 11185, 13345, 4774, 20335, 21752, 13990, 7975, 11218, 6560, 31215, 22315, 4584, 27525, 1390, 26862, 10705, 25189, 20802, 24768, 24935, 19933, 8148, 11986, 28353, 4218, 26509, 31954, 24494, 29570, 23590, 1997, 21003, 15024, 14737, 28543, 3464, 3366, 24693, 5621, 398, 29929, 20805, 21505, 8891, 17839, 31906, 25196, 12505, 19406, 10007, 8498, 8399, 9837, 24227, 657, 22098, 2864, 24793, 10497, 20626, 3064, 7817, 30025, 32130, 29044, 917, 5441, 536, 6823, 9999, 12508, 21598, 7273, 11689, 13355, 22954, 29655, 690, 1983, 31055, 14048, 30967, 628, 9152, 29796, 29696, 10084, 15182, 25832, 21881, 4267, 11584, 24884, 28676, 17608, 5905, 14962, 20251, 2790, 28241, 20609, 23547, 23058, 6611, 30182, 16512, 27042, 29728, 5105, 18959, 32158, 25553, 26633, 10777, 9873, 3795, 3298, 11843, 18381, 11569, 20975, 6925, 18435, 22747, 5638, 32150, 3949, 9951, 13782, 28352, 29712, 12220, 45, 12191, 6230, 28106, 8128, 10033, 24016, 22647, 15859, 8652, 10886, 31787, 29438, 1301, 27713, 4152, 28826, 1074, 29352, 20544, 18755, 17071, 11928, 21525, 21297, 12750, 20054, 22617, 27936, 7196, 8193, 4634, 4429, 22875, 19656, 21989, 98, 14789, 6461, 14776, 13635, 30922, 13803, 16003, 5162, 562, 4867, 26609, 25714, 1562, 6890, 24148, 1752, 5341, 30205, 32072, 9890, 28877, 15848, 4076, 21974, 11124, 19567, 599, 6138, 21755, 13146, 20825, 9226, 28133, 11445, 18594, 326, 4722, 15543, 2849, 21421, 4719, 7639, 31125, 984, 2774, 18077, 8051, 3296, 20792, 29170, 25069, 8946, 20030, 1504, 1696, 28183, 19726, 7183, 1132, 25688, 32026, 16606, 31009, 7498, 13923, 6337, 10858, 5796, 18803, 9426, 7017, 3101, 25902, 20668, 5654, 28434, 25548, 15007, 20442, 11079, 1198, 1000, 6248, 16283, 3819, 2072, 5308, 21100, 31142, 31729, 22653, 18783, 21758, 25593, 15436, 7935, 25399, 7530, 27274, 11644, 29639, 6252, 27671, 29567, 29450, 5895, 8826, 4366, 17766, 26493, 25895, 7033, 16628, 27559, 23490, 17304, 3898, 12692, 15593, 6094, 20542, 9937, 12874, 29415, 3753, 31863, 4380, 32209, 16158, 28668, 160, 7787, 13225, 19919, 13986, 16549, 20538, 2109, 19275, 14093, 3579, 28400, 19659, 3757, 17681, 2829, 22530, 30536, 23569, 4498, 2291, 20426, 18660, 2128, 10684, 6756, 17815, 30266, 7694, 7823, 11755, 11482, 29139, 4298, 10863, 18862, 19816, 13578, 4410, 11800, 16235, 3328, 5278, 24319, 7999, 27177, 23702, 18636, 21756, 552, 5507, 18311, 23831, 29210, 3608, 6497, 31652, 30027, 9575, 1477, 19740, 29484, 16437, 11115, 25972, 30127, 24240, 13786, 23585, 31592, 3517, 18453, 3279, 23520, 6075, 17152, 9988, 6921, 13764, 10201, 5157, 2933, 3341, 1070, 5261, 18255, 31130, 29917, 1682, 5396, 19497, 2012, 22551, 15916, 23260, 19124, 20861, 28498, 21309, 12727, 27968, 27085, 17205, 24417, 17166, 5839, 12279, 28811, 27997, 1853, 752, 14809, 31222, 12235, 9539, 15334, 13870, 25195, 15263, 23422, 9750, 15528, 30841, 29341, 436, 28594, 30141, 25611, 20127, 24526, 20928, 3505, 11167, 5100, 23660, 10859, 8772, 27087, 11475, 18941, 807, 3985, 21533, 25516, 12592, 14209, 2233, 10802, 12406, 26706, 4044, 1871, 21883, 11093, 28840, 12345, 17036, 29457, 8583, 9360, 11208, 30198, 12243, 30118, 5652, 7202, 2539, 16450, 12569, 1704, 13052, 3777, 11066, 11389, 25203, 15364, 29605, 14277, 13101, 16647, 28912, 5316, 24269, 5131, 14888, 6778, 24688, 26473, 19828, 3687, 16911, 31097, 1633, 9909, 26903, 20184, 29703, 9993, 23165, 4125, 17511, 12255, 29508, 2812, 2275, 18121, 25667, 3192, 30385, 4890, 30283, 12997, 5531, 9713, 29075, 29153, 12904, 7104, 18830, 21820, 29904, 26644, 27708, 21338, 32113, 13783, 8986, 7776, 6607, 29196, 11444, 18656, 14788, 28461, 16408, 30740, 25222, 4974, 20913, 14592, 23698, 10252, 18426, 28357, 4287, 19431, 23725, 1904, 31021, 4680, 2312, 18839, 12608, 12119, 16138, 23554, 31513, 23769, 10306, 20278, 27372, 26067, 21215, 27483, 31014, 17804, 18438, 28834, 19135, 3775, 17147, 28129, 1755, 31757, 23699, 3380, 10945, 30422, 23177, 15187, 16303, 2902, 18814, 3318, 18305, 9320, 17974, 13272, 19428, 18448, 27204, 19999, 6336, 7681, 13714, 7478, 28714, 9547, 5791, 731, 29102, 12164, 30039, 27627, 3401, 8716, 9949, 11595, 12289, 21585, 11851, 24261, 11035, 17869, 27907, 20422, 2196, 25928, 3802, 13112, 8339, 8476, 23187, 18399, 22675, 14796, 22696, 1473, 4935, 30575, 4929, 22151, 22038, 3893, 9428, 1860, 14021, 31017, 6593, 31502, 10989, 1101, 2534, 11061, 8847, 8292, 21760, 6841, 6511, 6932, 26985, 26895, 13820, 13364, 27122, 5021, 21548, 26598, 27149, 8871, 22316, 10352, 17832, 8117, 17063, 26374, 12534, 29333, 23116, 29593, 17638, 16707, 6860, 8533, 28656, 2149, 29216, 130, 6018, 14913, 22018, 25205, 28331, 31422, 17882, 12512, 31051, 3200, 188, 8078, 25575, 23052, 24366, 4104, 8036, 5597, 4583, 1778, 11764, 6828, 27357, 31295, 27638, 13832, 24554, 18522, 28642, 20485, 5339, 30666, 7606, 8131, 5962, 10048, 15573, 8179, 10327, 728, 13836, 7092, 10910, 1337, 21959, 7080, 27656, 9569, 4596, 22902, 31633, 17364, 15945, 3468, 16147, 23609, 10131, 22757, 30414, 2728, 24344, 4368, 10566, 25234, 17706, 21669, 27240, 24105, 20073, 5263, 28655, 15629, 3142, 6426, 18324, 6660, 5887, 23304, 9356, 23369, 28174, 22690, 11192, 4177, 8087, 20860, 12352, 30710, 25084, 26528, 12317, 5648, 12767, 31603, 3882, 31510, 5590, 16213, 5232, 30370, 31679, 20242, 6669, 13431, 29528, 28540, 13705, 23248, 6679, 4897, 26001, 15614, 18252, 25676, 6997, 2647, 26639, 17323, 31283, 3750, 28743, 11613, 8010, 7483, 17947, 19874, 1746, 14322, 16799, 22986, 17127, 13307, 23474, 7106, 28403, 31099, 11947, 15569, 16725, 27762, 9443, 6620, 25431, 12965, 5860, 20145, 8745, 2658, 20779, 14356, 25116, 12843, 892, 24192, 11162, 2482, 30340, 13763, 24599, 7330, 24739, 9151, 24583, 17188, 12132, 19057, 17554, 22274, 20071, 28314, 20695, 19981, 25849, 12862, 7461, 25298, 323, 8098, 12946, 22189, 6724, 15665, 29130, 31000, 18203, 25534, 14916, 11999, 1542, 25864, 31146, 1774, 3977, 28368, 30452, 19082, 1695, 26480, 18178, 29658, 9507, 24221, 8704, 19837, 21175, 17493, 20528, 28640, 15864, 10871, 15146, 12981, 1942, 6832, 11519, 4481, 21414, 3295, 7938, 15130, 32243, 2614, 5090, 3559, 16301, 25146, 19631, 22269, 23930, 4916, 10112, 7743, 20799, 13793, 5644, 15987, 1060, 10826, 13267, 14102, 22338, 18732, 17143, 31706, 13389, 31631, 10744, 14782, 27046, 28055, 31303, 27718, 31362, 28338, 28111, 875, 13745, 26144, 1637, 20113, 29744, 16594, 31904, 9700, 15611, 8521, 16282, 12179, 7518, 181, 9274, 10619, 21570, 9636, 14368, 26045, 17214, 20985, 1540, 9161, 27160, 23485, 29809, 11534, 20932, 23593, 7231, 15588, 7275, 23010, 15271, 17497, 27340, 31264, 16041, 23592, 20698, 25374, 30311, 14406, 3311, 19798, 14319, 26482, 9032, 25892, 16111, 2584, 38, 25432, 14036, 14896, 3658, 9065, 15632, 3968, 7493, 12964, 15729, 12994, 3400, 29115, 27633, 15854, 25540, 27445, 20959, 20843, 11473, 13524, 8122, 14523, 29060, 15554, 4486, 20857, 19316, 1439, 3482, 9324, 23640, 26267, 17898, 6277, 24222, 8189, 28429, 21112, 28958, 8205, 6526, 16015, 14665, 14524, 16985, 3021, 8681, 2131, 22158, 27691, 30872, 19603, 18029, 15488, 22608, 27897, 20798, 4746
INFO:root:train dataset: 68117, validation dataset: 3872, test dataset: 6454
INFO:root:used only channels: []; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.04944074
INFO:root:[1,   100] training loss: 0.04222722
INFO:root:[1,   150] training loss: 0.03465292
INFO:root:[1,   200] training loss: 0.03164375
INFO:root:[1,   250] training loss: 0.03088602
INFO:root:[1,   300] training loss: 0.02892055
INFO:root:[1,   350] training loss: 0.03276655
INFO:root:[1,   400] training loss: 0.00055115
INFO:root:[1,   450] training loss: 0.00023404
INFO:root:[1,   500] training loss: 0.00753989
INFO:root:[1,   550] training loss: 0.00493412
INFO:root:[1,   600] training loss: 0.03230838
INFO:root:[1,   650] training loss: 0.00002408
INFO:root:[1,   700] training loss: 0.00001071
INFO:root:[1,   750] training loss: 0.00001072
INFO:root:[1,   800] training loss: 0.00000932
INFO:root:[1,   850] training loss: 0.00000709
INFO:root:[1,   900] training loss: 0.11944183
INFO:root:[1,   950] training loss: 0.01600015
INFO:root:[1,  1000] training loss: 0.00007505
INFO:root:[1,  1050] training loss: 0.00002945
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.09548090
INFO:root:[2,   100] training loss: 0.03642637
INFO:root:[2,   150] training loss: 0.03015464
INFO:root:[2,   200] training loss: 0.02683146
INFO:root:[2,   250] training loss: 0.02882007
INFO:root:[2,   300] training loss: 0.02901787
INFO:root:[2,   350] training loss: 0.02803027
INFO:root:[2,   400] training loss: 0.00110122
INFO:root:[2,   450] training loss: 0.00018365
INFO:root:[2,   500] training loss: 0.00771105
INFO:root:[2,   550] training loss: 0.00496291
INFO:root:[2,   600] training loss: 0.02490638
INFO:root:[2,   650] training loss: 0.00000941
INFO:root:[2,   700] training loss: 0.00000860
INFO:root:[2,   750] training loss: 0.00000971
INFO:root:[2,   800] training loss: 0.00000917
INFO:root:[2,   850] training loss: 0.00000911
INFO:root:[2,   900] training loss: 0.07358230
INFO:root:[2,   950] training loss: 0.01797738
INFO:root:[2,  1000] training loss: 0.00008086
INFO:root:[2,  1050] training loss: 0.00006488
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.06056822
INFO:root:[3,   100] training loss: 0.02432904
INFO:root:[3,   150] training loss: 0.02800334
INFO:root:[3,   200] training loss: 0.02481518
INFO:root:[3,   250] training loss: 0.02825272
INFO:root:[3,   300] training loss: 0.02800499
INFO:root:[3,   350] training loss: 0.02478653
INFO:root:[3,   400] training loss: 0.00081178
INFO:root:[3,   450] training loss: 0.00024210
INFO:root:[3,   500] training loss: 0.00632116
INFO:root:[3,   550] training loss: 0.00545729
INFO:root:[3,   600] training loss: 0.02656420
INFO:root:[3,   650] training loss: 0.00003253
INFO:root:[3,   700] training loss: 0.00002994
INFO:root:[3,   750] training loss: 0.00002923
INFO:root:[3,   800] training loss: 0.00002741
INFO:root:[3,   850] training loss: 0.00002520
INFO:root:[3,   900] training loss: 0.06204199
INFO:root:[3,   950] training loss: 0.01761551
INFO:root:[3,  1000] training loss: 0.00009762
INFO:root:[3,  1050] training loss: 0.00005278
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.06741027
INFO:root:[4,   100] training loss: 0.02680663
INFO:root:[4,   150] training loss: 0.02433193
INFO:root:[4,   200] training loss: 0.02183415
INFO:root:[4,   250] training loss: 0.02272982
INFO:root:[4,   300] training loss: 0.02329294
INFO:root:[4,   350] training loss: 0.02410931
INFO:root:[4,   400] training loss: 0.00202621
INFO:root:[4,   450] training loss: 0.00017781
INFO:root:[4,   500] training loss: 0.00700717
INFO:root:[4,   550] training loss: 0.00795352
INFO:root:[4,   600] training loss: 0.02699856
INFO:root:[4,   650] training loss: 0.00005294
INFO:root:[4,   700] training loss: 0.00005264
INFO:root:[4,   750] training loss: 0.00005347
INFO:root:[4,   800] training loss: 0.00004191
INFO:root:[4,   850] training loss: 0.00003830
INFO:root:[4,   900] training loss: 0.05213210
INFO:root:[4,   950] training loss: 0.01927686
INFO:root:[4,  1000] training loss: 0.00044177
INFO:root:[4,  1050] training loss: 0.00015097
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.05866207
INFO:root:[5,   100] training loss: 0.02261654
INFO:root:[5,   150] training loss: 0.02323219
INFO:root:[5,   200] training loss: 0.01915884
INFO:root:[5,   250] training loss: 0.02015223
INFO:root:[5,   300] training loss: 0.02087108
INFO:root:[5,   350] training loss: 0.02528794
INFO:root:[5,   400] training loss: 0.00146456
INFO:root:[5,   450] training loss: 0.00020628
INFO:root:[5,   500] training loss: 0.00589377
INFO:root:[5,   550] training loss: 0.00847507
INFO:root:[5,   600] training loss: 0.02753565
INFO:root:[5,   650] training loss: 0.00008702
INFO:root:[5,   700] training loss: 0.00007359
INFO:root:[5,   750] training loss: 0.00007540
INFO:root:[5,   800] training loss: 0.00005738
INFO:root:[5,   850] training loss: 0.00005826
INFO:root:[5,   900] training loss: 0.05383786
INFO:root:[5,   950] training loss: 0.01791471
INFO:root:[5,  1000] training loss: 0.00041875
INFO:root:[5,  1050] training loss: 0.00012270
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.05783078
INFO:root:[6,   100] training loss: 0.02201948
INFO:root:[6,   150] training loss: 0.02451052
INFO:root:[6,   200] training loss: 0.02145622
INFO:root:[6,   250] training loss: 0.02041220
INFO:root:[6,   300] training loss: 0.02009757
INFO:root:[6,   350] training loss: 0.02494214
INFO:root:[6,   400] training loss: 0.00198606
INFO:root:[6,   450] training loss: 0.00024567
INFO:root:[6,   500] training loss: 0.00575534
INFO:root:[6,   550] training loss: 0.00749805
INFO:root:[6,   600] training loss: 0.02485278
INFO:root:[6,   650] training loss: 0.00010578
INFO:root:[6,   700] training loss: 0.00008724
INFO:root:[6,   750] training loss: 0.00008018
INFO:root:[6,   800] training loss: 0.00006979
INFO:root:[6,   850] training loss: 0.00005930
INFO:root:[6,   900] training loss: 0.06300287
INFO:root:[6,   950] training loss: 0.02300713
INFO:root:[6,  1000] training loss: 0.00054411
INFO:root:[6,  1050] training loss: 0.00019643
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.07473048
INFO:root:[7,   100] training loss: 0.03714489
INFO:root:[7,   150] training loss: 0.03380457
INFO:root:[7,   200] training loss: 0.03341174
INFO:root:[7,   250] training loss: 0.02962220
INFO:root:[7,   300] training loss: 0.02993898
INFO:root:[7,   350] training loss: 0.03067571
INFO:root:[7,   400] training loss: 0.00253696
INFO:root:[7,   450] training loss: 0.00022923
INFO:root:[7,   500] training loss: 0.00631102
INFO:root:[7,   550] training loss: 0.00895274
INFO:root:[7,   600] training loss: 0.02832773
INFO:root:[7,   650] training loss: 0.00020138
INFO:root:[7,   700] training loss: 0.00014383
INFO:root:[7,   750] training loss: 0.00012057
INFO:root:[7,   800] training loss: 0.00010303
INFO:root:[7,   850] training loss: 0.00008414
INFO:root:[7,   900] training loss: 0.06219936
INFO:root:[7,   950] training loss: 0.02121117
INFO:root:[7,  1000] training loss: 0.00069341
INFO:root:[7,  1050] training loss: 0.00033240
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.06069591
INFO:root:[8,   100] training loss: 0.02886373
INFO:root:[8,   150] training loss: 0.02849370
INFO:root:[8,   200] training loss: 0.02479686
INFO:root:[8,   250] training loss: 0.02664648
INFO:root:[8,   300] training loss: 0.02567201
INFO:root:[8,   350] training loss: 0.02792812
INFO:root:[8,   400] training loss: 0.00247185
INFO:root:[8,   450] training loss: 0.00018460
INFO:root:[8,   500] training loss: 0.00626544
INFO:root:[8,   550] training loss: 0.00915732
INFO:root:[8,   600] training loss: 0.02556028
INFO:root:[8,   650] training loss: 0.00032711
INFO:root:[8,   700] training loss: 0.00021216
INFO:root:[8,   750] training loss: 0.00016950
INFO:root:[8,   800] training loss: 0.00013075
INFO:root:[8,   850] training loss: 0.00011528
INFO:root:[8,   900] training loss: 0.05359444
INFO:root:[8,   950] training loss: 0.02148725
INFO:root:[8,  1000] training loss: 0.00074540
INFO:root:[8,  1050] training loss: 0.00030066
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.05678476
INFO:root:[9,   100] training loss: 0.02899708
INFO:root:[9,   150] training loss: 0.02722015
INFO:root:[9,   200] training loss: 0.02275928
INFO:root:[9,   250] training loss: 0.02411846
INFO:root:[9,   300] training loss: 0.02439506
INFO:root:[9,   350] training loss: 0.03100201
INFO:root:[9,   400] training loss: 0.00296204
INFO:root:[9,   450] training loss: 0.00019094
INFO:root:[9,   500] training loss: 0.00714877
INFO:root:[9,   550] training loss: 0.00839991
INFO:root:[9,   600] training loss: 0.02517716
INFO:root:[9,   650] training loss: 0.00018387
INFO:root:[9,   700] training loss: 0.00012596
INFO:root:[9,   750] training loss: 0.00011127
INFO:root:[9,   800] training loss: 0.00008640
INFO:root:[9,   850] training loss: 0.00007211
INFO:root:[9,   900] training loss: 0.05516244
INFO:root:[9,   950] training loss: 0.02011894
INFO:root:[9,  1000] training loss: 0.00045215
INFO:root:[9,  1050] training loss: 0.00020978
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.05617851
INFO:root:[10,   100] training loss: 0.02679145
INFO:root:[10,   150] training loss: 0.02633478
INFO:root:[10,   200] training loss: 0.02261718
INFO:root:[10,   250] training loss: 0.02237171
INFO:root:[10,   300] training loss: 0.02707915
INFO:root:[10,   350] training loss: 0.02506658
INFO:root:[10,   400] training loss: 0.00193930
INFO:root:[10,   450] training loss: 0.00017176
INFO:root:[10,   500] training loss: 0.00598187
INFO:root:[10,   550] training loss: 0.00969698
INFO:root:[10,   600] training loss: 0.02733077
INFO:root:[10,   650] training loss: 0.00038272
INFO:root:[10,   700] training loss: 0.00022974
INFO:root:[10,   750] training loss: 0.00017859
INFO:root:[10,   800] training loss: 0.00014037
INFO:root:[10,   850] training loss: 0.00011917
INFO:root:[10,   900] training loss: 0.04732793
INFO:root:[10,   950] training loss: 0.02380659
INFO:root:[10,  1000] training loss: 0.00095546
INFO:root:[10,  1050] training loss: 0.00039245
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.05531420
INFO:root:[11,   100] training loss: 0.02407037
INFO:root:[11,   150] training loss: 0.02892708
INFO:root:[11,   200] training loss: 0.02221955
INFO:root:[11,   250] training loss: 0.02331784
INFO:root:[11,   300] training loss: 0.02487213
INFO:root:[11,   350] training loss: 0.02473212
INFO:root:[11,   400] training loss: 0.00118807
INFO:root:[11,   450] training loss: 0.00028182
INFO:root:[11,   500] training loss: 0.00635267
INFO:root:[11,   550] training loss: 0.01066496
INFO:root:[11,   600] training loss: 0.02973745
INFO:root:[11,   650] training loss: 0.00039834
INFO:root:[11,   700] training loss: 0.00026280
INFO:root:[11,   750] training loss: 0.00019421
INFO:root:[11,   800] training loss: 0.00015258
INFO:root:[11,   850] training loss: 0.00012344
INFO:root:[11,   900] training loss: 0.05099741
INFO:root:[11,   950] training loss: 0.02284078
INFO:root:[11,  1000] training loss: 0.00093441
INFO:root:[11,  1050] training loss: 0.00039556
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2671    1.0000    0.4216      1034
   Telophase     1.0000    0.3333    0.5000         3

    accuracy                         0.2673      3872
   macro avg     0.1810    0.1905    0.1317      3872
weighted avg     0.0721    0.2673    0.1130      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.05569136
INFO:root:[12,   100] training loss: 0.02169180
INFO:root:[12,   150] training loss: 0.02628199
INFO:root:[12,   200] training loss: 0.02249930
INFO:root:[12,   250] training loss: 0.02184961
INFO:root:[12,   300] training loss: 0.02296921
INFO:root:[12,   350] training loss: 0.02138195
INFO:root:[12,   400] training loss: 0.00109667
INFO:root:[12,   450] training loss: 0.00021173
INFO:root:[12,   500] training loss: 0.00629049
INFO:root:[12,   550] training loss: 0.00880795
INFO:root:[12,   600] training loss: 0.02997934
INFO:root:[12,   650] training loss: 0.00038066
INFO:root:[12,   700] training loss: 0.00023914
INFO:root:[12,   750] training loss: 0.00018861
INFO:root:[12,   800] training loss: 0.00015273
INFO:root:[12,   850] training loss: 0.00012625
INFO:root:[12,   900] training loss: 0.04988884
INFO:root:[12,   950] training loss: 0.02231412
INFO:root:[12,  1000] training loss: 0.00062030
INFO:root:[12,  1050] training loss: 0.00029564
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.5000    0.1250    0.2000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2672    1.0000    0.4217      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.1096    0.1607    0.0888      3872
weighted avg     0.0724    0.2673    0.1130      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.05492518
INFO:root:[13,   100] training loss: 0.02244714
INFO:root:[13,   150] training loss: 0.02139330
INFO:root:[13,   200] training loss: 0.02059102
INFO:root:[13,   250] training loss: 0.02057721
INFO:root:[13,   300] training loss: 0.02426909
INFO:root:[13,   350] training loss: 0.02095179
INFO:root:[13,   400] training loss: 0.00114035
INFO:root:[13,   450] training loss: 0.00018265
INFO:root:[13,   500] training loss: 0.00486782
INFO:root:[13,   550] training loss: 0.00864931
INFO:root:[13,   600] training loss: 0.02582990
INFO:root:[13,   650] training loss: 0.00024602
INFO:root:[13,   700] training loss: 0.00015889
INFO:root:[13,   750] training loss: 0.00012703
INFO:root:[13,   800] training loss: 0.00010925
INFO:root:[13,   850] training loss: 0.00008737
INFO:root:[13,   900] training loss: 0.04273538
INFO:root:[13,   950] training loss: 0.02226195
INFO:root:[13,  1000] training loss: 0.00086062
INFO:root:[13,  1050] training loss: 0.00038826
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2673    1.0000    0.4218      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2673      3872
   macro avg     0.1096    0.2143    0.1317      3872
weighted avg     0.0716    0.2673    0.1129      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.05243072
INFO:root:[14,   100] training loss: 0.01993095
INFO:root:[14,   150] training loss: 0.02073924
INFO:root:[14,   200] training loss: 0.02024662
INFO:root:[14,   250] training loss: 0.01993132
INFO:root:[14,   300] training loss: 0.02588750
INFO:root:[14,   350] training loss: 0.02081960
INFO:root:[14,   400] training loss: 0.00068494
INFO:root:[14,   450] training loss: 0.00014802
INFO:root:[14,   500] training loss: 0.00462106
INFO:root:[14,   550] training loss: 0.01011301
INFO:root:[14,   600] training loss: 0.02914370
INFO:root:[14,   650] training loss: 0.00025407
INFO:root:[14,   700] training loss: 0.00017748
INFO:root:[14,   750] training loss: 0.00015560
INFO:root:[14,   800] training loss: 0.00011760
INFO:root:[14,   850] training loss: 0.00009173
INFO:root:[14,   900] training loss: 0.04324627
INFO:root:[14,   950] training loss: 0.02213231
INFO:root:[14,  1000] training loss: 0.00095530
INFO:root:[14,  1050] training loss: 0.00042741
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0769    0.1250    0.0952         8
    Anaphase     0.6250    0.1370    0.2247        73
          G2     0.2691    1.0000    0.4240      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2699      3872
   macro avg     0.1387    0.1803    0.1063      3872
weighted avg     0.0838    0.2699    0.1177      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.05185109
INFO:root:[15,   100] training loss: 0.01985890
INFO:root:[15,   150] training loss: 0.02192715
INFO:root:[15,   200] training loss: 0.01960993
INFO:root:[15,   250] training loss: 0.01885920
INFO:root:[15,   300] training loss: 0.02044962
INFO:root:[15,   350] training loss: 0.01854694
INFO:root:[15,   400] training loss: 0.00118939
INFO:root:[15,   450] training loss: 0.00027079
INFO:root:[15,   500] training loss: 0.00515193
INFO:root:[15,   550] training loss: 0.01140432
INFO:root:[15,   600] training loss: 0.02866609
INFO:root:[15,   650] training loss: 0.00034490
INFO:root:[15,   700] training loss: 0.00022101
INFO:root:[15,   750] training loss: 0.00016230
INFO:root:[15,   800] training loss: 0.00012413
INFO:root:[15,   850] training loss: 0.00009647
INFO:root:[15,   900] training loss: 0.04647585
INFO:root:[15,   950] training loss: 0.02138220
INFO:root:[15,  1000] training loss: 0.00074875
INFO:root:[15,  1050] training loss: 0.00037349
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.1667    0.1250    0.1429         8
    Anaphase     0.6667    0.0548    0.1013        73
          G2     0.2680    1.0000    0.4227      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2686      3872
   macro avg     0.2288    0.2400    0.1667      3872
weighted avg     0.0847    0.2686    0.1154      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.05008488
INFO:root:[16,   100] training loss: 0.01866894
INFO:root:[16,   150] training loss: 0.02167478
INFO:root:[16,   200] training loss: 0.01800144
INFO:root:[16,   250] training loss: 0.01912149
INFO:root:[16,   300] training loss: 0.02014681
INFO:root:[16,   350] training loss: 0.02044155
INFO:root:[16,   400] training loss: 0.00103758
INFO:root:[16,   450] training loss: 0.00024030
INFO:root:[16,   500] training loss: 0.00483087
INFO:root:[16,   550] training loss: 0.01197192
INFO:root:[16,   600] training loss: 0.02762654
INFO:root:[16,   650] training loss: 0.00047898
INFO:root:[16,   700] training loss: 0.00030792
INFO:root:[16,   750] training loss: 0.00028522
INFO:root:[16,   800] training loss: 0.00020269
INFO:root:[16,   850] training loss: 0.00015919
INFO:root:[16,   900] training loss: 0.04140889
INFO:root:[16,   950] training loss: 0.02023653
INFO:root:[16,  1000] training loss: 0.00076706
INFO:root:[16,  1050] training loss: 0.00034644
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.1111    0.1250    0.1176         8
    Anaphase     0.5000    0.1918    0.2772        73
          G2     0.2699    1.0000    0.4251      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2712      3872
   macro avg     0.1616    0.2595    0.1648      3872
weighted avg     0.0819    0.2712    0.1192      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.05112127
INFO:root:[17,   100] training loss: 0.02148745
INFO:root:[17,   150] training loss: 0.01879615
INFO:root:[17,   200] training loss: 0.01769207
INFO:root:[17,   250] training loss: 0.01716728
INFO:root:[17,   300] training loss: 0.02037508
INFO:root:[17,   350] training loss: 0.01884523
INFO:root:[17,   400] training loss: 0.00021343
INFO:root:[17,   450] training loss: 0.00011196
INFO:root:[17,   500] training loss: 0.00484545
INFO:root:[17,   550] training loss: 0.01092109
INFO:root:[17,   600] training loss: 0.03293197
INFO:root:[17,   650] training loss: 0.00051000
INFO:root:[17,   700] training loss: 0.00032376
INFO:root:[17,   750] training loss: 0.00024693
INFO:root:[17,   800] training loss: 0.00019966
INFO:root:[17,   850] training loss: 0.00017073
INFO:root:[17,   900] training loss: 0.04554178
INFO:root:[17,   950] training loss: 0.02223071
INFO:root:[17,  1000] training loss: 0.00079276
INFO:root:[17,  1050] training loss: 0.00043957
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2000    0.2500    0.2222         8
    Anaphase     0.4615    0.1644    0.2424        73
          G2     0.2696    1.0000    0.4247      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2707      3872
   macro avg     0.1330    0.2021    0.1271      3872
weighted avg     0.0811    0.2707    0.1185      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.05161024
INFO:root:[18,   100] training loss: 0.02011423
INFO:root:[18,   150] training loss: 0.02292115
INFO:root:[18,   200] training loss: 0.01931724
INFO:root:[18,   250] training loss: 0.01963007
INFO:root:[18,   300] training loss: 0.02017333
INFO:root:[18,   350] training loss: 0.01992641
INFO:root:[18,   400] training loss: 0.00072058
INFO:root:[18,   450] training loss: 0.00017976
INFO:root:[18,   500] training loss: 0.00507166
INFO:root:[18,   550] training loss: 0.01195835
INFO:root:[18,   600] training loss: 0.03073696
INFO:root:[18,   650] training loss: 0.00057069
INFO:root:[18,   700] training loss: 0.00034960
INFO:root:[18,   750] training loss: 0.00026909
INFO:root:[18,   800] training loss: 0.00020653
INFO:root:[18,   850] training loss: 0.00016038
INFO:root:[18,   900] training loss: 0.04627676
INFO:root:[18,   950] training loss: 0.02057863
INFO:root:[18,  1000] training loss: 0.00077784
INFO:root:[18,  1050] training loss: 0.00034755
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2000    0.2500    0.2222         8
    Anaphase     0.6667    0.2192    0.3299        73
          G2     0.2696    1.0000    0.4247      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2722      3872
   macro avg     0.3052    0.3051    0.2538      3872
weighted avg     0.0858    0.2722    0.1207      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.04863485
INFO:root:[19,   100] training loss: 0.02218708
INFO:root:[19,   150] training loss: 0.02108360
INFO:root:[19,   200] training loss: 0.01825053
INFO:root:[19,   250] training loss: 0.01848616
INFO:root:[19,   300] training loss: 0.01971702
INFO:root:[19,   350] training loss: 0.01690109
INFO:root:[19,   400] training loss: 0.00066502
INFO:root:[19,   450] training loss: 0.00014438
INFO:root:[19,   500] training loss: 0.00514954
INFO:root:[19,   550] training loss: 0.01143526
INFO:root:[19,   600] training loss: 0.03399449
INFO:root:[19,   650] training loss: 0.00053567
INFO:root:[19,   700] training loss: 0.00033302
INFO:root:[19,   750] training loss: 0.00025701
INFO:root:[19,   800] training loss: 0.00021398
INFO:root:[19,   850] training loss: 0.00017590
INFO:root:[19,   900] training loss: 0.04726703
INFO:root:[19,   950] training loss: 0.01966463
INFO:root:[19,  1000] training loss: 0.00092711
INFO:root:[19,  1050] training loss: 0.00046526
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3750    0.3750    0.3750         8
    Anaphase     0.7895    0.2055    0.3261        73
          G2     0.2689    1.0000    0.4239      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2717      3872
   macro avg     0.2048    0.2258    0.1607      3872
weighted avg     0.0875    0.2717    0.1201      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.04874655
INFO:root:[20,   100] training loss: 0.02077290
INFO:root:[20,   150] training loss: 0.02217283
INFO:root:[20,   200] training loss: 0.01864915
INFO:root:[20,   250] training loss: 0.01888721
INFO:root:[20,   300] training loss: 0.02092316
INFO:root:[20,   350] training loss: 0.01949608
INFO:root:[20,   400] training loss: 0.00070988
INFO:root:[20,   450] training loss: 0.00017302
INFO:root:[20,   500] training loss: 0.00561030
INFO:root:[20,   550] training loss: 0.01087515
INFO:root:[20,   600] training loss: 0.03258028
INFO:root:[20,   650] training loss: 0.00066827
INFO:root:[20,   700] training loss: 0.00037698
INFO:root:[20,   750] training loss: 0.00028605
INFO:root:[20,   800] training loss: 0.00022211
INFO:root:[20,   850] training loss: 0.00019930
INFO:root:[20,   900] training loss: 0.04987004
INFO:root:[20,   950] training loss: 0.01961061
INFO:root:[20,  1000] training loss: 0.00086310
INFO:root:[20,  1050] training loss: 0.00039648
INFO:root:              precision    recall  f1-score   support

    Prophase     0.3333    0.5000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3750    0.3750    0.3750         8
    Anaphase     0.8235    0.1918    0.3111        73
          G2     0.2691    1.0000    0.4241      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2722      3872
   macro avg     0.4001    0.3905    0.3300      3872
weighted avg     0.0891    0.2722    0.1207      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.04976940
INFO:root:[21,   100] training loss: 0.02174553
INFO:root:[21,   150] training loss: 0.02377517
INFO:root:[21,   200] training loss: 0.02027562
INFO:root:[21,   250] training loss: 0.01980825
INFO:root:[21,   300] training loss: 0.02049088
INFO:root:[21,   350] training loss: 0.01847813
INFO:root:[21,   400] training loss: 0.00076855
INFO:root:[21,   450] training loss: 0.00014541
INFO:root:[21,   500] training loss: 0.00468511
INFO:root:[21,   550] training loss: 0.01166034
INFO:root:[21,   600] training loss: 0.03309659
INFO:root:[21,   650] training loss: 0.00074540
INFO:root:[21,   700] training loss: 0.00042682
INFO:root:[21,   750] training loss: 0.00035220
INFO:root:[21,   800] training loss: 0.00025905
INFO:root:[21,   850] training loss: 0.00020581
INFO:root:[21,   900] training loss: 0.05763404
INFO:root:[21,   950] training loss: 0.02232598
INFO:root:[21,  1000] training loss: 0.00063241
INFO:root:[21,  1050] training loss: 0.00026803
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.0000    0.0000    0.0000        73
          G2     0.2670    1.0000    0.4215      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2670      3872
   macro avg     0.0381    0.1429    0.0602      3872
weighted avg     0.0713    0.2670    0.1126      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.12112746
INFO:root:[22,   100] training loss: 0.03348526
INFO:root:[22,   150] training loss: 0.03079188
INFO:root:[22,   200] training loss: 0.02333172
INFO:root:[22,   250] training loss: 0.02435184
INFO:root:[22,   300] training loss: 0.02239250
INFO:root:[22,   350] training loss: 0.02223387
INFO:root:[22,   400] training loss: 0.00040012
INFO:root:[22,   450] training loss: 0.00012611
INFO:root:[22,   500] training loss: 0.00483764
INFO:root:[22,   550] training loss: 0.00594943
INFO:root:[22,   600] training loss: 0.02669283
INFO:root:[22,   650] training loss: 0.00011970
INFO:root:[22,   700] training loss: 0.00009137
INFO:root:[22,   750] training loss: 0.00006733
INFO:root:[22,   800] training loss: 0.00005462
INFO:root:[22,   850] training loss: 0.00006238
INFO:root:[22,   900] training loss: 0.04558840
INFO:root:[22,   950] training loss: 0.01785786
INFO:root:[22,  1000] training loss: 0.00043658
INFO:root:[22,  1050] training loss: 0.00023984
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.5000    0.1250    0.2000         8
    Anaphase     1.0000    0.0548    0.1039        73
          G2     0.2675    1.0000    0.4221      1034
   Telophase     1.0000    0.3333    0.5000         3

    accuracy                         0.2686      3872
   macro avg     0.3954    0.2162    0.1751      3872
weighted avg     0.0921    0.2686    0.1155      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.04961590
INFO:root:[23,   100] training loss: 0.02048290
INFO:root:[23,   150] training loss: 0.02040410
INFO:root:[23,   200] training loss: 0.01921771
INFO:root:[23,   250] training loss: 0.02058837
INFO:root:[23,   300] training loss: 0.02219939
INFO:root:[23,   350] training loss: 0.01906983
INFO:root:[23,   400] training loss: 0.00085593
INFO:root:[23,   450] training loss: 0.00025214
INFO:root:[23,   500] training loss: 0.00496675
INFO:root:[23,   550] training loss: 0.00999795
INFO:root:[23,   600] training loss: 0.02992273
INFO:root:[23,   650] training loss: 0.00029600
INFO:root:[23,   700] training loss: 0.00020062
INFO:root:[23,   750] training loss: 0.00017333
INFO:root:[23,   800] training loss: 0.00013159
INFO:root:[23,   850] training loss: 0.00011438
INFO:root:[23,   900] training loss: 0.04331437
INFO:root:[23,   950] training loss: 0.01866114
INFO:root:[23,  1000] training loss: 0.00069293
INFO:root:[23,  1050] training loss: 0.00035247
INFO:root:              precision    recall  f1-score   support

    Prophase     0.1667    0.5000    0.2500         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.1818    0.2500    0.2105         8
    Anaphase     0.6552    0.2603    0.3725        73
          G2     0.2703    1.0000    0.4255      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2727      3872
   macro avg     0.1820    0.2872    0.1798      3872
weighted avg     0.0850    0.2727    0.1212      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.04693494
INFO:root:[24,   100] training loss: 0.02394966
INFO:root:[24,   150] training loss: 0.01960327
INFO:root:[24,   200] training loss: 0.01678773
INFO:root:[24,   250] training loss: 0.01788079
INFO:root:[24,   300] training loss: 0.01930303
INFO:root:[24,   350] training loss: 0.01724273
INFO:root:[24,   400] training loss: 0.00031072
INFO:root:[24,   450] training loss: 0.00013360
INFO:root:[24,   500] training loss: 0.00501136
INFO:root:[24,   550] training loss: 0.00910049
INFO:root:[24,   600] training loss: 0.02966520
INFO:root:[24,   650] training loss: 0.00041295
INFO:root:[24,   700] training loss: 0.00026318
INFO:root:[24,   750] training loss: 0.00020502
INFO:root:[24,   800] training loss: 0.00016190
INFO:root:[24,   850] training loss: 0.00015126
INFO:root:[24,   900] training loss: 0.04399595
INFO:root:[24,   950] training loss: 0.02778460
INFO:root:[24,  1000] training loss: 0.00052881
INFO:root:[24,  1050] training loss: 0.00027932
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3333    0.2500    0.2857         8
    Anaphase     0.8182    0.2466    0.3789        73
          G2     0.2690    1.0000    0.4239      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2722      3872
   macro avg     0.2029    0.2138    0.1555      3872
weighted avg     0.0879    0.2722    0.1209      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.04865670
INFO:root:[25,   100] training loss: 0.02056384
INFO:root:[25,   150] training loss: 0.02013738
INFO:root:[25,   200] training loss: 0.01821719
INFO:root:[25,   250] training loss: 0.01946102
INFO:root:[25,   300] training loss: 0.02301715
INFO:root:[25,   350] training loss: 0.01851110
INFO:root:[25,   400] training loss: 0.00064684
INFO:root:[25,   450] training loss: 0.00018641
INFO:root:[25,   500] training loss: 0.00479678
INFO:root:[25,   550] training loss: 0.01027305
INFO:root:[25,   600] training loss: 0.03086405
INFO:root:[25,   650] training loss: 0.00046358
INFO:root:[25,   700] training loss: 0.00029783
INFO:root:[25,   750] training loss: 0.00024064
INFO:root:[25,   800] training loss: 0.00019139
INFO:root:[25,   850] training loss: 0.00016483
INFO:root:[25,   900] training loss: 0.04181042
INFO:root:[25,   950] training loss: 0.02103949
INFO:root:[25,  1000] training loss: 0.00076255
INFO:root:[25,  1050] training loss: 0.00038816
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3333    0.1250    0.1818         8
    Anaphase     0.8462    0.1507    0.2558        73
          G2     0.2683    1.0000    0.4231      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2707      3872
   macro avg     0.3497    0.2775    0.2372      3872
weighted avg     0.0891    0.2707    0.1188      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.04592282
INFO:root:[26,   100] training loss: 0.01896868
INFO:root:[26,   150] training loss: 0.02423259
INFO:root:[26,   200] training loss: 0.01806289
INFO:root:[26,   250] training loss: 0.02264732
INFO:root:[26,   300] training loss: 0.02261193
INFO:root:[26,   350] training loss: 0.01834893
INFO:root:[26,   400] training loss: 0.00038906
INFO:root:[26,   450] training loss: 0.00018957
INFO:root:[26,   500] training loss: 0.00527647
INFO:root:[26,   550] training loss: 0.00827676
INFO:root:[26,   600] training loss: 0.02784253
INFO:root:[26,   650] training loss: 0.00043994
INFO:root:[26,   700] training loss: 0.00031537
INFO:root:[26,   750] training loss: 0.00021632
INFO:root:[26,   800] training loss: 0.00017967
INFO:root:[26,   850] training loss: 0.00015503
INFO:root:[26,   900] training loss: 0.04598373
INFO:root:[26,   950] training loss: 0.02247962
INFO:root:[26,  1000] training loss: 0.00096408
INFO:root:[26,  1050] training loss: 0.00037524
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.0000    0.0000    0.0000         8
    Anaphase     0.8182    0.1233    0.2143        73
          G2     0.2679    1.0000    0.4226      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2694      3872
   macro avg     0.1552    0.1605    0.0910      3872
weighted avg     0.0870    0.2694    0.1169      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.04704728
INFO:root:[27,   100] training loss: 0.02110115
INFO:root:[27,   150] training loss: 0.02261633
INFO:root:[27,   200] training loss: 0.01799940
INFO:root:[27,   250] training loss: 0.02048121
INFO:root:[27,   300] training loss: 0.01972607
INFO:root:[27,   350] training loss: 0.01721825
INFO:root:[27,   400] training loss: 0.00112490
INFO:root:[27,   450] training loss: 0.00022821
INFO:root:[27,   500] training loss: 0.00511232
INFO:root:[27,   550] training loss: 0.01083000
INFO:root:[27,   600] training loss: 0.03093446
INFO:root:[27,   650] training loss: 0.00081611
INFO:root:[27,   700] training loss: 0.00045919
INFO:root:[27,   750] training loss: 0.00033118
INFO:root:[27,   800] training loss: 0.00026370
INFO:root:[27,   850] training loss: 0.00019945
INFO:root:[27,   900] training loss: 0.04114874
INFO:root:[27,   950] training loss: 0.02196796
INFO:root:[27,  1000] training loss: 0.00099586
INFO:root:[27,  1050] training loss: 0.00049798
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3333    0.2500    0.2857         8
    Anaphase     0.5676    0.2877    0.3818        73
          G2     0.2700    1.0000    0.4253      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2730      3872
   macro avg     0.1673    0.2197    0.1561      3872
weighted avg     0.0835    0.2730    0.1214      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.04849783
INFO:root:[28,   100] training loss: 0.02233619
INFO:root:[28,   150] training loss: 0.01945066
INFO:root:[28,   200] training loss: 0.01720812
INFO:root:[28,   250] training loss: 0.01801260
INFO:root:[28,   300] training loss: 0.02017592
INFO:root:[28,   350] training loss: 0.01671745
INFO:root:[28,   400] training loss: 0.00067532
INFO:root:[28,   450] training loss: 0.00023545
INFO:root:[28,   500] training loss: 0.00453036
INFO:root:[28,   550] training loss: 0.00986568
INFO:root:[28,   600] training loss: 0.02922468
INFO:root:[28,   650] training loss: 0.00081997
INFO:root:[28,   700] training loss: 0.00046750
INFO:root:[28,   750] training loss: 0.00038468
INFO:root:[28,   800] training loss: 0.00027326
INFO:root:[28,   850] training loss: 0.00020106
INFO:root:[28,   900] training loss: 0.04107206
INFO:root:[28,   950] training loss: 0.02155469
INFO:root:[28,  1000] training loss: 0.00098612
INFO:root:[28,  1050] training loss: 0.00052576
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2857    0.2500    0.2667         8
    Anaphase     0.8750    0.1918    0.3146        73
          G2     0.2687    1.0000    0.4236      1034
   Telophase     1.0000    0.3333    0.5000         3

    accuracy                         0.2714      3872
   macro avg     0.3471    0.2536    0.2150      3872
weighted avg     0.0896    0.2714    0.1200      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.09675063
INFO:root:[29,   100] training loss: 0.04348375
INFO:root:[29,   150] training loss: 0.03756346
INFO:root:[29,   200] training loss: 0.03591302
INFO:root:[29,   250] training loss: 0.02593525
INFO:root:[29,   300] training loss: 0.02541502
INFO:root:[29,   350] training loss: 0.02163078
INFO:root:[29,   400] training loss: 0.00033669
INFO:root:[29,   450] training loss: 0.00013847
INFO:root:[29,   500] training loss: 0.00448945
INFO:root:[29,   550] training loss: 0.00757956
INFO:root:[29,   600] training loss: 0.02822090
INFO:root:[29,   650] training loss: 0.00023774
INFO:root:[29,   700] training loss: 0.00017411
INFO:root:[29,   750] training loss: 0.00013384
INFO:root:[29,   800] training loss: 0.00009839
INFO:root:[29,   850] training loss: 0.00008964
INFO:root:[29,   900] training loss: 0.04177330
INFO:root:[29,   950] training loss: 0.02102387
INFO:root:[29,  1000] training loss: 0.00061655
INFO:root:[29,  1050] training loss: 0.00034286
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.1667    0.2500    0.2000         8
    Anaphase     1.0000    0.0822    0.1519        73
          G2     0.2684    1.0000    0.4232      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2691      3872
   macro avg     0.2050    0.1903    0.1107      3872
weighted avg     0.0909    0.2691    0.1163      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.04968720
INFO:root:[30,   100] training loss: 0.01968884
INFO:root:[30,   150] training loss: 0.02514404
INFO:root:[30,   200] training loss: 0.02009728
INFO:root:[30,   250] training loss: 0.01965974
INFO:root:[30,   300] training loss: 0.02081906
INFO:root:[30,   350] training loss: 0.01803179
INFO:root:[30,   400] training loss: 0.00041641
INFO:root:[30,   450] training loss: 0.00025699
INFO:root:[30,   500] training loss: 0.00454282
INFO:root:[30,   550] training loss: 0.00919413
INFO:root:[30,   600] training loss: 0.02909506
INFO:root:[30,   650] training loss: 0.00054758
INFO:root:[30,   700] training loss: 0.00034491
INFO:root:[30,   750] training loss: 0.00028693
INFO:root:[30,   800] training loss: 0.00021819
INFO:root:[30,   850] training loss: 0.00016637
INFO:root:[30,   900] training loss: 0.04316965
INFO:root:[30,   950] training loss: 0.01966643
INFO:root:[30,  1000] training loss: 0.00072505
INFO:root:[30,  1050] training loss: 0.00037574
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2857    0.7500    0.4138         8
    Anaphase     0.5185    0.1918    0.2800        73
          G2     0.2706    1.0000    0.4260      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2727      3872
   macro avg     0.2964    0.3726    0.2742      3872
weighted avg     0.0834    0.2727    0.1205      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.04445931
INFO:root:[31,   100] training loss: 0.02048616
INFO:root:[31,   150] training loss: 0.02091040
INFO:root:[31,   200] training loss: 0.01740837
INFO:root:[31,   250] training loss: 0.01728842
INFO:root:[31,   300] training loss: 0.01846419
INFO:root:[31,   350] training loss: 0.01625702
INFO:root:[31,   400] training loss: 0.00087176
INFO:root:[31,   450] training loss: 0.00019514
INFO:root:[31,   500] training loss: 0.00457072
INFO:root:[31,   550] training loss: 0.01079326
INFO:root:[31,   600] training loss: 0.03251046
INFO:root:[31,   650] training loss: 0.00055899
INFO:root:[31,   700] training loss: 0.00038038
INFO:root:[31,   750] training loss: 0.00027930
INFO:root:[31,   800] training loss: 0.00022186
INFO:root:[31,   850] training loss: 0.00016047
INFO:root:[31,   900] training loss: 0.04312621
INFO:root:[31,   950] training loss: 0.01954652
INFO:root:[31,  1000] training loss: 0.00079339
INFO:root:[31,  1050] training loss: 0.00039926
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    1.0000    1.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.4545    0.6250    0.5263         8
    Anaphase     0.6471    0.3014    0.4112        73
          G2     0.2705    1.0000    0.4259      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2753      3872
   macro avg     0.4817    0.5609    0.4805      3872
weighted avg     0.0867    0.2753    0.1239      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.04500084
INFO:root:[32,   100] training loss: 0.01973739
INFO:root:[32,   150] training loss: 0.01914317
INFO:root:[32,   200] training loss: 0.01749251
INFO:root:[32,   250] training loss: 0.01827519
INFO:root:[32,   300] training loss: 0.02050269
INFO:root:[32,   350] training loss: 0.01732876
INFO:root:[32,   400] training loss: 0.00071690
INFO:root:[32,   450] training loss: 0.00016711
INFO:root:[32,   500] training loss: 0.00440378
INFO:root:[32,   550] training loss: 0.01096864
INFO:root:[32,   600] training loss: 0.03174902
INFO:root:[32,   650] training loss: 0.00058841
INFO:root:[32,   700] training loss: 0.00031643
INFO:root:[32,   750] training loss: 0.00029132
INFO:root:[32,   800] training loss: 0.00021779
INFO:root:[32,   850] training loss: 0.00016106
INFO:root:[32,   900] training loss: 0.04213816
INFO:root:[32,   950] training loss: 0.01994563
INFO:root:[32,  1000] training loss: 0.00119952
INFO:root:[32,  1050] training loss: 0.00054155
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.7500    0.3750    0.5000         8
    Anaphase     0.7353    0.3425    0.4673        73
          G2     0.2699    1.0000    0.4251      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2751      3872
   macro avg     0.3936    0.3882    0.3418      3872
weighted avg     0.0883    0.2751    0.1241      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.04639223
INFO:root:[33,   100] training loss: 0.02044689
INFO:root:[33,   150] training loss: 0.01971677
INFO:root:[33,   200] training loss: 0.01762419
INFO:root:[33,   250] training loss: 0.01825300
INFO:root:[33,   300] training loss: 0.01903813
INFO:root:[33,   350] training loss: 0.01573349
INFO:root:[33,   400] training loss: 0.00050505
INFO:root:[33,   450] training loss: 0.00017402
INFO:root:[33,   500] training loss: 0.00454906
INFO:root:[33,   550] training loss: 0.01096563
INFO:root:[33,   600] training loss: 0.03168475
INFO:root:[33,   650] training loss: 0.00084761
INFO:root:[33,   700] training loss: 0.00049195
INFO:root:[33,   750] training loss: 0.00032469
INFO:root:[33,   800] training loss: 0.00026386
INFO:root:[33,   850] training loss: 0.00019529
INFO:root:[33,   900] training loss: 0.03962035
INFO:root:[33,   950] training loss: 0.02119404
INFO:root:[33,  1000] training loss: 0.00109572
INFO:root:[33,  1050] training loss: 0.00054191
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.5000    0.5000    0.5000         8
    Anaphase     0.6585    0.3699    0.4737        73
          G2     0.2707    1.0000    0.4260      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2758      3872
   macro avg     0.3470    0.4100    0.3428      3872
weighted avg     0.0865    0.2758    0.1245      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.04385312
INFO:root:[34,   100] training loss: 0.02105332
INFO:root:[34,   150] training loss: 0.02155457
INFO:root:[34,   200] training loss: 0.01870750
INFO:root:[34,   250] training loss: 0.01657091
INFO:root:[34,   300] training loss: 0.01875779
INFO:root:[34,   350] training loss: 0.01584676
INFO:root:[34,   400] training loss: 0.00058437
INFO:root:[34,   450] training loss: 0.00022033
INFO:root:[34,   500] training loss: 0.00411863
INFO:root:[34,   550] training loss: 0.01057676
INFO:root:[34,   600] training loss: 0.03245104
INFO:root:[34,   650] training loss: 0.00082913
INFO:root:[34,   700] training loss: 0.00048376
INFO:root:[34,   750] training loss: 0.00031664
INFO:root:[34,   800] training loss: 0.00025161
INFO:root:[34,   850] training loss: 0.00019096
INFO:root:[34,   900] training loss: 0.03736586
INFO:root:[34,   950] training loss: 0.02144243
INFO:root:[34,  1000] training loss: 0.00107876
INFO:root:[34,  1050] training loss: 0.00050953
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2857    0.5000    0.3636         8
    Anaphase     0.7500    0.2466    0.3711        73
          G2     0.2699    1.0000    0.4251      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2735      3872
   macro avg     0.3294    0.3924    0.3085      3872
weighted avg     0.0876    0.2735    0.1220      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.04704995
INFO:root:[35,   100] training loss: 0.01897968
INFO:root:[35,   150] training loss: 0.02053705
INFO:root:[35,   200] training loss: 0.01769028
INFO:root:[35,   250] training loss: 0.01836508
INFO:root:[35,   300] training loss: 0.01912390
INFO:root:[35,   350] training loss: 0.01623368
INFO:root:[35,   400] training loss: 0.00030369
INFO:root:[35,   450] training loss: 0.00023907
INFO:root:[35,   500] training loss: 0.00442823
INFO:root:[35,   550] training loss: 0.01034144
INFO:root:[35,   600] training loss: 0.03155052
INFO:root:[35,   650] training loss: 0.00089294
INFO:root:[35,   700] training loss: 0.00051509
INFO:root:[35,   750] training loss: 0.00038941
INFO:root:[35,   800] training loss: 0.00028872
INFO:root:[35,   850] training loss: 0.00023815
INFO:root:[35,   900] training loss: 0.03863332
INFO:root:[35,   950] training loss: 0.02257524
INFO:root:[35,  1000] training loss: 0.00102188
INFO:root:[35,  1050] training loss: 0.00051554
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3846    0.6250    0.4762         8
    Anaphase     0.6486    0.3288    0.4364        73
          G2     0.2706    0.9990    0.4258      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2753      3872
   macro avg     0.4720    0.4933    0.4293      3872
weighted avg     0.0866    0.2753    0.1240      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.04167935
INFO:root:[36,   100] training loss: 0.01882533
INFO:root:[36,   150] training loss: 0.01669396
INFO:root:[36,   200] training loss: 0.01763142
INFO:root:[36,   250] training loss: 0.01809675
INFO:root:[36,   300] training loss: 0.01808248
INFO:root:[36,   350] training loss: 0.01776916
INFO:root:[36,   400] training loss: 0.00021124
INFO:root:[36,   450] training loss: 0.00014213
INFO:root:[36,   500] training loss: 0.00411636
INFO:root:[36,   550] training loss: 0.00974144
INFO:root:[36,   600] training loss: 0.03013872
INFO:root:[36,   650] training loss: 0.00093336
INFO:root:[36,   700] training loss: 0.00049668
INFO:root:[36,   750] training loss: 0.00035335
INFO:root:[36,   800] training loss: 0.00028000
INFO:root:[36,   850] training loss: 0.00021797
INFO:root:[36,   900] training loss: 0.03677547
INFO:root:[36,   950] training loss: 0.02274982
INFO:root:[36,  1000] training loss: 0.00105145
INFO:root:[36,  1050] training loss: 0.00055251
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    1.0000    1.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3158    0.7500    0.4444         8
    Anaphase     0.5385    0.2877    0.3750        73
          G2     0.2712    0.9990    0.4266      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2751      3872
   macro avg     0.4465    0.5767    0.4637      3872
weighted avg     0.0845    0.2751    0.1232      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.04338490
INFO:root:[37,   100] training loss: 0.01899730
INFO:root:[37,   150] training loss: 0.01871667
INFO:root:[37,   200] training loss: 0.01576908
INFO:root:[37,   250] training loss: 0.01711883
INFO:root:[37,   300] training loss: 0.01927771
INFO:root:[37,   350] training loss: 0.01506797
INFO:root:[37,   400] training loss: 0.00042672
INFO:root:[37,   450] training loss: 0.00060221
INFO:root:[37,   500] training loss: 0.00392426
INFO:root:[37,   550] training loss: 0.00880359
INFO:root:[37,   600] training loss: 0.02837597
INFO:root:[37,   650] training loss: 0.00092968
INFO:root:[37,   700] training loss: 0.00047446
INFO:root:[37,   750] training loss: 0.00035981
INFO:root:[37,   800] training loss: 0.00028043
INFO:root:[37,   850] training loss: 0.00021767
INFO:root:[37,   900] training loss: 0.03856375
INFO:root:[37,   950] training loss: 0.02272723
INFO:root:[37,  1000] training loss: 0.00115999
INFO:root:[37,  1050] training loss: 0.00061272
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.5000    0.3750    0.4286         8
    Anaphase     0.8333    0.1370    0.2353        73
          G2     0.2685    1.0000    0.4233      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2712      3872
   macro avg     0.3717    0.3589    0.2982      3872
weighted avg     0.0892    0.2712    0.1191      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.04284330
INFO:root:[38,   100] training loss: 0.01942562
INFO:root:[38,   150] training loss: 0.01930107
INFO:root:[38,   200] training loss: 0.01734348
INFO:root:[38,   250] training loss: 0.01893374
INFO:root:[38,   300] training loss: 0.01823273
INFO:root:[38,   350] training loss: 0.01807412
INFO:root:[38,   400] training loss: 0.00025760
INFO:root:[38,   450] training loss: 0.00015503
INFO:root:[38,   500] training loss: 0.00423707
INFO:root:[38,   550] training loss: 0.00940963
INFO:root:[38,   600] training loss: 0.02796891
INFO:root:[38,   650] training loss: 0.00088869
INFO:root:[38,   700] training loss: 0.00045171
INFO:root:[38,   750] training loss: 0.00032526
INFO:root:[38,   800] training loss: 0.00024842
INFO:root:[38,   850] training loss: 0.00019380
INFO:root:[38,   900] training loss: 0.03842273
INFO:root:[38,   950] training loss: 0.02335620
INFO:root:[38,  1000] training loss: 0.00120023
INFO:root:[38,  1050] training loss: 0.00060214
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2500    0.5000    0.3333         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.5714    0.5000    0.5333         8
    Anaphase     0.6757    0.3425    0.4545        73
          G2     0.2704    1.0000    0.4257      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2748      3872
   macro avg     0.2525    0.3346    0.2496      3872
weighted avg     0.0863    0.2748    0.1235      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.04358962
INFO:root:[39,   100] training loss: 0.01960873
INFO:root:[39,   150] training loss: 0.01976307
INFO:root:[39,   200] training loss: 0.01620927
INFO:root:[39,   250] training loss: 0.02984059
INFO:root:[39,   300] training loss: 0.02524317
INFO:root:[39,   350] training loss: 0.01920531
INFO:root:[39,   400] training loss: 0.00020295
INFO:root:[39,   450] training loss: 0.00016809
INFO:root:[39,   500] training loss: 0.00384955
INFO:root:[39,   550] training loss: 0.00700293
INFO:root:[39,   600] training loss: 0.03060498
INFO:root:[39,   650] training loss: 0.00073027
INFO:root:[39,   700] training loss: 0.00041986
INFO:root:[39,   750] training loss: 0.00033332
INFO:root:[39,   800] training loss: 0.00023927
INFO:root:[39,   850] training loss: 0.00020755
INFO:root:[39,   900] training loss: 0.04333823
INFO:root:[39,   950] training loss: 0.02116286
INFO:root:[39,  1000] training loss: 0.00113691
INFO:root:[39,  1050] training loss: 0.00055145
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3000    0.3750    0.3333         8
    Anaphase     0.5897    0.3151    0.4107        73
          G2     0.2706    0.9990    0.4259      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2745      3872
   macro avg     0.3801    0.4794    0.3767      3872
weighted avg     0.0850    0.2745    0.1231      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.03949789
INFO:root:[40,   100] training loss: 0.01906917
INFO:root:[40,   150] training loss: 0.02030979
INFO:root:[40,   200] training loss: 0.01817076
INFO:root:[40,   250] training loss: 0.01664978
INFO:root:[40,   300] training loss: 0.02067086
INFO:root:[40,   350] training loss: 0.01627371
INFO:root:[40,   400] training loss: 0.00028713
INFO:root:[40,   450] training loss: 0.00010557
INFO:root:[40,   500] training loss: 0.00406640
INFO:root:[40,   550] training loss: 0.00668887
INFO:root:[40,   600] training loss: 0.02723943
INFO:root:[40,   650] training loss: 0.00075998
INFO:root:[40,   700] training loss: 0.00042504
INFO:root:[40,   750] training loss: 0.00035202
INFO:root:[40,   800] training loss: 0.00020960
INFO:root:[40,   850] training loss: 0.00017934
INFO:root:[40,   900] training loss: 0.03976664
INFO:root:[40,   950] training loss: 0.02433665
INFO:root:[40,  1000] training loss: 0.00098086
INFO:root:[40,  1050] training loss: 0.00056508
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3000    0.3750    0.3333         8
    Anaphase     0.6098    0.3425    0.4386        73
          G2     0.2705    0.9990    0.4257      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2745      3872
   macro avg     0.3115    0.3405    0.2854      3872
weighted avg     0.0851    0.2745    0.1233      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.03970644
INFO:root:[41,   100] training loss: 0.01896473
INFO:root:[41,   150] training loss: 0.02002974
INFO:root:[41,   200] training loss: 0.04167554
INFO:root:[41,   250] training loss: 0.03304667
INFO:root:[41,   300] training loss: 0.03048232
INFO:root:[41,   350] training loss: 0.02799471
INFO:root:[41,   400] training loss: 0.00041910
INFO:root:[41,   450] training loss: 0.00026128
INFO:root:[41,   500] training loss: 0.00492819
INFO:root:[41,   550] training loss: 0.00544178
INFO:root:[41,   600] training loss: 0.02827995
INFO:root:[41,   650] training loss: 0.00055552
INFO:root:[41,   700] training loss: 0.00036165
INFO:root:[41,   750] training loss: 0.00027787
INFO:root:[41,   800] training loss: 0.00019158
INFO:root:[41,   850] training loss: 0.00016879
INFO:root:[41,   900] training loss: 0.04075027
INFO:root:[41,   950] training loss: 0.02444662
INFO:root:[41,  1000] training loss: 0.00077564
INFO:root:[41,  1050] training loss: 0.00040977
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.4000    0.2500    0.3077         8
    Anaphase     0.5952    0.3425    0.4348        73
          G2     0.2705    1.0000    0.4259      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2748      3872
   macro avg     0.3237    0.3704    0.3098      3872
weighted avg     0.0851    0.2748    0.1233      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.03924159
INFO:root:[42,   100] training loss: 0.01930870
INFO:root:[42,   150] training loss: 0.01958130
INFO:root:[42,   200] training loss: 0.01890525
INFO:root:[42,   250] training loss: 0.01724708
INFO:root:[42,   300] training loss: 0.01843365
INFO:root:[42,   350] training loss: 0.01477134
INFO:root:[42,   400] training loss: 0.00018964
INFO:root:[42,   450] training loss: 0.00012373
INFO:root:[42,   500] training loss: 0.00376754
INFO:root:[42,   550] training loss: 0.00705316
INFO:root:[42,   600] training loss: 0.02745701
INFO:root:[42,   650] training loss: 0.00036985
INFO:root:[42,   700] training loss: 0.00022973
INFO:root:[42,   750] training loss: 0.00020463
INFO:root:[42,   800] training loss: 0.00015426
INFO:root:[42,   850] training loss: 0.00012112
INFO:root:[42,   900] training loss: 0.04159602
INFO:root:[42,   950] training loss: 0.02161187
INFO:root:[42,  1000] training loss: 0.00075223
INFO:root:[42,  1050] training loss: 0.00038592
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2500    0.1250    0.1667         8
    Anaphase     1.0000    0.0137    0.0270        73
          G2     0.2677    1.0000    0.4223      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2686      3872
   macro avg     0.5025    0.3770    0.3261      3872
weighted avg     0.0921    0.2686    0.1147      3872

INFO:root:Accuracy of the network on the 3872 validation images: 26 %
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.04537897
INFO:root:[43,   100] training loss: 0.01939271
INFO:root:[43,   150] training loss: 0.01997129
INFO:root:[43,   200] training loss: 0.01842606
INFO:root:[43,   250] training loss: 0.01917426
INFO:root:[43,   300] training loss: 0.01998307
INFO:root:[43,   350] training loss: 0.01865301
INFO:root:[43,   400] training loss: 0.00080022
INFO:root:[43,   450] training loss: 0.00046839
INFO:root:[43,   500] training loss: 0.00340176
INFO:root:[43,   550] training loss: 0.00505666
INFO:root:[43,   600] training loss: 0.02493240
INFO:root:[43,   650] training loss: 0.00071661
INFO:root:[43,   700] training loss: 0.00042392
INFO:root:[43,   750] training loss: 0.00027563
INFO:root:[43,   800] training loss: 0.00024088
INFO:root:[43,   850] training loss: 0.00019863
INFO:root:[43,   900] training loss: 0.03598497
INFO:root:[43,   950] training loss: 0.02112135
INFO:root:[43,  1000] training loss: 0.00086076
INFO:root:[43,  1050] training loss: 0.00047509
INFO:root:              precision    recall  f1-score   support

    Prophase     1.0000    0.5000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.3333    0.5000    0.4000         8
    Anaphase     0.8125    0.1781    0.2921        73
          G2     0.2692    1.0000    0.4242      1034
   Telophase     1.0000    0.6667    0.8000         3

    accuracy                         0.2722      3872
   macro avg     0.4879    0.4064    0.3690      3872
weighted avg     0.0892    0.2722    0.1206      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.04137943
INFO:root:[44,   100] training loss: 0.02017960
INFO:root:[44,   150] training loss: 0.02000339
INFO:root:[44,   200] training loss: 0.01828394
INFO:root:[44,   250] training loss: 0.01857393
INFO:root:[44,   300] training loss: 0.01921720
INFO:root:[44,   350] training loss: 0.01622588
INFO:root:[44,   400] training loss: 0.00050656
INFO:root:[44,   450] training loss: 0.00016541
INFO:root:[44,   500] training loss: 0.00388520
INFO:root:[44,   550] training loss: 0.00514386
INFO:root:[44,   600] training loss: 0.02438961
INFO:root:[44,   650] training loss: 0.00068137
INFO:root:[44,   700] training loss: 0.00036280
INFO:root:[44,   750] training loss: 0.00024161
INFO:root:[44,   800] training loss: 0.00015820
INFO:root:[44,   850] training loss: 0.00014890
INFO:root:[44,   900] training loss: 0.03617950
INFO:root:[44,   950] training loss: 0.02216340
INFO:root:[44,  1000] training loss: 0.00105395
INFO:root:[44,  1050] training loss: 0.00055887
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2143    0.3750    0.2727         8
    Anaphase     0.5769    0.4110    0.4800        73
          G2     0.2718    0.9990    0.4274      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2766      3872
   macro avg     0.3900    0.5407    0.4257      3872
weighted avg     0.0850    0.2766    0.1249      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.03843832
INFO:root:[45,   100] training loss: 0.01808651
INFO:root:[45,   150] training loss: 0.01908780
INFO:root:[45,   200] training loss: 0.01660434
INFO:root:[45,   250] training loss: 0.01694197
INFO:root:[45,   300] training loss: 0.01731709
INFO:root:[45,   350] training loss: 0.01491615
INFO:root:[45,   400] training loss: 0.00053519
INFO:root:[45,   450] training loss: 0.00015714
INFO:root:[45,   500] training loss: 0.00370704
INFO:root:[45,   550] training loss: 0.00543142
INFO:root:[45,   600] training loss: 0.02318856
INFO:root:[45,   650] training loss: 0.00074870
INFO:root:[45,   700] training loss: 0.00040987
INFO:root:[45,   750] training loss: 0.00025230
INFO:root:[45,   800] training loss: 0.00018342
INFO:root:[45,   850] training loss: 0.00012457
INFO:root:[45,   900] training loss: 0.03263639
INFO:root:[45,   950] training loss: 0.02025084
INFO:root:[45,  1000] training loss: 0.00094067
INFO:root:[45,  1050] training loss: 0.00049199
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2000    0.6250    0.3030         8
    Anaphase     0.5273    0.3973    0.4531        73
          G2     0.2723    0.9971    0.4278      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2763      3872
   macro avg     0.3809    0.5742    0.4263      3872
weighted avg     0.0842    0.2763    0.1246      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.03778966
INFO:root:[46,   100] training loss: 0.01819457
INFO:root:[46,   150] training loss: 0.01719486
INFO:root:[46,   200] training loss: 0.01668179
INFO:root:[46,   250] training loss: 0.01848150
INFO:root:[46,   300] training loss: 0.01833429
INFO:root:[46,   350] training loss: 0.01406690
INFO:root:[46,   400] training loss: 0.00032633
INFO:root:[46,   450] training loss: 0.00021683
INFO:root:[46,   500] training loss: 0.00345193
INFO:root:[46,   550] training loss: 0.00453967
INFO:root:[46,   600] training loss: 0.02171950
INFO:root:[46,   650] training loss: 0.00086091
INFO:root:[46,   700] training loss: 0.00047119
INFO:root:[46,   750] training loss: 0.00036330
INFO:root:[46,   800] training loss: 0.00030855
INFO:root:[46,   850] training loss: 0.00021746
INFO:root:[46,   900] training loss: 0.02995778
INFO:root:[46,   950] training loss: 0.02245948
INFO:root:[46,  1000] training loss: 0.00106297
INFO:root:[46,  1050] training loss: 0.00050306
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2778    0.6250    0.3846         8
    Anaphase     0.7222    0.3562    0.4771        73
          G2     0.2706    0.9990    0.4258      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.2748      3872
   macro avg     0.1815    0.2829    0.1839      3872
weighted avg     0.0864    0.2748    0.1235      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.03899853
INFO:root:[47,   100] training loss: 0.01904608
INFO:root:[47,   150] training loss: 0.01901583
INFO:root:[47,   200] training loss: 0.01690145
INFO:root:[47,   250] training loss: 0.01719358
INFO:root:[47,   300] training loss: 0.01736060
INFO:root:[47,   350] training loss: 0.01550306
INFO:root:[47,   400] training loss: 0.00074371
INFO:root:[47,   450] training loss: 0.00013324
INFO:root:[47,   500] training loss: 0.00313878
INFO:root:[47,   550] training loss: 0.00432607
INFO:root:[47,   600] training loss: 0.01994796
INFO:root:[47,   650] training loss: 0.00085906
INFO:root:[47,   700] training loss: 0.00048410
INFO:root:[47,   750] training loss: 0.00039577
INFO:root:[47,   800] training loss: 0.00028714
INFO:root:[47,   850] training loss: 0.00020669
INFO:root:[47,   900] training loss: 0.03112599
INFO:root:[47,   950] training loss: 0.01956836
INFO:root:[47,  1000] training loss: 0.00089437
INFO:root:[47,  1050] training loss: 0.00047977
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.5797    0.5479    0.5634        73
          G2     0.2722    0.9971    0.4277      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2789      3872
   macro avg     0.3876    0.5779    0.4455      3872
weighted avg     0.0855    0.2789    0.1269      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.03185100
INFO:root:[48,   100] training loss: 0.01777480
INFO:root:[48,   150] training loss: 0.01723140
INFO:root:[48,   200] training loss: 0.01877785
INFO:root:[48,   250] training loss: 0.01692892
INFO:root:[48,   300] training loss: 0.01772297
INFO:root:[48,   350] training loss: 0.01398918
INFO:root:[48,   400] training loss: 0.00029443
INFO:root:[48,   450] training loss: 0.00027669
INFO:root:[48,   500] training loss: 0.00270662
INFO:root:[48,   550] training loss: 0.00324792
INFO:root:[48,   600] training loss: 0.01785769
INFO:root:[48,   650] training loss: 0.00092467
INFO:root:[48,   700] training loss: 0.00047874
INFO:root:[48,   750] training loss: 0.00040460
INFO:root:[48,   800] training loss: 0.00028672
INFO:root:[48,   850] training loss: 0.00023227
INFO:root:[48,   900] training loss: 0.02848259
INFO:root:[48,   950] training loss: 0.02075439
INFO:root:[48,  1000] training loss: 0.00080508
INFO:root:[48,  1050] training loss: 0.00043564
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2500    0.5000    0.3333         8
    Anaphase     0.6271    0.5068    0.5606        73
          G2     0.2712    0.9952    0.4263      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2771      3872
   macro avg     0.3069    0.4289    0.3315      3872
weighted avg     0.0855    0.2771    0.1259      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.03253944
INFO:root:[49,   100] training loss: 0.01767673
INFO:root:[49,   150] training loss: 0.01836235
INFO:root:[49,   200] training loss: 0.01484120
INFO:root:[49,   250] training loss: 0.01518493
INFO:root:[49,   300] training loss: 0.01795351
INFO:root:[49,   350] training loss: 0.01700230
INFO:root:[49,   400] training loss: 0.00029203
INFO:root:[49,   450] training loss: 0.00012096
INFO:root:[49,   500] training loss: 0.00303128
INFO:root:[49,   550] training loss: 0.00306204
INFO:root:[49,   600] training loss: 0.01738316
INFO:root:[49,   650] training loss: 0.00077030
INFO:root:[49,   700] training loss: 0.00042940
INFO:root:[49,   750] training loss: 0.00036028
INFO:root:[49,   800] training loss: 0.00028181
INFO:root:[49,   850] training loss: 0.00021581
INFO:root:[49,   900] training loss: 0.03047712
INFO:root:[49,   950] training loss: 0.01954386
INFO:root:[49,  1000] training loss: 0.00072976
INFO:root:[49,  1050] training loss: 0.00038897
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2083    0.6250    0.3125         8
    Anaphase     0.3889    0.4795    0.4294        73
          G2     0.2731    0.9913    0.4282      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2758      3872
   macro avg     0.2672    0.4422    0.3100      3872
weighted avg     0.0815    0.2758    0.1239      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.02957181
INFO:root:[50,   100] training loss: 0.01684727
INFO:root:[50,   150] training loss: 0.01915401
INFO:root:[50,   200] training loss: 0.01854438
INFO:root:[50,   250] training loss: 0.01609478
INFO:root:[50,   300] training loss: 0.01837447
INFO:root:[50,   350] training loss: 0.01593151
INFO:root:[50,   400] training loss: 0.00028527
INFO:root:[50,   450] training loss: 0.00018006
INFO:root:[50,   500] training loss: 0.00188477
INFO:root:[50,   550] training loss: 0.00235579
INFO:root:[50,   600] training loss: 0.01525711
INFO:root:[50,   650] training loss: 0.00072562
INFO:root:[50,   700] training loss: 0.00041159
INFO:root:[50,   750] training loss: 0.00041552
INFO:root:[50,   800] training loss: 0.00029342
INFO:root:[50,   850] training loss: 0.00022003
INFO:root:[50,   900] training loss: 0.02872772
INFO:root:[50,   950] training loss: 0.01907015
INFO:root:[50,  1000] training loss: 0.00072233
INFO:root:[50,  1050] training loss: 0.00037869
INFO:root:              precision    recall  f1-score   support

    Prophase     0.0000    0.0000    0.0000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2857    0.5000    0.3636         8
    Anaphase     0.4211    0.5479    0.4762        73
          G2     0.2723    0.9903    0.4272      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2766      3872
   macro avg     0.2827    0.4340    0.3239      3872
weighted avg     0.0820    0.2766    0.1246      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch50
INFO:root:[51,    50] training loss: 0.02847662
INFO:root:[51,   100] training loss: 0.01712633
INFO:root:[51,   150] training loss: 0.01739644
INFO:root:[51,   200] training loss: 0.01822097
INFO:root:[51,   250] training loss: 0.01595213
INFO:root:[51,   300] training loss: 0.01669388
INFO:root:[51,   350] training loss: 0.01451512
INFO:root:[51,   400] training loss: 0.00025248
INFO:root:[51,   450] training loss: 0.00027273
INFO:root:[51,   500] training loss: 0.00148090
INFO:root:[51,   550] training loss: 0.00133435
INFO:root:[51,   600] training loss: 0.01356714
INFO:root:[51,   650] training loss: 0.00063272
INFO:root:[51,   700] training loss: 0.00035410
INFO:root:[51,   750] training loss: 0.00032196
INFO:root:[51,   800] training loss: 0.00021394
INFO:root:[51,   850] training loss: 0.00016155
INFO:root:[51,   900] training loss: 0.02643487
INFO:root:[51,   950] training loss: 0.01917870
INFO:root:[51,  1000] training loss: 0.00064789
INFO:root:[51,  1050] training loss: 0.00037566
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2632    0.6250    0.3704         8
    Anaphase     0.5082    0.4247    0.4627        73
          G2     0.2715    0.9942    0.4266      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2761      3872
   macro avg     0.3871    0.5777    0.4371      3872
weighted avg     0.0838    0.2761    0.1246      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch51
INFO:root:[52,    50] training loss: 0.02843559
INFO:root:[52,   100] training loss: 0.01519806
INFO:root:[52,   150] training loss: 0.01617742
INFO:root:[52,   200] training loss: 0.01566780
INFO:root:[52,   250] training loss: 0.01457889
INFO:root:[52,   300] training loss: 0.01741369
INFO:root:[52,   350] training loss: 0.01462880
INFO:root:[52,   400] training loss: 0.00019778
INFO:root:[52,   450] training loss: 0.00015037
INFO:root:[52,   500] training loss: 0.00121039
INFO:root:[52,   550] training loss: 0.00158585
INFO:root:[52,   600] training loss: 0.01341650
INFO:root:[52,   650] training loss: 0.00070142
INFO:root:[52,   700] training loss: 0.00038977
INFO:root:[52,   750] training loss: 0.00036837
INFO:root:[52,   800] training loss: 0.00024489
INFO:root:[52,   850] training loss: 0.00019807
INFO:root:[52,   900] training loss: 0.02471757
INFO:root:[52,   950] training loss: 0.01876111
INFO:root:[52,  1000] training loss: 0.00052154
INFO:root:[52,  1050] training loss: 0.00028389
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2632    0.6250    0.3704         8
    Anaphase     0.3571    0.5479    0.4324        73
          G2     0.2742    0.9903    0.4295      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2774      3872
   macro avg     0.3421    0.5948    0.4141      3872
weighted avg     0.0815    0.2774    0.1247      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch52
INFO:root:[53,    50] training loss: 0.02888101
INFO:root:[53,   100] training loss: 0.01678404
INFO:root:[53,   150] training loss: 0.01650582
INFO:root:[53,   200] training loss: 0.01510597
INFO:root:[53,   250] training loss: 0.01521603
INFO:root:[53,   300] training loss: 0.01676567
INFO:root:[53,   350] training loss: 0.01314284
INFO:root:[53,   400] training loss: 0.00014268
INFO:root:[53,   450] training loss: 0.00014967
INFO:root:[53,   500] training loss: 0.00138792
INFO:root:[53,   550] training loss: 0.00125512
INFO:root:[53,   600] training loss: 0.01408398
INFO:root:[53,   650] training loss: 0.00071869
INFO:root:[53,   700] training loss: 0.00040028
INFO:root:[53,   750] training loss: 0.00039064
INFO:root:[53,   800] training loss: 0.00028585
INFO:root:[53,   850] training loss: 0.00021682
INFO:root:[53,   900] training loss: 0.02677750
INFO:root:[53,   950] training loss: 0.01726282
INFO:root:[53,  1000] training loss: 0.00046346
INFO:root:[53,  1050] training loss: 0.00026700
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.1875    0.7500    0.3000         8
    Anaphase     0.2315    0.6438    0.3406        73
          G2     0.2778    0.9749    0.4324      1034
   Telophase     0.6000    1.0000    0.7500         3

    accuracy                         0.2753      3872
   macro avg     0.2567    0.6241    0.3557      3872
weighted avg     0.0797    0.2753    0.1234      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch53
INFO:root:[54,    50] training loss: 0.02644979
INFO:root:[54,   100] training loss: 0.01607754
INFO:root:[54,   150] training loss: 0.01967073
INFO:root:[54,   200] training loss: 0.01564170
INFO:root:[54,   250] training loss: 0.01568043
INFO:root:[54,   300] training loss: 0.01640591
INFO:root:[54,   350] training loss: 0.01344119
INFO:root:[54,   400] training loss: 0.00017732
INFO:root:[54,   450] training loss: 0.00012233
INFO:root:[54,   500] training loss: 0.00100187
INFO:root:[54,   550] training loss: 0.00088488
INFO:root:[54,   600] training loss: 0.01246157
INFO:root:[54,   650] training loss: 0.00072807
INFO:root:[54,   700] training loss: 0.00041471
INFO:root:[54,   750] training loss: 0.00046085
INFO:root:[54,   800] training loss: 0.00028075
INFO:root:[54,   850] training loss: 0.00022420
INFO:root:[54,   900] training loss: 0.02325386
INFO:root:[54,   950] training loss: 0.01807622
INFO:root:[54,  1000] training loss: 0.00038438
INFO:root:[54,  1050] training loss: 0.00022235
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    0.5000    0.5000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     1.0000    0.0029    0.0058      1032
          G1     0.2083    0.6250    0.3125         8
    Anaphase     0.2202    0.6575    0.3299        73
          G2     0.2748    0.9623    0.4275      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2725      3872
   macro avg     0.4219    0.5354    0.3475      3872
weighted avg     0.3453    0.2725    0.1235      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch54
INFO:root:[55,    50] training loss: 0.02607850
INFO:root:[55,   100] training loss: 0.01562379
INFO:root:[55,   150] training loss: 0.01640499
INFO:root:[55,   200] training loss: 0.02214582
INFO:root:[55,   250] training loss: 0.02205886
INFO:root:[55,   300] training loss: 0.02108036
INFO:root:[55,   350] training loss: 0.02079740
INFO:root:[55,   400] training loss: 0.00029723
INFO:root:[55,   450] training loss: 0.00012557
INFO:root:[55,   500] training loss: 0.00179085
INFO:root:[55,   550] training loss: 0.00155203
INFO:root:[55,   600] training loss: 0.01448610
INFO:root:[55,   650] training loss: 0.00074306
INFO:root:[55,   700] training loss: 0.00044521
INFO:root:[55,   750] training loss: 0.00036339
INFO:root:[55,   800] training loss: 0.00027631
INFO:root:[55,   850] training loss: 0.00022489
INFO:root:[55,   900] training loss: 0.02871775
INFO:root:[55,   950] training loss: 0.02041047
INFO:root:[55,  1000] training loss: 0.00040046
INFO:root:[55,  1050] training loss: 0.00023760
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2381    0.6250    0.3448         8
    Anaphase     0.4018    0.6164    0.4865        73
          G2     0.2737    0.9874    0.4285      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2779      3872
   macro avg     0.3091    0.6041    0.3977      3872
weighted avg     0.0820    0.2779    0.1253      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch55
INFO:root:[56,    50] training loss: 0.02799263
INFO:root:[56,   100] training loss: 0.01686062
INFO:root:[56,   150] training loss: 0.01881221
INFO:root:[56,   200] training loss: 0.01591142
INFO:root:[56,   250] training loss: 0.01586668
INFO:root:[56,   300] training loss: 0.01774158
INFO:root:[56,   350] training loss: 0.01524323
INFO:root:[56,   400] training loss: 0.00020967
INFO:root:[56,   450] training loss: 0.00036574
INFO:root:[56,   500] training loss: 0.00125438
INFO:root:[56,   550] training loss: 0.00131554
INFO:root:[56,   600] training loss: 0.01269883
INFO:root:[56,   650] training loss: 0.00080459
INFO:root:[56,   700] training loss: 0.00044818
INFO:root:[56,   750] training loss: 0.00047019
INFO:root:[56,   800] training loss: 0.00031677
INFO:root:[56,   850] training loss: 0.00025320
INFO:root:[56,   900] training loss: 0.02705904
INFO:root:[56,   950] training loss: 0.01782450
INFO:root:[56,  1000] training loss: 0.00031891
INFO:root:[56,  1050] training loss: 0.00017263
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.0000    0.0000    0.0000      1032
          G1     0.2105    0.5000    0.2963         8
    Anaphase     0.2372    0.6986    0.3542        73
          G2     0.2793    0.9807    0.4347      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2774      3872
   macro avg     0.3062    0.5970    0.3918      3872
weighted avg     0.0804    0.2774    0.1245      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch56
INFO:root:[57,    50] training loss: 0.02538762
INFO:root:[57,   100] training loss: 0.01570100
INFO:root:[57,   150] training loss: 0.01640367
INFO:root:[57,   200] training loss: 0.01532092
INFO:root:[57,   250] training loss: 0.01464870
INFO:root:[57,   300] training loss: 0.01598250
INFO:root:[57,   350] training loss: 0.01391439
INFO:root:[57,   400] training loss: 0.00017886
INFO:root:[57,   450] training loss: 0.00009676
INFO:root:[57,   500] training loss: 0.00155211
INFO:root:[57,   550] training loss: 0.00085118
INFO:root:[57,   600] training loss: 0.01177778
INFO:root:[57,   650] training loss: 0.00065343
INFO:root:[57,   700] training loss: 0.00038651
INFO:root:[57,   750] training loss: 0.00045387
INFO:root:[57,   800] training loss: 0.00028770
INFO:root:[57,   850] training loss: 0.00022140
INFO:root:[57,   900] training loss: 0.02461093
INFO:root:[57,   950] training loss: 0.01646368
INFO:root:[57,  1000] training loss: 0.00025018
INFO:root:[57,  1050] training loss: 0.00014027
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     1.0000    0.0136    0.0268      1032
          G1     0.1905    0.5000    0.2759         8
    Anaphase     0.1929    0.7397    0.3059        73
          G2     0.2827    0.9710    0.4379      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.2792      3872
   macro avg     0.4761    0.6035    0.4066      3872
weighted avg     0.3472    0.2792    0.1316      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch57
INFO:root:[58,    50] training loss: 0.02303378
INFO:root:[58,   100] training loss: 0.01608431
INFO:root:[58,   150] training loss: 0.01541445
INFO:root:[58,   200] training loss: 0.01423590
INFO:root:[58,   250] training loss: 0.01470437
INFO:root:[58,   300] training loss: 0.01686588
INFO:root:[58,   350] training loss: 0.01401077
INFO:root:[58,   400] training loss: 0.00010000
INFO:root:[58,   450] training loss: 0.00013718
INFO:root:[58,   500] training loss: 0.00095229
INFO:root:[58,   550] training loss: 0.00091712
INFO:root:[58,   600] training loss: 0.01074518
INFO:root:[58,   650] training loss: 0.00069648
INFO:root:[58,   700] training loss: 0.00042291
INFO:root:[58,   750] training loss: 0.00044906
INFO:root:[58,   800] training loss: 0.00030985
INFO:root:[58,   850] training loss: 0.00023977
INFO:root:[58,   900] training loss: 0.02237062
INFO:root:[58,   950] training loss: 0.01517658
INFO:root:[58,  1000] training loss: 0.00019413
INFO:root:[58,  1050] training loss: 0.00011755
INFO:root:              precision    recall  f1-score   support

    Prophase     0.2500    1.0000    0.4000         2
           S     0.0000    0.0000    0.0000      1720
   Metaphase     0.9231    0.0349    0.0672      1032
          G1     0.1923    0.6250    0.2941         8
    Anaphase     0.1473    0.7808    0.2478        73
          G2     0.2858    0.9420    0.4385      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.2782      3872
   macro avg     0.3641    0.6261    0.3293      3872
weighted avg     0.3262    0.2782    0.1412      3872

INFO:root:Accuracy of the network on the 3872 validation images: 27 %
INFO:root:epoch58
INFO:root:[59,    50] training loss: 0.02175532
INFO:root:[59,   100] training loss: 0.01420458
INFO:root:[59,   150] training loss: 0.01529291
INFO:root:[59,   200] training loss: 0.01402938
INFO:root:[59,   250] training loss: 0.01432596
INFO:root:[59,   300] training loss: 0.01509719
INFO:root:[59,   350] training loss: 0.01281253
INFO:root:[59,   400] training loss: 0.00023426
INFO:root:[59,   450] training loss: 0.00010903
INFO:root:[59,   500] training loss: 0.00066432
INFO:root:[59,   550] training loss: 0.00088889
INFO:root:[59,   600] training loss: 0.00931836
INFO:root:[59,   650] training loss: 0.00066386
INFO:root:[59,   700] training loss: 0.00039202
INFO:root:[59,   750] training loss: 0.00050172
INFO:root:[59,   800] training loss: 0.00028506
INFO:root:[59,   850] training loss: 0.00021216
INFO:root:[59,   900] training loss: 0.02329644
INFO:root:[59,   950] training loss: 0.01232064
INFO:root:[59,  1000] training loss: 0.00013882
INFO:root:[59,  1050] training loss: 0.00007565
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8537    0.0203    0.0398      1720
   Metaphase     0.9118    0.1802    0.3010      1032
          G1     0.0930    0.5000    0.1569         8
    Anaphase     0.1873    0.7260    0.2978        73
          G2     0.2997    0.9545    0.4562      1034
   Telophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3280      3872
   macro avg     0.5160    0.6259    0.4002      3872
weighted avg     0.7068    0.3280    0.2266      3872

INFO:root:Accuracy of the network on the 3872 validation images: 32 %
INFO:root:epoch59
INFO:root:[60,    50] training loss: 0.01913797
INFO:root:[60,   100] training loss: 0.01416952
INFO:root:[60,   150] training loss: 0.01793177
INFO:root:[60,   200] training loss: 0.01450114
INFO:root:[60,   250] training loss: 0.01499610
INFO:root:[60,   300] training loss: 0.01663972
INFO:root:[60,   350] training loss: 0.01509023
INFO:root:[60,   400] training loss: 0.00018697
INFO:root:[60,   450] training loss: 0.00017011
INFO:root:[60,   500] training loss: 0.00085738
INFO:root:[60,   550] training loss: 0.00081696
INFO:root:[60,   600] training loss: 0.00985030
INFO:root:[60,   650] training loss: 0.00062898
INFO:root:[60,   700] training loss: 0.00036220
INFO:root:[60,   750] training loss: 0.00046843
INFO:root:[60,   800] training loss: 0.00027494
INFO:root:[60,   850] training loss: 0.00021488
INFO:root:[60,   900] training loss: 0.02401384
INFO:root:[60,   950] training loss: 0.01300464
INFO:root:[60,  1000] training loss: 0.00012522
INFO:root:[60,  1050] training loss: 0.00007426
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     0.8261    0.0110    0.0218      1720
   Metaphase     0.9500    0.1105    0.1979      1032
          G1     0.1667    0.6250    0.2632         8
    Anaphase     0.1738    0.7808    0.2843        73
          G2     0.2903    0.9449    0.4442      1034
   Telophase     1.0000    0.3333    0.5000         3

    accuracy                         0.3035      3872
   macro avg     0.5438    0.5436    0.3261      3872
weighted avg     0.7023    0.3035    0.1876      3872

INFO:root:Accuracy of the network on the 3872 validation images: 30 %
INFO:root:epoch60
INFO:root:[61,    50] training loss: 0.01985000
INFO:root:[61,   100] training loss: 0.01503976
INFO:root:[61,   150] training loss: 0.01659774
INFO:root:[61,   200] training loss: 0.01523628
INFO:root:[61,   250] training loss: 0.01451282
INFO:root:[61,   300] training loss: 0.01537282
INFO:root:[61,   350] training loss: 0.01310665
INFO:root:[61,   400] training loss: 0.00008586
INFO:root:[61,   450] training loss: 0.00007599
INFO:root:[61,   500] training loss: 0.00053669
INFO:root:[61,   550] training loss: 0.00062166
INFO:root:[61,   600] training loss: 0.00821763
INFO:root:[61,   650] training loss: 0.00057075
INFO:root:[61,   700] training loss: 0.00033882
INFO:root:[61,   750] training loss: 0.00044108
INFO:root:[61,   800] training loss: 0.00026465
INFO:root:[61,   850] training loss: 0.00021573
INFO:root:[61,   900] training loss: 0.02135717
INFO:root:[61,   950] training loss: 0.01155171
INFO:root:[61,  1000] training loss: 0.00008543
INFO:root:[61,  1050] training loss: 0.00005879
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.9434    0.0291    0.0564      1720
   Metaphase     0.8611    0.3963    0.5428      1032
          G1     0.2353    0.5000    0.3200         8
    Anaphase     0.1520    0.7808    0.2545        73
          G2     0.3081    0.8772    0.4560      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.3698      3872
   macro avg     0.5357    0.6548    0.4505      3872
weighted avg     0.7350    0.3698    0.2980      3872

INFO:root:Accuracy of the network on the 3872 validation images: 36 %
INFO:root:epoch61
INFO:root:[62,    50] training loss: 0.01894068
INFO:root:[62,   100] training loss: 0.01439368
INFO:root:[62,   150] training loss: 0.01505186
INFO:root:[62,   200] training loss: 0.01400601
INFO:root:[62,   250] training loss: 0.01622720
INFO:root:[62,   300] training loss: 0.01860781
INFO:root:[62,   350] training loss: 0.01354530
INFO:root:[62,   400] training loss: 0.00012628
INFO:root:[62,   450] training loss: 0.00007524
INFO:root:[62,   500] training loss: 0.00048095
INFO:root:[62,   550] training loss: 0.00064960
INFO:root:[62,   600] training loss: 0.00739156
INFO:root:[62,   650] training loss: 0.00063571
INFO:root:[62,   700] training loss: 0.00034114
INFO:root:[62,   750] training loss: 0.00049296
INFO:root:[62,   800] training loss: 0.00027941
INFO:root:[62,   850] training loss: 0.00020331
INFO:root:[62,   900] training loss: 0.02046443
INFO:root:[62,   950] training loss: 0.01098809
INFO:root:[62,  1000] training loss: 0.00007033
INFO:root:[62,  1050] training loss: 0.00004439
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9524    0.0233    0.0454      1720
   Metaphase     0.8291    0.4467    0.5806      1032
          G1     0.1613    0.6250    0.2564         8
    Anaphase     0.1723    0.6986    0.2764        73
          G2     0.3034    0.8627    0.4489      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.3755      3872
   macro avg     0.5479    0.6652    0.4664      3872
weighted avg     0.7296    0.3755    0.3016      3872

INFO:root:Accuracy of the network on the 3872 validation images: 37 %
INFO:root:epoch62
INFO:root:[63,    50] training loss: 0.01765997
INFO:root:[63,   100] training loss: 0.01508167
INFO:root:[63,   150] training loss: 0.01552292
INFO:root:[63,   200] training loss: 0.01444365
INFO:root:[63,   250] training loss: 0.01380820
INFO:root:[63,   300] training loss: 0.01676966
INFO:root:[63,   350] training loss: 0.01311417
INFO:root:[63,   400] training loss: 0.00006959
INFO:root:[63,   450] training loss: 0.00007073
INFO:root:[63,   500] training loss: 0.00048258
INFO:root:[63,   550] training loss: 0.00057557
INFO:root:[63,   600] training loss: 0.00736583
INFO:root:[63,   650] training loss: 0.00052245
INFO:root:[63,   700] training loss: 0.00032650
INFO:root:[63,   750] training loss: 0.00037789
INFO:root:[63,   800] training loss: 0.00023982
INFO:root:[63,   850] training loss: 0.00016317
INFO:root:[63,   900] training loss: 0.02292467
INFO:root:[63,   950] training loss: 0.01207621
INFO:root:[63,  1000] training loss: 0.00009008
INFO:root:[63,  1050] training loss: 0.00006072
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.8966    0.0302    0.0585      1720
   Metaphase     0.9071    0.1609    0.2733      1032
          G1     0.1556    0.8750    0.2642         8
    Anaphase     0.2286    0.5479    0.3226        73
          G2     0.2928    0.9632    0.4491      1034
   Telophase     0.6000    1.0000    0.7500         3

    accuracy                         0.3270      3872
   macro avg     0.5115    0.6539    0.3977      3872
weighted avg     0.7236    0.3270    0.2263      3872

INFO:root:Accuracy of the network on the 3872 validation images: 32 %
INFO:root:epoch63
INFO:root:[64,    50] training loss: 0.01829658
INFO:root:[64,   100] training loss: 0.01466476
INFO:root:[64,   150] training loss: 0.01727993
INFO:root:[64,   200] training loss: 0.01467393
INFO:root:[64,   250] training loss: 0.01394981
INFO:root:[64,   300] training loss: 0.01458555
INFO:root:[64,   350] training loss: 0.01229600
INFO:root:[64,   400] training loss: 0.00006849
INFO:root:[64,   450] training loss: 0.00013519
INFO:root:[64,   500] training loss: 0.00058915
INFO:root:[64,   550] training loss: 0.00070365
INFO:root:[64,   600] training loss: 0.00740555
INFO:root:[64,   650] training loss: 0.00052494
INFO:root:[64,   700] training loss: 0.00031069
INFO:root:[64,   750] training loss: 0.00045408
INFO:root:[64,   800] training loss: 0.00024498
INFO:root:[64,   850] training loss: 0.00019312
INFO:root:[64,   900] training loss: 0.01950692
INFO:root:[64,   950] training loss: 0.00883356
INFO:root:[64,  1000] training loss: 0.00007384
INFO:root:[64,  1050] training loss: 0.00003933
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9508    0.1012    0.1829      1720
   Metaphase     0.8098    0.4952    0.6146      1032
          G1     0.2632    0.6250    0.3704         8
    Anaphase     0.1786    0.8219    0.2934        73
          G2     0.3238    0.8443    0.4681      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.4205      3872
   macro avg     0.5633    0.6982    0.5123      3872
weighted avg     0.7295    0.4205    0.3774      3872

INFO:root:Accuracy of the network on the 3872 validation images: 42 %
INFO:root:epoch64
INFO:root:[65,    50] training loss: 0.01626571
INFO:root:[65,   100] training loss: 0.01373188
INFO:root:[65,   150] training loss: 0.01771443
INFO:root:[65,   200] training loss: 0.01378707
INFO:root:[65,   250] training loss: 0.01443487
INFO:root:[65,   300] training loss: 0.01569240
INFO:root:[65,   350] training loss: 0.01372232
INFO:root:[65,   400] training loss: 0.00010402
INFO:root:[65,   450] training loss: 0.00018575
INFO:root:[65,   500] training loss: 0.00046662
INFO:root:[65,   550] training loss: 0.00061547
INFO:root:[65,   600] training loss: 0.00652396
INFO:root:[65,   650] training loss: 0.00044613
INFO:root:[65,   700] training loss: 0.00027011
INFO:root:[65,   750] training loss: 0.00040056
INFO:root:[65,   800] training loss: 0.00023031
INFO:root:[65,   850] training loss: 0.00016056
INFO:root:[65,   900] training loss: 0.01914151
INFO:root:[65,   950] training loss: 0.00691660
INFO:root:[65,  1000] training loss: 0.00006411
INFO:root:[65,  1050] training loss: 0.00004060
INFO:root:              precision    recall  f1-score   support

    Prophase     0.4000    1.0000    0.5714         2
           S     0.9325    0.2250    0.3625      1720
   Metaphase     0.6622    0.5795    0.6181      1032
          G1     0.1224    0.7500    0.2105         8
    Anaphase     0.1213    0.7808    0.2099        73
          G2     0.3202    0.6277    0.4240      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.4396      3872
   macro avg     0.5084    0.7090    0.4852      3872
weighted avg     0.6798    0.4396    0.4445      3872

INFO:root:Accuracy of the network on the 3872 validation images: 43 %
INFO:root:epoch65
INFO:root:[66,    50] training loss: 0.01759904
INFO:root:[66,   100] training loss: 0.01484931
INFO:root:[66,   150] training loss: 0.01472182
INFO:root:[66,   200] training loss: 0.01343928
INFO:root:[66,   250] training loss: 0.01532903
INFO:root:[66,   300] training loss: 0.01552138
INFO:root:[66,   350] training loss: 0.01271264
INFO:root:[66,   400] training loss: 0.00005580
INFO:root:[66,   450] training loss: 0.00005299
INFO:root:[66,   500] training loss: 0.00041599
INFO:root:[66,   550] training loss: 0.00050796
INFO:root:[66,   600] training loss: 0.00513070
INFO:root:[66,   650] training loss: 0.00043835
INFO:root:[66,   700] training loss: 0.00023408
INFO:root:[66,   750] training loss: 0.00042600
INFO:root:[66,   800] training loss: 0.00022971
INFO:root:[66,   850] training loss: 0.00015029
INFO:root:[66,   900] training loss: 0.01735437
INFO:root:[66,   950] training loss: 0.00679977
INFO:root:[66,  1000] training loss: 0.00004089
INFO:root:[66,  1050] training loss: 0.00003021
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9394    0.3424    0.5019      1720
   Metaphase     0.7246    0.6628    0.6923      1032
          G1     0.2069    0.7500    0.3243         8
    Anaphase     0.1579    0.7808    0.2627        73
          G2     0.3619    0.6663    0.4690      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.5243      3872
   macro avg     0.5439    0.7432    0.5582      3872
weighted avg     0.7114    0.5243    0.5394      3872

INFO:root:Accuracy of the network on the 3872 validation images: 52 %
INFO:root:epoch66
INFO:root:[67,    50] training loss: 0.01554467
INFO:root:[67,   100] training loss: 0.01457106
INFO:root:[67,   150] training loss: 0.01478816
INFO:root:[67,   200] training loss: 0.01500146
INFO:root:[67,   250] training loss: 0.01444680
INFO:root:[67,   300] training loss: 0.01504603
INFO:root:[67,   350] training loss: 0.01393776
INFO:root:[67,   400] training loss: 0.00004074
INFO:root:[67,   450] training loss: 0.00005261
INFO:root:[67,   500] training loss: 0.00033260
INFO:root:[67,   550] training loss: 0.00042958
INFO:root:[67,   600] training loss: 0.00471760
INFO:root:[67,   650] training loss: 0.00044690
INFO:root:[67,   700] training loss: 0.00024609
INFO:root:[67,   750] training loss: 0.00042947
INFO:root:[67,   800] training loss: 0.00023129
INFO:root:[67,   850] training loss: 0.00016824
INFO:root:[67,   900] training loss: 0.01660107
INFO:root:[67,   950] training loss: 0.00527722
INFO:root:[67,  1000] training loss: 0.00006376
INFO:root:[67,  1050] training loss: 0.00003819
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9294    0.5128    0.6609      1720
   Metaphase     0.6206    0.7229    0.6679      1032
          G1     0.3125    0.6250    0.4167         8
    Anaphase     0.1657    0.8219    0.2759        73
          G2     0.3725    0.4816    0.4201      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.5671      3872
   macro avg     0.5811    0.7377    0.6059      3872
weighted avg     0.6826    0.5671    0.5910      3872

INFO:root:Accuracy of the network on the 3872 validation images: 56 %
INFO:root:epoch67
INFO:root:[68,    50] training loss: 0.01464239
INFO:root:[68,   100] training loss: 0.01353245
INFO:root:[68,   150] training loss: 0.01467244
INFO:root:[68,   200] training loss: 0.01253871
INFO:root:[68,   250] training loss: 0.01348547
INFO:root:[68,   300] training loss: 0.01411483
INFO:root:[68,   350] training loss: 0.01225988
INFO:root:[68,   400] training loss: 0.00004130
INFO:root:[68,   450] training loss: 0.00005981
INFO:root:[68,   500] training loss: 0.00030680
INFO:root:[68,   550] training loss: 0.00043688
INFO:root:[68,   600] training loss: 0.00424784
INFO:root:[68,   650] training loss: 0.00039189
INFO:root:[68,   700] training loss: 0.00021891
INFO:root:[68,   750] training loss: 0.00043953
INFO:root:[68,   800] training loss: 0.00021621
INFO:root:[68,   850] training loss: 0.00014929
INFO:root:[68,   900] training loss: 0.01901894
INFO:root:[68,   950] training loss: 0.00468126
INFO:root:[68,  1000] training loss: 0.00009473
INFO:root:[68,  1050] training loss: 0.00004777
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9246    0.5279    0.6721      1720
   Metaphase     0.5805    0.6880    0.6297      1032
          G1     0.2000    0.5000    0.2857         8
    Anaphase     0.1625    0.8904    0.2748        73
          G2     0.3613    0.4333    0.3940      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.5527      3872
   macro avg     0.5208    0.7199    0.5591      3872
weighted avg     0.6664    0.5527    0.5785      3872

INFO:root:Accuracy of the network on the 3872 validation images: 55 %
INFO:root:epoch68
INFO:root:[69,    50] training loss: 0.01422847
INFO:root:[69,   100] training loss: 0.01466590
INFO:root:[69,   150] training loss: 0.01450024
INFO:root:[69,   200] training loss: 0.01239304
INFO:root:[69,   250] training loss: 0.01339308
INFO:root:[69,   300] training loss: 0.01440758
INFO:root:[69,   350] training loss: 0.01206224
INFO:root:[69,   400] training loss: 0.00003502
INFO:root:[69,   450] training loss: 0.00004758
INFO:root:[69,   500] training loss: 0.00019954
INFO:root:[69,   550] training loss: 0.00044471
INFO:root:[69,   600] training loss: 0.00356127
INFO:root:[69,   650] training loss: 0.00035112
INFO:root:[69,   700] training loss: 0.00018564
INFO:root:[69,   750] training loss: 0.00042640
INFO:root:[69,   800] training loss: 0.00018175
INFO:root:[69,   850] training loss: 0.00013588
INFO:root:[69,   900] training loss: 0.01553974
INFO:root:[69,   950] training loss: 0.00496728
INFO:root:[69,  1000] training loss: 0.00009534
INFO:root:[69,  1050] training loss: 0.00004439
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9179    0.5657    0.7000      1720
   Metaphase     0.6478    0.7645    0.7013      1032
          G1     0.2632    0.6250    0.3704         8
    Anaphase     0.1981    0.8356    0.3202        73
          G2     0.4163    0.5077    0.4575      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6090      3872
   macro avg     0.5871    0.7569    0.6213      3872
weighted avg     0.6970    0.6090    0.6280      3872

INFO:root:Accuracy of the network on the 3872 validation images: 60 %
INFO:root:epoch69
INFO:root:[70,    50] training loss: 0.01419218
INFO:root:[70,   100] training loss: 0.01333716
INFO:root:[70,   150] training loss: 0.01644437
INFO:root:[70,   200] training loss: 0.01303822
INFO:root:[70,   250] training loss: 0.01367476
INFO:root:[70,   300] training loss: 0.01483173
INFO:root:[70,   350] training loss: 0.01289312
INFO:root:[70,   400] training loss: 0.00006115
INFO:root:[70,   450] training loss: 0.00005834
INFO:root:[70,   500] training loss: 0.00022851
INFO:root:[70,   550] training loss: 0.00045361
INFO:root:[70,   600] training loss: 0.00433140
INFO:root:[70,   650] training loss: 0.00031168
INFO:root:[70,   700] training loss: 0.00020344
INFO:root:[70,   750] training loss: 0.00041166
INFO:root:[70,   800] training loss: 0.00021790
INFO:root:[70,   850] training loss: 0.00014974
INFO:root:[70,   900] training loss: 0.01630031
INFO:root:[70,   950] training loss: 0.00465725
INFO:root:[70,  1000] training loss: 0.00004441
INFO:root:[70,  1050] training loss: 0.00003445
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9265    0.5866    0.7184      1720
   Metaphase     0.6720    0.7781    0.7211      1032
          G1     0.4167    0.6250    0.5000         8
    Anaphase     0.2470    0.8356    0.3813        73
          G2     0.4437    0.5677    0.4981      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6379      3872
   macro avg     0.6246    0.7704    0.6598      3872
weighted avg     0.7158    0.6379    0.6538      3872

INFO:root:Accuracy of the network on the 3872 validation images: 63 %
INFO:root:epoch70
INFO:root:[71,    50] training loss: 0.01334483
INFO:root:[71,   100] training loss: 0.01341250
INFO:root:[71,   150] training loss: 0.01537815
INFO:root:[71,   200] training loss: 0.01321153
INFO:root:[71,   250] training loss: 0.01289165
INFO:root:[71,   300] training loss: 0.01480636
INFO:root:[71,   350] training loss: 0.01448847
INFO:root:[71,   400] training loss: 0.00010381
INFO:root:[71,   450] training loss: 0.00006878
INFO:root:[71,   500] training loss: 0.00083525
INFO:root:[71,   550] training loss: 0.00033188
INFO:root:[71,   600] training loss: 0.00453443
INFO:root:[71,   650] training loss: 0.00028392
INFO:root:[71,   700] training loss: 0.00016993
INFO:root:[71,   750] training loss: 0.00040115
INFO:root:[71,   800] training loss: 0.00019246
INFO:root:[71,   850] training loss: 0.00012002
INFO:root:[71,   900] training loss: 0.01733526
INFO:root:[71,   950] training loss: 0.00410174
INFO:root:[71,  1000] training loss: 0.00004936
INFO:root:[71,  1050] training loss: 0.00005602
INFO:root:              precision    recall  f1-score   support

    Prophase     0.5000    1.0000    0.6667         2
           S     0.9034    0.6471    0.7541      1720
   Metaphase     0.7064    0.7578    0.7312      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.2353    0.7671    0.3601        73
          G2     0.4824    0.5977    0.5339      1034
   Telophase     1.0000    0.3333    0.5000         3

    accuracy                         0.6653      3872
   macro avg     0.6103    0.6576    0.5738      3872
weighted avg     0.7248    0.6653    0.6809      3872

INFO:root:Accuracy of the network on the 3872 validation images: 66 %
INFO:root:epoch71
INFO:root:[72,    50] training loss: 0.01809377
INFO:root:[72,   100] training loss: 0.01393108
INFO:root:[72,   150] training loss: 0.01386446
INFO:root:[72,   200] training loss: 0.01377916
INFO:root:[72,   250] training loss: 0.01265383
INFO:root:[72,   300] training loss: 0.01462819
INFO:root:[72,   350] training loss: 0.01161364
INFO:root:[72,   400] training loss: 0.00005503
INFO:root:[72,   450] training loss: 0.00035248
INFO:root:[72,   500] training loss: 0.00018441
INFO:root:[72,   550] training loss: 0.00037200
INFO:root:[72,   600] training loss: 0.00284291
INFO:root:[72,   650] training loss: 0.00026717
INFO:root:[72,   700] training loss: 0.00014807
INFO:root:[72,   750] training loss: 0.00040660
INFO:root:[72,   800] training loss: 0.00018935
INFO:root:[72,   850] training loss: 0.00011353
INFO:root:[72,   900] training loss: 0.01546101
INFO:root:[72,   950] training loss: 0.00516404
INFO:root:[72,  1000] training loss: 0.00006955
INFO:root:[72,  1050] training loss: 0.00003967
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8819    0.7209    0.7933      1720
   Metaphase     0.6526    0.7955    0.7170      1032
          G1     0.2222    0.5000    0.3077         8
    Anaphase     0.2735    0.8356    0.4122        73
          G2     0.4990    0.4632    0.4804      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.6741      3872
   macro avg     0.5637    0.7593    0.6240      3872
weighted avg     0.7055    0.6741    0.6813      3872

INFO:root:Accuracy of the network on the 3872 validation images: 67 %
INFO:root:epoch72
INFO:root:[73,    50] training loss: 0.01352777
INFO:root:[73,   100] training loss: 0.01347696
INFO:root:[73,   150] training loss: 0.01375837
INFO:root:[73,   200] training loss: 0.01359135
INFO:root:[73,   250] training loss: 0.01276269
INFO:root:[73,   300] training loss: 0.01293748
INFO:root:[73,   350] training loss: 0.01246541
INFO:root:[73,   400] training loss: 0.00005567
INFO:root:[73,   450] training loss: 0.00008082
INFO:root:[73,   500] training loss: 0.00028010
INFO:root:[73,   550] training loss: 0.00034441
INFO:root:[73,   600] training loss: 0.00285163
INFO:root:[73,   650] training loss: 0.00027455
INFO:root:[73,   700] training loss: 0.00014223
INFO:root:[73,   750] training loss: 0.00042679
INFO:root:[73,   800] training loss: 0.00018219
INFO:root:[73,   850] training loss: 0.00010758
INFO:root:[73,   900] training loss: 0.01519277
INFO:root:[73,   950] training loss: 0.00361048
INFO:root:[73,  1000] training loss: 0.00007792
INFO:root:[73,  1050] training loss: 0.00004428
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8936    0.7273    0.8019      1720
   Metaphase     0.6624    0.8062    0.7273      1032
          G1     0.1852    0.6250    0.2857         8
    Anaphase     0.2365    0.6575    0.3478        73
          G2     0.5173    0.4903    0.5035      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6839      3872
   macro avg     0.5945    0.7581    0.6380      3872
weighted avg     0.7176    0.6839    0.6929      3872

INFO:root:Accuracy of the network on the 3872 validation images: 68 %
INFO:root:epoch73
INFO:root:[74,    50] training loss: 0.01437100
INFO:root:[74,   100] training loss: 0.01342430
INFO:root:[74,   150] training loss: 0.01380842
INFO:root:[74,   200] training loss: 0.01269622
INFO:root:[74,   250] training loss: 0.01218822
INFO:root:[74,   300] training loss: 0.01428779
INFO:root:[74,   350] training loss: 0.01215694
INFO:root:[74,   400] training loss: 0.00003917
INFO:root:[74,   450] training loss: 0.00006170
INFO:root:[74,   500] training loss: 0.00014309
INFO:root:[74,   550] training loss: 0.00037003
INFO:root:[74,   600] training loss: 0.00240838
INFO:root:[74,   650] training loss: 0.00021520
INFO:root:[74,   700] training loss: 0.00011990
INFO:root:[74,   750] training loss: 0.00039681
INFO:root:[74,   800] training loss: 0.00015225
INFO:root:[74,   850] training loss: 0.00010207
INFO:root:[74,   900] training loss: 0.01366398
INFO:root:[74,   950] training loss: 0.00316443
INFO:root:[74,  1000] training loss: 0.00008565
INFO:root:[74,  1050] training loss: 0.00003825
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8953    0.7355    0.8075      1720
   Metaphase     0.6749    0.8169    0.7391      1032
          G1     0.2174    0.6250    0.3226         8
    Anaphase     0.2548    0.7260    0.3772        73
          G2     0.5262    0.4952    0.5102      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6929      3872
   macro avg     0.6050    0.7712    0.6510      3872
weighted avg     0.7245    0.6929    0.7009      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch74
INFO:root:[75,    50] training loss: 0.01269420
INFO:root:[75,   100] training loss: 0.01546381
INFO:root:[75,   150] training loss: 0.01399276
INFO:root:[75,   200] training loss: 0.01223219
INFO:root:[75,   250] training loss: 0.01190480
INFO:root:[75,   300] training loss: 0.01374914
INFO:root:[75,   350] training loss: 0.01613217
INFO:root:[75,   400] training loss: 0.00005710
INFO:root:[75,   450] training loss: 0.00005563
INFO:root:[75,   500] training loss: 0.00021803
INFO:root:[75,   550] training loss: 0.00043424
INFO:root:[75,   600] training loss: 0.00292979
INFO:root:[75,   650] training loss: 0.00022126
INFO:root:[75,   700] training loss: 0.00011995
INFO:root:[75,   750] training loss: 0.00033452
INFO:root:[75,   800] training loss: 0.00014213
INFO:root:[75,   850] training loss: 0.00009508
INFO:root:[75,   900] training loss: 0.01606485
INFO:root:[75,   950] training loss: 0.00384644
INFO:root:[75,  1000] training loss: 0.00003867
INFO:root:[75,  1050] training loss: 0.00002353
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8939    0.7442    0.8122      1720
   Metaphase     0.7412    0.7742    0.7573      1032
          G1     0.3333    0.5000    0.4000         8
    Anaphase     0.3030    0.8219    0.4428        73
          G2     0.5541    0.6141    0.5826      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7188      3872
   macro avg     0.6417    0.7792    0.6850      3872
weighted avg     0.7501    0.7188    0.7286      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch75
INFO:root:[76,    50] training loss: 0.01250912
INFO:root:[76,   100] training loss: 0.01247393
INFO:root:[76,   150] training loss: 0.01271245
INFO:root:[76,   200] training loss: 0.01245895
INFO:root:[76,   250] training loss: 0.01239585
INFO:root:[76,   300] training loss: 0.01384213
INFO:root:[76,   350] training loss: 0.01081862
INFO:root:[76,   400] training loss: 0.00003521
INFO:root:[76,   450] training loss: 0.00003869
INFO:root:[76,   500] training loss: 0.00014372
INFO:root:[76,   550] training loss: 0.00040121
INFO:root:[76,   600] training loss: 0.00210567
INFO:root:[76,   650] training loss: 0.00019068
INFO:root:[76,   700] training loss: 0.00012442
INFO:root:[76,   750] training loss: 0.00040416
INFO:root:[76,   800] training loss: 0.00014866
INFO:root:[76,   850] training loss: 0.00008460
INFO:root:[76,   900] training loss: 0.01244222
INFO:root:[76,   950] training loss: 0.00298187
INFO:root:[76,  1000] training loss: 0.00007704
INFO:root:[76,  1050] training loss: 0.00003840
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8921    0.7500    0.8149      1720
   Metaphase     0.6584    0.8275    0.7334      1032
          G1     0.5000    0.5000    0.5000         8
    Anaphase     0.3010    0.8493    0.4444        73
          G2     0.5237    0.4603    0.4900      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6950      3872
   macro avg     0.6488    0.7696    0.6832      3872
weighted avg     0.7195    0.6950    0.6989      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch76
INFO:root:[77,    50] training loss: 0.01283894
INFO:root:[77,   100] training loss: 0.01232736
INFO:root:[77,   150] training loss: 0.01300319
INFO:root:[77,   200] training loss: 0.01279628
INFO:root:[77,   250] training loss: 0.01158677
INFO:root:[77,   300] training loss: 0.01269332
INFO:root:[77,   350] training loss: 0.01234015
INFO:root:[77,   400] training loss: 0.00006438
INFO:root:[77,   450] training loss: 0.00003482
INFO:root:[77,   500] training loss: 0.00020096
INFO:root:[77,   550] training loss: 0.00046945
INFO:root:[77,   600] training loss: 0.00238553
INFO:root:[77,   650] training loss: 0.00017572
INFO:root:[77,   700] training loss: 0.00009667
INFO:root:[77,   750] training loss: 0.00045343
INFO:root:[77,   800] training loss: 0.00011002
INFO:root:[77,   850] training loss: 0.00008311
INFO:root:[77,   900] training loss: 0.01349173
INFO:root:[77,   950] training loss: 0.00330146
INFO:root:[77,  1000] training loss: 0.00006692
INFO:root:[77,  1050] training loss: 0.00003066
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9114    0.7116    0.7992      1720
   Metaphase     0.6541    0.8227    0.7288      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.2748    0.8356    0.4136        73
          G2     0.4950    0.4758    0.4852      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6805      3872
   macro avg     0.6352    0.7637    0.6710      3872
weighted avg     0.7186    0.6805    0.6888      3872

INFO:root:Accuracy of the network on the 3872 validation images: 68 %
INFO:root:epoch77
INFO:root:[78,    50] training loss: 0.01161801
INFO:root:[78,   100] training loss: 0.01229803
INFO:root:[78,   150] training loss: 0.01292483
INFO:root:[78,   200] training loss: 0.01449858
INFO:root:[78,   250] training loss: 0.01263254
INFO:root:[78,   300] training loss: 0.01296749
INFO:root:[78,   350] training loss: 0.01158083
INFO:root:[78,   400] training loss: 0.00004692
INFO:root:[78,   450] training loss: 0.00007157
INFO:root:[78,   500] training loss: 0.00015389
INFO:root:[78,   550] training loss: 0.00028921
INFO:root:[78,   600] training loss: 0.00199260
INFO:root:[78,   650] training loss: 0.00016990
INFO:root:[78,   700] training loss: 0.00010188
INFO:root:[78,   750] training loss: 0.00051401
INFO:root:[78,   800] training loss: 0.00013312
INFO:root:[78,   850] training loss: 0.00010474
INFO:root:[78,   900] training loss: 0.01385701
INFO:root:[78,   950] training loss: 0.00292358
INFO:root:[78,  1000] training loss: 0.00005539
INFO:root:[78,  1050] training loss: 0.00003894
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9119    0.7105    0.7987      1720
   Metaphase     0.6954    0.8052    0.7463      1032
          G1     0.1316    0.6250    0.2174         8
    Anaphase     0.2844    0.8219    0.4225        73
          G2     0.5268    0.5513    0.5388      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.6955      3872
   macro avg     0.6024    0.7877    0.6462      3872
weighted avg     0.7379    0.6955    0.7072      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch78
INFO:root:[79,    50] training loss: 0.01180266
INFO:root:[79,   100] training loss: 0.01266081
INFO:root:[79,   150] training loss: 0.01413436
INFO:root:[79,   200] training loss: 0.01251421
INFO:root:[79,   250] training loss: 0.01297434
INFO:root:[79,   300] training loss: 0.01695935
INFO:root:[79,   350] training loss: 0.01151347
INFO:root:[79,   400] training loss: 0.00007085
INFO:root:[79,   450] training loss: 0.00003548
INFO:root:[79,   500] training loss: 0.00018013
INFO:root:[79,   550] training loss: 0.00033118
INFO:root:[79,   600] training loss: 0.00171122
INFO:root:[79,   650] training loss: 0.00016115
INFO:root:[79,   700] training loss: 0.00010989
INFO:root:[79,   750] training loss: 0.00049198
INFO:root:[79,   800] training loss: 0.00012276
INFO:root:[79,   850] training loss: 0.00008951
INFO:root:[79,   900] training loss: 0.01278054
INFO:root:[79,   950] training loss: 0.00263776
INFO:root:[79,  1000] training loss: 0.00007540
INFO:root:[79,  1050] training loss: 0.00003717
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9019    0.8070    0.8518      1720
   Metaphase     0.6838    0.8382    0.7532      1032
          G1     0.2941    0.6250    0.4000         8
    Anaphase     0.3027    0.7671    0.4341        73
          G2     0.5977    0.4971    0.5428      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7317      3872
   macro avg     0.6353    0.7906    0.6831      3872
weighted avg     0.7499    0.7317    0.7343      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch79
INFO:root:[80,    50] training loss: 0.01168314
INFO:root:[80,   100] training loss: 0.01387900
INFO:root:[80,   150] training loss: 0.01281150
INFO:root:[80,   200] training loss: 0.01201852
INFO:root:[80,   250] training loss: 0.01096201
INFO:root:[80,   300] training loss: 0.01320491
INFO:root:[80,   350] training loss: 0.01244408
INFO:root:[80,   400] training loss: 0.00011264
INFO:root:[80,   450] training loss: 0.00003707
INFO:root:[80,   500] training loss: 0.00015587
INFO:root:[80,   550] training loss: 0.00023533
INFO:root:[80,   600] training loss: 0.00167675
INFO:root:[80,   650] training loss: 0.00015157
INFO:root:[80,   700] training loss: 0.00008931
INFO:root:[80,   750] training loss: 0.00044727
INFO:root:[80,   800] training loss: 0.00014138
INFO:root:[80,   850] training loss: 0.00007755
INFO:root:[80,   900] training loss: 0.01165207
INFO:root:[80,   950] training loss: 0.00321948
INFO:root:[80,  1000] training loss: 0.00007218
INFO:root:[80,  1050] training loss: 0.00004493
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8911    0.7988    0.8424      1720
   Metaphase     0.6712    0.8130    0.7353      1032
          G1     0.4167    0.6250    0.5000         8
    Anaphase     0.2976    0.8356    0.4388        73
          G2     0.5759    0.4768    0.5217      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7172      3872
   macro avg     0.6099    0.7927    0.6708      3872
weighted avg     0.7359    0.7172    0.7199      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch80
INFO:root:[81,    50] training loss: 0.01096908
INFO:root:[81,   100] training loss: 0.01374465
INFO:root:[81,   150] training loss: 0.01210630
INFO:root:[81,   200] training loss: 0.01106239
INFO:root:[81,   250] training loss: 0.01075674
INFO:root:[81,   300] training loss: 0.01341748
INFO:root:[81,   350] training loss: 0.01166735
INFO:root:[81,   400] training loss: 0.00004797
INFO:root:[81,   450] training loss: 0.00002779
INFO:root:[81,   500] training loss: 0.00011094
INFO:root:[81,   550] training loss: 0.00029932
INFO:root:[81,   600] training loss: 0.00130139
INFO:root:[81,   650] training loss: 0.00012450
INFO:root:[81,   700] training loss: 0.00008142
INFO:root:[81,   750] training loss: 0.00045469
INFO:root:[81,   800] training loss: 0.00011886
INFO:root:[81,   850] training loss: 0.00007281
INFO:root:[81,   900] training loss: 0.01208399
INFO:root:[81,   950] training loss: 0.00292184
INFO:root:[81,  1000] training loss: 0.00005088
INFO:root:[81,  1050] training loss: 0.00003825
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9041    0.7837    0.8396      1720
   Metaphase     0.6980    0.8266    0.7569      1032
          G1     0.3077    0.5000    0.3810         8
    Anaphase     0.3295    0.7945    0.4659        73
          G2     0.5788    0.5397    0.5586      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7299      3872
   macro avg     0.6407    0.7778    0.6860      3872
weighted avg     0.7502    0.7299    0.7346      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch81
INFO:root:[82,    50] training loss: 0.01229245
INFO:root:[82,   100] training loss: 0.01238452
INFO:root:[82,   150] training loss: 0.01268682
INFO:root:[82,   200] training loss: 0.01108359
INFO:root:[82,   250] training loss: 0.01133099
INFO:root:[82,   300] training loss: 0.01237048
INFO:root:[82,   350] training loss: 0.01152214
INFO:root:[82,   400] training loss: 0.00002017
INFO:root:[82,   450] training loss: 0.00001826
INFO:root:[82,   500] training loss: 0.00010293
INFO:root:[82,   550] training loss: 0.00033991
INFO:root:[82,   600] training loss: 0.00121426
INFO:root:[82,   650] training loss: 0.00014747
INFO:root:[82,   700] training loss: 0.00008027
INFO:root:[82,   750] training loss: 0.00044544
INFO:root:[82,   800] training loss: 0.00011103
INFO:root:[82,   850] training loss: 0.00007267
INFO:root:[82,   900] training loss: 0.01077640
INFO:root:[82,   950] training loss: 0.00263112
INFO:root:[82,  1000] training loss: 0.00005025
INFO:root:[82,  1050] training loss: 0.00002605
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8967    0.7924    0.8414      1720
   Metaphase     0.6809    0.8333    0.7495      1032
          G1     0.2353    0.5000    0.3200         8
    Anaphase     0.3136    0.7260    0.4380        73
          G2     0.5741    0.4981    0.5334      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7231      3872
   macro avg     0.6239    0.7643    0.6689      3872
weighted avg     0.7407    0.7231    0.7260      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch82
INFO:root:[83,    50] training loss: 0.01104121
INFO:root:[83,   100] training loss: 0.01138525
INFO:root:[83,   150] training loss: 0.01228533
INFO:root:[83,   200] training loss: 0.01161178
INFO:root:[83,   250] training loss: 0.01287555
INFO:root:[83,   300] training loss: 0.01376192
INFO:root:[83,   350] training loss: 0.01366169
INFO:root:[83,   400] training loss: 0.00004015
INFO:root:[83,   450] training loss: 0.00004722
INFO:root:[83,   500] training loss: 0.00024151
INFO:root:[83,   550] training loss: 0.00047507
INFO:root:[83,   600] training loss: 0.00235327
INFO:root:[83,   650] training loss: 0.00012417
INFO:root:[83,   700] training loss: 0.00008768
INFO:root:[83,   750] training loss: 0.00035513
INFO:root:[83,   800] training loss: 0.00011891
INFO:root:[83,   850] training loss: 0.00007454
INFO:root:[83,   900] training loss: 0.01356892
INFO:root:[83,   950] training loss: 0.00328495
INFO:root:[83,  1000] training loss: 0.00006249
INFO:root:[83,  1050] training loss: 0.00003431
INFO:root:              precision    recall  f1-score   support

    Prophase     0.3333    1.0000    0.5000         2
           S     0.9180    0.7419    0.8206      1720
   Metaphase     0.6502    0.8178    0.7245      1032
          G1     0.2857    0.7500    0.4138         8
    Anaphase     0.2670    0.7534    0.3943        73
          G2     0.5268    0.4845    0.5048      1034
   Telophase     0.0000    0.0000    0.0000         3

    accuracy                         0.6932      3872
   macro avg     0.4259    0.6497    0.4797      3872
weighted avg     0.7276    0.6932    0.7010      3872

INFO:root:Accuracy of the network on the 3872 validation images: 69 %
INFO:root:epoch83
INFO:root:[84,    50] training loss: 0.01603455
INFO:root:[84,   100] training loss: 0.01219529
INFO:root:[84,   150] training loss: 0.01240285
INFO:root:[84,   200] training loss: 0.01206312
INFO:root:[84,   250] training loss: 0.01295533
INFO:root:[84,   300] training loss: 0.01248049
INFO:root:[84,   350] training loss: 0.01006465
INFO:root:[84,   400] training loss: 0.00003657
INFO:root:[84,   450] training loss: 0.00004607
INFO:root:[84,   500] training loss: 0.00014666
INFO:root:[84,   550] training loss: 0.00020726
INFO:root:[84,   600] training loss: 0.00123194
INFO:root:[84,   650] training loss: 0.00013022
INFO:root:[84,   700] training loss: 0.00007782
INFO:root:[84,   750] training loss: 0.00048103
INFO:root:[84,   800] training loss: 0.00009775
INFO:root:[84,   850] training loss: 0.00005939
INFO:root:[84,   900] training loss: 0.01106499
INFO:root:[84,   950] training loss: 0.00230146
INFO:root:[84,  1000] training loss: 0.00006663
INFO:root:[84,  1050] training loss: 0.00003159
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8963    0.8041    0.8477      1720
   Metaphase     0.6979    0.8508    0.7668      1032
          G1     0.4545    0.6250    0.5263         8
    Anaphase     0.3782    0.8082    0.5153        73
          G2     0.5947    0.5164    0.5528      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7397      3872
   macro avg     0.6698    0.8006    0.7156      3872
weighted avg     0.7522    0.7397    0.7405      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch84
INFO:root:[85,    50] training loss: 0.01056479
INFO:root:[85,   100] training loss: 0.01172130
INFO:root:[85,   150] training loss: 0.01279088
INFO:root:[85,   200] training loss: 0.01180108
INFO:root:[85,   250] training loss: 0.01236866
INFO:root:[85,   300] training loss: 0.01311718
INFO:root:[85,   350] training loss: 0.01176897
INFO:root:[85,   400] training loss: 0.00003914
INFO:root:[85,   450] training loss: 0.00004017
INFO:root:[85,   500] training loss: 0.00014469
INFO:root:[85,   550] training loss: 0.00020633
INFO:root:[85,   600] training loss: 0.00092172
INFO:root:[85,   650] training loss: 0.00011796
INFO:root:[85,   700] training loss: 0.00007269
INFO:root:[85,   750] training loss: 0.00050699
INFO:root:[85,   800] training loss: 0.00008074
INFO:root:[85,   850] training loss: 0.00006182
INFO:root:[85,   900] training loss: 0.01049172
INFO:root:[85,   950] training loss: 0.00310974
INFO:root:[85,  1000] training loss: 0.00005139
INFO:root:[85,  1050] training loss: 0.00002564
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8931    0.7872    0.8368      1720
   Metaphase     0.6769    0.8362    0.7482      1032
          G1     0.3077    0.5000    0.3810         8
    Anaphase     0.3065    0.7808    0.4402        73
          G2     0.5662    0.4797    0.5194      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7177      3872
   macro avg     0.6310    0.7691    0.6751      3872
weighted avg     0.7359    0.7177    0.7201      3872

INFO:root:Accuracy of the network on the 3872 validation images: 71 %
INFO:root:epoch85
INFO:root:[86,    50] training loss: 0.01101558
INFO:root:[86,   100] training loss: 0.01151218
INFO:root:[86,   150] training loss: 0.01208844
INFO:root:[86,   200] training loss: 0.01085456
INFO:root:[86,   250] training loss: 0.01019603
INFO:root:[86,   300] training loss: 0.01146558
INFO:root:[86,   350] training loss: 0.01050258
INFO:root:[86,   400] training loss: 0.00003408
INFO:root:[86,   450] training loss: 0.00002168
INFO:root:[86,   500] training loss: 0.00006588
INFO:root:[86,   550] training loss: 0.00021679
INFO:root:[86,   600] training loss: 0.00088326
INFO:root:[86,   650] training loss: 0.00010183
INFO:root:[86,   700] training loss: 0.00006851
INFO:root:[86,   750] training loss: 0.00045822
INFO:root:[86,   800] training loss: 0.00010515
INFO:root:[86,   850] training loss: 0.00007868
INFO:root:[86,   900] training loss: 0.01208314
INFO:root:[86,   950] training loss: 0.00281125
INFO:root:[86,  1000] training loss: 0.00003985
INFO:root:[86,  1050] training loss: 0.00002388
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9151    0.7895    0.8477      1720
   Metaphase     0.7039    0.8479    0.7692      1032
          G1     0.5000    0.2500    0.3333         8
    Anaphase     0.3294    0.7671    0.4609        73
          G2     0.5886    0.5493    0.5683      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7397      3872
   macro avg     0.6720    0.7434    0.6828      3872
weighted avg     0.7597    0.7397    0.7439      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch86
INFO:root:[87,    50] training loss: 0.01065088
INFO:root:[87,   100] training loss: 0.01100450
INFO:root:[87,   150] training loss: 0.01181720
INFO:root:[87,   200] training loss: 0.01032238
INFO:root:[87,   250] training loss: 0.01136948
INFO:root:[87,   300] training loss: 0.01347306
INFO:root:[87,   350] training loss: 0.01267608
INFO:root:[87,   400] training loss: 0.00002865
INFO:root:[87,   450] training loss: 0.00003690
INFO:root:[87,   500] training loss: 0.00010096
INFO:root:[87,   550] training loss: 0.00023200
INFO:root:[87,   600] training loss: 0.00172160
INFO:root:[87,   650] training loss: 0.00009835
INFO:root:[87,   700] training loss: 0.00007441
INFO:root:[87,   750] training loss: 0.00050866
INFO:root:[87,   800] training loss: 0.00009593
INFO:root:[87,   850] training loss: 0.00006234
INFO:root:[87,   900] training loss: 0.01156160
INFO:root:[87,   950] training loss: 0.00248295
INFO:root:[87,  1000] training loss: 0.00005879
INFO:root:[87,  1050] training loss: 0.00003250
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8924    0.8145    0.8517      1720
   Metaphase     0.7172    0.8256    0.7676      1032
          G1     0.4167    0.6250    0.5000         8
    Anaphase     0.3372    0.7945    0.4735        73
          G2     0.6169    0.5513    0.5822      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7466      3872
   macro avg     0.6639    0.8016    0.7107      3872
weighted avg     0.7606    0.7466    0.7495      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch87
INFO:root:[88,    50] training loss: 0.01120157
INFO:root:[88,   100] training loss: 0.01164029
INFO:root:[88,   150] training loss: 0.01167456
INFO:root:[88,   200] training loss: 0.00990437
INFO:root:[88,   250] training loss: 0.01126267
INFO:root:[88,   300] training loss: 0.01133342
INFO:root:[88,   350] training loss: 0.01054172
INFO:root:[88,   400] training loss: 0.00003799
INFO:root:[88,   450] training loss: 0.00003380
INFO:root:[88,   500] training loss: 0.00010007
INFO:root:[88,   550] training loss: 0.00016431
INFO:root:[88,   600] training loss: 0.00079514
INFO:root:[88,   650] training loss: 0.00013138
INFO:root:[88,   700] training loss: 0.00006174
INFO:root:[88,   750] training loss: 0.00055112
INFO:root:[88,   800] training loss: 0.00008783
INFO:root:[88,   850] training loss: 0.00006324
INFO:root:[88,   900] training loss: 0.00918936
INFO:root:[88,   950] training loss: 0.00258564
INFO:root:[88,  1000] training loss: 0.00004139
INFO:root:[88,  1050] training loss: 0.00003474
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9011    0.8209    0.8591      1720
   Metaphase     0.6909    0.8207    0.7502      1032
          G1     0.7500    0.3750    0.5000         8
    Anaphase     0.2850    0.8356    0.4251        73
          G2     0.6152    0.5087    0.5569      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7371      3872
   macro avg     0.7013    0.7659    0.6988      3872
weighted avg     0.7567    0.7371    0.7406      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch88
INFO:root:[89,    50] training loss: 0.01106179
INFO:root:[89,   100] training loss: 0.01191379
INFO:root:[89,   150] training loss: 0.01126082
INFO:root:[89,   200] training loss: 0.01010828
INFO:root:[89,   250] training loss: 0.01083480
INFO:root:[89,   300] training loss: 0.01242889
INFO:root:[89,   350] training loss: 0.01105532
INFO:root:[89,   400] training loss: 0.00002282
INFO:root:[89,   450] training loss: 0.00003132
INFO:root:[89,   500] training loss: 0.00008262
INFO:root:[89,   550] training loss: 0.00018122
INFO:root:[89,   600] training loss: 0.00083676
INFO:root:[89,   650] training loss: 0.00009791
INFO:root:[89,   700] training loss: 0.00005324
INFO:root:[89,   750] training loss: 0.00048428
INFO:root:[89,   800] training loss: 0.00007946
INFO:root:[89,   850] training loss: 0.00005924
INFO:root:[89,   900] training loss: 0.01016761
INFO:root:[89,   950] training loss: 0.00211640
INFO:root:[89,  1000] training loss: 0.00005206
INFO:root:[89,  1050] training loss: 0.00003337
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8878    0.8465    0.8667      1720
   Metaphase     0.7068    0.8411    0.7681      1032
          G1     0.2857    0.5000    0.3636         8
    Anaphase     0.3500    0.7671    0.4807        73
          G2     0.6306    0.5019    0.5590      1034
   Telophase     0.7500    1.0000    0.8571         3

    accuracy                         0.7510      3872
   macro avg     0.6111    0.7795    0.6707      3872
weighted avg     0.7593    0.7510    0.7499      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch89
INFO:root:[90,    50] training loss: 0.01083030
INFO:root:[90,   100] training loss: 0.01160528
INFO:root:[90,   150] training loss: 0.01128516
INFO:root:[90,   200] training loss: 0.01030876
INFO:root:[90,   250] training loss: 0.00989569
INFO:root:[90,   300] training loss: 0.01093454
INFO:root:[90,   350] training loss: 0.01141680
INFO:root:[90,   400] training loss: 0.00002162
INFO:root:[90,   450] training loss: 0.00003154
INFO:root:[90,   500] training loss: 0.00024666
INFO:root:[90,   550] training loss: 0.00018595
INFO:root:[90,   600] training loss: 0.00068308
INFO:root:[90,   650] training loss: 0.00010260
INFO:root:[90,   700] training loss: 0.00005712
INFO:root:[90,   750] training loss: 0.00057613
INFO:root:[90,   800] training loss: 0.00007559
INFO:root:[90,   850] training loss: 0.00003912
INFO:root:[90,   900] training loss: 0.00935896
INFO:root:[90,   950] training loss: 0.00230821
INFO:root:[90,  1000] training loss: 0.00003854
INFO:root:[90,  1050] training loss: 0.00001884
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8906    0.8186    0.8531      1720
   Metaphase     0.6881    0.8488    0.7601      1032
          G1     0.3077    0.5000    0.3810         8
    Anaphase     0.3648    0.7945    0.5000        73
          G2     0.5976    0.4855    0.5358      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7368      3872
   macro avg     0.6451    0.7782    0.6900      3872
weighted avg     0.7472    0.7368    0.7360      3872

INFO:root:Accuracy of the network on the 3872 validation images: 73 %
INFO:root:epoch90
INFO:root:[91,    50] training loss: 0.01088818
INFO:root:[91,   100] training loss: 0.01069926
INFO:root:[91,   150] training loss: 0.01102733
INFO:root:[91,   200] training loss: 0.01049420
INFO:root:[91,   250] training loss: 0.01124771
INFO:root:[91,   300] training loss: 0.01147542
INFO:root:[91,   350] training loss: 0.00945120
INFO:root:[91,   400] training loss: 0.00002982
INFO:root:[91,   450] training loss: 0.00002623
INFO:root:[91,   500] training loss: 0.00006271
INFO:root:[91,   550] training loss: 0.00018426
INFO:root:[91,   600] training loss: 0.00078672
INFO:root:[91,   650] training loss: 0.00007476
INFO:root:[91,   700] training loss: 0.00005275
INFO:root:[91,   750] training loss: 0.00050709
INFO:root:[91,   800] training loss: 0.00008105
INFO:root:[91,   850] training loss: 0.00007123
INFO:root:[91,   900] training loss: 0.01061827
INFO:root:[91,   950] training loss: 0.00272700
INFO:root:[91,  1000] training loss: 0.00003895
INFO:root:[91,  1050] training loss: 0.00002591
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9063    0.8041    0.8521      1720
   Metaphase     0.7178    0.8159    0.7637      1032
          G1     0.3125    0.6250    0.4167         8
    Anaphase     0.3081    0.7808    0.4419        73
          G2     0.5952    0.5561    0.5750      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7404      3872
   macro avg     0.6438    0.7974    0.6928      3872
weighted avg     0.7604    0.7404    0.7460      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch91
INFO:root:[92,    50] training loss: 0.01115313
INFO:root:[92,   100] training loss: 0.01995323
INFO:root:[92,   150] training loss: 0.01278991
INFO:root:[92,   200] training loss: 0.01158438
INFO:root:[92,   250] training loss: 0.01169775
INFO:root:[92,   300] training loss: 0.01188158
INFO:root:[92,   350] training loss: 0.00946789
INFO:root:[92,   400] training loss: 0.00002468
INFO:root:[92,   450] training loss: 0.00001742
INFO:root:[92,   500] training loss: 0.00009003
INFO:root:[92,   550] training loss: 0.00023847
INFO:root:[92,   600] training loss: 0.00092295
INFO:root:[92,   650] training loss: 0.00010501
INFO:root:[92,   700] training loss: 0.00006199
INFO:root:[92,   750] training loss: 0.00053017
INFO:root:[92,   800] training loss: 0.00008492
INFO:root:[92,   850] training loss: 0.00005233
INFO:root:[92,   900] training loss: 0.01018652
INFO:root:[92,   950] training loss: 0.00232376
INFO:root:[92,  1000] training loss: 0.00003069
INFO:root:[92,  1050] training loss: 0.00002593
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8890    0.8058    0.8454      1720
   Metaphase     0.6855    0.8236    0.7482      1032
          G1     0.4000    0.5000    0.4444         8
    Anaphase     0.3182    0.7671    0.4498        73
          G2     0.5743    0.4894    0.5285      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7249      3872
   macro avg     0.6477    0.7694    0.6880      3872
weighted avg     0.7389    0.7249    0.7267      3872

INFO:root:Accuracy of the network on the 3872 validation images: 72 %
INFO:root:epoch92
INFO:root:[93,    50] training loss: 0.01068960
INFO:root:[93,   100] training loss: 0.01028043
INFO:root:[93,   150] training loss: 0.01079114
INFO:root:[93,   200] training loss: 0.00962279
INFO:root:[93,   250] training loss: 0.01094901
INFO:root:[93,   300] training loss: 0.01381973
INFO:root:[93,   350] training loss: 0.01122985
INFO:root:[93,   400] training loss: 0.00003510
INFO:root:[93,   450] training loss: 0.00003816
INFO:root:[93,   500] training loss: 0.00014079
INFO:root:[93,   550] training loss: 0.00016403
INFO:root:[93,   600] training loss: 0.00056342
INFO:root:[93,   650] training loss: 0.00008489
INFO:root:[93,   700] training loss: 0.00004954
INFO:root:[93,   750] training loss: 0.00046861
INFO:root:[93,   800] training loss: 0.00005985
INFO:root:[93,   850] training loss: 0.00004864
INFO:root:[93,   900] training loss: 0.00890396
INFO:root:[93,   950] training loss: 0.00223363
INFO:root:[93,  1000] training loss: 0.00003351
INFO:root:[93,  1050] training loss: 0.00002097
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8994    0.8215    0.8587      1720
   Metaphase     0.7110    0.8295    0.7657      1032
          G1     0.7143    0.6250    0.6667         8
    Anaphase     0.3152    0.7945    0.4514        73
          G2     0.6122    0.5329    0.5698      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7459      3872
   macro avg     0.7027    0.8005    0.7303      3872
weighted avg     0.7611    0.7459    0.7488      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch93
INFO:root:[94,    50] training loss: 0.01006263
INFO:root:[94,   100] training loss: 0.00954011
INFO:root:[94,   150] training loss: 0.01036893
INFO:root:[94,   200] training loss: 0.00977852
INFO:root:[94,   250] training loss: 0.00919289
INFO:root:[94,   300] training loss: 0.01333389
INFO:root:[94,   350] training loss: 0.01036488
INFO:root:[94,   400] training loss: 0.00001794
INFO:root:[94,   450] training loss: 0.00001691
INFO:root:[94,   500] training loss: 0.00006760
INFO:root:[94,   550] training loss: 0.00021279
INFO:root:[94,   600] training loss: 0.00061816
INFO:root:[94,   650] training loss: 0.00010227
INFO:root:[94,   700] training loss: 0.00006025
INFO:root:[94,   750] training loss: 0.00056305
INFO:root:[94,   800] training loss: 0.00007136
INFO:root:[94,   850] training loss: 0.00004134
INFO:root:[94,   900] training loss: 0.00981945
INFO:root:[94,   950] training loss: 0.00256731
INFO:root:[94,  1000] training loss: 0.00003583
INFO:root:[94,  1050] training loss: 0.00002265
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9009    0.8297    0.8638      1720
   Metaphase     0.7110    0.8295    0.7657      1032
          G1     0.3333    0.5000    0.4000         8
    Anaphase     0.3376    0.7260    0.4609        73
          G2     0.6216    0.5464    0.5816      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7515      3872
   macro avg     0.6530    0.7759    0.6960      3872
weighted avg     0.7638    0.7515    0.7538      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch94
INFO:root:[95,    50] training loss: 0.01073234
INFO:root:[95,   100] training loss: 0.01005989
INFO:root:[95,   150] training loss: 0.01046400
INFO:root:[95,   200] training loss: 0.00969552
INFO:root:[95,   250] training loss: 0.01040088
INFO:root:[95,   300] training loss: 0.01131060
INFO:root:[95,   350] training loss: 0.00882476
INFO:root:[95,   400] training loss: 0.00001642
INFO:root:[95,   450] training loss: 0.00001380
INFO:root:[95,   500] training loss: 0.00004616
INFO:root:[95,   550] training loss: 0.00014114
INFO:root:[95,   600] training loss: 0.00048059
INFO:root:[95,   650] training loss: 0.00008111
INFO:root:[95,   700] training loss: 0.00004701
INFO:root:[95,   750] training loss: 0.00059732
INFO:root:[95,   800] training loss: 0.00006211
INFO:root:[95,   850] training loss: 0.00003935
INFO:root:[95,   900] training loss: 0.00870238
INFO:root:[95,   950] training loss: 0.00178811
INFO:root:[95,  1000] training loss: 0.00003151
INFO:root:[95,  1050] training loss: 0.00002818
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8911    0.8419    0.8658      1720
   Metaphase     0.7042    0.8672    0.7772      1032
          G1     0.8571    0.7500    0.8000         8
    Anaphase     0.4113    0.6986    0.5178        73
          G2     0.6210    0.5039    0.5563      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7557      3872
   macro avg     0.7359    0.8088    0.7596      3872
weighted avg     0.7600    0.7557    0.7529      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch95
INFO:root:[96,    50] training loss: 0.00992148
INFO:root:[96,   100] training loss: 0.00998539
INFO:root:[96,   150] training loss: 0.01068336
INFO:root:[96,   200] training loss: 0.01114939
INFO:root:[96,   250] training loss: 0.01230018
INFO:root:[96,   300] training loss: 0.01123782
INFO:root:[96,   350] training loss: 0.00905734
INFO:root:[96,   400] training loss: 0.00001228
INFO:root:[96,   450] training loss: 0.00001511
INFO:root:[96,   500] training loss: 0.00003749
INFO:root:[96,   550] training loss: 0.00015658
INFO:root:[96,   600] training loss: 0.00047253
INFO:root:[96,   650] training loss: 0.00006700
INFO:root:[96,   700] training loss: 0.00005533
INFO:root:[96,   750] training loss: 0.00052307
INFO:root:[96,   800] training loss: 0.00006052
INFO:root:[96,   850] training loss: 0.00003432
INFO:root:[96,   900] training loss: 0.00818614
INFO:root:[96,   950] training loss: 0.00224650
INFO:root:[96,  1000] training loss: 0.00003365
INFO:root:[96,  1050] training loss: 0.00002090
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9031    0.8349    0.8677      1720
   Metaphase     0.7166    0.8527    0.7788      1032
          G1     0.3571    0.6250    0.4545         8
    Anaphase     0.3467    0.7123    0.4664        73
          G2     0.6233    0.5329    0.5746      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7565      3872
   macro avg     0.6591    0.7940    0.7060      3872
weighted avg     0.7670    0.7565    0.7573      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch96
INFO:root:[97,    50] training loss: 0.00959306
INFO:root:[97,   100] training loss: 0.01322960
INFO:root:[97,   150] training loss: 0.01108794
INFO:root:[97,   200] training loss: 0.00926987
INFO:root:[97,   250] training loss: 0.01002924
INFO:root:[97,   300] training loss: 0.01194311
INFO:root:[97,   350] training loss: 0.00972422
INFO:root:[97,   400] training loss: 0.00001415
INFO:root:[97,   450] training loss: 0.00001293
INFO:root:[97,   500] training loss: 0.00012993
INFO:root:[97,   550] training loss: 0.00011181
INFO:root:[97,   600] training loss: 0.00062404
INFO:root:[97,   650] training loss: 0.00006936
INFO:root:[97,   700] training loss: 0.00006234
INFO:root:[97,   750] training loss: 0.00052011
INFO:root:[97,   800] training loss: 0.00005328
INFO:root:[97,   850] training loss: 0.00004518
INFO:root:[97,   900] training loss: 0.00844970
INFO:root:[97,   950] training loss: 0.00229323
INFO:root:[97,  1000] training loss: 0.00002955
INFO:root:[97,  1050] training loss: 0.00001785
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8800    0.8698    0.8749      1720
   Metaphase     0.7266    0.8266    0.7733      1032
          G1     0.4615    0.7500    0.5714         8
    Anaphase     0.3522    0.7671    0.4828        73
          G2     0.6524    0.5174    0.5771      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7621      3872
   macro avg     0.6771    0.8187    0.7256      3872
weighted avg     0.7675    0.7621    0.7603      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch97
INFO:root:[98,    50] training loss: 0.01017503
INFO:root:[98,   100] training loss: 0.01011861
INFO:root:[98,   150] training loss: 0.01039943
INFO:root:[98,   200] training loss: 0.00966592
INFO:root:[98,   250] training loss: 0.00994672
INFO:root:[98,   300] training loss: 0.01206773
INFO:root:[98,   350] training loss: 0.00966069
INFO:root:[98,   400] training loss: 0.00001446
INFO:root:[98,   450] training loss: 0.00001488
INFO:root:[98,   500] training loss: 0.00004450
INFO:root:[98,   550] training loss: 0.00013866
INFO:root:[98,   600] training loss: 0.00040988
INFO:root:[98,   650] training loss: 0.00006714
INFO:root:[98,   700] training loss: 0.00003826
INFO:root:[98,   750] training loss: 0.00054512
INFO:root:[98,   800] training loss: 0.00005302
INFO:root:[98,   850] training loss: 0.00003295
INFO:root:[98,   900] training loss: 0.00814585
INFO:root:[98,   950] training loss: 0.00187663
INFO:root:[98,  1000] training loss: 0.00003305
INFO:root:[98,  1050] training loss: 0.00002242
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8922    0.8273    0.8585      1720
   Metaphase     0.7066    0.8401    0.7676      1032
          G1     0.5556    0.6250    0.5882         8
    Anaphase     0.3375    0.7397    0.4635        73
          G2     0.6137    0.5193    0.5626      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7466      3872
   macro avg     0.6817    0.7931    0.7201      3872
weighted avg     0.7572    0.7466    0.7473      3872

INFO:root:Accuracy of the network on the 3872 validation images: 74 %
INFO:root:epoch98
INFO:root:[99,    50] training loss: 0.01065714
INFO:root:[99,   100] training loss: 0.00949516
INFO:root:[99,   150] training loss: 0.01014745
INFO:root:[99,   200] training loss: 0.00920663
INFO:root:[99,   250] training loss: 0.00952743
INFO:root:[99,   300] training loss: 0.01009866
INFO:root:[99,   350] training loss: 0.00913878
INFO:root:[99,   400] training loss: 0.00006391
INFO:root:[99,   450] training loss: 0.00002519
INFO:root:[99,   500] training loss: 0.00010057
INFO:root:[99,   550] training loss: 0.00016849
INFO:root:[99,   600] training loss: 0.00049490
INFO:root:[99,   650] training loss: 0.00006342
INFO:root:[99,   700] training loss: 0.00003301
INFO:root:[99,   750] training loss: 0.00049539
INFO:root:[99,   800] training loss: 0.00003867
INFO:root:[99,   850] training loss: 0.00004045
INFO:root:[99,   900] training loss: 0.00683868
INFO:root:[99,   950] training loss: 0.00189117
INFO:root:[99,  1000] training loss: 0.00003500
INFO:root:[99,  1050] training loss: 0.00002165
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8898    0.8541    0.8716      1720
   Metaphase     0.7025    0.8556    0.7715      1032
          G1     0.5000    0.3750    0.4286         8
    Anaphase     0.3605    0.7260    0.4818        73
          G2     0.6422    0.5000    0.5623      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7567      3872
   macro avg     0.6802    0.7587    0.7022      3872
weighted avg     0.7629    0.7567    0.7541      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch99
INFO:root:[100,    50] training loss: 0.00935502
INFO:root:[100,   100] training loss: 0.01346337
INFO:root:[100,   150] training loss: 0.01096975
INFO:root:[100,   200] training loss: 0.01007967
INFO:root:[100,   250] training loss: 0.00948756
INFO:root:[100,   300] training loss: 0.01067069
INFO:root:[100,   350] training loss: 0.00848154
INFO:root:[100,   400] training loss: 0.00001464
INFO:root:[100,   450] training loss: 0.00001633
INFO:root:[100,   500] training loss: 0.00003993
INFO:root:[100,   550] training loss: 0.00013750
INFO:root:[100,   600] training loss: 0.00033924
INFO:root:[100,   650] training loss: 0.00005212
INFO:root:[100,   700] training loss: 0.00005253
INFO:root:[100,   750] training loss: 0.00052181
INFO:root:[100,   800] training loss: 0.00005814
INFO:root:[100,   850] training loss: 0.00003676
INFO:root:[100,   900] training loss: 0.00909928
INFO:root:[100,   950] training loss: 0.00231335
INFO:root:[100,  1000] training loss: 0.00003335
INFO:root:[100,  1050] training loss: 0.00002572
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9039    0.8145    0.8569      1720
   Metaphase     0.7006    0.8595    0.7720      1032
          G1     0.5000    0.5000    0.5000         8
    Anaphase     0.4365    0.7534    0.5528        73
          G2     0.6037    0.5348    0.5672      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7503      3872
   macro avg     0.6873    0.7803    0.7213      3872
weighted avg     0.7599    0.7503    0.7505      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch100
INFO:root:[101,    50] training loss: 0.01026737
INFO:root:[101,   100] training loss: 0.00989257
INFO:root:[101,   150] training loss: 0.00947843
INFO:root:[101,   200] training loss: 0.00884410
INFO:root:[101,   250] training loss: 0.01036097
INFO:root:[101,   300] training loss: 0.01071285
INFO:root:[101,   350] training loss: 0.00848596
INFO:root:[101,   400] training loss: 0.00001391
INFO:root:[101,   450] training loss: 0.00001622
INFO:root:[101,   500] training loss: 0.00002504
INFO:root:[101,   550] training loss: 0.00014095
INFO:root:[101,   600] training loss: 0.00045062
INFO:root:[101,   650] training loss: 0.00006903
INFO:root:[101,   700] training loss: 0.00003599
INFO:root:[101,   750] training loss: 0.00054982
INFO:root:[101,   800] training loss: 0.00004438
INFO:root:[101,   850] training loss: 0.00003187
INFO:root:[101,   900] training loss: 0.00743561
INFO:root:[101,   950] training loss: 0.00248226
INFO:root:[101,  1000] training loss: 0.00003381
INFO:root:[101,  1050] training loss: 0.00002050
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8968    0.8488    0.8722      1720
   Metaphase     0.7357    0.8120    0.7720      1032
          G1     0.3333    0.5000    0.4000         8
    Anaphase     0.2737    0.6712    0.3889        73
          G2     0.6377    0.5600    0.5963      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7580      3872
   macro avg     0.6491    0.7703    0.6899      3872
weighted avg     0.7717    0.7580    0.7618      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch101
INFO:root:[102,    50] training loss: 0.00888790
INFO:root:[102,   100] training loss: 0.00895051
INFO:root:[102,   150] training loss: 0.00939977
INFO:root:[102,   200] training loss: 0.00879246
INFO:root:[102,   250] training loss: 0.01197580
INFO:root:[102,   300] training loss: 0.01144338
INFO:root:[102,   350] training loss: 0.00870248
INFO:root:[102,   400] training loss: 0.00001298
INFO:root:[102,   450] training loss: 0.00001262
INFO:root:[102,   500] training loss: 0.00003115
INFO:root:[102,   550] training loss: 0.00012891
INFO:root:[102,   600] training loss: 0.00036061
INFO:root:[102,   650] training loss: 0.00006928
INFO:root:[102,   700] training loss: 0.00004658
INFO:root:[102,   750] training loss: 0.00052510
INFO:root:[102,   800] training loss: 0.00004641
INFO:root:[102,   850] training loss: 0.00003684
INFO:root:[102,   900] training loss: 0.00707064
INFO:root:[102,   950] training loss: 0.00183281
INFO:root:[102,  1000] training loss: 0.00002745
INFO:root:[102,  1050] training loss: 0.00001551
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8854    0.8622    0.8736      1720
   Metaphase     0.7365    0.8479    0.7883      1032
          G1     0.5714    0.5000    0.5333         8
    Anaphase     0.4286    0.7397    0.5427        73
          G2     0.6506    0.5474    0.5945      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7714      3872
   macro avg     0.7056    0.7853    0.7332      3872
weighted avg     0.7737    0.7714    0.7695      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch102
INFO:root:[103,    50] training loss: 0.00995610
INFO:root:[103,   100] training loss: 0.00916501
INFO:root:[103,   150] training loss: 0.00930108
INFO:root:[103,   200] training loss: 0.00903879
INFO:root:[103,   250] training loss: 0.00892176
INFO:root:[103,   300] training loss: 0.01000233
INFO:root:[103,   350] training loss: 0.00876462
INFO:root:[103,   400] training loss: 0.00001339
INFO:root:[103,   450] training loss: 0.00003054
INFO:root:[103,   500] training loss: 0.00006445
INFO:root:[103,   550] training loss: 0.00015343
INFO:root:[103,   600] training loss: 0.00039968
INFO:root:[103,   650] training loss: 0.00004596
INFO:root:[103,   700] training loss: 0.00002763
INFO:root:[103,   750] training loss: 0.00049731
INFO:root:[103,   800] training loss: 0.00004054
INFO:root:[103,   850] training loss: 0.00004149
INFO:root:[103,   900] training loss: 0.00693171
INFO:root:[103,   950] training loss: 0.00198019
INFO:root:[103,  1000] training loss: 0.00002402
INFO:root:[103,  1050] training loss: 0.00001986
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8883    0.8512    0.8694      1720
   Metaphase     0.7230    0.8169    0.7671      1032
          G1     0.4286    0.3750    0.4000         8
    Anaphase     0.3314    0.7808    0.4653        73
          G2     0.6357    0.5368    0.5821      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7559      3872
   macro avg     0.6677    0.7658    0.6977      3872
weighted avg     0.7653    0.7559    0.7569      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch103
INFO:root:[104,    50] training loss: 0.00862903
INFO:root:[104,   100] training loss: 0.00949727
INFO:root:[104,   150] training loss: 0.01041493
INFO:root:[104,   200] training loss: 0.00922858
INFO:root:[104,   250] training loss: 0.01209777
INFO:root:[104,   300] training loss: 0.01121300
INFO:root:[104,   350] training loss: 0.00890926
INFO:root:[104,   400] training loss: 0.00001254
INFO:root:[104,   450] training loss: 0.00001256
INFO:root:[104,   500] training loss: 0.00003470
INFO:root:[104,   550] training loss: 0.00012509
INFO:root:[104,   600] training loss: 0.00030327
INFO:root:[104,   650] training loss: 0.00005871
INFO:root:[104,   700] training loss: 0.00004706
INFO:root:[104,   750] training loss: 0.00055167
INFO:root:[104,   800] training loss: 0.00003980
INFO:root:[104,   850] training loss: 0.00002508
INFO:root:[104,   900] training loss: 0.00686911
INFO:root:[104,   950] training loss: 0.00174846
INFO:root:[104,  1000] training loss: 0.00002655
INFO:root:[104,  1050] training loss: 0.00001748
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9018    0.8547    0.8776      1720
   Metaphase     0.7416    0.8566    0.7950      1032
          G1     0.6667    0.5000    0.5714         8
    Anaphase     0.3740    0.6712    0.4804        73
          G2     0.6571    0.5764    0.6141      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.7154    0.7798    0.7341      3872
weighted avg     0.7833    0.7769    0.7772      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch104
INFO:root:[105,    50] training loss: 0.00878231
INFO:root:[105,   100] training loss: 0.00854066
INFO:root:[105,   150] training loss: 0.01024077
INFO:root:[105,   200] training loss: 0.00920437
INFO:root:[105,   250] training loss: 0.01100074
INFO:root:[105,   300] training loss: 0.01138009
INFO:root:[105,   350] training loss: 0.01022598
INFO:root:[105,   400] training loss: 0.00001413
INFO:root:[105,   450] training loss: 0.00002587
INFO:root:[105,   500] training loss: 0.00003399
INFO:root:[105,   550] training loss: 0.00011925
INFO:root:[105,   600] training loss: 0.00035652
INFO:root:[105,   650] training loss: 0.00006169
INFO:root:[105,   700] training loss: 0.00004181
INFO:root:[105,   750] training loss: 0.00049721
INFO:root:[105,   800] training loss: 0.00004644
INFO:root:[105,   850] training loss: 0.00004644
INFO:root:[105,   900] training loss: 0.00715913
INFO:root:[105,   950] training loss: 0.00162865
INFO:root:[105,  1000] training loss: 0.00002250
INFO:root:[105,  1050] training loss: 0.00001412
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8948    0.8355    0.8641      1720
   Metaphase     0.7175    0.8440    0.7756      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3796    0.7123    0.4952        73
          G2     0.6156    0.5358    0.5729      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7549      3872
   macro avg     0.6741    0.7754    0.7112      3872
weighted avg     0.7623    0.7549    0.7551      3872

INFO:root:Accuracy of the network on the 3872 validation images: 75 %
INFO:root:epoch105
INFO:root:[106,    50] training loss: 0.00948108
INFO:root:[106,   100] training loss: 0.01069860
INFO:root:[106,   150] training loss: 0.01268083
INFO:root:[106,   200] training loss: 0.01128138
INFO:root:[106,   250] training loss: 0.00910940
INFO:root:[106,   300] training loss: 0.01016172
INFO:root:[106,   350] training loss: 0.00923535
INFO:root:[106,   400] training loss: 0.00001608
INFO:root:[106,   450] training loss: 0.00001661
INFO:root:[106,   500] training loss: 0.00006762
INFO:root:[106,   550] training loss: 0.00022629
INFO:root:[106,   600] training loss: 0.00029137
INFO:root:[106,   650] training loss: 0.00005040
INFO:root:[106,   700] training loss: 0.00003618
INFO:root:[106,   750] training loss: 0.00052659
INFO:root:[106,   800] training loss: 0.00005195
INFO:root:[106,   850] training loss: 0.00002613
INFO:root:[106,   900] training loss: 0.00769334
INFO:root:[106,   950] training loss: 0.00150997
INFO:root:[106,  1000] training loss: 0.00002546
INFO:root:[106,  1050] training loss: 0.00001944
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8833    0.8669    0.8750      1720
   Metaphase     0.7319    0.8517    0.7873      1032
          G1     0.4545    0.6250    0.5263         8
    Anaphase     0.3937    0.6849    0.5000        73
          G2     0.6532    0.5300    0.5852      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7691      3872
   macro avg     0.6833    0.7941    0.7248      3872
weighted avg     0.7713    0.7691    0.7665      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch106
INFO:root:[107,    50] training loss: 0.00938847
INFO:root:[107,   100] training loss: 0.00929838
INFO:root:[107,   150] training loss: 0.01095991
INFO:root:[107,   200] training loss: 0.01209535
INFO:root:[107,   250] training loss: 0.01037746
INFO:root:[107,   300] training loss: 0.01044370
INFO:root:[107,   350] training loss: 0.00860905
INFO:root:[107,   400] training loss: 0.00001058
INFO:root:[107,   450] training loss: 0.00026919
INFO:root:[107,   500] training loss: 0.00005433
INFO:root:[107,   550] training loss: 0.00011214
INFO:root:[107,   600] training loss: 0.00037537
INFO:root:[107,   650] training loss: 0.00006025
INFO:root:[107,   700] training loss: 0.00003366
INFO:root:[107,   750] training loss: 0.00046284
INFO:root:[107,   800] training loss: 0.00005639
INFO:root:[107,   850] training loss: 0.00004000
INFO:root:[107,   900] training loss: 0.00700127
INFO:root:[107,   950] training loss: 0.00244999
INFO:root:[107,  1000] training loss: 0.00003701
INFO:root:[107,  1050] training loss: 0.00002138
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8867    0.8692    0.8779      1720
   Metaphase     0.7390    0.8120    0.7738      1032
          G1     0.3529    0.7500    0.4800         8
    Anaphase     0.3623    0.6849    0.4739        73
          G2     0.6521    0.5619    0.6036      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7683      3872
   macro avg     0.6657    0.8111    0.7156      3872
weighted avg     0.7737    0.7683    0.7685      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch107
INFO:root:[108,    50] training loss: 0.01009364
INFO:root:[108,   100] training loss: 0.00950510
INFO:root:[108,   150] training loss: 0.00914361
INFO:root:[108,   200] training loss: 0.01029895
INFO:root:[108,   250] training loss: 0.00926294
INFO:root:[108,   300] training loss: 0.01014768
INFO:root:[108,   350] training loss: 0.00833122
INFO:root:[108,   400] training loss: 0.00001177
INFO:root:[108,   450] training loss: 0.00001546
INFO:root:[108,   500] training loss: 0.00003395
INFO:root:[108,   550] training loss: 0.00009153
INFO:root:[108,   600] training loss: 0.00020022
INFO:root:[108,   650] training loss: 0.00004069
INFO:root:[108,   700] training loss: 0.00003608
INFO:root:[108,   750] training loss: 0.00045920
INFO:root:[108,   800] training loss: 0.00004853
INFO:root:[108,   850] training loss: 0.00003213
INFO:root:[108,   900] training loss: 0.00903237
INFO:root:[108,   950] training loss: 0.00234363
INFO:root:[108,  1000] training loss: 0.00003068
INFO:root:[108,  1050] training loss: 0.00002120
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8763    0.8692    0.8727      1720
   Metaphase     0.7556    0.7849    0.7700      1032
          G1     0.5556    0.6250    0.5882         8
    Anaphase     0.3049    0.6849    0.4219        73
          G2     0.6459    0.5716    0.6065      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7634      3872
   macro avg     0.6864    0.7908    0.7228      3872
weighted avg     0.7712    0.7634    0.7652      3872

INFO:root:Accuracy of the network on the 3872 validation images: 76 %
INFO:root:epoch108
INFO:root:[109,    50] training loss: 0.00971499
INFO:root:[109,   100] training loss: 0.01045826
INFO:root:[109,   150] training loss: 0.00939894
INFO:root:[109,   200] training loss: 0.00868877
INFO:root:[109,   250] training loss: 0.00975140
INFO:root:[109,   300] training loss: 0.00961060
INFO:root:[109,   350] training loss: 0.00808840
INFO:root:[109,   400] training loss: 0.00001185
INFO:root:[109,   450] training loss: 0.00003172
INFO:root:[109,   500] training loss: 0.00003770
INFO:root:[109,   550] training loss: 0.00016544
INFO:root:[109,   600] training loss: 0.00047177
INFO:root:[109,   650] training loss: 0.00026053
INFO:root:[109,   700] training loss: 0.00022082
INFO:root:[109,   750] training loss: 0.00324599
INFO:root:[109,   800] training loss: 0.00089785
INFO:root:[109,   850] training loss: 0.00054962
INFO:root:[109,   900] training loss: 0.00724173
INFO:root:[109,   950] training loss: 0.00189038
INFO:root:[109,  1000] training loss: 0.00001934
INFO:root:[109,  1050] training loss: 0.00001146
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9087    0.8221    0.8632      1720
   Metaphase     0.7597    0.8362    0.7961      1032
          G1     0.5000    0.7500    0.6000         8
    Anaphase     0.4425    0.6849    0.5376        73
          G2     0.6215    0.6306    0.6260      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7722      3872
   macro avg     0.6999    0.8177    0.7461      3872
weighted avg     0.7826    0.7722    0.7754      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch109
INFO:root:[110,    50] training loss: 0.00957326
INFO:root:[110,   100] training loss: 0.00909299
INFO:root:[110,   150] training loss: 0.00885314
INFO:root:[110,   200] training loss: 0.00827399
INFO:root:[110,   250] training loss: 0.00879796
INFO:root:[110,   300] training loss: 0.00901533
INFO:root:[110,   350] training loss: 0.00696954
INFO:root:[110,   400] training loss: 0.00001162
INFO:root:[110,   450] training loss: 0.00001453
INFO:root:[110,   500] training loss: 0.00002749
INFO:root:[110,   550] training loss: 0.00012845
INFO:root:[110,   600] training loss: 0.00025394
INFO:root:[110,   650] training loss: 0.00006852
INFO:root:[110,   700] training loss: 0.00010588
INFO:root:[110,   750] training loss: 0.00177468
INFO:root:[110,   800] training loss: 0.00068117
INFO:root:[110,   850] training loss: 0.00035197
INFO:root:[110,   900] training loss: 0.00675542
INFO:root:[110,   950] training loss: 0.00152787
INFO:root:[110,  1000] training loss: 0.00001493
INFO:root:[110,  1050] training loss: 0.00000984
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9009    0.8355    0.8670      1720
   Metaphase     0.7722    0.8081    0.7898      1032
          G1     0.4545    0.6250    0.5263         8
    Anaphase     0.3876    0.6849    0.4950        73
          G2     0.6280    0.6383    0.6331      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7725      3872
   macro avg     0.6871    0.7988    0.7302      3872
weighted avg     0.7831    0.7725    0.7763      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch110
INFO:root:[111,    50] training loss: 0.00884998
INFO:root:[111,   100] training loss: 0.00889301
INFO:root:[111,   150] training loss: 0.00852737
INFO:root:[111,   200] training loss: 0.00803868
INFO:root:[111,   250] training loss: 0.00823336
INFO:root:[111,   300] training loss: 0.00872865
INFO:root:[111,   350] training loss: 0.00748195
INFO:root:[111,   400] training loss: 0.00001399
INFO:root:[111,   450] training loss: 0.00003405
INFO:root:[111,   500] training loss: 0.00001987
INFO:root:[111,   550] training loss: 0.00014632
INFO:root:[111,   600] training loss: 0.00017394
INFO:root:[111,   650] training loss: 0.00005510
INFO:root:[111,   700] training loss: 0.00006493
INFO:root:[111,   750] training loss: 0.00149737
INFO:root:[111,   800] training loss: 0.00047428
INFO:root:[111,   850] training loss: 0.00034395
INFO:root:[111,   900] training loss: 0.00516868
INFO:root:[111,   950] training loss: 0.00186693
INFO:root:[111,  1000] training loss: 0.00001303
INFO:root:[111,  1050] training loss: 0.00001075
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8974    0.8488    0.8724      1720
   Metaphase     0.7859    0.7791    0.7825      1032
          G1     0.4545    0.6250    0.5263         8
    Anaphase     0.3630    0.7260    0.4840        73
          G2     0.6364    0.6518    0.6441      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7751      3872
   macro avg     0.6863    0.8044    0.7299      3872
weighted avg     0.7870    0.7751    0.7795      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch111
INFO:root:[112,    50] training loss: 0.00865134
INFO:root:[112,   100] training loss: 0.00814373
INFO:root:[112,   150] training loss: 0.00837518
INFO:root:[112,   200] training loss: 0.00785893
INFO:root:[112,   250] training loss: 0.00844659
INFO:root:[112,   300] training loss: 0.00871022
INFO:root:[112,   350] training loss: 0.00752607
INFO:root:[112,   400] training loss: 0.00001171
INFO:root:[112,   450] training loss: 0.00002033
INFO:root:[112,   500] training loss: 0.00003196
INFO:root:[112,   550] training loss: 0.00017018
INFO:root:[112,   600] training loss: 0.00019987
INFO:root:[112,   650] training loss: 0.00004890
INFO:root:[112,   700] training loss: 0.00003092
INFO:root:[112,   750] training loss: 0.00120963
INFO:root:[112,   800] training loss: 0.00048115
INFO:root:[112,   850] training loss: 0.00029141
INFO:root:[112,   900] training loss: 0.00525890
INFO:root:[112,   950] training loss: 0.00165774
INFO:root:[112,  1000] training loss: 0.00002403
INFO:root:[112,  1050] training loss: 0.00000969
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8986    0.8349    0.8656      1720
   Metaphase     0.7830    0.7868    0.7849      1032
          G1     0.4000    0.5000    0.4444         8
    Anaphase     0.3759    0.7260    0.4953        73
          G2     0.6269    0.6547    0.6405      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7714      3872
   macro avg     0.6787    0.7861    0.7187      3872
weighted avg     0.7843    0.7714    0.7762      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch112
INFO:root:[113,    50] training loss: 0.00846664
INFO:root:[113,   100] training loss: 0.00793354
INFO:root:[113,   150] training loss: 0.00863802
INFO:root:[113,   200] training loss: 0.00743715
INFO:root:[113,   250] training loss: 0.00893304
INFO:root:[113,   300] training loss: 0.00905705
INFO:root:[113,   350] training loss: 0.00738618
INFO:root:[113,   400] training loss: 0.00001009
INFO:root:[113,   450] training loss: 0.00001739
INFO:root:[113,   500] training loss: 0.00005050
INFO:root:[113,   550] training loss: 0.00015943
INFO:root:[113,   600] training loss: 0.00018420
INFO:root:[113,   650] training loss: 0.00004148
INFO:root:[113,   700] training loss: 0.00004791
INFO:root:[113,   750] training loss: 0.00116825
INFO:root:[113,   800] training loss: 0.00041002
INFO:root:[113,   850] training loss: 0.00031266
INFO:root:[113,   900] training loss: 0.00523579
INFO:root:[113,   950] training loss: 0.00174844
INFO:root:[113,  1000] training loss: 0.00001455
INFO:root:[113,  1050] training loss: 0.00001096
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8944    0.8471    0.8701      1720
   Metaphase     0.7960    0.7713    0.7835      1032
          G1     0.4000    0.5000    0.4444         8
    Anaphase     0.3439    0.7397    0.4696        73
          G2     0.6393    0.6615    0.6502      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7748      3872
   macro avg     0.6772    0.7885    0.7168      3872
weighted avg     0.7886    0.7748    0.7799      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch113
INFO:root:[114,    50] training loss: 0.00829789
INFO:root:[114,   100] training loss: 0.00801831
INFO:root:[114,   150] training loss: 0.00881974
INFO:root:[114,   200] training loss: 0.00759007
INFO:root:[114,   250] training loss: 0.00833240
INFO:root:[114,   300] training loss: 0.00814759
INFO:root:[114,   350] training loss: 0.00732858
INFO:root:[114,   400] training loss: 0.00000986
INFO:root:[114,   450] training loss: 0.00001650
INFO:root:[114,   500] training loss: 0.00002712
INFO:root:[114,   550] training loss: 0.00018747
INFO:root:[114,   600] training loss: 0.00017900
INFO:root:[114,   650] training loss: 0.00003078
INFO:root:[114,   700] training loss: 0.00002622
INFO:root:[114,   750] training loss: 0.00089264
INFO:root:[114,   800] training loss: 0.00037348
INFO:root:[114,   850] training loss: 0.00027969
INFO:root:[114,   900] training loss: 0.00469904
INFO:root:[114,   950] training loss: 0.00172340
INFO:root:[114,  1000] training loss: 0.00002008
INFO:root:[114,  1050] training loss: 0.00001444
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8958    0.8494    0.8720      1720
   Metaphase     0.7836    0.7859    0.7847      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3595    0.7534    0.4867        73
          G2     0.6435    0.6460    0.6448      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7758      3872
   macro avg     0.6848    0.7907    0.7227      3872
weighted avg     0.7874    0.7758    0.7800      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch114
INFO:root:[115,    50] training loss: 0.00869530
INFO:root:[115,   100] training loss: 0.00805889
INFO:root:[115,   150] training loss: 0.00916027
INFO:root:[115,   200] training loss: 0.00746367
INFO:root:[115,   250] training loss: 0.00802969
INFO:root:[115,   300] training loss: 0.00932823
INFO:root:[115,   350] training loss: 0.00700134
INFO:root:[115,   400] training loss: 0.00000912
INFO:root:[115,   450] training loss: 0.00001253
INFO:root:[115,   500] training loss: 0.00002479
INFO:root:[115,   550] training loss: 0.00010644
INFO:root:[115,   600] training loss: 0.00017575
INFO:root:[115,   650] training loss: 0.00002904
INFO:root:[115,   700] training loss: 0.00002792
INFO:root:[115,   750] training loss: 0.00094243
INFO:root:[115,   800] training loss: 0.00035468
INFO:root:[115,   850] training loss: 0.00021430
INFO:root:[115,   900] training loss: 0.00482379
INFO:root:[115,   950] training loss: 0.00168693
INFO:root:[115,  1000] training loss: 0.00001620
INFO:root:[115,  1050] training loss: 0.00001165
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8981    0.8349    0.8653      1720
   Metaphase     0.7912    0.7859    0.7885      1032
          G1     0.3636    0.5000    0.4211         8
    Anaphase     0.3553    0.7397    0.4800        73
          G2     0.6293    0.6567    0.6427      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7720      3872
   macro avg     0.6720    0.7882    0.7139      3872
weighted avg     0.7864    0.7720    0.7773      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch115
INFO:root:[116,    50] training loss: 0.00772876
INFO:root:[116,   100] training loss: 0.00744133
INFO:root:[116,   150] training loss: 0.00781837
INFO:root:[116,   200] training loss: 0.00777839
INFO:root:[116,   250] training loss: 0.00781231
INFO:root:[116,   300] training loss: 0.00815304
INFO:root:[116,   350] training loss: 0.00702551
INFO:root:[116,   400] training loss: 0.00000845
INFO:root:[116,   450] training loss: 0.00001699
INFO:root:[116,   500] training loss: 0.00002645
INFO:root:[116,   550] training loss: 0.00013501
INFO:root:[116,   600] training loss: 0.00017354
INFO:root:[116,   650] training loss: 0.00002402
INFO:root:[116,   700] training loss: 0.00002539
INFO:root:[116,   750] training loss: 0.00080926
INFO:root:[116,   800] training loss: 0.00040240
INFO:root:[116,   850] training loss: 0.00024036
INFO:root:[116,   900] training loss: 0.00453352
INFO:root:[116,   950] training loss: 0.00147273
INFO:root:[116,  1000] training loss: 0.00001208
INFO:root:[116,  1050] training loss: 0.00001531
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8980    0.8448    0.8706      1720
   Metaphase     0.7887    0.7849    0.7868      1032
          G1     0.3636    0.5000    0.4211         8
    Anaphase     0.3533    0.7260    0.4753        73
          G2     0.6387    0.6547    0.6466      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7753      3872
   macro avg     0.6727    0.7872    0.7143      3872
weighted avg     0.7882    0.7753    0.7801      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch116
INFO:root:[117,    50] training loss: 0.00778036
INFO:root:[117,   100] training loss: 0.00801235
INFO:root:[117,   150] training loss: 0.00844719
INFO:root:[117,   200] training loss: 0.00749522
INFO:root:[117,   250] training loss: 0.00744438
INFO:root:[117,   300] training loss: 0.00805948
INFO:root:[117,   350] training loss: 0.00699603
INFO:root:[117,   400] training loss: 0.00000838
INFO:root:[117,   450] training loss: 0.00001252
INFO:root:[117,   500] training loss: 0.00003155
INFO:root:[117,   550] training loss: 0.00018366
INFO:root:[117,   600] training loss: 0.00015947
INFO:root:[117,   650] training loss: 0.00002267
INFO:root:[117,   700] training loss: 0.00002430
INFO:root:[117,   750] training loss: 0.00071997
INFO:root:[117,   800] training loss: 0.00036718
INFO:root:[117,   850] training loss: 0.00019904
INFO:root:[117,   900] training loss: 0.00438028
INFO:root:[117,   950] training loss: 0.00137276
INFO:root:[117,  1000] training loss: 0.00001470
INFO:root:[117,  1050] training loss: 0.00001405
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8960    0.8413    0.8678      1720
   Metaphase     0.7909    0.7917    0.7913      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3803    0.7397    0.5023        73
          G2     0.6354    0.6557    0.6454      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7761      3872
   macro avg     0.6877    0.7898    0.7253      3872
weighted avg     0.7877    0.7761    0.7804      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch117
INFO:root:[118,    50] training loss: 0.00784740
INFO:root:[118,   100] training loss: 0.00804810
INFO:root:[118,   150] training loss: 0.00780160
INFO:root:[118,   200] training loss: 0.00727971
INFO:root:[118,   250] training loss: 0.00762605
INFO:root:[118,   300] training loss: 0.00870732
INFO:root:[118,   350] training loss: 0.00758059
INFO:root:[118,   400] training loss: 0.00000899
INFO:root:[118,   450] training loss: 0.00001461
INFO:root:[118,   500] training loss: 0.00002037
INFO:root:[118,   550] training loss: 0.00012473
INFO:root:[118,   600] training loss: 0.00015900
INFO:root:[118,   650] training loss: 0.00002235
INFO:root:[118,   700] training loss: 0.00002138
INFO:root:[118,   750] training loss: 0.00079666
INFO:root:[118,   800] training loss: 0.00029545
INFO:root:[118,   850] training loss: 0.00018596
INFO:root:[118,   900] training loss: 0.00475933
INFO:root:[118,   950] training loss: 0.00177056
INFO:root:[118,  1000] training loss: 0.00001335
INFO:root:[118,  1050] training loss: 0.00000919
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8923    0.8576    0.8746      1720
   Metaphase     0.8040    0.7829    0.7933      1032
          G1     0.4167    0.6250    0.5000         8
    Anaphase     0.3562    0.7123    0.4749        73
          G2     0.6505    0.6605    0.6555      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7820      3872
   macro avg     0.6838    0.8055    0.7283      3872
weighted avg     0.7931    0.7820    0.7862      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch118
INFO:root:[119,    50] training loss: 0.00791451
INFO:root:[119,   100] training loss: 0.00841252
INFO:root:[119,   150] training loss: 0.00778908
INFO:root:[119,   200] training loss: 0.00758763
INFO:root:[119,   250] training loss: 0.00753243
INFO:root:[119,   300] training loss: 0.00849587
INFO:root:[119,   350] training loss: 0.00671260
INFO:root:[119,   400] training loss: 0.00000856
INFO:root:[119,   450] training loss: 0.00002166
INFO:root:[119,   500] training loss: 0.00001644
INFO:root:[119,   550] training loss: 0.00011199
INFO:root:[119,   600] training loss: 0.00013874
INFO:root:[119,   650] training loss: 0.00003484
INFO:root:[119,   700] training loss: 0.00002214
INFO:root:[119,   750] training loss: 0.00063658
INFO:root:[119,   800] training loss: 0.00033371
INFO:root:[119,   850] training loss: 0.00023571
INFO:root:[119,   900] training loss: 0.00477320
INFO:root:[119,   950] training loss: 0.00120082
INFO:root:[119,  1000] training loss: 0.00001871
INFO:root:[119,  1050] training loss: 0.00002114
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8955    0.8523    0.8734      1720
   Metaphase     0.7990    0.7897    0.7943      1032
          G1     0.3846    0.6250    0.4762         8
    Anaphase     0.3813    0.7260    0.5000        73
          G2     0.6443    0.6586    0.6514      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7812      3872
   macro avg     0.6816    0.8074    0.7279      3872
weighted avg     0.7919    0.7812    0.7852      3872

INFO:root:Accuracy of the network on the 3872 validation images: 78 %
INFO:root:epoch119
INFO:root:[120,    50] training loss: 0.00805324
INFO:root:[120,   100] training loss: 0.00805051
INFO:root:[120,   150] training loss: 0.00773822
INFO:root:[120,   200] training loss: 0.00738358
INFO:root:[120,   250] training loss: 0.00753233
INFO:root:[120,   300] training loss: 0.00803728
INFO:root:[120,   350] training loss: 0.00673457
INFO:root:[120,   400] training loss: 0.00000878
INFO:root:[120,   450] training loss: 0.00001227
INFO:root:[120,   500] training loss: 0.00003058
INFO:root:[120,   550] training loss: 0.00011935
INFO:root:[120,   600] training loss: 0.00016976
INFO:root:[120,   650] training loss: 0.00002162
INFO:root:[120,   700] training loss: 0.00001850
INFO:root:[120,   750] training loss: 0.00052115
INFO:root:[120,   800] training loss: 0.00028712
INFO:root:[120,   850] training loss: 0.00018052
INFO:root:[120,   900] training loss: 0.00427755
INFO:root:[120,   950] training loss: 0.00164528
INFO:root:[120,  1000] training loss: 0.00001426
INFO:root:[120,  1050] training loss: 0.00001243
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8959    0.8453    0.8699      1720
   Metaphase     0.7976    0.7868    0.7922      1032
          G1     0.5000    0.5000    0.5000         8
    Anaphase     0.3741    0.7534    0.5000        73
          G2     0.6402    0.6625    0.6511      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7787      3872
   macro avg     0.6964    0.7926    0.7305      3872
weighted avg     0.7907    0.7787    0.7831      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch120
INFO:root:[121,    50] training loss: 0.00709875
INFO:root:[121,   100] training loss: 0.00759327
INFO:root:[121,   150] training loss: 0.00778540
INFO:root:[121,   200] training loss: 0.00737831
INFO:root:[121,   250] training loss: 0.00759722
INFO:root:[121,   300] training loss: 0.00905695
INFO:root:[121,   350] training loss: 0.00684643
INFO:root:[121,   400] training loss: 0.00000949
INFO:root:[121,   450] training loss: 0.00001221
INFO:root:[121,   500] training loss: 0.00004856
INFO:root:[121,   550] training loss: 0.00015440
INFO:root:[121,   600] training loss: 0.00011633
INFO:root:[121,   650] training loss: 0.00002177
INFO:root:[121,   700] training loss: 0.00002395
INFO:root:[121,   750] training loss: 0.00071159
INFO:root:[121,   800] training loss: 0.00027747
INFO:root:[121,   850] training loss: 0.00015833
INFO:root:[121,   900] training loss: 0.00405711
INFO:root:[121,   950] training loss: 0.00159512
INFO:root:[121,  1000] training loss: 0.00001408
INFO:root:[121,  1050] training loss: 0.00001358
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8949    0.8413    0.8672      1720
   Metaphase     0.7860    0.7936    0.7898      1032
          G1     0.4000    0.5000    0.4444         8
    Anaphase     0.3581    0.7260    0.4796        73
          G2     0.6358    0.6451    0.6404      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7735      3872
   macro avg     0.6774    0.7866    0.7174      3872
weighted avg     0.7855    0.7735    0.7779      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch121
INFO:root:[122,    50] training loss: 0.00773322
INFO:root:[122,   100] training loss: 0.00782842
INFO:root:[122,   150] training loss: 0.00764038
INFO:root:[122,   200] training loss: 0.00709001
INFO:root:[122,   250] training loss: 0.00766700
INFO:root:[122,   300] training loss: 0.00781579
INFO:root:[122,   350] training loss: 0.00647951
INFO:root:[122,   400] training loss: 0.00000872
INFO:root:[122,   450] training loss: 0.00001068
INFO:root:[122,   500] training loss: 0.00002207
INFO:root:[122,   550] training loss: 0.00011512
INFO:root:[122,   600] training loss: 0.00016227
INFO:root:[122,   650] training loss: 0.00001908
INFO:root:[122,   700] training loss: 0.00002034
INFO:root:[122,   750] training loss: 0.00060837
INFO:root:[122,   800] training loss: 0.00034565
INFO:root:[122,   850] training loss: 0.00021223
INFO:root:[122,   900] training loss: 0.00472217
INFO:root:[122,   950] training loss: 0.00148948
INFO:root:[122,  1000] training loss: 0.00002193
INFO:root:[122,  1050] training loss: 0.00001493
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8928    0.8424    0.8669      1720
   Metaphase     0.7972    0.7849    0.7910      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3681    0.7260    0.4885        73
          G2     0.6350    0.6596    0.6471      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7756      3872
   macro avg     0.6863    0.7876    0.7234      3872
weighted avg     0.7876    0.7756    0.7801      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch122
INFO:root:[123,    50] training loss: 0.00742214
INFO:root:[123,   100] training loss: 0.00848111
INFO:root:[123,   150] training loss: 0.00745322
INFO:root:[123,   200] training loss: 0.00674887
INFO:root:[123,   250] training loss: 0.00797114
INFO:root:[123,   300] training loss: 0.00768081
INFO:root:[123,   350] training loss: 0.00710142
INFO:root:[123,   400] training loss: 0.00000821
INFO:root:[123,   450] training loss: 0.00001535
INFO:root:[123,   500] training loss: 0.00001827
INFO:root:[123,   550] training loss: 0.00010039
INFO:root:[123,   600] training loss: 0.00016659
INFO:root:[123,   650] training loss: 0.00002403
INFO:root:[123,   700] training loss: 0.00003538
INFO:root:[123,   750] training loss: 0.00103732
INFO:root:[123,   800] training loss: 0.00077868
INFO:root:[123,   850] training loss: 0.00050258
INFO:root:[123,   900] training loss: 0.00413550
INFO:root:[123,   950] training loss: 0.00148175
INFO:root:[123,  1000] training loss: 0.00001750
INFO:root:[123,  1050] training loss: 0.00001184
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.8998    0.8250    0.8608      1720
   Metaphase     0.7971    0.7994    0.7983      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6236    0.6683    0.6452      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7743      3872
   macro avg     0.6894    0.7903    0.7270      3872
weighted avg     0.7882    0.7743    0.7793      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch123
INFO:root:[124,    50] training loss: 0.00831542
INFO:root:[124,   100] training loss: 0.00751492
INFO:root:[124,   150] training loss: 0.00741453
INFO:root:[124,   200] training loss: 0.00730764
INFO:root:[124,   250] training loss: 0.00735743
INFO:root:[124,   300] training loss: 0.00806552
INFO:root:[124,   350] training loss: 0.00683999
INFO:root:[124,   400] training loss: 0.00000961
INFO:root:[124,   450] training loss: 0.00001209
INFO:root:[124,   500] training loss: 0.00004066
INFO:root:[124,   550] training loss: 0.00012345
INFO:root:[124,   600] training loss: 0.00015897
INFO:root:[124,   650] training loss: 0.00002222
INFO:root:[124,   700] training loss: 0.00001638
INFO:root:[124,   750] training loss: 0.00076691
INFO:root:[124,   800] training loss: 0.00058681
INFO:root:[124,   850] training loss: 0.00037376
INFO:root:[124,   900] training loss: 0.00360951
INFO:root:[124,   950] training loss: 0.00098339
INFO:root:[124,  1000] training loss: 0.00001398
INFO:root:[124,  1050] training loss: 0.00001126
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9018    0.8221    0.8601      1720
   Metaphase     0.7967    0.8014    0.7990      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6230    0.6712    0.6462      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7743      3872
   macro avg     0.6895    0.7906    0.7272      3872
weighted avg     0.7888    0.7743    0.7795      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch124
INFO:root:[125,    50] training loss: 0.00813443
INFO:root:[125,   100] training loss: 0.00776370
INFO:root:[125,   150] training loss: 0.00797085
INFO:root:[125,   200] training loss: 0.00701716
INFO:root:[125,   250] training loss: 0.00748048
INFO:root:[125,   300] training loss: 0.00880319
INFO:root:[125,   350] training loss: 0.00658172
INFO:root:[125,   400] training loss: 0.00000855
INFO:root:[125,   450] training loss: 0.00001184
INFO:root:[125,   500] training loss: 0.00002182
INFO:root:[125,   550] training loss: 0.00012207
INFO:root:[125,   600] training loss: 0.00017124
INFO:root:[125,   650] training loss: 0.00002016
INFO:root:[125,   700] training loss: 0.00001650
INFO:root:[125,   750] training loss: 0.00065507
INFO:root:[125,   800] training loss: 0.00044538
INFO:root:[125,   850] training loss: 0.00042216
INFO:root:[125,   900] training loss: 0.00468103
INFO:root:[125,   950] training loss: 0.00114513
INFO:root:[125,  1000] training loss: 0.00001903
INFO:root:[125,  1050] training loss: 0.00001253
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9006    0.8215    0.8592      1720
   Metaphase     0.7983    0.8014    0.7998      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6219    0.6712    0.6456      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7740      3872
   macro avg     0.6898    0.7905    0.7274      3872
weighted avg     0.7884    0.7740    0.7792      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch125
INFO:root:[126,    50] training loss: 0.00786371
INFO:root:[126,   100] training loss: 0.00841481
INFO:root:[126,   150] training loss: 0.00722224
INFO:root:[126,   200] training loss: 0.00717901
INFO:root:[126,   250] training loss: 0.00714440
INFO:root:[126,   300] training loss: 0.00851128
INFO:root:[126,   350] training loss: 0.00643062
INFO:root:[126,   400] training loss: 0.00000947
INFO:root:[126,   450] training loss: 0.00001239
INFO:root:[126,   500] training loss: 0.00006722
INFO:root:[126,   550] training loss: 0.00011667
INFO:root:[126,   600] training loss: 0.00018481
INFO:root:[126,   650] training loss: 0.00001521
INFO:root:[126,   700] training loss: 0.00001878
INFO:root:[126,   750] training loss: 0.00057507
INFO:root:[126,   800] training loss: 0.00055776
INFO:root:[126,   850] training loss: 0.00043651
INFO:root:[126,   900] training loss: 0.00435698
INFO:root:[126,   950] training loss: 0.00117281
INFO:root:[126,  1000] training loss: 0.00002085
INFO:root:[126,  1050] training loss: 0.00001498
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9001    0.8221    0.8593      1720
   Metaphase     0.7961    0.7984    0.7973      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6203    0.6683    0.6434      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7727      3872
   macro avg     0.6888    0.7898    0.7264      3872
weighted avg     0.7871    0.7727    0.7779      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch126
INFO:root:[127,    50] training loss: 0.00721199
INFO:root:[127,   100] training loss: 0.00739110
INFO:root:[127,   150] training loss: 0.00716413
INFO:root:[127,   200] training loss: 0.00849678
INFO:root:[127,   250] training loss: 0.00788653
INFO:root:[127,   300] training loss: 0.00807923
INFO:root:[127,   350] training loss: 0.00636950
INFO:root:[127,   400] training loss: 0.00001015
INFO:root:[127,   450] training loss: 0.00001080
INFO:root:[127,   500] training loss: 0.00003396
INFO:root:[127,   550] training loss: 0.00013473
INFO:root:[127,   600] training loss: 0.00013006
INFO:root:[127,   650] training loss: 0.00001653
INFO:root:[127,   700] training loss: 0.00002003
INFO:root:[127,   750] training loss: 0.00050876
INFO:root:[127,   800] training loss: 0.00031653
INFO:root:[127,   850] training loss: 0.00039410
INFO:root:[127,   900] training loss: 0.00451748
INFO:root:[127,   950] training loss: 0.00183226
INFO:root:[127,  1000] training loss: 0.00001611
INFO:root:[127,  1050] training loss: 0.00001296
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9007    0.8227    0.8599      1720
   Metaphase     0.8016    0.7984    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6230    0.6760    0.6484      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7751      3872
   macro avg     0.6905    0.7910    0.7280      3872
weighted avg     0.7896    0.7751    0.7803      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch127
INFO:root:[128,    50] training loss: 0.00706672
INFO:root:[128,   100] training loss: 0.00814305
INFO:root:[128,   150] training loss: 0.00788988
INFO:root:[128,   200] training loss: 0.00720978
INFO:root:[128,   250] training loss: 0.00723949
INFO:root:[128,   300] training loss: 0.00832107
INFO:root:[128,   350] training loss: 0.00709601
INFO:root:[128,   400] training loss: 0.00000893
INFO:root:[128,   450] training loss: 0.00001156
INFO:root:[128,   500] training loss: 0.00001668
INFO:root:[128,   550] training loss: 0.00014499
INFO:root:[128,   600] training loss: 0.00010529
INFO:root:[128,   650] training loss: 0.00001555
INFO:root:[128,   700] training loss: 0.00001888
INFO:root:[128,   750] training loss: 0.00047830
INFO:root:[128,   800] training loss: 0.00033636
INFO:root:[128,   850] training loss: 0.00037794
INFO:root:[128,   900] training loss: 0.00371146
INFO:root:[128,   950] training loss: 0.00102399
INFO:root:[128,  1000] training loss: 0.00001579
INFO:root:[128,  1050] training loss: 0.00001398
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9024    0.8221    0.8604      1720
   Metaphase     0.8027    0.7926    0.7977      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3885    0.7397    0.5094        73
          G2     0.6228    0.6818    0.6510      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7748      3872
   macro avg     0.6896    0.7909    0.7270      3872
weighted avg     0.7905    0.7748    0.7804      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch128
INFO:root:[129,    50] training loss: 0.00719942
INFO:root:[129,   100] training loss: 0.00746166
INFO:root:[129,   150] training loss: 0.00747669
INFO:root:[129,   200] training loss: 0.00670938
INFO:root:[129,   250] training loss: 0.00798496
INFO:root:[129,   300] training loss: 0.00738982
INFO:root:[129,   350] training loss: 0.00645958
INFO:root:[129,   400] training loss: 0.00000957
INFO:root:[129,   450] training loss: 0.00001104
INFO:root:[129,   500] training loss: 0.00003473
INFO:root:[129,   550] training loss: 0.00016673
INFO:root:[129,   600] training loss: 0.00012437
INFO:root:[129,   650] training loss: 0.00002457
INFO:root:[129,   700] training loss: 0.00001952
INFO:root:[129,   750] training loss: 0.00042739
INFO:root:[129,   800] training loss: 0.00042378
INFO:root:[129,   850] training loss: 0.00034945
INFO:root:[129,   900] training loss: 0.00422296
INFO:root:[129,   950] training loss: 0.00123152
INFO:root:[129,  1000] training loss: 0.00001586
INFO:root:[129,  1050] training loss: 0.00001605
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9020    0.8238    0.8611      1720
   Metaphase     0.8037    0.7936    0.7986      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6225    0.6809    0.6503      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7756      3872
   macro avg     0.6909    0.7911    0.7282      3872
weighted avg     0.7906    0.7756    0.7810      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch129
INFO:root:[130,    50] training loss: 0.00816767
INFO:root:[130,   100] training loss: 0.00718867
INFO:root:[130,   150] training loss: 0.00750248
INFO:root:[130,   200] training loss: 0.00739703
INFO:root:[130,   250] training loss: 0.00761954
INFO:root:[130,   300] training loss: 0.00774074
INFO:root:[130,   350] training loss: 0.00651315
INFO:root:[130,   400] training loss: 0.00000911
INFO:root:[130,   450] training loss: 0.00001402
INFO:root:[130,   500] training loss: 0.00001723
INFO:root:[130,   550] training loss: 0.00017795
INFO:root:[130,   600] training loss: 0.00011972
INFO:root:[130,   650] training loss: 0.00002635
INFO:root:[130,   700] training loss: 0.00001897
INFO:root:[130,   750] training loss: 0.00043125
INFO:root:[130,   800] training loss: 0.00032345
INFO:root:[130,   850] training loss: 0.00035710
INFO:root:[130,   900] training loss: 0.00415756
INFO:root:[130,   950] training loss: 0.00131504
INFO:root:[130,  1000] training loss: 0.00001578
INFO:root:[130,  1050] training loss: 0.00001596
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9020    0.8192    0.8586      1720
   Metaphase     0.8016    0.7946    0.7981      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6185    0.6789    0.6473      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7732      3872
   macro avg     0.6896    0.7903    0.7270      3872
weighted avg     0.7890    0.7732    0.7788      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch130
INFO:root:[131,    50] training loss: 0.00716252
INFO:root:[131,   100] training loss: 0.00704488
INFO:root:[131,   150] training loss: 0.00723115
INFO:root:[131,   200] training loss: 0.00685483
INFO:root:[131,   250] training loss: 0.00719210
INFO:root:[131,   300] training loss: 0.00745325
INFO:root:[131,   350] training loss: 0.00726153
INFO:root:[131,   400] training loss: 0.00000917
INFO:root:[131,   450] training loss: 0.00001404
INFO:root:[131,   500] training loss: 0.00001740
INFO:root:[131,   550] training loss: 0.00012160
INFO:root:[131,   600] training loss: 0.00015802
INFO:root:[131,   650] training loss: 0.00002248
INFO:root:[131,   700] training loss: 0.00001442
INFO:root:[131,   750] training loss: 0.00044395
INFO:root:[131,   800] training loss: 0.00035588
INFO:root:[131,   850] training loss: 0.00029554
INFO:root:[131,   900] training loss: 0.00418360
INFO:root:[131,   950] training loss: 0.00133184
INFO:root:[131,  1000] training loss: 0.00005318
INFO:root:[131,  1050] training loss: 0.00001347
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9003    0.8238    0.8604      1720
   Metaphase     0.8021    0.7975    0.7998      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.4030    0.7397    0.5217        73
          G2     0.6224    0.6760    0.6481      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7753      3872
   macro avg     0.6913    0.7910    0.7287      3872
weighted avg     0.7896    0.7753    0.7804      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch131
INFO:root:[132,    50] training loss: 0.00773732
INFO:root:[132,   100] training loss: 0.00735859
INFO:root:[132,   150] training loss: 0.00736918
INFO:root:[132,   200] training loss: 0.00706874
INFO:root:[132,   250] training loss: 0.00748899
INFO:root:[132,   300] training loss: 0.00776415
INFO:root:[132,   350] training loss: 0.00648633
INFO:root:[132,   400] training loss: 0.00000841
INFO:root:[132,   450] training loss: 0.00001063
INFO:root:[132,   500] training loss: 0.00002564
INFO:root:[132,   550] training loss: 0.00012265
INFO:root:[132,   600] training loss: 0.00015466
INFO:root:[132,   650] training loss: 0.00001449
INFO:root:[132,   700] training loss: 0.00001646
INFO:root:[132,   750] training loss: 0.00039243
INFO:root:[132,   800] training loss: 0.00037034
INFO:root:[132,   850] training loss: 0.00036008
INFO:root:[132,   900] training loss: 0.00390955
INFO:root:[132,   950] training loss: 0.00140407
INFO:root:[132,  1000] training loss: 0.00001814
INFO:root:[132,  1050] training loss: 0.00001208
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9009    0.8244    0.8610      1720
   Metaphase     0.8014    0.7975    0.7994      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6232    0.6750    0.6481      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7753      3872
   macro avg     0.6905    0.7910    0.7280      3872
weighted avg     0.7897    0.7753    0.7805      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch132
INFO:root:[133,    50] training loss: 0.00758682
INFO:root:[133,   100] training loss: 0.00743800
INFO:root:[133,   150] training loss: 0.00768566
INFO:root:[133,   200] training loss: 0.00696489
INFO:root:[133,   250] training loss: 0.00723344
INFO:root:[133,   300] training loss: 0.00752025
INFO:root:[133,   350] training loss: 0.00677365
INFO:root:[133,   400] training loss: 0.00000883
INFO:root:[133,   450] training loss: 0.00001133
INFO:root:[133,   500] training loss: 0.00002737
INFO:root:[133,   550] training loss: 0.00015129
INFO:root:[133,   600] training loss: 0.00013899
INFO:root:[133,   650] training loss: 0.00001603
INFO:root:[133,   700] training loss: 0.00001564
INFO:root:[133,   750] training loss: 0.00034311
INFO:root:[133,   800] training loss: 0.00037949
INFO:root:[133,   850] training loss: 0.00034757
INFO:root:[133,   900] training loss: 0.00425147
INFO:root:[133,   950] training loss: 0.00120266
INFO:root:[133,  1000] training loss: 0.00001535
INFO:root:[133,  1050] training loss: 0.00001405
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9020    0.8244    0.8615      1720
   Metaphase     0.8047    0.7984    0.8016      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6258    0.6809    0.6522      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6915    0.7919    0.7289      3872
weighted avg     0.7918    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch133
INFO:root:[134,    50] training loss: 0.00760461
INFO:root:[134,   100] training loss: 0.00721920
INFO:root:[134,   150] training loss: 0.00749857
INFO:root:[134,   200] training loss: 0.00725848
INFO:root:[134,   250] training loss: 0.00735269
INFO:root:[134,   300] training loss: 0.00776758
INFO:root:[134,   350] training loss: 0.00676359
INFO:root:[134,   400] training loss: 0.00000926
INFO:root:[134,   450] training loss: 0.00001227
INFO:root:[134,   500] training loss: 0.00001814
INFO:root:[134,   550] training loss: 0.00015955
INFO:root:[134,   600] training loss: 0.00020006
INFO:root:[134,   650] training loss: 0.00001653
INFO:root:[134,   700] training loss: 0.00001574
INFO:root:[134,   750] training loss: 0.00033777
INFO:root:[134,   800] training loss: 0.00034013
INFO:root:[134,   850] training loss: 0.00028180
INFO:root:[134,   900] training loss: 0.00341416
INFO:root:[134,   950] training loss: 0.00213894
INFO:root:[134,  1000] training loss: 0.00002248
INFO:root:[134,  1050] training loss: 0.00001978
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9021    0.8250    0.8618      1720
   Metaphase     0.8041    0.7994    0.8017      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6266    0.6799    0.6521      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6916    0.7920    0.7290      3872
weighted avg     0.7919    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch134
INFO:root:[135,    50] training loss: 0.00709783
INFO:root:[135,   100] training loss: 0.00761903
INFO:root:[135,   150] training loss: 0.00749414
INFO:root:[135,   200] training loss: 0.00672906
INFO:root:[135,   250] training loss: 0.00702752
INFO:root:[135,   300] training loss: 0.00768562
INFO:root:[135,   350] training loss: 0.00652711
INFO:root:[135,   400] training loss: 0.00001067
INFO:root:[135,   450] training loss: 0.00001242
INFO:root:[135,   500] training loss: 0.00001564
INFO:root:[135,   550] training loss: 0.00011652
INFO:root:[135,   600] training loss: 0.00012971
INFO:root:[135,   650] training loss: 0.00001569
INFO:root:[135,   700] training loss: 0.00001337
INFO:root:[135,   750] training loss: 0.00034211
INFO:root:[135,   800] training loss: 0.00036023
INFO:root:[135,   850] training loss: 0.00034192
INFO:root:[135,   900] training loss: 0.00431137
INFO:root:[135,   950] training loss: 0.00146623
INFO:root:[135,  1000] training loss: 0.00001762
INFO:root:[135,  1050] training loss: 0.00001318
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9016    0.8256    0.8619      1720
   Metaphase     0.8041    0.7994    0.8017      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6268    0.6789    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7917    0.7774    0.7825      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch135
INFO:root:[136,    50] training loss: 0.00797122
INFO:root:[136,   100] training loss: 0.00734437
INFO:root:[136,   150] training loss: 0.00731516
INFO:root:[136,   200] training loss: 0.00759581
INFO:root:[136,   250] training loss: 0.00698301
INFO:root:[136,   300] training loss: 0.00770887
INFO:root:[136,   350] training loss: 0.00779550
INFO:root:[136,   400] training loss: 0.00000854
INFO:root:[136,   450] training loss: 0.00001308
INFO:root:[136,   500] training loss: 0.00001813
INFO:root:[136,   550] training loss: 0.00016777
INFO:root:[136,   600] training loss: 0.00013951
INFO:root:[136,   650] training loss: 0.00001535
INFO:root:[136,   700] training loss: 0.00002397
INFO:root:[136,   750] training loss: 0.00041142
INFO:root:[136,   800] training loss: 0.00035985
INFO:root:[136,   850] training loss: 0.00036873
INFO:root:[136,   900] training loss: 0.00475690
INFO:root:[136,   950] training loss: 0.00136438
INFO:root:[136,  1000] training loss: 0.00005384
INFO:root:[136,  1050] training loss: 0.00001320
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9016    0.8256    0.8619      1720
   Metaphase     0.8029    0.7975    0.8002      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6259    0.6779    0.6509      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6908    0.7915    0.7283      3872
weighted avg     0.7911    0.7766    0.7818      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch136
INFO:root:[137,    50] training loss: 0.00735474
INFO:root:[137,   100] training loss: 0.00717669
INFO:root:[137,   150] training loss: 0.00722052
INFO:root:[137,   200] training loss: 0.00687564
INFO:root:[137,   250] training loss: 0.00709050
INFO:root:[137,   300] training loss: 0.00799540
INFO:root:[137,   350] training loss: 0.00653606
INFO:root:[137,   400] training loss: 0.00000782
INFO:root:[137,   450] training loss: 0.00001500
INFO:root:[137,   500] training loss: 0.00001487
INFO:root:[137,   550] training loss: 0.00016093
INFO:root:[137,   600] training loss: 0.00013745
INFO:root:[137,   650] training loss: 0.00001506
INFO:root:[137,   700] training loss: 0.00001701
INFO:root:[137,   750] training loss: 0.00039342
INFO:root:[137,   800] training loss: 0.00033502
INFO:root:[137,   850] training loss: 0.00036835
INFO:root:[137,   900] training loss: 0.00357023
INFO:root:[137,   950] training loss: 0.00152424
INFO:root:[137,  1000] training loss: 0.00002755
INFO:root:[137,  1050] training loss: 0.00001563
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9016    0.8262    0.8623      1720
   Metaphase     0.8033    0.7994    0.8014      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.4000    0.7397    0.5192        73
          G2     0.6265    0.6779    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6918    0.7919    0.7292      3872
weighted avg     0.7915    0.7774    0.7825      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch137
INFO:root:[138,    50] training loss: 0.00799146
INFO:root:[138,   100] training loss: 0.00779733
INFO:root:[138,   150] training loss: 0.00694078
INFO:root:[138,   200] training loss: 0.00777883
INFO:root:[138,   250] training loss: 0.00753992
INFO:root:[138,   300] training loss: 0.00792095
INFO:root:[138,   350] training loss: 0.00641472
INFO:root:[138,   400] training loss: 0.00000867
INFO:root:[138,   450] training loss: 0.00001111
INFO:root:[138,   500] training loss: 0.00002162
INFO:root:[138,   550] training loss: 0.00011264
INFO:root:[138,   600] training loss: 0.00013844
INFO:root:[138,   650] training loss: 0.00001321
INFO:root:[138,   700] training loss: 0.00001365
INFO:root:[138,   750] training loss: 0.00038353
INFO:root:[138,   800] training loss: 0.00040087
INFO:root:[138,   850] training loss: 0.00032618
INFO:root:[138,   900] training loss: 0.00413635
INFO:root:[138,   950] training loss: 0.00191408
INFO:root:[138,  1000] training loss: 0.00001882
INFO:root:[138,  1050] training loss: 0.00001715
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9016    0.8256    0.8619      1720
   Metaphase     0.8025    0.7994    0.8010      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.4000    0.7397    0.5192        73
          G2     0.6256    0.6770    0.6503      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6915    0.7917    0.7290      3872
weighted avg     0.7910    0.7769    0.7820      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch138
INFO:root:[139,    50] training loss: 0.00682216
INFO:root:[139,   100] training loss: 0.00726589
INFO:root:[139,   150] training loss: 0.00776997
INFO:root:[139,   200] training loss: 0.00700355
INFO:root:[139,   250] training loss: 0.00692970
INFO:root:[139,   300] training loss: 0.00753812
INFO:root:[139,   350] training loss: 0.00658133
INFO:root:[139,   400] training loss: 0.00000823
INFO:root:[139,   450] training loss: 0.00001093
INFO:root:[139,   500] training loss: 0.00001669
INFO:root:[139,   550] training loss: 0.00013721
INFO:root:[139,   600] training loss: 0.00015489
INFO:root:[139,   650] training loss: 0.00001525
INFO:root:[139,   700] training loss: 0.00001696
INFO:root:[139,   750] training loss: 0.00033657
INFO:root:[139,   800] training loss: 0.00038984
INFO:root:[139,   850] training loss: 0.00031415
INFO:root:[139,   900] training loss: 0.00365662
INFO:root:[139,   950] training loss: 0.00163391
INFO:root:[139,  1000] training loss: 0.00001610
INFO:root:[139,  1050] training loss: 0.00001824
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9022    0.8262    0.8625      1720
   Metaphase     0.8035    0.8004    0.8019      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.4030    0.7397    0.5217        73
          G2     0.6259    0.6779    0.6509      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7776      3872
   macro avg     0.6922    0.7920    0.7297      3872
weighted avg     0.7917    0.7776    0.7827      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch139
INFO:root:[140,    50] training loss: 0.00743620
INFO:root:[140,   100] training loss: 0.00724284
INFO:root:[140,   150] training loss: 0.00719942
INFO:root:[140,   200] training loss: 0.00701675
INFO:root:[140,   250] training loss: 0.00708077
INFO:root:[140,   300] training loss: 0.00769045
INFO:root:[140,   350] training loss: 0.00656852
INFO:root:[140,   400] training loss: 0.00000847
INFO:root:[140,   450] training loss: 0.00001166
INFO:root:[140,   500] training loss: 0.00001898
INFO:root:[140,   550] training loss: 0.00015535
INFO:root:[140,   600] training loss: 0.00016210
INFO:root:[140,   650] training loss: 0.00002460
INFO:root:[140,   700] training loss: 0.00002058
INFO:root:[140,   750] training loss: 0.00040038
INFO:root:[140,   800] training loss: 0.00033745
INFO:root:[140,   850] training loss: 0.00037768
INFO:root:[140,   900] training loss: 0.00359949
INFO:root:[140,   950] training loss: 0.00209369
INFO:root:[140,  1000] training loss: 0.00001500
INFO:root:[140,  1050] training loss: 0.00001256
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9016    0.8262    0.8623      1720
   Metaphase     0.8031    0.7984    0.8008      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6265    0.6779    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6913    0.7918    0.7288      3872
weighted avg     0.7914    0.7771    0.7823      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch140
INFO:root:[141,    50] training loss: 0.00733324
INFO:root:[141,   100] training loss: 0.00739387
INFO:root:[141,   150] training loss: 0.00781226
INFO:root:[141,   200] training loss: 0.00715413
INFO:root:[141,   250] training loss: 0.00734180
INFO:root:[141,   300] training loss: 0.00791750
INFO:root:[141,   350] training loss: 0.00639789
INFO:root:[141,   400] training loss: 0.00000932
INFO:root:[141,   450] training loss: 0.00001385
INFO:root:[141,   500] training loss: 0.00001649
INFO:root:[141,   550] training loss: 0.00012220
INFO:root:[141,   600] training loss: 0.00014981
INFO:root:[141,   650] training loss: 0.00001592
INFO:root:[141,   700] training loss: 0.00001612
INFO:root:[141,   750] training loss: 0.00039789
INFO:root:[141,   800] training loss: 0.00036979
INFO:root:[141,   850] training loss: 0.00034556
INFO:root:[141,   900] training loss: 0.00392714
INFO:root:[141,   950] training loss: 0.00141150
INFO:root:[141,  1000] training loss: 0.00002354
INFO:root:[141,  1050] training loss: 0.00001373
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9015    0.8250    0.8616      1720
   Metaphase     0.8031    0.7984    0.8008      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6253    0.6779    0.6506      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6912    0.7916    0.7286      3872
weighted avg     0.7910    0.7766    0.7818      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch141
INFO:root:[142,    50] training loss: 0.00761951
INFO:root:[142,   100] training loss: 0.00743019
INFO:root:[142,   150] training loss: 0.00750262
INFO:root:[142,   200] training loss: 0.00707542
INFO:root:[142,   250] training loss: 0.00712716
INFO:root:[142,   300] training loss: 0.00826554
INFO:root:[142,   350] training loss: 0.00672218
INFO:root:[142,   400] training loss: 0.00000793
INFO:root:[142,   450] training loss: 0.00001522
INFO:root:[142,   500] training loss: 0.00002521
INFO:root:[142,   550] training loss: 0.00013848
INFO:root:[142,   600] training loss: 0.00012367
INFO:root:[142,   650] training loss: 0.00001743
INFO:root:[142,   700] training loss: 0.00001542
INFO:root:[142,   750] training loss: 0.00037404
INFO:root:[142,   800] training loss: 0.00034510
INFO:root:[142,   850] training loss: 0.00031213
INFO:root:[142,   900] training loss: 0.00380685
INFO:root:[142,   950] training loss: 0.00147008
INFO:root:[142,  1000] training loss: 0.00001923
INFO:root:[142,  1050] training loss: 0.00001448
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9016    0.8262    0.8623      1720
   Metaphase     0.8031    0.7984    0.8008      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6265    0.6779    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6913    0.7918    0.7288      3872
weighted avg     0.7914    0.7771    0.7823      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch142
INFO:root:[143,    50] training loss: 0.00729589
INFO:root:[143,   100] training loss: 0.00697438
INFO:root:[143,   150] training loss: 0.00758232
INFO:root:[143,   200] training loss: 0.00704299
INFO:root:[143,   250] training loss: 0.00746325
INFO:root:[143,   300] training loss: 0.00788126
INFO:root:[143,   350] training loss: 0.00656315
INFO:root:[143,   400] training loss: 0.00000885
INFO:root:[143,   450] training loss: 0.00001314
INFO:root:[143,   500] training loss: 0.00002941
INFO:root:[143,   550] training loss: 0.00013239
INFO:root:[143,   600] training loss: 0.00012461
INFO:root:[143,   650] training loss: 0.00001434
INFO:root:[143,   700] training loss: 0.00001809
INFO:root:[143,   750] training loss: 0.00036567
INFO:root:[143,   800] training loss: 0.00031796
INFO:root:[143,   850] training loss: 0.00028980
INFO:root:[143,   900] training loss: 0.00363138
INFO:root:[143,   950] training loss: 0.00113978
INFO:root:[143,  1000] training loss: 0.00001507
INFO:root:[143,  1050] training loss: 0.00001209
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9015    0.8244    0.8612      1720
   Metaphase     0.8031    0.7984    0.8008      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6248    0.6779    0.6503      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7763      3872
   macro avg     0.6911    0.7915    0.7285      3872
weighted avg     0.7909    0.7763    0.7816      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch143
INFO:root:[144,    50] training loss: 0.00742139
INFO:root:[144,   100] training loss: 0.00739871
INFO:root:[144,   150] training loss: 0.00749434
INFO:root:[144,   200] training loss: 0.00669107
INFO:root:[144,   250] training loss: 0.00709882
INFO:root:[144,   300] training loss: 0.00760380
INFO:root:[144,   350] training loss: 0.00620869
INFO:root:[144,   400] training loss: 0.00001235
INFO:root:[144,   450] training loss: 0.00001837
INFO:root:[144,   500] training loss: 0.00002165
INFO:root:[144,   550] training loss: 0.00010717
INFO:root:[144,   600] training loss: 0.00013889
INFO:root:[144,   650] training loss: 0.00001772
INFO:root:[144,   700] training loss: 0.00001958
INFO:root:[144,   750] training loss: 0.00045205
INFO:root:[144,   800] training loss: 0.00029821
INFO:root:[144,   850] training loss: 0.00042852
INFO:root:[144,   900] training loss: 0.00390135
INFO:root:[144,   950] training loss: 0.00145815
INFO:root:[144,  1000] training loss: 0.00002447
INFO:root:[144,  1050] training loss: 0.00001387
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6913    0.7917    0.7287      3872
weighted avg     0.7916    0.7769    0.7821      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch144
INFO:root:[145,    50] training loss: 0.00716791
INFO:root:[145,   100] training loss: 0.00720231
INFO:root:[145,   150] training loss: 0.00723715
INFO:root:[145,   200] training loss: 0.00670213
INFO:root:[145,   250] training loss: 0.00745503
INFO:root:[145,   300] training loss: 0.00808869
INFO:root:[145,   350] training loss: 0.00685776
INFO:root:[145,   400] training loss: 0.00000935
INFO:root:[145,   450] training loss: 0.00001286
INFO:root:[145,   500] training loss: 0.00001585
INFO:root:[145,   550] training loss: 0.00016424
INFO:root:[145,   600] training loss: 0.00017488
INFO:root:[145,   650] training loss: 0.00001638
INFO:root:[145,   700] training loss: 0.00001408
INFO:root:[145,   750] training loss: 0.00039651
INFO:root:[145,   800] training loss: 0.00027592
INFO:root:[145,   850] training loss: 0.00036258
INFO:root:[145,   900] training loss: 0.00366651
INFO:root:[145,   950] training loss: 0.00132470
INFO:root:[145,  1000] training loss: 0.00002205
INFO:root:[145,  1050] training loss: 0.00001617
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6913    0.7917    0.7287      3872
weighted avg     0.7916    0.7769    0.7821      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch145
INFO:root:[146,    50] training loss: 0.00729235
INFO:root:[146,   100] training loss: 0.00722385
INFO:root:[146,   150] training loss: 0.00710130
INFO:root:[146,   200] training loss: 0.00680615
INFO:root:[146,   250] training loss: 0.00718705
INFO:root:[146,   300] training loss: 0.00799128
INFO:root:[146,   350] training loss: 0.00659890
INFO:root:[146,   400] training loss: 0.00001089
INFO:root:[146,   450] training loss: 0.00001202
INFO:root:[146,   500] training loss: 0.00001705
INFO:root:[146,   550] training loss: 0.00012628
INFO:root:[146,   600] training loss: 0.00014794
INFO:root:[146,   650] training loss: 0.00001486
INFO:root:[146,   700] training loss: 0.00001434
INFO:root:[146,   750] training loss: 0.00034500
INFO:root:[146,   800] training loss: 0.00035791
INFO:root:[146,   850] training loss: 0.00030246
INFO:root:[146,   900] training loss: 0.00384768
INFO:root:[146,   950] training loss: 0.00180131
INFO:root:[146,  1000] training loss: 0.00001389
INFO:root:[146,  1050] training loss: 0.00001328
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6914    0.7918    0.7288      3872
weighted avg     0.7918    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch146
INFO:root:[147,    50] training loss: 0.00738420
INFO:root:[147,   100] training loss: 0.00773138
INFO:root:[147,   150] training loss: 0.00729440
INFO:root:[147,   200] training loss: 0.00839705
INFO:root:[147,   250] training loss: 0.00740623
INFO:root:[147,   300] training loss: 0.00763110
INFO:root:[147,   350] training loss: 0.00728802
INFO:root:[147,   400] training loss: 0.00000877
INFO:root:[147,   450] training loss: 0.00001043
INFO:root:[147,   500] training loss: 0.00002947
INFO:root:[147,   550] training loss: 0.00021512
INFO:root:[147,   600] training loss: 0.00012326
INFO:root:[147,   650] training loss: 0.00001840
INFO:root:[147,   700] training loss: 0.00002298
INFO:root:[147,   750] training loss: 0.00034380
INFO:root:[147,   800] training loss: 0.00031731
INFO:root:[147,   850] training loss: 0.00044575
INFO:root:[147,   900] training loss: 0.00426301
INFO:root:[147,   950] training loss: 0.00140088
INFO:root:[147,  1000] training loss: 0.00001306
INFO:root:[147,  1050] training loss: 0.00002026
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch147
INFO:root:[148,    50] training loss: 0.00725552
INFO:root:[148,   100] training loss: 0.00758520
INFO:root:[148,   150] training loss: 0.00788343
INFO:root:[148,   200] training loss: 0.00741936
INFO:root:[148,   250] training loss: 0.00758761
INFO:root:[148,   300] training loss: 0.00809327
INFO:root:[148,   350] training loss: 0.00626686
INFO:root:[148,   400] training loss: 0.00000964
INFO:root:[148,   450] training loss: 0.00001161
INFO:root:[148,   500] training loss: 0.00001845
INFO:root:[148,   550] training loss: 0.00014155
INFO:root:[148,   600] training loss: 0.00014973
INFO:root:[148,   650] training loss: 0.00001302
INFO:root:[148,   700] training loss: 0.00001494
INFO:root:[148,   750] training loss: 0.00043111
INFO:root:[148,   800] training loss: 0.00029733
INFO:root:[148,   850] training loss: 0.00034062
INFO:root:[148,   900] training loss: 0.00354074
INFO:root:[148,   950] training loss: 0.00153098
INFO:root:[148,  1000] training loss: 0.00001317
INFO:root:[148,  1050] training loss: 0.00001887
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6915    0.7919    0.7289      3872
weighted avg     0.7918    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch148
INFO:root:[149,    50] training loss: 0.00719092
INFO:root:[149,   100] training loss: 0.00754942
INFO:root:[149,   150] training loss: 0.00729786
INFO:root:[149,   200] training loss: 0.00666576
INFO:root:[149,   250] training loss: 0.00693493
INFO:root:[149,   300] training loss: 0.00828984
INFO:root:[149,   350] training loss: 0.00660740
INFO:root:[149,   400] training loss: 0.00000981
INFO:root:[149,   450] training loss: 0.00001042
INFO:root:[149,   500] training loss: 0.00001683
INFO:root:[149,   550] training loss: 0.00057938
INFO:root:[149,   600] training loss: 0.00014958
INFO:root:[149,   650] training loss: 0.00001340
INFO:root:[149,   700] training loss: 0.00001566
INFO:root:[149,   750] training loss: 0.00037101
INFO:root:[149,   800] training loss: 0.00034213
INFO:root:[149,   850] training loss: 0.00023403
INFO:root:[149,   900] training loss: 0.00378241
INFO:root:[149,   950] training loss: 0.00101258
INFO:root:[149,  1000] training loss: 0.00001801
INFO:root:[149,  1050] training loss: 0.00001240
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch149
INFO:root:[150,    50] training loss: 0.00745451
INFO:root:[150,   100] training loss: 0.00766737
INFO:root:[150,   150] training loss: 0.00821948
INFO:root:[150,   200] training loss: 0.00704501
INFO:root:[150,   250] training loss: 0.00679115
INFO:root:[150,   300] training loss: 0.00780901
INFO:root:[150,   350] training loss: 0.00667875
INFO:root:[150,   400] training loss: 0.00000992
INFO:root:[150,   450] training loss: 0.00001098
INFO:root:[150,   500] training loss: 0.00001993
INFO:root:[150,   550] training loss: 0.00013852
INFO:root:[150,   600] training loss: 0.00020353
INFO:root:[150,   650] training loss: 0.00001846
INFO:root:[150,   700] training loss: 0.00001505
INFO:root:[150,   750] training loss: 0.00028491
INFO:root:[150,   800] training loss: 0.00028956
INFO:root:[150,   850] training loss: 0.00032713
INFO:root:[150,   900] training loss: 0.00466892
INFO:root:[150,   950] training loss: 0.00141084
INFO:root:[150,  1000] training loss: 0.00001679
INFO:root:[150,  1050] training loss: 0.00001116
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch150
INFO:root:[151,    50] training loss: 0.00757472
INFO:root:[151,   100] training loss: 0.00709279
INFO:root:[151,   150] training loss: 0.00690708
INFO:root:[151,   200] training loss: 0.00676549
INFO:root:[151,   250] training loss: 0.00724189
INFO:root:[151,   300] training loss: 0.00778485
INFO:root:[151,   350] training loss: 0.00638184
INFO:root:[151,   400] training loss: 0.00001088
INFO:root:[151,   450] training loss: 0.00001468
INFO:root:[151,   500] training loss: 0.00001604
INFO:root:[151,   550] training loss: 0.00017710
INFO:root:[151,   600] training loss: 0.00013904
INFO:root:[151,   650] training loss: 0.00001782
INFO:root:[151,   700] training loss: 0.00001272
INFO:root:[151,   750] training loss: 0.00038914
INFO:root:[151,   800] training loss: 0.00029803
INFO:root:[151,   850] training loss: 0.00031777
INFO:root:[151,   900] training loss: 0.00370788
INFO:root:[151,   950] training loss: 0.00177314
INFO:root:[151,  1000] training loss: 0.00001560
INFO:root:[151,  1050] training loss: 0.00001635
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch151
INFO:root:[152,    50] training loss: 0.00737621
INFO:root:[152,   100] training loss: 0.00730063
INFO:root:[152,   150] training loss: 0.00721006
INFO:root:[152,   200] training loss: 0.00683486
INFO:root:[152,   250] training loss: 0.00816121
INFO:root:[152,   300] training loss: 0.00737944
INFO:root:[152,   350] training loss: 0.00642959
INFO:root:[152,   400] training loss: 0.00000998
INFO:root:[152,   450] training loss: 0.00001267
INFO:root:[152,   500] training loss: 0.00002569
INFO:root:[152,   550] training loss: 0.00014450
INFO:root:[152,   600] training loss: 0.00015544
INFO:root:[152,   650] training loss: 0.00001428
INFO:root:[152,   700] training loss: 0.00001790
INFO:root:[152,   750] training loss: 0.00036288
INFO:root:[152,   800] training loss: 0.00033538
INFO:root:[152,   850] training loss: 0.00034245
INFO:root:[152,   900] training loss: 0.00502023
INFO:root:[152,   950] training loss: 0.00138920
INFO:root:[152,  1000] training loss: 0.00001756
INFO:root:[152,  1050] training loss: 0.00001110
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9026    0.8244    0.8617      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6914    0.7918    0.7288      3872
weighted avg     0.7916    0.7769    0.7821      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch152
INFO:root:[153,    50] training loss: 0.00755981
INFO:root:[153,   100] training loss: 0.00772484
INFO:root:[153,   150] training loss: 0.00815906
INFO:root:[153,   200] training loss: 0.00697070
INFO:root:[153,   250] training loss: 0.00697506
INFO:root:[153,   300] training loss: 0.00726924
INFO:root:[153,   350] training loss: 0.00673244
INFO:root:[153,   400] training loss: 0.00000955
INFO:root:[153,   450] training loss: 0.00001123
INFO:root:[153,   500] training loss: 0.00003553
INFO:root:[153,   550] training loss: 0.00012606
INFO:root:[153,   600] training loss: 0.00009717
INFO:root:[153,   650] training loss: 0.00002149
INFO:root:[153,   700] training loss: 0.00001362
INFO:root:[153,   750] training loss: 0.00036485
INFO:root:[153,   800] training loss: 0.00031662
INFO:root:[153,   850] training loss: 0.00032057
INFO:root:[153,   900] training loss: 0.00370509
INFO:root:[153,   950] training loss: 0.00195955
INFO:root:[153,  1000] training loss: 0.00001710
INFO:root:[153,  1050] training loss: 0.00001329
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch153
INFO:root:[154,    50] training loss: 0.00721252
INFO:root:[154,   100] training loss: 0.00769286
INFO:root:[154,   150] training loss: 0.00778815
INFO:root:[154,   200] training loss: 0.00722811
INFO:root:[154,   250] training loss: 0.00717480
INFO:root:[154,   300] training loss: 0.00757322
INFO:root:[154,   350] training loss: 0.00655562
INFO:root:[154,   400] training loss: 0.00000932
INFO:root:[154,   450] training loss: 0.00001562
INFO:root:[154,   500] training loss: 0.00001706
INFO:root:[154,   550] training loss: 0.00013503
INFO:root:[154,   600] training loss: 0.00012623
INFO:root:[154,   650] training loss: 0.00001675
INFO:root:[154,   700] training loss: 0.00001416
INFO:root:[154,   750] training loss: 0.00036369
INFO:root:[154,   800] training loss: 0.00035238
INFO:root:[154,   850] training loss: 0.00039810
INFO:root:[154,   900] training loss: 0.00419066
INFO:root:[154,   950] training loss: 0.00150080
INFO:root:[154,  1000] training loss: 0.00002135
INFO:root:[154,  1050] training loss: 0.00001545
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6913    0.7917    0.7287      3872
weighted avg     0.7916    0.7769    0.7821      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch154
INFO:root:[155,    50] training loss: 0.00699404
INFO:root:[155,   100] training loss: 0.00810087
INFO:root:[155,   150] training loss: 0.00723570
INFO:root:[155,   200] training loss: 0.00778825
INFO:root:[155,   250] training loss: 0.00720810
INFO:root:[155,   300] training loss: 0.00775395
INFO:root:[155,   350] training loss: 0.00727471
INFO:root:[155,   400] training loss: 0.00001043
INFO:root:[155,   450] training loss: 0.00001352
INFO:root:[155,   500] training loss: 0.00001643
INFO:root:[155,   550] training loss: 0.00011839
INFO:root:[155,   600] training loss: 0.00012300
INFO:root:[155,   650] training loss: 0.00001512
INFO:root:[155,   700] training loss: 0.00002142
INFO:root:[155,   750] training loss: 0.00031710
INFO:root:[155,   800] training loss: 0.00029569
INFO:root:[155,   850] training loss: 0.00041465
INFO:root:[155,   900] training loss: 0.00403122
INFO:root:[155,   950] training loss: 0.00122255
INFO:root:[155,  1000] training loss: 0.00001411
INFO:root:[155,  1050] training loss: 0.00001454
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch155
INFO:root:[156,    50] training loss: 0.00740691
INFO:root:[156,   100] training loss: 0.00757593
INFO:root:[156,   150] training loss: 0.00764605
INFO:root:[156,   200] training loss: 0.00744925
INFO:root:[156,   250] training loss: 0.00768950
INFO:root:[156,   300] training loss: 0.00753478
INFO:root:[156,   350] training loss: 0.00641933
INFO:root:[156,   400] training loss: 0.00000846
INFO:root:[156,   450] training loss: 0.00001042
INFO:root:[156,   500] training loss: 0.00002711
INFO:root:[156,   550] training loss: 0.00016248
INFO:root:[156,   600] training loss: 0.00030543
INFO:root:[156,   650] training loss: 0.00001472
INFO:root:[156,   700] training loss: 0.00001649
INFO:root:[156,   750] training loss: 0.00031148
INFO:root:[156,   800] training loss: 0.00032294
INFO:root:[156,   850] training loss: 0.00030105
INFO:root:[156,   900] training loss: 0.00387137
INFO:root:[156,   950] training loss: 0.00182885
INFO:root:[156,  1000] training loss: 0.00001575
INFO:root:[156,  1050] training loss: 0.00001302
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch156
INFO:root:[157,    50] training loss: 0.00705657
INFO:root:[157,   100] training loss: 0.00752248
INFO:root:[157,   150] training loss: 0.00759650
INFO:root:[157,   200] training loss: 0.00713640
INFO:root:[157,   250] training loss: 0.00735783
INFO:root:[157,   300] training loss: 0.00766392
INFO:root:[157,   350] training loss: 0.00633836
INFO:root:[157,   400] training loss: 0.00000958
INFO:root:[157,   450] training loss: 0.00001066
INFO:root:[157,   500] training loss: 0.00002281
INFO:root:[157,   550] training loss: 0.00013660
INFO:root:[157,   600] training loss: 0.00011003
INFO:root:[157,   650] training loss: 0.00001407
INFO:root:[157,   700] training loss: 0.00001389
INFO:root:[157,   750] training loss: 0.00032153
INFO:root:[157,   800] training loss: 0.00032899
INFO:root:[157,   850] training loss: 0.00027021
INFO:root:[157,   900] training loss: 0.00407042
INFO:root:[157,   950] training loss: 0.00115044
INFO:root:[157,  1000] training loss: 0.00002204
INFO:root:[157,  1050] training loss: 0.00002163
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch157
INFO:root:[158,    50] training loss: 0.00695586
INFO:root:[158,   100] training loss: 0.00726008
INFO:root:[158,   150] training loss: 0.00707669
INFO:root:[158,   200] training loss: 0.00738946
INFO:root:[158,   250] training loss: 0.00676926
INFO:root:[158,   300] training loss: 0.00765421
INFO:root:[158,   350] training loss: 0.00670909
INFO:root:[158,   400] training loss: 0.00000868
INFO:root:[158,   450] training loss: 0.00001670
INFO:root:[158,   500] training loss: 0.00001584
INFO:root:[158,   550] training loss: 0.00013885
INFO:root:[158,   600] training loss: 0.00008843
INFO:root:[158,   650] training loss: 0.00002066
INFO:root:[158,   700] training loss: 0.00001783
INFO:root:[158,   750] training loss: 0.00031948
INFO:root:[158,   800] training loss: 0.00031492
INFO:root:[158,   850] training loss: 0.00039086
INFO:root:[158,   900] training loss: 0.00395744
INFO:root:[158,   950] training loss: 0.00127252
INFO:root:[158,  1000] training loss: 0.00001752
INFO:root:[158,  1050] training loss: 0.00001520
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch158
INFO:root:[159,    50] training loss: 0.00727446
INFO:root:[159,   100] training loss: 0.00722287
INFO:root:[159,   150] training loss: 0.00751239
INFO:root:[159,   200] training loss: 0.00743933
INFO:root:[159,   250] training loss: 0.00705881
INFO:root:[159,   300] training loss: 0.00773179
INFO:root:[159,   350] training loss: 0.00691597
INFO:root:[159,   400] training loss: 0.00000858
INFO:root:[159,   450] training loss: 0.00001138
INFO:root:[159,   500] training loss: 0.00001831
INFO:root:[159,   550] training loss: 0.00014031
INFO:root:[159,   600] training loss: 0.00009947
INFO:root:[159,   650] training loss: 0.00001657
INFO:root:[159,   700] training loss: 0.00001537
INFO:root:[159,   750] training loss: 0.00048850
INFO:root:[159,   800] training loss: 0.00033117
INFO:root:[159,   850] training loss: 0.00033510
INFO:root:[159,   900] training loss: 0.00397024
INFO:root:[159,   950] training loss: 0.00129425
INFO:root:[159,  1000] training loss: 0.00001708
INFO:root:[159,  1050] training loss: 0.00001376
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch159
INFO:root:[160,    50] training loss: 0.00710883
INFO:root:[160,   100] training loss: 0.00755053
INFO:root:[160,   150] training loss: 0.00754078
INFO:root:[160,   200] training loss: 0.00756369
INFO:root:[160,   250] training loss: 0.00723731
INFO:root:[160,   300] training loss: 0.00790591
INFO:root:[160,   350] training loss: 0.00653268
INFO:root:[160,   400] training loss: 0.00000828
INFO:root:[160,   450] training loss: 0.00001707
INFO:root:[160,   500] training loss: 0.00002456
INFO:root:[160,   550] training loss: 0.00013410
INFO:root:[160,   600] training loss: 0.00010299
INFO:root:[160,   650] training loss: 0.00001924
INFO:root:[160,   700] training loss: 0.00001459
INFO:root:[160,   750] training loss: 0.00031445
INFO:root:[160,   800] training loss: 0.00038721
INFO:root:[160,   850] training loss: 0.00029403
INFO:root:[160,   900] training loss: 0.00359051
INFO:root:[160,   950] training loss: 0.00133086
INFO:root:[160,  1000] training loss: 0.00001592
INFO:root:[160,  1050] training loss: 0.00001272
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch160
INFO:root:[161,    50] training loss: 0.00708774
INFO:root:[161,   100] training loss: 0.00750860
INFO:root:[161,   150] training loss: 0.00746523
INFO:root:[161,   200] training loss: 0.00722727
INFO:root:[161,   250] training loss: 0.00707489
INFO:root:[161,   300] training loss: 0.00805175
INFO:root:[161,   350] training loss: 0.00716031
INFO:root:[161,   400] training loss: 0.00000788
INFO:root:[161,   450] training loss: 0.00001095
INFO:root:[161,   500] training loss: 0.00003247
INFO:root:[161,   550] training loss: 0.00010629
INFO:root:[161,   600] training loss: 0.00016391
INFO:root:[161,   650] training loss: 0.00001812
INFO:root:[161,   700] training loss: 0.00001576
INFO:root:[161,   750] training loss: 0.00037407
INFO:root:[161,   800] training loss: 0.00041848
INFO:root:[161,   850] training loss: 0.00032416
INFO:root:[161,   900] training loss: 0.00400889
INFO:root:[161,   950] training loss: 0.00129025
INFO:root:[161,  1000] training loss: 0.00001663
INFO:root:[161,  1050] training loss: 0.00001283
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch161
INFO:root:[162,    50] training loss: 0.00719042
INFO:root:[162,   100] training loss: 0.00719581
INFO:root:[162,   150] training loss: 0.00711399
INFO:root:[162,   200] training loss: 0.00693223
INFO:root:[162,   250] training loss: 0.00739874
INFO:root:[162,   300] training loss: 0.00803424
INFO:root:[162,   350] training loss: 0.00670466
INFO:root:[162,   400] training loss: 0.00000950
INFO:root:[162,   450] training loss: 0.00001286
INFO:root:[162,   500] training loss: 0.00009628
INFO:root:[162,   550] training loss: 0.00014506
INFO:root:[162,   600] training loss: 0.00008504
INFO:root:[162,   650] training loss: 0.00001518
INFO:root:[162,   700] training loss: 0.00001364
INFO:root:[162,   750] training loss: 0.00038498
INFO:root:[162,   800] training loss: 0.00035457
INFO:root:[162,   850] training loss: 0.00034099
INFO:root:[162,   900] training loss: 0.00444915
INFO:root:[162,   950] training loss: 0.00121565
INFO:root:[162,  1000] training loss: 0.00001682
INFO:root:[162,  1050] training loss: 0.00001323
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch162
INFO:root:[163,    50] training loss: 0.00706596
INFO:root:[163,   100] training loss: 0.00713347
INFO:root:[163,   150] training loss: 0.00748529
INFO:root:[163,   200] training loss: 0.00727538
INFO:root:[163,   250] training loss: 0.00704861
INFO:root:[163,   300] training loss: 0.00763517
INFO:root:[163,   350] training loss: 0.00706289
INFO:root:[163,   400] training loss: 0.00000864
INFO:root:[163,   450] training loss: 0.00001366
INFO:root:[163,   500] training loss: 0.00002234
INFO:root:[163,   550] training loss: 0.00012731
INFO:root:[163,   600] training loss: 0.00014997
INFO:root:[163,   650] training loss: 0.00001318
INFO:root:[163,   700] training loss: 0.00001572
INFO:root:[163,   750] training loss: 0.00037507
INFO:root:[163,   800] training loss: 0.00037382
INFO:root:[163,   850] training loss: 0.00024077
INFO:root:[163,   900] training loss: 0.00461432
INFO:root:[163,   950] training loss: 0.00114705
INFO:root:[163,  1000] training loss: 0.00001856
INFO:root:[163,  1050] training loss: 0.00001104
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch163
INFO:root:[164,    50] training loss: 0.00715407
INFO:root:[164,   100] training loss: 0.00765295
INFO:root:[164,   150] training loss: 0.00734525
INFO:root:[164,   200] training loss: 0.00711506
INFO:root:[164,   250] training loss: 0.00703177
INFO:root:[164,   300] training loss: 0.00811366
INFO:root:[164,   350] training loss: 0.00663540
INFO:root:[164,   400] training loss: 0.00000977
INFO:root:[164,   450] training loss: 0.00001430
INFO:root:[164,   500] training loss: 0.00001423
INFO:root:[164,   550] training loss: 0.00012433
INFO:root:[164,   600] training loss: 0.00012909
INFO:root:[164,   650] training loss: 0.00001683
INFO:root:[164,   700] training loss: 0.00001411
INFO:root:[164,   750] training loss: 0.00038589
INFO:root:[164,   800] training loss: 0.00038824
INFO:root:[164,   850] training loss: 0.00030019
INFO:root:[164,   900] training loss: 0.00380153
INFO:root:[164,   950] training loss: 0.00161101
INFO:root:[164,  1000] training loss: 0.00001668
INFO:root:[164,  1050] training loss: 0.00001386
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8039    0.7984    0.8012      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3971    0.7397    0.5167        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7774      3872
   macro avg     0.6915    0.7919    0.7290      3872
weighted avg     0.7920    0.7774    0.7826      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch164
INFO:root:[165,    50] training loss: 0.00701546
INFO:root:[165,   100] training loss: 0.00736092
INFO:root:[165,   150] training loss: 0.00765026
INFO:root:[165,   200] training loss: 0.00671491
INFO:root:[165,   250] training loss: 0.00772620
INFO:root:[165,   300] training loss: 0.00766294
INFO:root:[165,   350] training loss: 0.00648952
INFO:root:[165,   400] training loss: 0.00000856
INFO:root:[165,   450] training loss: 0.00001177
INFO:root:[165,   500] training loss: 0.00002189
INFO:root:[165,   550] training loss: 0.00011929
INFO:root:[165,   600] training loss: 0.00018998
INFO:root:[165,   650] training loss: 0.00001591
INFO:root:[165,   700] training loss: 0.00001474
INFO:root:[165,   750] training loss: 0.00049417
INFO:root:[165,   800] training loss: 0.00027040
INFO:root:[165,   850] training loss: 0.00035352
INFO:root:[165,   900] training loss: 0.00385414
INFO:root:[165,   950] training loss: 0.00148614
INFO:root:[165,  1000] training loss: 0.00001438
INFO:root:[165,  1050] training loss: 0.00001242
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6911    0.7918    0.7285      3872
weighted avg     0.7919    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch165
INFO:root:[166,    50] training loss: 0.00726856
INFO:root:[166,   100] training loss: 0.00881043
INFO:root:[166,   150] training loss: 0.00700819
INFO:root:[166,   200] training loss: 0.00712110
INFO:root:[166,   250] training loss: 0.00697726
INFO:root:[166,   300] training loss: 0.00825719
INFO:root:[166,   350] training loss: 0.00633128
INFO:root:[166,   400] training loss: 0.00000803
INFO:root:[166,   450] training loss: 0.00001987
INFO:root:[166,   500] training loss: 0.00003083
INFO:root:[166,   550] training loss: 0.00010718
INFO:root:[166,   600] training loss: 0.00011878
INFO:root:[166,   650] training loss: 0.00001638
INFO:root:[166,   700] training loss: 0.00001990
INFO:root:[166,   750] training loss: 0.00038473
INFO:root:[166,   800] training loss: 0.00029620
INFO:root:[166,   850] training loss: 0.00033744
INFO:root:[166,   900] training loss: 0.00444948
INFO:root:[166,   950] training loss: 0.00147763
INFO:root:[166,  1000] training loss: 0.00001553
INFO:root:[166,  1050] training loss: 0.00001542
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6911    0.7918    0.7285      3872
weighted avg     0.7919    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch166
INFO:root:[167,    50] training loss: 0.00746126
INFO:root:[167,   100] training loss: 0.00752815
INFO:root:[167,   150] training loss: 0.00711164
INFO:root:[167,   200] training loss: 0.00758379
INFO:root:[167,   250] training loss: 0.00683781
INFO:root:[167,   300] training loss: 0.00817278
INFO:root:[167,   350] training loss: 0.00637314
INFO:root:[167,   400] training loss: 0.00001261
INFO:root:[167,   450] training loss: 0.00001107
INFO:root:[167,   500] training loss: 0.00002524
INFO:root:[167,   550] training loss: 0.00013269
INFO:root:[167,   600] training loss: 0.00014435
INFO:root:[167,   650] training loss: 0.00001367
INFO:root:[167,   700] training loss: 0.00001517
INFO:root:[167,   750] training loss: 0.00041383
INFO:root:[167,   800] training loss: 0.00028764
INFO:root:[167,   850] training loss: 0.00030938
INFO:root:[167,   900] training loss: 0.00356219
INFO:root:[167,   950] training loss: 0.00147120
INFO:root:[167,  1000] training loss: 0.00001509
INFO:root:[167,  1050] training loss: 0.00001605
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6911    0.7918    0.7285      3872
weighted avg     0.7919    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch167
INFO:root:[168,    50] training loss: 0.00701857
INFO:root:[168,   100] training loss: 0.00731352
INFO:root:[168,   150] training loss: 0.00740526
INFO:root:[168,   200] training loss: 0.00696616
INFO:root:[168,   250] training loss: 0.00733372
INFO:root:[168,   300] training loss: 0.00840922
INFO:root:[168,   350] training loss: 0.00664022
INFO:root:[168,   400] training loss: 0.00000977
INFO:root:[168,   450] training loss: 0.00001229
INFO:root:[168,   500] training loss: 0.00001829
INFO:root:[168,   550] training loss: 0.00011321
INFO:root:[168,   600] training loss: 0.00014455
INFO:root:[168,   650] training loss: 0.00001505
INFO:root:[168,   700] training loss: 0.00001872
INFO:root:[168,   750] training loss: 0.00036512
INFO:root:[168,   800] training loss: 0.00040548
INFO:root:[168,   850] training loss: 0.00029040
INFO:root:[168,   900] training loss: 0.00491702
INFO:root:[168,   950] training loss: 0.00169992
INFO:root:[168,  1000] training loss: 0.00001270
INFO:root:[168,  1050] training loss: 0.00001363
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6911    0.7918    0.7285      3872
weighted avg     0.7919    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch168
INFO:root:[169,    50] training loss: 0.00791649
INFO:root:[169,   100] training loss: 0.00731663
INFO:root:[169,   150] training loss: 0.00719577
INFO:root:[169,   200] training loss: 0.00924746
INFO:root:[169,   250] training loss: 0.00712251
INFO:root:[169,   300] training loss: 0.00772989
INFO:root:[169,   350] training loss: 0.00670918
INFO:root:[169,   400] training loss: 0.00000923
INFO:root:[169,   450] training loss: 0.00001641
INFO:root:[169,   500] training loss: 0.00002042
INFO:root:[169,   550] training loss: 0.00015077
INFO:root:[169,   600] training loss: 0.00015260
INFO:root:[169,   650] training loss: 0.00001985
INFO:root:[169,   700] training loss: 0.00001385
INFO:root:[169,   750] training loss: 0.00042736
INFO:root:[169,   800] training loss: 0.00029829
INFO:root:[169,   850] training loss: 0.00027719
INFO:root:[169,   900] training loss: 0.00385273
INFO:root:[169,   950] training loss: 0.00144402
INFO:root:[169,  1000] training loss: 0.00001518
INFO:root:[169,  1050] training loss: 0.00001660
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6911    0.7918    0.7285      3872
weighted avg     0.7919    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch169
INFO:root:[170,    50] training loss: 0.00719355
INFO:root:[170,   100] training loss: 0.00788365
INFO:root:[170,   150] training loss: 0.00732179
INFO:root:[170,   200] training loss: 0.00750109
INFO:root:[170,   250] training loss: 0.00711870
INFO:root:[170,   300] training loss: 0.00805463
INFO:root:[170,   350] training loss: 0.00667105
INFO:root:[170,   400] training loss: 0.00001030
INFO:root:[170,   450] training loss: 0.00001324
INFO:root:[170,   500] training loss: 0.00001540
INFO:root:[170,   550] training loss: 0.00010407
INFO:root:[170,   600] training loss: 0.00012518
INFO:root:[170,   650] training loss: 0.00001733
INFO:root:[170,   700] training loss: 0.00001450
INFO:root:[170,   750] training loss: 0.00031143
INFO:root:[170,   800] training loss: 0.00031545
INFO:root:[170,   850] training loss: 0.00030999
INFO:root:[170,   900] training loss: 0.00395505
INFO:root:[170,   950] training loss: 0.00134537
INFO:root:[170,  1000] training loss: 0.00001341
INFO:root:[170,  1050] training loss: 0.00001388
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8256    0.8624      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6260    0.6799    0.6518      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7771      3872
   macro avg     0.6911    0.7918    0.7285      3872
weighted avg     0.7919    0.7771    0.7824      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch170
INFO:root:[171,    50] training loss: 0.00726608
INFO:root:[171,   100] training loss: 0.00732333
INFO:root:[171,   150] training loss: 0.00684775
INFO:root:[171,   200] training loss: 0.00724397
INFO:root:[171,   250] training loss: 0.00847157
INFO:root:[171,   300] training loss: 0.00833278
INFO:root:[171,   350] training loss: 0.00668886
INFO:root:[171,   400] training loss: 0.00000863
INFO:root:[171,   450] training loss: 0.00001457
INFO:root:[171,   500] training loss: 0.00002796
INFO:root:[171,   550] training loss: 0.00022366
INFO:root:[171,   600] training loss: 0.00012720
INFO:root:[171,   650] training loss: 0.00001987
INFO:root:[171,   700] training loss: 0.00001573
INFO:root:[171,   750] training loss: 0.00033777
INFO:root:[171,   800] training loss: 0.00030438
INFO:root:[171,   850] training loss: 0.00033439
INFO:root:[171,   900] training loss: 0.00444954
INFO:root:[171,   950] training loss: 0.00147093
INFO:root:[171,  1000] training loss: 0.00001847
INFO:root:[171,  1050] training loss: 0.00001237
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch171
INFO:root:[172,    50] training loss: 0.00752259
INFO:root:[172,   100] training loss: 0.00774467
INFO:root:[172,   150] training loss: 0.00777685
INFO:root:[172,   200] training loss: 0.00711342
INFO:root:[172,   250] training loss: 0.00761220
INFO:root:[172,   300] training loss: 0.00722762
INFO:root:[172,   350] training loss: 0.00655337
INFO:root:[172,   400] training loss: 0.00000909
INFO:root:[172,   450] training loss: 0.00001308
INFO:root:[172,   500] training loss: 0.00001875
INFO:root:[172,   550] training loss: 0.00013236
INFO:root:[172,   600] training loss: 0.00011067
INFO:root:[172,   650] training loss: 0.00001424
INFO:root:[172,   700] training loss: 0.00001564
INFO:root:[172,   750] training loss: 0.00037675
INFO:root:[172,   800] training loss: 0.00033075
INFO:root:[172,   850] training loss: 0.00032481
INFO:root:[172,   900] training loss: 0.00475034
INFO:root:[172,   950] training loss: 0.00168552
INFO:root:[172,  1000] training loss: 0.00001308
INFO:root:[172,  1050] training loss: 0.00001739
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch172
INFO:root:[173,    50] training loss: 0.00752072
INFO:root:[173,   100] training loss: 0.00803443
INFO:root:[173,   150] training loss: 0.00854775
INFO:root:[173,   200] training loss: 0.00717019
INFO:root:[173,   250] training loss: 0.00715928
INFO:root:[173,   300] training loss: 0.00819948
INFO:root:[173,   350] training loss: 0.00611455
INFO:root:[173,   400] training loss: 0.00000816
INFO:root:[173,   450] training loss: 0.00001137
INFO:root:[173,   500] training loss: 0.00001726
INFO:root:[173,   550] training loss: 0.00011438
INFO:root:[173,   600] training loss: 0.00011318
INFO:root:[173,   650] training loss: 0.00001505
INFO:root:[173,   700] training loss: 0.00001776
INFO:root:[173,   750] training loss: 0.00043475
INFO:root:[173,   800] training loss: 0.00032380
INFO:root:[173,   850] training loss: 0.00039790
INFO:root:[173,   900] training loss: 0.00389462
INFO:root:[173,   950] training loss: 0.00120451
INFO:root:[173,  1000] training loss: 0.00001582
INFO:root:[173,  1050] training loss: 0.00001493
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch173
INFO:root:[174,    50] training loss: 0.00756581
INFO:root:[174,   100] training loss: 0.00782430
INFO:root:[174,   150] training loss: 0.00726157
INFO:root:[174,   200] training loss: 0.00687642
INFO:root:[174,   250] training loss: 0.00798638
INFO:root:[174,   300] training loss: 0.00783208
INFO:root:[174,   350] training loss: 0.00750645
INFO:root:[174,   400] training loss: 0.00000907
INFO:root:[174,   450] training loss: 0.00002055
INFO:root:[174,   500] training loss: 0.00002096
INFO:root:[174,   550] training loss: 0.00015046
INFO:root:[174,   600] training loss: 0.00014402
INFO:root:[174,   650] training loss: 0.00001419
INFO:root:[174,   700] training loss: 0.00001399
INFO:root:[174,   750] training loss: 0.00033871
INFO:root:[174,   800] training loss: 0.00029243
INFO:root:[174,   850] training loss: 0.00028965
INFO:root:[174,   900] training loss: 0.00372899
INFO:root:[174,   950] training loss: 0.00193169
INFO:root:[174,  1000] training loss: 0.00001662
INFO:root:[174,  1050] training loss: 0.00001082
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch174
INFO:root:[175,    50] training loss: 0.00707631
INFO:root:[175,   100] training loss: 0.00745741
INFO:root:[175,   150] training loss: 0.00705219
INFO:root:[175,   200] training loss: 0.00701876
INFO:root:[175,   250] training loss: 0.00710290
INFO:root:[175,   300] training loss: 0.00768826
INFO:root:[175,   350] training loss: 0.00676866
INFO:root:[175,   400] training loss: 0.00001010
INFO:root:[175,   450] training loss: 0.00001327
INFO:root:[175,   500] training loss: 0.00001819
INFO:root:[175,   550] training loss: 0.00014578
INFO:root:[175,   600] training loss: 0.00019872
INFO:root:[175,   650] training loss: 0.00001477
INFO:root:[175,   700] training loss: 0.00001366
INFO:root:[175,   750] training loss: 0.00036388
INFO:root:[175,   800] training loss: 0.00033595
INFO:root:[175,   850] training loss: 0.00032518
INFO:root:[175,   900] training loss: 0.00400824
INFO:root:[175,   950] training loss: 0.00160626
INFO:root:[175,  1000] training loss: 0.00002491
INFO:root:[175,  1050] training loss: 0.00001077
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch175
INFO:root:[176,    50] training loss: 0.00766239
INFO:root:[176,   100] training loss: 0.00771626
INFO:root:[176,   150] training loss: 0.00699812
INFO:root:[176,   200] training loss: 0.00689217
INFO:root:[176,   250] training loss: 0.00737794
INFO:root:[176,   300] training loss: 0.00767208
INFO:root:[176,   350] training loss: 0.00633568
INFO:root:[176,   400] training loss: 0.00000873
INFO:root:[176,   450] training loss: 0.00002946
INFO:root:[176,   500] training loss: 0.00004771
INFO:root:[176,   550] training loss: 0.00012710
INFO:root:[176,   600] training loss: 0.00014939
INFO:root:[176,   650] training loss: 0.00001649
INFO:root:[176,   700] training loss: 0.00001345
INFO:root:[176,   750] training loss: 0.00032540
INFO:root:[176,   800] training loss: 0.00029960
INFO:root:[176,   850] training loss: 0.00033462
INFO:root:[176,   900] training loss: 0.00394323
INFO:root:[176,   950] training loss: 0.00148423
INFO:root:[176,  1000] training loss: 0.00001302
INFO:root:[176,  1050] training loss: 0.00002051
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch176
INFO:root:[177,    50] training loss: 0.00738077
INFO:root:[177,   100] training loss: 0.00746502
INFO:root:[177,   150] training loss: 0.00735971
INFO:root:[177,   200] training loss: 0.00690841
INFO:root:[177,   250] training loss: 0.00712351
INFO:root:[177,   300] training loss: 0.00839060
INFO:root:[177,   350] training loss: 0.00741945
INFO:root:[177,   400] training loss: 0.00000922
INFO:root:[177,   450] training loss: 0.00001125
INFO:root:[177,   500] training loss: 0.00002759
INFO:root:[177,   550] training loss: 0.00013285
INFO:root:[177,   600] training loss: 0.00021834
INFO:root:[177,   650] training loss: 0.00001593
INFO:root:[177,   700] training loss: 0.00002064
INFO:root:[177,   750] training loss: 0.00039099
INFO:root:[177,   800] training loss: 0.00033844
INFO:root:[177,   850] training loss: 0.00038623
INFO:root:[177,   900] training loss: 0.00423037
INFO:root:[177,   950] training loss: 0.00107586
INFO:root:[177,  1000] training loss: 0.00001758
INFO:root:[177,  1050] training loss: 0.00001368
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch177
INFO:root:[178,    50] training loss: 0.00752615
INFO:root:[178,   100] training loss: 0.00766358
INFO:root:[178,   150] training loss: 0.00734713
INFO:root:[178,   200] training loss: 0.00700054
INFO:root:[178,   250] training loss: 0.00704149
INFO:root:[178,   300] training loss: 0.00745609
INFO:root:[178,   350] training loss: 0.00658853
INFO:root:[178,   400] training loss: 0.00000777
INFO:root:[178,   450] training loss: 0.00001655
INFO:root:[178,   500] training loss: 0.00001723
INFO:root:[178,   550] training loss: 0.00049232
INFO:root:[178,   600] training loss: 0.00017239
INFO:root:[178,   650] training loss: 0.00001559
INFO:root:[178,   700] training loss: 0.00001593
INFO:root:[178,   750] training loss: 0.00040516
INFO:root:[178,   800] training loss: 0.00031452
INFO:root:[178,   850] training loss: 0.00028210
INFO:root:[178,   900] training loss: 0.00452748
INFO:root:[178,   950] training loss: 0.00124655
INFO:root:[178,  1000] training loss: 0.00002647
INFO:root:[178,  1050] training loss: 0.00001472
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch178
INFO:root:[179,    50] training loss: 0.00775981
INFO:root:[179,   100] training loss: 0.00777804
INFO:root:[179,   150] training loss: 0.00727551
INFO:root:[179,   200] training loss: 0.00732623
INFO:root:[179,   250] training loss: 0.00705530
INFO:root:[179,   300] training loss: 0.00774690
INFO:root:[179,   350] training loss: 0.00649766
INFO:root:[179,   400] training loss: 0.00001002
INFO:root:[179,   450] training loss: 0.00001552
INFO:root:[179,   500] training loss: 0.00001892
INFO:root:[179,   550] training loss: 0.00012833
INFO:root:[179,   600] training loss: 0.00017060
INFO:root:[179,   650] training loss: 0.00001570
INFO:root:[179,   700] training loss: 0.00001645
INFO:root:[179,   750] training loss: 0.00035073
INFO:root:[179,   800] training loss: 0.00031831
INFO:root:[179,   850] training loss: 0.00037379
INFO:root:[179,   900] training loss: 0.00418255
INFO:root:[179,   950] training loss: 0.00163467
INFO:root:[179,  1000] training loss: 0.00001655
INFO:root:[179,  1050] training loss: 0.00001303
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch179
INFO:root:[180,    50] training loss: 0.00751617
INFO:root:[180,   100] training loss: 0.00732141
INFO:root:[180,   150] training loss: 0.00913299
INFO:root:[180,   200] training loss: 0.00708532
INFO:root:[180,   250] training loss: 0.00735833
INFO:root:[180,   300] training loss: 0.00845317
INFO:root:[180,   350] training loss: 0.00655068
INFO:root:[180,   400] training loss: 0.00000759
INFO:root:[180,   450] training loss: 0.00001308
INFO:root:[180,   500] training loss: 0.00009757
INFO:root:[180,   550] training loss: 0.00013457
INFO:root:[180,   600] training loss: 0.00012974
INFO:root:[180,   650] training loss: 0.00001589
INFO:root:[180,   700] training loss: 0.00001926
INFO:root:[180,   750] training loss: 0.00041102
INFO:root:[180,   800] training loss: 0.00032817
INFO:root:[180,   850] training loss: 0.00027806
INFO:root:[180,   900] training loss: 0.00453971
INFO:root:[180,   950] training loss: 0.00141672
INFO:root:[180,  1000] training loss: 0.00001841
INFO:root:[180,  1050] training loss: 0.00001072
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch180
INFO:root:[181,    50] training loss: 0.00811000
INFO:root:[181,   100] training loss: 0.00728366
INFO:root:[181,   150] training loss: 0.00737362
INFO:root:[181,   200] training loss: 0.00737859
INFO:root:[181,   250] training loss: 0.00714400
INFO:root:[181,   300] training loss: 0.00750191
INFO:root:[181,   350] training loss: 0.00680643
INFO:root:[181,   400] training loss: 0.00000924
INFO:root:[181,   450] training loss: 0.00001265
INFO:root:[181,   500] training loss: 0.00006048
INFO:root:[181,   550] training loss: 0.00013683
INFO:root:[181,   600] training loss: 0.00010386
INFO:root:[181,   650] training loss: 0.00001517
INFO:root:[181,   700] training loss: 0.00001488
INFO:root:[181,   750] training loss: 0.00032196
INFO:root:[181,   800] training loss: 0.00036636
INFO:root:[181,   850] training loss: 0.00031444
INFO:root:[181,   900] training loss: 0.00389805
INFO:root:[181,   950] training loss: 0.00137494
INFO:root:[181,  1000] training loss: 0.00002565
INFO:root:[181,  1050] training loss: 0.00001468
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch181
INFO:root:[182,    50] training loss: 0.00778123
INFO:root:[182,   100] training loss: 0.00772746
INFO:root:[182,   150] training loss: 0.00763270
INFO:root:[182,   200] training loss: 0.00725153
INFO:root:[182,   250] training loss: 0.00725473
INFO:root:[182,   300] training loss: 0.00752996
INFO:root:[182,   350] training loss: 0.00717637
INFO:root:[182,   400] training loss: 0.00000896
INFO:root:[182,   450] training loss: 0.00001300
INFO:root:[182,   500] training loss: 0.00001621
INFO:root:[182,   550] training loss: 0.00011374
INFO:root:[182,   600] training loss: 0.00010337
INFO:root:[182,   650] training loss: 0.00001751
INFO:root:[182,   700] training loss: 0.00001638
INFO:root:[182,   750] training loss: 0.00031248
INFO:root:[182,   800] training loss: 0.00033818
INFO:root:[182,   850] training loss: 0.00033442
INFO:root:[182,   900] training loss: 0.00446672
INFO:root:[182,   950] training loss: 0.00190065
INFO:root:[182,  1000] training loss: 0.00001507
INFO:root:[182,  1050] training loss: 0.00001470
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch182
INFO:root:[183,    50] training loss: 0.00725149
INFO:root:[183,   100] training loss: 0.00756179
INFO:root:[183,   150] training loss: 0.00702993
INFO:root:[183,   200] training loss: 0.00727856
INFO:root:[183,   250] training loss: 0.00777258
INFO:root:[183,   300] training loss: 0.00774930
INFO:root:[183,   350] training loss: 0.00642490
INFO:root:[183,   400] training loss: 0.00000774
INFO:root:[183,   450] training loss: 0.00001297
INFO:root:[183,   500] training loss: 0.00002073
INFO:root:[183,   550] training loss: 0.00015744
INFO:root:[183,   600] training loss: 0.00016719
INFO:root:[183,   650] training loss: 0.00001408
INFO:root:[183,   700] training loss: 0.00001527
INFO:root:[183,   750] training loss: 0.00046478
INFO:root:[183,   800] training loss: 0.00037407
INFO:root:[183,   850] training loss: 0.00040994
INFO:root:[183,   900] training loss: 0.00418116
INFO:root:[183,   950] training loss: 0.00169952
INFO:root:[183,  1000] training loss: 0.00002161
INFO:root:[183,  1050] training loss: 0.00001783
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch183
INFO:root:[184,    50] training loss: 0.00726586
INFO:root:[184,   100] training loss: 0.00757392
INFO:root:[184,   150] training loss: 0.00718822
INFO:root:[184,   200] training loss: 0.00749594
INFO:root:[184,   250] training loss: 0.00719618
INFO:root:[184,   300] training loss: 0.00747697
INFO:root:[184,   350] training loss: 0.00651845
INFO:root:[184,   400] training loss: 0.00000897
INFO:root:[184,   450] training loss: 0.00001323
INFO:root:[184,   500] training loss: 0.00001806
INFO:root:[184,   550] training loss: 0.00016982
INFO:root:[184,   600] training loss: 0.00010390
INFO:root:[184,   650] training loss: 0.00002138
INFO:root:[184,   700] training loss: 0.00001639
INFO:root:[184,   750] training loss: 0.00027567
INFO:root:[184,   800] training loss: 0.00031813
INFO:root:[184,   850] training loss: 0.00034960
INFO:root:[184,   900] training loss: 0.00386235
INFO:root:[184,   950] training loss: 0.00172233
INFO:root:[184,  1000] training loss: 0.00001962
INFO:root:[184,  1050] training loss: 0.00001335
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch184
INFO:root:[185,    50] training loss: 0.00758225
INFO:root:[185,   100] training loss: 0.00752462
INFO:root:[185,   150] training loss: 0.00754687
INFO:root:[185,   200] training loss: 0.00741090
INFO:root:[185,   250] training loss: 0.00737350
INFO:root:[185,   300] training loss: 0.00779132
INFO:root:[185,   350] training loss: 0.00681463
INFO:root:[185,   400] training loss: 0.00000802
INFO:root:[185,   450] training loss: 0.00001232
INFO:root:[185,   500] training loss: 0.00002397
INFO:root:[185,   550] training loss: 0.00013055
INFO:root:[185,   600] training loss: 0.00016104
INFO:root:[185,   650] training loss: 0.00002088
INFO:root:[185,   700] training loss: 0.00001777
INFO:root:[185,   750] training loss: 0.00035499
INFO:root:[185,   800] training loss: 0.00032897
INFO:root:[185,   850] training loss: 0.00028972
INFO:root:[185,   900] training loss: 0.00395729
INFO:root:[185,   950] training loss: 0.00130863
INFO:root:[185,  1000] training loss: 0.00001555
INFO:root:[185,  1050] training loss: 0.00002398
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch185
INFO:root:[186,    50] training loss: 0.00701871
INFO:root:[186,   100] training loss: 0.00744518
INFO:root:[186,   150] training loss: 0.00711914
INFO:root:[186,   200] training loss: 0.00704588
INFO:root:[186,   250] training loss: 0.00703938
INFO:root:[186,   300] training loss: 0.00768545
INFO:root:[186,   350] training loss: 0.00596865
INFO:root:[186,   400] training loss: 0.00000821
INFO:root:[186,   450] training loss: 0.00001167
INFO:root:[186,   500] training loss: 0.00002186
INFO:root:[186,   550] training loss: 0.00014908
INFO:root:[186,   600] training loss: 0.00019098
INFO:root:[186,   650] training loss: 0.00002046
INFO:root:[186,   700] training loss: 0.00001375
INFO:root:[186,   750] training loss: 0.00034915
INFO:root:[186,   800] training loss: 0.00034080
INFO:root:[186,   850] training loss: 0.00032069
INFO:root:[186,   900] training loss: 0.00356397
INFO:root:[186,   950] training loss: 0.00130202
INFO:root:[186,  1000] training loss: 0.00002620
INFO:root:[186,  1050] training loss: 0.00001370
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch186
INFO:root:[187,    50] training loss: 0.00696654
INFO:root:[187,   100] training loss: 0.00735743
INFO:root:[187,   150] training loss: 0.00804328
INFO:root:[187,   200] training loss: 0.00667651
INFO:root:[187,   250] training loss: 0.00709087
INFO:root:[187,   300] training loss: 0.00759526
INFO:root:[187,   350] training loss: 0.00661294
INFO:root:[187,   400] training loss: 0.00000905
INFO:root:[187,   450] training loss: 0.00002372
INFO:root:[187,   500] training loss: 0.00001797
INFO:root:[187,   550] training loss: 0.00019315
INFO:root:[187,   600] training loss: 0.00013137
INFO:root:[187,   650] training loss: 0.00001763
INFO:root:[187,   700] training loss: 0.00001787
INFO:root:[187,   750] training loss: 0.00035398
INFO:root:[187,   800] training loss: 0.00029718
INFO:root:[187,   850] training loss: 0.00034423
INFO:root:[187,   900] training loss: 0.00356249
INFO:root:[187,   950] training loss: 0.00156900
INFO:root:[187,  1000] training loss: 0.00001518
INFO:root:[187,  1050] training loss: 0.00001115
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch187
INFO:root:[188,    50] training loss: 0.00729390
INFO:root:[188,   100] training loss: 0.00774917
INFO:root:[188,   150] training loss: 0.00749295
INFO:root:[188,   200] training loss: 0.00726364
INFO:root:[188,   250] training loss: 0.00783608
INFO:root:[188,   300] training loss: 0.00745474
INFO:root:[188,   350] training loss: 0.00672182
INFO:root:[188,   400] training loss: 0.00000848
INFO:root:[188,   450] training loss: 0.00001227
INFO:root:[188,   500] training loss: 0.00001882
INFO:root:[188,   550] training loss: 0.00010330
INFO:root:[188,   600] training loss: 0.00018130
INFO:root:[188,   650] training loss: 0.00001423
INFO:root:[188,   700] training loss: 0.00001551
INFO:root:[188,   750] training loss: 0.00034681
INFO:root:[188,   800] training loss: 0.00032120
INFO:root:[188,   850] training loss: 0.00027202
INFO:root:[188,   900] training loss: 0.00396754
INFO:root:[188,   950] training loss: 0.00128146
INFO:root:[188,  1000] training loss: 0.00002638
INFO:root:[188,  1050] training loss: 0.00001211
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch188
INFO:root:[189,    50] training loss: 0.00755411
INFO:root:[189,   100] training loss: 0.00795505
INFO:root:[189,   150] training loss: 0.00723811
INFO:root:[189,   200] training loss: 0.00706535
INFO:root:[189,   250] training loss: 0.00735167
INFO:root:[189,   300] training loss: 0.00794863
INFO:root:[189,   350] training loss: 0.00625033
INFO:root:[189,   400] training loss: 0.00000937
INFO:root:[189,   450] training loss: 0.00001222
INFO:root:[189,   500] training loss: 0.00001750
INFO:root:[189,   550] training loss: 0.00012648
INFO:root:[189,   600] training loss: 0.00008515
INFO:root:[189,   650] training loss: 0.00001619
INFO:root:[189,   700] training loss: 0.00001404
INFO:root:[189,   750] training loss: 0.00028757
INFO:root:[189,   800] training loss: 0.00037615
INFO:root:[189,   850] training loss: 0.00034633
INFO:root:[189,   900] training loss: 0.00387763
INFO:root:[189,   950] training loss: 0.00152948
INFO:root:[189,  1000] training loss: 0.00001764
INFO:root:[189,  1050] training loss: 0.00001447
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch189
INFO:root:[190,    50] training loss: 0.00731030
INFO:root:[190,   100] training loss: 0.00731256
INFO:root:[190,   150] training loss: 0.00783521
INFO:root:[190,   200] training loss: 0.00711581
INFO:root:[190,   250] training loss: 0.00710822
INFO:root:[190,   300] training loss: 0.00774626
INFO:root:[190,   350] training loss: 0.00668193
INFO:root:[190,   400] training loss: 0.00000908
INFO:root:[190,   450] training loss: 0.00001035
INFO:root:[190,   500] training loss: 0.00001941
INFO:root:[190,   550] training loss: 0.00014156
INFO:root:[190,   600] training loss: 0.00010057
INFO:root:[190,   650] training loss: 0.00001677
INFO:root:[190,   700] training loss: 0.00001268
INFO:root:[190,   750] training loss: 0.00028382
INFO:root:[190,   800] training loss: 0.00028112
INFO:root:[190,   850] training loss: 0.00030694
INFO:root:[190,   900] training loss: 0.00394665
INFO:root:[190,   950] training loss: 0.00115273
INFO:root:[190,  1000] training loss: 0.00002022
INFO:root:[190,  1050] training loss: 0.00001192
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch190
INFO:root:[191,    50] training loss: 0.00724977
INFO:root:[191,   100] training loss: 0.00731884
INFO:root:[191,   150] training loss: 0.00703578
INFO:root:[191,   200] training loss: 0.00695183
INFO:root:[191,   250] training loss: 0.00781346
INFO:root:[191,   300] training loss: 0.00878030
INFO:root:[191,   350] training loss: 0.00682398
INFO:root:[191,   400] training loss: 0.00000941
INFO:root:[191,   450] training loss: 0.00001209
INFO:root:[191,   500] training loss: 0.00001966
INFO:root:[191,   550] training loss: 0.00010715
INFO:root:[191,   600] training loss: 0.00012008
INFO:root:[191,   650] training loss: 0.00001789
INFO:root:[191,   700] training loss: 0.00001600
INFO:root:[191,   750] training loss: 0.00042337
INFO:root:[191,   800] training loss: 0.00037077
INFO:root:[191,   850] training loss: 0.00033856
INFO:root:[191,   900] training loss: 0.00354949
INFO:root:[191,   950] training loss: 0.00184310
INFO:root:[191,  1000] training loss: 0.00002440
INFO:root:[191,  1050] training loss: 0.00001336
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch191
INFO:root:[192,    50] training loss: 0.00769915
INFO:root:[192,   100] training loss: 0.00763592
INFO:root:[192,   150] training loss: 0.00830229
INFO:root:[192,   200] training loss: 0.00724477
INFO:root:[192,   250] training loss: 0.00731112
INFO:root:[192,   300] training loss: 0.00785512
INFO:root:[192,   350] training loss: 0.00619102
INFO:root:[192,   400] training loss: 0.00001001
INFO:root:[192,   450] training loss: 0.00001467
INFO:root:[192,   500] training loss: 0.00001627
INFO:root:[192,   550] training loss: 0.00035680
INFO:root:[192,   600] training loss: 0.00010780
INFO:root:[192,   650] training loss: 0.00002077
INFO:root:[192,   700] training loss: 0.00001383
INFO:root:[192,   750] training loss: 0.00038161
INFO:root:[192,   800] training loss: 0.00031447
INFO:root:[192,   850] training loss: 0.00034391
INFO:root:[192,   900] training loss: 0.00432511
INFO:root:[192,   950] training loss: 0.00161070
INFO:root:[192,  1000] training loss: 0.00002389
INFO:root:[192,  1050] training loss: 0.00001326
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch192
INFO:root:[193,    50] training loss: 0.00785744
INFO:root:[193,   100] training loss: 0.00749769
INFO:root:[193,   150] training loss: 0.00764636
INFO:root:[193,   200] training loss: 0.00683628
INFO:root:[193,   250] training loss: 0.00704784
INFO:root:[193,   300] training loss: 0.00758578
INFO:root:[193,   350] training loss: 0.00702615
INFO:root:[193,   400] training loss: 0.00000829
INFO:root:[193,   450] training loss: 0.00002590
INFO:root:[193,   500] training loss: 0.00003973
INFO:root:[193,   550] training loss: 0.00021605
INFO:root:[193,   600] training loss: 0.00015719
INFO:root:[193,   650] training loss: 0.00001960
INFO:root:[193,   700] training loss: 0.00001876
INFO:root:[193,   750] training loss: 0.00030696
INFO:root:[193,   800] training loss: 0.00037375
INFO:root:[193,   850] training loss: 0.00032088
INFO:root:[193,   900] training loss: 0.00357919
INFO:root:[193,   950] training loss: 0.00165906
INFO:root:[193,  1000] training loss: 0.00002206
INFO:root:[193,  1050] training loss: 0.00001134
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch193
INFO:root:[194,    50] training loss: 0.00776544
INFO:root:[194,   100] training loss: 0.00795538
INFO:root:[194,   150] training loss: 0.00729892
INFO:root:[194,   200] training loss: 0.00693240
INFO:root:[194,   250] training loss: 0.00837266
INFO:root:[194,   300] training loss: 0.00803217
INFO:root:[194,   350] training loss: 0.00676889
INFO:root:[194,   400] training loss: 0.00000883
INFO:root:[194,   450] training loss: 0.00001182
INFO:root:[194,   500] training loss: 0.00002615
INFO:root:[194,   550] training loss: 0.00010599
INFO:root:[194,   600] training loss: 0.00017942
INFO:root:[194,   650] training loss: 0.00001460
INFO:root:[194,   700] training loss: 0.00001799
INFO:root:[194,   750] training loss: 0.00036169
INFO:root:[194,   800] training loss: 0.00036309
INFO:root:[194,   850] training loss: 0.00031650
INFO:root:[194,   900] training loss: 0.00391635
INFO:root:[194,   950] training loss: 0.00122273
INFO:root:[194,  1000] training loss: 0.00002696
INFO:root:[194,  1050] training loss: 0.00001335
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch194
INFO:root:[195,    50] training loss: 0.00746962
INFO:root:[195,   100] training loss: 0.00754086
INFO:root:[195,   150] training loss: 0.00743694
INFO:root:[195,   200] training loss: 0.00752138
INFO:root:[195,   250] training loss: 0.00736840
INFO:root:[195,   300] training loss: 0.00785287
INFO:root:[195,   350] training loss: 0.00674207
INFO:root:[195,   400] training loss: 0.00000923
INFO:root:[195,   450] training loss: 0.00001505
INFO:root:[195,   500] training loss: 0.00001521
INFO:root:[195,   550] training loss: 0.00021438
INFO:root:[195,   600] training loss: 0.00014157
INFO:root:[195,   650] training loss: 0.00001628
INFO:root:[195,   700] training loss: 0.00001757
INFO:root:[195,   750] training loss: 0.00040080
INFO:root:[195,   800] training loss: 0.00033020
INFO:root:[195,   850] training loss: 0.00036349
INFO:root:[195,   900] training loss: 0.00421065
INFO:root:[195,   950] training loss: 0.00122568
INFO:root:[195,  1000] training loss: 0.00001221
INFO:root:[195,  1050] training loss: 0.00001369
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch195
INFO:root:[196,    50] training loss: 0.00779304
INFO:root:[196,   100] training loss: 0.00732071
INFO:root:[196,   150] training loss: 0.00759596
INFO:root:[196,   200] training loss: 0.00708888
INFO:root:[196,   250] training loss: 0.00728570
INFO:root:[196,   300] training loss: 0.00775140
INFO:root:[196,   350] training loss: 0.00661283
INFO:root:[196,   400] training loss: 0.00001149
INFO:root:[196,   450] training loss: 0.00001868
INFO:root:[196,   500] training loss: 0.00003005
INFO:root:[196,   550] training loss: 0.00013673
INFO:root:[196,   600] training loss: 0.00015346
INFO:root:[196,   650] training loss: 0.00001381
INFO:root:[196,   700] training loss: 0.00002201
INFO:root:[196,   750] training loss: 0.00039683
INFO:root:[196,   800] training loss: 0.00031553
INFO:root:[196,   850] training loss: 0.00033617
INFO:root:[196,   900] training loss: 0.00414614
INFO:root:[196,   950] training loss: 0.00119152
INFO:root:[196,  1000] training loss: 0.00001391
INFO:root:[196,  1050] training loss: 0.00001563
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch196
INFO:root:[197,    50] training loss: 0.00702924
INFO:root:[197,   100] training loss: 0.00748820
INFO:root:[197,   150] training loss: 0.00727107
INFO:root:[197,   200] training loss: 0.00704745
INFO:root:[197,   250] training loss: 0.00907069
INFO:root:[197,   300] training loss: 0.00781601
INFO:root:[197,   350] training loss: 0.00661127
INFO:root:[197,   400] training loss: 0.00000822
INFO:root:[197,   450] training loss: 0.00001787
INFO:root:[197,   500] training loss: 0.00002195
INFO:root:[197,   550] training loss: 0.00015114
INFO:root:[197,   600] training loss: 0.00013327
INFO:root:[197,   650] training loss: 0.00001443
INFO:root:[197,   700] training loss: 0.00001469
INFO:root:[197,   750] training loss: 0.00036682
INFO:root:[197,   800] training loss: 0.00036345
INFO:root:[197,   850] training loss: 0.00031451
INFO:root:[197,   900] training loss: 0.00393676
INFO:root:[197,   950] training loss: 0.00115154
INFO:root:[197,  1000] training loss: 0.00002036
INFO:root:[197,  1050] training loss: 0.00003081
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch197
INFO:root:[198,    50] training loss: 0.00710420
INFO:root:[198,   100] training loss: 0.00791592
INFO:root:[198,   150] training loss: 0.00693799
INFO:root:[198,   200] training loss: 0.00776646
INFO:root:[198,   250] training loss: 0.00686972
INFO:root:[198,   300] training loss: 0.00764975
INFO:root:[198,   350] training loss: 0.00679328
INFO:root:[198,   400] training loss: 0.00000909
INFO:root:[198,   450] training loss: 0.00001571
INFO:root:[198,   500] training loss: 0.00001732
INFO:root:[198,   550] training loss: 0.00015908
INFO:root:[198,   600] training loss: 0.00014643
INFO:root:[198,   650] training loss: 0.00001575
INFO:root:[198,   700] training loss: 0.00002320
INFO:root:[198,   750] training loss: 0.00036762
INFO:root:[198,   800] training loss: 0.00028983
INFO:root:[198,   850] training loss: 0.00031911
INFO:root:[198,   900] training loss: 0.00395833
INFO:root:[198,   950] training loss: 0.00119783
INFO:root:[198,  1000] training loss: 0.00001571
INFO:root:[198,  1050] training loss: 0.00001458
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch198
INFO:root:[199,    50] training loss: 0.00744496
INFO:root:[199,   100] training loss: 0.00784923
INFO:root:[199,   150] training loss: 0.00762063
INFO:root:[199,   200] training loss: 0.00690457
INFO:root:[199,   250] training loss: 0.00732890
INFO:root:[199,   300] training loss: 0.00783343
INFO:root:[199,   350] training loss: 0.00653975
INFO:root:[199,   400] training loss: 0.00000821
INFO:root:[199,   450] training loss: 0.00001699
INFO:root:[199,   500] training loss: 0.00002841
INFO:root:[199,   550] training loss: 0.00021416
INFO:root:[199,   600] training loss: 0.00017705
INFO:root:[199,   650] training loss: 0.00001557
INFO:root:[199,   700] training loss: 0.00001695
INFO:root:[199,   750] training loss: 0.00044963
INFO:root:[199,   800] training loss: 0.00032050
INFO:root:[199,   850] training loss: 0.00033513
INFO:root:[199,   900] training loss: 0.00487738
INFO:root:[199,   950] training loss: 0.00116402
INFO:root:[199,  1000] training loss: 0.00002178
INFO:root:[199,  1050] training loss: 0.00001306
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch199
INFO:root:[200,    50] training loss: 0.00734590
INFO:root:[200,   100] training loss: 0.00725835
INFO:root:[200,   150] training loss: 0.00771406
INFO:root:[200,   200] training loss: 0.00721524
INFO:root:[200,   250] training loss: 0.00716872
INFO:root:[200,   300] training loss: 0.00790432
INFO:root:[200,   350] training loss: 0.00661733
INFO:root:[200,   400] training loss: 0.00000894
INFO:root:[200,   450] training loss: 0.00001325
INFO:root:[200,   500] training loss: 0.00002177
INFO:root:[200,   550] training loss: 0.00010750
INFO:root:[200,   600] training loss: 0.00014218
INFO:root:[200,   650] training loss: 0.00001406
INFO:root:[200,   700] training loss: 0.00001637
INFO:root:[200,   750] training loss: 0.00041013
INFO:root:[200,   800] training loss: 0.00036857
INFO:root:[200,   850] training loss: 0.00037504
INFO:root:[200,   900] training loss: 0.00470373
INFO:root:[200,   950] training loss: 0.00113001
INFO:root:[200,  1000] training loss: 0.00001448
INFO:root:[200,  1050] training loss: 0.00001368
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch200
INFO:root:[201,    50] training loss: 0.00751066
INFO:root:[201,   100] training loss: 0.00770207
INFO:root:[201,   150] training loss: 0.00735416
INFO:root:[201,   200] training loss: 0.00713370
INFO:root:[201,   250] training loss: 0.00726816
INFO:root:[201,   300] training loss: 0.00853098
INFO:root:[201,   350] training loss: 0.00668821
INFO:root:[201,   400] training loss: 0.00000892
INFO:root:[201,   450] training loss: 0.00001116
INFO:root:[201,   500] training loss: 0.00001552
INFO:root:[201,   550] training loss: 0.00010858
INFO:root:[201,   600] training loss: 0.00010849
INFO:root:[201,   650] training loss: 0.00001430
INFO:root:[201,   700] training loss: 0.00001742
INFO:root:[201,   750] training loss: 0.00043050
INFO:root:[201,   800] training loss: 0.00036664
INFO:root:[201,   850] training loss: 0.00039523
INFO:root:[201,   900] training loss: 0.00430607
INFO:root:[201,   950] training loss: 0.00132353
INFO:root:[201,  1000] training loss: 0.00001432
INFO:root:[201,  1050] training loss: 0.00001101
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch201
INFO:root:[202,    50] training loss: 0.00763618
INFO:root:[202,   100] training loss: 0.00772519
INFO:root:[202,   150] training loss: 0.00721157
INFO:root:[202,   200] training loss: 0.00740640
INFO:root:[202,   250] training loss: 0.00702423
INFO:root:[202,   300] training loss: 0.00862878
INFO:root:[202,   350] training loss: 0.00639473
INFO:root:[202,   400] training loss: 0.00000751
INFO:root:[202,   450] training loss: 0.00001819
INFO:root:[202,   500] training loss: 0.00002793
INFO:root:[202,   550] training loss: 0.00012182
INFO:root:[202,   600] training loss: 0.00010918
INFO:root:[202,   650] training loss: 0.00001522
INFO:root:[202,   700] training loss: 0.00002241
INFO:root:[202,   750] training loss: 0.00040732
INFO:root:[202,   800] training loss: 0.00040625
INFO:root:[202,   850] training loss: 0.00033065
INFO:root:[202,   900] training loss: 0.00426449
INFO:root:[202,   950] training loss: 0.00115552
INFO:root:[202,  1000] training loss: 0.00001379
INFO:root:[202,  1050] training loss: 0.00002645
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch202
INFO:root:[203,    50] training loss: 0.00710361
INFO:root:[203,   100] training loss: 0.00737198
INFO:root:[203,   150] training loss: 0.00701872
INFO:root:[203,   200] training loss: 0.00698363
INFO:root:[203,   250] training loss: 0.00699428
INFO:root:[203,   300] training loss: 0.00780101
INFO:root:[203,   350] training loss: 0.00622293
INFO:root:[203,   400] training loss: 0.00001013
INFO:root:[203,   450] training loss: 0.00001315
INFO:root:[203,   500] training loss: 0.00002153
INFO:root:[203,   550] training loss: 0.00014052
INFO:root:[203,   600] training loss: 0.00016359
INFO:root:[203,   650] training loss: 0.00001839
INFO:root:[203,   700] training loss: 0.00001525
INFO:root:[203,   750] training loss: 0.00041995
INFO:root:[203,   800] training loss: 0.00030517
INFO:root:[203,   850] training loss: 0.00027006
INFO:root:[203,   900] training loss: 0.00363999
INFO:root:[203,   950] training loss: 0.00141981
INFO:root:[203,  1000] training loss: 0.00002089
INFO:root:[203,  1050] training loss: 0.00001139
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch203
INFO:root:[204,    50] training loss: 0.00739513
INFO:root:[204,   100] training loss: 0.00877486
INFO:root:[204,   150] training loss: 0.00717098
INFO:root:[204,   200] training loss: 0.00704825
INFO:root:[204,   250] training loss: 0.00728567
INFO:root:[204,   300] training loss: 0.00767799
INFO:root:[204,   350] training loss: 0.00668274
INFO:root:[204,   400] training loss: 0.00000755
INFO:root:[204,   450] training loss: 0.00000971
INFO:root:[204,   500] training loss: 0.00002028
INFO:root:[204,   550] training loss: 0.00016275
INFO:root:[204,   600] training loss: 0.00013106
INFO:root:[204,   650] training loss: 0.00002460
INFO:root:[204,   700] training loss: 0.00001945
INFO:root:[204,   750] training loss: 0.00041549
INFO:root:[204,   800] training loss: 0.00027401
INFO:root:[204,   850] training loss: 0.00031098
INFO:root:[204,   900] training loss: 0.00365293
INFO:root:[204,   950] training loss: 0.00166053
INFO:root:[204,  1000] training loss: 0.00002699
INFO:root:[204,  1050] training loss: 0.00001782
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch204
INFO:root:[205,    50] training loss: 0.00734131
INFO:root:[205,   100] training loss: 0.00752887
INFO:root:[205,   150] training loss: 0.00742354
INFO:root:[205,   200] training loss: 0.00688429
INFO:root:[205,   250] training loss: 0.00757179
INFO:root:[205,   300] training loss: 0.00776488
INFO:root:[205,   350] training loss: 0.00641417
INFO:root:[205,   400] training loss: 0.00000907
INFO:root:[205,   450] training loss: 0.00001160
INFO:root:[205,   500] training loss: 0.00002046
INFO:root:[205,   550] training loss: 0.00018464
INFO:root:[205,   600] training loss: 0.00011691
INFO:root:[205,   650] training loss: 0.00001925
INFO:root:[205,   700] training loss: 0.00002028
INFO:root:[205,   750] training loss: 0.00035011
INFO:root:[205,   800] training loss: 0.00029301
INFO:root:[205,   850] training loss: 0.00033357
INFO:root:[205,   900] training loss: 0.00397823
INFO:root:[205,   950] training loss: 0.00166683
INFO:root:[205,  1000] training loss: 0.00001645
INFO:root:[205,  1050] training loss: 0.00001151
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch205
INFO:root:[206,    50] training loss: 0.00733641
INFO:root:[206,   100] training loss: 0.00719307
INFO:root:[206,   150] training loss: 0.00732414
INFO:root:[206,   200] training loss: 0.00661869
INFO:root:[206,   250] training loss: 0.00694938
INFO:root:[206,   300] training loss: 0.00785192
INFO:root:[206,   350] training loss: 0.00671219
INFO:root:[206,   400] training loss: 0.00000942
INFO:root:[206,   450] training loss: 0.00001544
INFO:root:[206,   500] training loss: 0.00002094
INFO:root:[206,   550] training loss: 0.00012253
INFO:root:[206,   600] training loss: 0.00013726
INFO:root:[206,   650] training loss: 0.00001909
INFO:root:[206,   700] training loss: 0.00001539
INFO:root:[206,   750] training loss: 0.00042893
INFO:root:[206,   800] training loss: 0.00035343
INFO:root:[206,   850] training loss: 0.00028100
INFO:root:[206,   900] training loss: 0.00404335
INFO:root:[206,   950] training loss: 0.00173748
INFO:root:[206,  1000] training loss: 0.00002476
INFO:root:[206,  1050] training loss: 0.00001753
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch206
INFO:root:[207,    50] training loss: 0.00742107
INFO:root:[207,   100] training loss: 0.00751870
INFO:root:[207,   150] training loss: 0.00725209
INFO:root:[207,   200] training loss: 0.00692381
INFO:root:[207,   250] training loss: 0.00759545
INFO:root:[207,   300] training loss: 0.00811288
INFO:root:[207,   350] training loss: 0.00666741
INFO:root:[207,   400] training loss: 0.00001066
INFO:root:[207,   450] training loss: 0.00001181
INFO:root:[207,   500] training loss: 0.00002559
INFO:root:[207,   550] training loss: 0.00015466
INFO:root:[207,   600] training loss: 0.00012340
INFO:root:[207,   650] training loss: 0.00001365
INFO:root:[207,   700] training loss: 0.00001470
INFO:root:[207,   750] training loss: 0.00041028
INFO:root:[207,   800] training loss: 0.00030660
INFO:root:[207,   850] training loss: 0.00031211
INFO:root:[207,   900] training loss: 0.00421148
INFO:root:[207,   950] training loss: 0.00131696
INFO:root:[207,  1000] training loss: 0.00001638
INFO:root:[207,  1050] training loss: 0.00001483
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch207
INFO:root:[208,    50] training loss: 0.00702422
INFO:root:[208,   100] training loss: 0.00723737
INFO:root:[208,   150] training loss: 0.00688284
INFO:root:[208,   200] training loss: 0.00712258
INFO:root:[208,   250] training loss: 0.00704772
INFO:root:[208,   300] training loss: 0.00779773
INFO:root:[208,   350] training loss: 0.00654453
INFO:root:[208,   400] training loss: 0.00000791
INFO:root:[208,   450] training loss: 0.00001384
INFO:root:[208,   500] training loss: 0.00001849
INFO:root:[208,   550] training loss: 0.00013499
INFO:root:[208,   600] training loss: 0.00011036
INFO:root:[208,   650] training loss: 0.00001651
INFO:root:[208,   700] training loss: 0.00001795
INFO:root:[208,   750] training loss: 0.00033573
INFO:root:[208,   800] training loss: 0.00046408
INFO:root:[208,   850] training loss: 0.00030269
INFO:root:[208,   900] training loss: 0.00473436
INFO:root:[208,   950] training loss: 0.00122081
INFO:root:[208,  1000] training loss: 0.00002472
INFO:root:[208,  1050] training loss: 0.00001598
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch208
INFO:root:[209,    50] training loss: 0.00753399
INFO:root:[209,   100] training loss: 0.00714408
INFO:root:[209,   150] training loss: 0.00729359
INFO:root:[209,   200] training loss: 0.00672596
INFO:root:[209,   250] training loss: 0.00719982
INFO:root:[209,   300] training loss: 0.00757715
INFO:root:[209,   350] training loss: 0.00657173
INFO:root:[209,   400] training loss: 0.00001095
INFO:root:[209,   450] training loss: 0.00001206
INFO:root:[209,   500] training loss: 0.00001383
INFO:root:[209,   550] training loss: 0.00016203
INFO:root:[209,   600] training loss: 0.00017023
INFO:root:[209,   650] training loss: 0.00001657
INFO:root:[209,   700] training loss: 0.00001504
INFO:root:[209,   750] training loss: 0.00042366
INFO:root:[209,   800] training loss: 0.00032361
INFO:root:[209,   850] training loss: 0.00029216
INFO:root:[209,   900] training loss: 0.00380016
INFO:root:[209,   950] training loss: 0.00150436
INFO:root:[209,  1000] training loss: 0.00001410
INFO:root:[209,  1050] training loss: 0.00001253
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch209
INFO:root:[210,    50] training loss: 0.00714301
INFO:root:[210,   100] training loss: 0.00756437
INFO:root:[210,   150] training loss: 0.00765112
INFO:root:[210,   200] training loss: 0.00727498
INFO:root:[210,   250] training loss: 0.00708216
INFO:root:[210,   300] training loss: 0.00792713
INFO:root:[210,   350] training loss: 0.00810835
INFO:root:[210,   400] training loss: 0.00000879
INFO:root:[210,   450] training loss: 0.00001296
INFO:root:[210,   500] training loss: 0.00003001
INFO:root:[210,   550] training loss: 0.00010943
INFO:root:[210,   600] training loss: 0.00014162
INFO:root:[210,   650] training loss: 0.00001427
INFO:root:[210,   700] training loss: 0.00001837
INFO:root:[210,   750] training loss: 0.00038522
INFO:root:[210,   800] training loss: 0.00035573
INFO:root:[210,   850] training loss: 0.00029250
INFO:root:[210,   900] training loss: 0.00411901
INFO:root:[210,   950] training loss: 0.00148191
INFO:root:[210,  1000] training loss: 0.00001631
INFO:root:[210,  1050] training loss: 0.00001297
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch210
INFO:root:[211,    50] training loss: 0.00717782
INFO:root:[211,   100] training loss: 0.00767508
INFO:root:[211,   150] training loss: 0.00761583
INFO:root:[211,   200] training loss: 0.00722613
INFO:root:[211,   250] training loss: 0.00708352
INFO:root:[211,   300] training loss: 0.00775432
INFO:root:[211,   350] training loss: 0.00639208
INFO:root:[211,   400] training loss: 0.00000949
INFO:root:[211,   450] training loss: 0.00001297
INFO:root:[211,   500] training loss: 0.00001990
INFO:root:[211,   550] training loss: 0.00010142
INFO:root:[211,   600] training loss: 0.00013172
INFO:root:[211,   650] training loss: 0.00001687
INFO:root:[211,   700] training loss: 0.00001597
INFO:root:[211,   750] training loss: 0.00033464
INFO:root:[211,   800] training loss: 0.00037875
INFO:root:[211,   850] training loss: 0.00038234
INFO:root:[211,   900] training loss: 0.00363965
INFO:root:[211,   950] training loss: 0.00147597
INFO:root:[211,  1000] training loss: 0.00002506
INFO:root:[211,  1050] training loss: 0.00001899
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch211
INFO:root:[212,    50] training loss: 0.00760688
INFO:root:[212,   100] training loss: 0.00740229
INFO:root:[212,   150] training loss: 0.00710275
INFO:root:[212,   200] training loss: 0.00785659
INFO:root:[212,   250] training loss: 0.00747220
INFO:root:[212,   300] training loss: 0.00752885
INFO:root:[212,   350] training loss: 0.00603704
INFO:root:[212,   400] training loss: 0.00000832
INFO:root:[212,   450] training loss: 0.00001373
INFO:root:[212,   500] training loss: 0.00001952
INFO:root:[212,   550] training loss: 0.00023564
INFO:root:[212,   600] training loss: 0.00017216
INFO:root:[212,   650] training loss: 0.00001381
INFO:root:[212,   700] training loss: 0.00001862
INFO:root:[212,   750] training loss: 0.00049821
INFO:root:[212,   800] training loss: 0.00034491
INFO:root:[212,   850] training loss: 0.00035930
INFO:root:[212,   900] training loss: 0.00361058
INFO:root:[212,   950] training loss: 0.00159246
INFO:root:[212,  1000] training loss: 0.00002271
INFO:root:[212,  1050] training loss: 0.00001228
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch212
INFO:root:[213,    50] training loss: 0.00762450
INFO:root:[213,   100] training loss: 0.00741083
INFO:root:[213,   150] training loss: 0.00729683
INFO:root:[213,   200] training loss: 0.00706543
INFO:root:[213,   250] training loss: 0.00722766
INFO:root:[213,   300] training loss: 0.00814368
INFO:root:[213,   350] training loss: 0.00604763
INFO:root:[213,   400] training loss: 0.00000926
INFO:root:[213,   450] training loss: 0.00001960
INFO:root:[213,   500] training loss: 0.00002194
INFO:root:[213,   550] training loss: 0.00011706
INFO:root:[213,   600] training loss: 0.00010913
INFO:root:[213,   650] training loss: 0.00001681
INFO:root:[213,   700] training loss: 0.00001803
INFO:root:[213,   750] training loss: 0.00041628
INFO:root:[213,   800] training loss: 0.00029589
INFO:root:[213,   850] training loss: 0.00033562
INFO:root:[213,   900] training loss: 0.00353402
INFO:root:[213,   950] training loss: 0.00158624
INFO:root:[213,  1000] training loss: 0.00001692
INFO:root:[213,  1050] training loss: 0.00002021
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch213
INFO:root:[214,    50] training loss: 0.00728680
INFO:root:[214,   100] training loss: 0.00768779
INFO:root:[214,   150] training loss: 0.00775987
INFO:root:[214,   200] training loss: 0.00689576
INFO:root:[214,   250] training loss: 0.00691311
INFO:root:[214,   300] training loss: 0.00815904
INFO:root:[214,   350] training loss: 0.00684748
INFO:root:[214,   400] training loss: 0.00000966
INFO:root:[214,   450] training loss: 0.00001147
INFO:root:[214,   500] training loss: 0.00001973
INFO:root:[214,   550] training loss: 0.00016397
INFO:root:[214,   600] training loss: 0.00009910
INFO:root:[214,   650] training loss: 0.00001341
INFO:root:[214,   700] training loss: 0.00001362
INFO:root:[214,   750] training loss: 0.00033499
INFO:root:[214,   800] training loss: 0.00029469
INFO:root:[214,   850] training loss: 0.00026671
INFO:root:[214,   900] training loss: 0.00374219
INFO:root:[214,   950] training loss: 0.00151661
INFO:root:[214,  1000] training loss: 0.00002234
INFO:root:[214,  1050] training loss: 0.00001993
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch214
INFO:root:[215,    50] training loss: 0.00750382
INFO:root:[215,   100] training loss: 0.00868405
INFO:root:[215,   150] training loss: 0.00764639
INFO:root:[215,   200] training loss: 0.00686031
INFO:root:[215,   250] training loss: 0.00724822
INFO:root:[215,   300] training loss: 0.00775112
INFO:root:[215,   350] training loss: 0.00652247
INFO:root:[215,   400] training loss: 0.00000979
INFO:root:[215,   450] training loss: 0.00001421
INFO:root:[215,   500] training loss: 0.00002085
INFO:root:[215,   550] training loss: 0.00013431
INFO:root:[215,   600] training loss: 0.00014709
INFO:root:[215,   650] training loss: 0.00001841
INFO:root:[215,   700] training loss: 0.00001423
INFO:root:[215,   750] training loss: 0.00038449
INFO:root:[215,   800] training loss: 0.00036651
INFO:root:[215,   850] training loss: 0.00029740
INFO:root:[215,   900] training loss: 0.00423133
INFO:root:[215,   950] training loss: 0.00158463
INFO:root:[215,  1000] training loss: 0.00001198
INFO:root:[215,  1050] training loss: 0.00001099
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch215
INFO:root:[216,    50] training loss: 0.00774440
INFO:root:[216,   100] training loss: 0.00765098
INFO:root:[216,   150] training loss: 0.00723159
INFO:root:[216,   200] training loss: 0.00669655
INFO:root:[216,   250] training loss: 0.00723297
INFO:root:[216,   300] training loss: 0.00791757
INFO:root:[216,   350] training loss: 0.00651505
INFO:root:[216,   400] training loss: 0.00000893
INFO:root:[216,   450] training loss: 0.00001190
INFO:root:[216,   500] training loss: 0.00002506
INFO:root:[216,   550] training loss: 0.00022884
INFO:root:[216,   600] training loss: 0.00012686
INFO:root:[216,   650] training loss: 0.00001707
INFO:root:[216,   700] training loss: 0.00001466
INFO:root:[216,   750] training loss: 0.00035141
INFO:root:[216,   800] training loss: 0.00035382
INFO:root:[216,   850] training loss: 0.00029843
INFO:root:[216,   900] training loss: 0.00408510
INFO:root:[216,   950] training loss: 0.00136932
INFO:root:[216,  1000] training loss: 0.00001384
INFO:root:[216,  1050] training loss: 0.00001170
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch216
INFO:root:[217,    50] training loss: 0.00738899
INFO:root:[217,   100] training loss: 0.00722684
INFO:root:[217,   150] training loss: 0.00769058
INFO:root:[217,   200] training loss: 0.00736569
INFO:root:[217,   250] training loss: 0.00724477
INFO:root:[217,   300] training loss: 0.00751682
INFO:root:[217,   350] training loss: 0.00650384
INFO:root:[217,   400] training loss: 0.00000914
INFO:root:[217,   450] training loss: 0.00001095
INFO:root:[217,   500] training loss: 0.00004472
INFO:root:[217,   550] training loss: 0.00016982
INFO:root:[217,   600] training loss: 0.00015854
INFO:root:[217,   650] training loss: 0.00001820
INFO:root:[217,   700] training loss: 0.00001231
INFO:root:[217,   750] training loss: 0.00044528
INFO:root:[217,   800] training loss: 0.00027442
INFO:root:[217,   850] training loss: 0.00034421
INFO:root:[217,   900] training loss: 0.00478041
INFO:root:[217,   950] training loss: 0.00169384
INFO:root:[217,  1000] training loss: 0.00004516
INFO:root:[217,  1050] training loss: 0.00001577
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch217
INFO:root:[218,    50] training loss: 0.00805641
INFO:root:[218,   100] training loss: 0.00751467
INFO:root:[218,   150] training loss: 0.00730321
INFO:root:[218,   200] training loss: 0.00694882
INFO:root:[218,   250] training loss: 0.00735195
INFO:root:[218,   300] training loss: 0.00753281
INFO:root:[218,   350] training loss: 0.00682424
INFO:root:[218,   400] training loss: 0.00000836
INFO:root:[218,   450] training loss: 0.00001366
INFO:root:[218,   500] training loss: 0.00003340
INFO:root:[218,   550] training loss: 0.00015602
INFO:root:[218,   600] training loss: 0.00014024
INFO:root:[218,   650] training loss: 0.00001576
INFO:root:[218,   700] training loss: 0.00002420
INFO:root:[218,   750] training loss: 0.00034497
INFO:root:[218,   800] training loss: 0.00027828
INFO:root:[218,   850] training loss: 0.00028872
INFO:root:[218,   900] training loss: 0.00366964
INFO:root:[218,   950] training loss: 0.00166653
INFO:root:[218,  1000] training loss: 0.00001665
INFO:root:[218,  1050] training loss: 0.00001274
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch218
INFO:root:[219,    50] training loss: 0.00722293
INFO:root:[219,   100] training loss: 0.00754224
INFO:root:[219,   150] training loss: 0.00728684
INFO:root:[219,   200] training loss: 0.00723206
INFO:root:[219,   250] training loss: 0.00720877
INFO:root:[219,   300] training loss: 0.00753836
INFO:root:[219,   350] training loss: 0.00629880
INFO:root:[219,   400] training loss: 0.00000763
INFO:root:[219,   450] training loss: 0.00001340
INFO:root:[219,   500] training loss: 0.00005435
INFO:root:[219,   550] training loss: 0.00011397
INFO:root:[219,   600] training loss: 0.00013315
INFO:root:[219,   650] training loss: 0.00001199
INFO:root:[219,   700] training loss: 0.00001667
INFO:root:[219,   750] training loss: 0.00035467
INFO:root:[219,   800] training loss: 0.00042715
INFO:root:[219,   850] training loss: 0.00033903
INFO:root:[219,   900] training loss: 0.00406713
INFO:root:[219,   950] training loss: 0.00139329
INFO:root:[219,  1000] training loss: 0.00002190
INFO:root:[219,  1050] training loss: 0.00001327
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8037    0.7975    0.8006      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6254    0.6799    0.6515      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7769      3872
   macro avg     0.6910    0.7917    0.7284      3872
weighted avg     0.7917    0.7769    0.7822      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch219
INFO:root:[220,    50] training loss: 0.00752406
INFO:root:[220,   100] training loss: 0.00783128
INFO:root:[220,   150] training loss: 0.00736886
INFO:root:[220,   200] training loss: 0.00686927
INFO:root:[220,   250] training loss: 0.00771347
INFO:root:[220,   300] training loss: 0.00796733
INFO:root:[220,   350] training loss: 0.00648594
INFO:root:[220,   400] training loss: 0.00000924
INFO:root:[220,   450] training loss: 0.00001277
INFO:root:[220,   500] training loss: 0.00001788
INFO:root:[220,   550] training loss: 0.00014253
INFO:root:[220,   600] training loss: 0.00017067
INFO:root:[220,   650] training loss: 0.00001799
INFO:root:[220,   700] training loss: 0.00001883
INFO:root:[220,   750] training loss: 0.00040294
INFO:root:[220,   800] training loss: 0.00032030
INFO:root:[220,   850] training loss: 0.00040667
INFO:root:[220,   900] training loss: 0.00458513
INFO:root:[220,   950] training loss: 0.00152242
INFO:root:[220,  1000] training loss: 0.00001196
INFO:root:[220,  1050] training loss: 0.00001305
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch220
INFO:root:[221,    50] training loss: 0.00709233
INFO:root:[221,   100] training loss: 0.00736521
INFO:root:[221,   150] training loss: 0.00740427
INFO:root:[221,   200] training loss: 0.00701635
INFO:root:[221,   250] training loss: 0.00699388
INFO:root:[221,   300] training loss: 0.00751567
INFO:root:[221,   350] training loss: 0.00718500
INFO:root:[221,   400] training loss: 0.00000978
INFO:root:[221,   450] training loss: 0.00001234
INFO:root:[221,   500] training loss: 0.00002471
INFO:root:[221,   550] training loss: 0.00017661
INFO:root:[221,   600] training loss: 0.00011625
INFO:root:[221,   650] training loss: 0.00001645
INFO:root:[221,   700] training loss: 0.00002093
INFO:root:[221,   750] training loss: 0.00034000
INFO:root:[221,   800] training loss: 0.00031053
INFO:root:[221,   850] training loss: 0.00034462
INFO:root:[221,   900] training loss: 0.00372043
INFO:root:[221,   950] training loss: 0.00128659
INFO:root:[221,  1000] training loss: 0.00001449
INFO:root:[221,  1050] training loss: 0.00001375
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch221
INFO:root:[222,    50] training loss: 0.00720846
INFO:root:[222,   100] training loss: 0.00724693
INFO:root:[222,   150] training loss: 0.00722717
INFO:root:[222,   200] training loss: 0.00681210
INFO:root:[222,   250] training loss: 0.00729522
INFO:root:[222,   300] training loss: 0.00767867
INFO:root:[222,   350] training loss: 0.00687588
INFO:root:[222,   400] training loss: 0.00000857
INFO:root:[222,   450] training loss: 0.00001279
INFO:root:[222,   500] training loss: 0.00003210
INFO:root:[222,   550] training loss: 0.00012833
INFO:root:[222,   600] training loss: 0.00013679
INFO:root:[222,   650] training loss: 0.00001753
INFO:root:[222,   700] training loss: 0.00001391
INFO:root:[222,   750] training loss: 0.00031928
INFO:root:[222,   800] training loss: 0.00037310
INFO:root:[222,   850] training loss: 0.00032805
INFO:root:[222,   900] training loss: 0.00394339
INFO:root:[222,   950] training loss: 0.00145654
INFO:root:[222,  1000] training loss: 0.00002622
INFO:root:[222,  1050] training loss: 0.00001076
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch222
INFO:root:[223,    50] training loss: 0.00729948
INFO:root:[223,   100] training loss: 0.00749929
INFO:root:[223,   150] training loss: 0.00742873
INFO:root:[223,   200] training loss: 0.00718428
INFO:root:[223,   250] training loss: 0.00743339
INFO:root:[223,   300] training loss: 0.00839706
INFO:root:[223,   350] training loss: 0.00705168
INFO:root:[223,   400] training loss: 0.00000925
INFO:root:[223,   450] training loss: 0.00001211
INFO:root:[223,   500] training loss: 0.00002522
INFO:root:[223,   550] training loss: 0.00012668
INFO:root:[223,   600] training loss: 0.00011620
INFO:root:[223,   650] training loss: 0.00001649
INFO:root:[223,   700] training loss: 0.00001398
INFO:root:[223,   750] training loss: 0.00044047
INFO:root:[223,   800] training loss: 0.00032596
INFO:root:[223,   850] training loss: 0.00030605
INFO:root:[223,   900] training loss: 0.00402950
INFO:root:[223,   950] training loss: 0.00156563
INFO:root:[223,  1000] training loss: 0.00002051
INFO:root:[223,  1050] training loss: 0.00001162
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch223
INFO:root:[224,    50] training loss: 0.00778369
INFO:root:[224,   100] training loss: 0.00835828
INFO:root:[224,   150] training loss: 0.00784075
INFO:root:[224,   200] training loss: 0.00795047
INFO:root:[224,   250] training loss: 0.00726542
INFO:root:[224,   300] training loss: 0.00849707
INFO:root:[224,   350] training loss: 0.00650337
INFO:root:[224,   400] training loss: 0.00000787
INFO:root:[224,   450] training loss: 0.00001271
INFO:root:[224,   500] training loss: 0.00002351
INFO:root:[224,   550] training loss: 0.00014773
INFO:root:[224,   600] training loss: 0.00013131
INFO:root:[224,   650] training loss: 0.00001482
INFO:root:[224,   700] training loss: 0.00001374
INFO:root:[224,   750] training loss: 0.00032883
INFO:root:[224,   800] training loss: 0.00037214
INFO:root:[224,   850] training loss: 0.00030340
INFO:root:[224,   900] training loss: 0.00399733
INFO:root:[224,   950] training loss: 0.00169600
INFO:root:[224,  1000] training loss: 0.00002428
INFO:root:[224,  1050] training loss: 0.00001522
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch224
INFO:root:[225,    50] training loss: 0.00749835
INFO:root:[225,   100] training loss: 0.00713987
INFO:root:[225,   150] training loss: 0.00763561
INFO:root:[225,   200] training loss: 0.00686045
INFO:root:[225,   250] training loss: 0.00738314
INFO:root:[225,   300] training loss: 0.00774911
INFO:root:[225,   350] training loss: 0.00719395
INFO:root:[225,   400] training loss: 0.00001020
INFO:root:[225,   450] training loss: 0.00001869
INFO:root:[225,   500] training loss: 0.00001678
INFO:root:[225,   550] training loss: 0.00013459
INFO:root:[225,   600] training loss: 0.00019299
INFO:root:[225,   650] training loss: 0.00001450
INFO:root:[225,   700] training loss: 0.00001718
INFO:root:[225,   750] training loss: 0.00035933
INFO:root:[225,   800] training loss: 0.00037520
INFO:root:[225,   850] training loss: 0.00034896
INFO:root:[225,   900] training loss: 0.00392892
INFO:root:[225,   950] training loss: 0.00211758
INFO:root:[225,  1000] training loss: 0.00001723
INFO:root:[225,  1050] training loss: 0.00001355
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch225
INFO:root:[226,    50] training loss: 0.00770812
INFO:root:[226,   100] training loss: 0.00710947
INFO:root:[226,   150] training loss: 0.00701122
INFO:root:[226,   200] training loss: 0.00740321
INFO:root:[226,   250] training loss: 0.00679003
INFO:root:[226,   300] training loss: 0.00717492
INFO:root:[226,   350] training loss: 0.00651339
INFO:root:[226,   400] training loss: 0.00000800
INFO:root:[226,   450] training loss: 0.00001151
INFO:root:[226,   500] training loss: 0.00002667
INFO:root:[226,   550] training loss: 0.00016519
INFO:root:[226,   600] training loss: 0.00016403
INFO:root:[226,   650] training loss: 0.00001612
INFO:root:[226,   700] training loss: 0.00001588
INFO:root:[226,   750] training loss: 0.00037316
INFO:root:[226,   800] training loss: 0.00029947
INFO:root:[226,   850] training loss: 0.00029299
INFO:root:[226,   900] training loss: 0.00388641
INFO:root:[226,   950] training loss: 0.00152230
INFO:root:[226,  1000] training loss: 0.00001429
INFO:root:[226,  1050] training loss: 0.00001370
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch226
INFO:root:[227,    50] training loss: 0.00733458
INFO:root:[227,   100] training loss: 0.00759886
INFO:root:[227,   150] training loss: 0.00728438
INFO:root:[227,   200] training loss: 0.00685412
INFO:root:[227,   250] training loss: 0.00697599
INFO:root:[227,   300] training loss: 0.00762838
INFO:root:[227,   350] training loss: 0.00634781
INFO:root:[227,   400] training loss: 0.00000906
INFO:root:[227,   450] training loss: 0.00001741
INFO:root:[227,   500] training loss: 0.00001573
INFO:root:[227,   550] training loss: 0.00015382
INFO:root:[227,   600] training loss: 0.00013448
INFO:root:[227,   650] training loss: 0.00001490
INFO:root:[227,   700] training loss: 0.00001736
INFO:root:[227,   750] training loss: 0.00038381
INFO:root:[227,   800] training loss: 0.00027563
INFO:root:[227,   850] training loss: 0.00032470
INFO:root:[227,   900] training loss: 0.00456602
INFO:root:[227,   950] training loss: 0.00130650
INFO:root:[227,  1000] training loss: 0.00001712
INFO:root:[227,  1050] training loss: 0.00001262
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch227
INFO:root:[228,    50] training loss: 0.00777186
INFO:root:[228,   100] training loss: 0.00741292
INFO:root:[228,   150] training loss: 0.00679040
INFO:root:[228,   200] training loss: 0.00710650
INFO:root:[228,   250] training loss: 0.00772657
INFO:root:[228,   300] training loss: 0.00750031
INFO:root:[228,   350] training loss: 0.00671895
INFO:root:[228,   400] training loss: 0.00001136
INFO:root:[228,   450] training loss: 0.00001560
INFO:root:[228,   500] training loss: 0.00001565
INFO:root:[228,   550] training loss: 0.00012480
INFO:root:[228,   600] training loss: 0.00013392
INFO:root:[228,   650] training loss: 0.00001263
INFO:root:[228,   700] training loss: 0.00001577
INFO:root:[228,   750] training loss: 0.00035025
INFO:root:[228,   800] training loss: 0.00031836
INFO:root:[228,   850] training loss: 0.00034037
INFO:root:[228,   900] training loss: 0.00410799
INFO:root:[228,   950] training loss: 0.00162048
INFO:root:[228,  1000] training loss: 0.00002085
INFO:root:[228,  1050] training loss: 0.00001086
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch228
INFO:root:[229,    50] training loss: 0.00731398
INFO:root:[229,   100] training loss: 0.00743761
INFO:root:[229,   150] training loss: 0.00776912
INFO:root:[229,   200] training loss: 0.00694460
INFO:root:[229,   250] training loss: 0.00741058
INFO:root:[229,   300] training loss: 0.00751167
INFO:root:[229,   350] training loss: 0.00744896
INFO:root:[229,   400] training loss: 0.00000965
INFO:root:[229,   450] training loss: 0.00001334
INFO:root:[229,   500] training loss: 0.00001600
INFO:root:[229,   550] training loss: 0.00013552
INFO:root:[229,   600] training loss: 0.00015419
INFO:root:[229,   650] training loss: 0.00001489
INFO:root:[229,   700] training loss: 0.00001575
INFO:root:[229,   750] training loss: 0.00031791
INFO:root:[229,   800] training loss: 0.00031123
INFO:root:[229,   850] training loss: 0.00043146
INFO:root:[229,   900] training loss: 0.00452636
INFO:root:[229,   950] training loss: 0.00132012
INFO:root:[229,  1000] training loss: 0.00001275
INFO:root:[229,  1050] training loss: 0.00001281
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch229
INFO:root:[230,    50] training loss: 0.00683384
INFO:root:[230,   100] training loss: 0.00759414
INFO:root:[230,   150] training loss: 0.00727846
INFO:root:[230,   200] training loss: 0.00687724
INFO:root:[230,   250] training loss: 0.00714231
INFO:root:[230,   300] training loss: 0.00848633
INFO:root:[230,   350] training loss: 0.00744333
INFO:root:[230,   400] training loss: 0.00000868
INFO:root:[230,   450] training loss: 0.00001656
INFO:root:[230,   500] training loss: 0.00001742
INFO:root:[230,   550] training loss: 0.00014327
INFO:root:[230,   600] training loss: 0.00015230
INFO:root:[230,   650] training loss: 0.00001595
INFO:root:[230,   700] training loss: 0.00001621
INFO:root:[230,   750] training loss: 0.00033389
INFO:root:[230,   800] training loss: 0.00038397
INFO:root:[230,   850] training loss: 0.00033607
INFO:root:[230,   900] training loss: 0.00455950
INFO:root:[230,   950] training loss: 0.00122270
INFO:root:[230,  1000] training loss: 0.00001604
INFO:root:[230,  1050] training loss: 0.00001626
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch230
INFO:root:[231,    50] training loss: 0.00717676
INFO:root:[231,   100] training loss: 0.00751267
INFO:root:[231,   150] training loss: 0.00753778
INFO:root:[231,   200] training loss: 0.00702747
INFO:root:[231,   250] training loss: 0.00734923
INFO:root:[231,   300] training loss: 0.00735490
INFO:root:[231,   350] training loss: 0.00653501
INFO:root:[231,   400] training loss: 0.00000865
INFO:root:[231,   450] training loss: 0.00001297
INFO:root:[231,   500] training loss: 0.00002686
INFO:root:[231,   550] training loss: 0.00014732
INFO:root:[231,   600] training loss: 0.00016830
INFO:root:[231,   650] training loss: 0.00001909
INFO:root:[231,   700] training loss: 0.00001749
INFO:root:[231,   750] training loss: 0.00031210
INFO:root:[231,   800] training loss: 0.00023707
INFO:root:[231,   850] training loss: 0.00033286
INFO:root:[231,   900] training loss: 0.00431594
INFO:root:[231,   950] training loss: 0.00123979
INFO:root:[231,  1000] training loss: 0.00001776
INFO:root:[231,  1050] training loss: 0.00001733
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch231
INFO:root:[232,    50] training loss: 0.00777080
INFO:root:[232,   100] training loss: 0.00723805
INFO:root:[232,   150] training loss: 0.00732540
INFO:root:[232,   200] training loss: 0.00716642
INFO:root:[232,   250] training loss: 0.00797293
INFO:root:[232,   300] training loss: 0.00767304
INFO:root:[232,   350] training loss: 0.00631038
INFO:root:[232,   400] training loss: 0.00000823
INFO:root:[232,   450] training loss: 0.00001110
INFO:root:[232,   500] training loss: 0.00002680
INFO:root:[232,   550] training loss: 0.00011606
INFO:root:[232,   600] training loss: 0.00013987
INFO:root:[232,   650] training loss: 0.00001848
INFO:root:[232,   700] training loss: 0.00003209
INFO:root:[232,   750] training loss: 0.00037019
INFO:root:[232,   800] training loss: 0.00027189
INFO:root:[232,   850] training loss: 0.00034473
INFO:root:[232,   900] training loss: 0.00356988
INFO:root:[232,   950] training loss: 0.00143575
INFO:root:[232,  1000] training loss: 0.00001830
INFO:root:[232,  1050] training loss: 0.00001426
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch232
INFO:root:[233,    50] training loss: 0.00738403
INFO:root:[233,   100] training loss: 0.00740897
INFO:root:[233,   150] training loss: 0.00793940
INFO:root:[233,   200] training loss: 0.00718321
INFO:root:[233,   250] training loss: 0.00757384
INFO:root:[233,   300] training loss: 0.00776816
INFO:root:[233,   350] training loss: 0.00678197
INFO:root:[233,   400] training loss: 0.00000975
INFO:root:[233,   450] training loss: 0.00001059
INFO:root:[233,   500] training loss: 0.00002989
INFO:root:[233,   550] training loss: 0.00010353
INFO:root:[233,   600] training loss: 0.00016468
INFO:root:[233,   650] training loss: 0.00001785
INFO:root:[233,   700] training loss: 0.00001556
INFO:root:[233,   750] training loss: 0.00030077
INFO:root:[233,   800] training loss: 0.00031740
INFO:root:[233,   850] training loss: 0.00032275
INFO:root:[233,   900] training loss: 0.00436590
INFO:root:[233,   950] training loss: 0.00134195
INFO:root:[233,  1000] training loss: 0.00002334
INFO:root:[233,  1050] training loss: 0.00001219
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch233
INFO:root:[234,    50] training loss: 0.00760531
INFO:root:[234,   100] training loss: 0.00737436
INFO:root:[234,   150] training loss: 0.00724027
INFO:root:[234,   200] training loss: 0.00699764
INFO:root:[234,   250] training loss: 0.00770849
INFO:root:[234,   300] training loss: 0.00796571
INFO:root:[234,   350] training loss: 0.00652952
INFO:root:[234,   400] training loss: 0.00001081
INFO:root:[234,   450] training loss: 0.00001135
INFO:root:[234,   500] training loss: 0.00007911
INFO:root:[234,   550] training loss: 0.00015461
INFO:root:[234,   600] training loss: 0.00011564
INFO:root:[234,   650] training loss: 0.00001856
INFO:root:[234,   700] training loss: 0.00001411
INFO:root:[234,   750] training loss: 0.00038590
INFO:root:[234,   800] training loss: 0.00030833
INFO:root:[234,   850] training loss: 0.00029705
INFO:root:[234,   900] training loss: 0.00410495
INFO:root:[234,   950] training loss: 0.00137124
INFO:root:[234,  1000] training loss: 0.00002071
INFO:root:[234,  1050] training loss: 0.00001632
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch234
INFO:root:[235,    50] training loss: 0.00713402
INFO:root:[235,   100] training loss: 0.00758543
INFO:root:[235,   150] training loss: 0.00731476
INFO:root:[235,   200] training loss: 0.00692539
INFO:root:[235,   250] training loss: 0.00702789
INFO:root:[235,   300] training loss: 0.00769108
INFO:root:[235,   350] training loss: 0.00660343
INFO:root:[235,   400] training loss: 0.00000899
INFO:root:[235,   450] training loss: 0.00001314
INFO:root:[235,   500] training loss: 0.00002056
INFO:root:[235,   550] training loss: 0.00013451
INFO:root:[235,   600] training loss: 0.00011443
INFO:root:[235,   650] training loss: 0.00001841
INFO:root:[235,   700] training loss: 0.00001551
INFO:root:[235,   750] training loss: 0.00029216
INFO:root:[235,   800] training loss: 0.00040877
INFO:root:[235,   850] training loss: 0.00031885
INFO:root:[235,   900] training loss: 0.00426472
INFO:root:[235,   950] training loss: 0.00146837
INFO:root:[235,  1000] training loss: 0.00002196
INFO:root:[235,  1050] training loss: 0.00001328
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch235
INFO:root:[236,    50] training loss: 0.00732509
INFO:root:[236,   100] training loss: 0.00780914
INFO:root:[236,   150] training loss: 0.00742553
INFO:root:[236,   200] training loss: 0.00713501
INFO:root:[236,   250] training loss: 0.00728622
INFO:root:[236,   300] training loss: 0.00794114
INFO:root:[236,   350] training loss: 0.00713086
INFO:root:[236,   400] training loss: 0.00000898
INFO:root:[236,   450] training loss: 0.00001179
INFO:root:[236,   500] training loss: 0.00002337
INFO:root:[236,   550] training loss: 0.00012220
INFO:root:[236,   600] training loss: 0.00016993
INFO:root:[236,   650] training loss: 0.00002062
INFO:root:[236,   700] training loss: 0.00001488
INFO:root:[236,   750] training loss: 0.00032572
INFO:root:[236,   800] training loss: 0.00034916
INFO:root:[236,   850] training loss: 0.00033448
INFO:root:[236,   900] training loss: 0.00423882
INFO:root:[236,   950] training loss: 0.00133373
INFO:root:[236,  1000] training loss: 0.00002324
INFO:root:[236,  1050] training loss: 0.00001610
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch236
INFO:root:[237,    50] training loss: 0.00741195
INFO:root:[237,   100] training loss: 0.00745385
INFO:root:[237,   150] training loss: 0.00755634
INFO:root:[237,   200] training loss: 0.00711305
INFO:root:[237,   250] training loss: 0.00729596
INFO:root:[237,   300] training loss: 0.00793937
INFO:root:[237,   350] training loss: 0.00725556
INFO:root:[237,   400] training loss: 0.00001037
INFO:root:[237,   450] training loss: 0.00000983
INFO:root:[237,   500] training loss: 0.00001762
INFO:root:[237,   550] training loss: 0.00013583
INFO:root:[237,   600] training loss: 0.00011523
INFO:root:[237,   650] training loss: 0.00001633
INFO:root:[237,   700] training loss: 0.00002100
INFO:root:[237,   750] training loss: 0.00034250
INFO:root:[237,   800] training loss: 0.00032616
INFO:root:[237,   850] training loss: 0.00027505
INFO:root:[237,   900] training loss: 0.00356923
INFO:root:[237,   950] training loss: 0.00106169
INFO:root:[237,  1000] training loss: 0.00001575
INFO:root:[237,  1050] training loss: 0.00001637
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch237
INFO:root:[238,    50] training loss: 0.00744797
INFO:root:[238,   100] training loss: 0.00829691
INFO:root:[238,   150] training loss: 0.00739099
INFO:root:[238,   200] training loss: 0.00702477
INFO:root:[238,   250] training loss: 0.00747155
INFO:root:[238,   300] training loss: 0.00793331
INFO:root:[238,   350] training loss: 0.00674270
INFO:root:[238,   400] training loss: 0.00000943
INFO:root:[238,   450] training loss: 0.00001106
INFO:root:[238,   500] training loss: 0.00001546
INFO:root:[238,   550] training loss: 0.00010154
INFO:root:[238,   600] training loss: 0.00015126
INFO:root:[238,   650] training loss: 0.00001460
INFO:root:[238,   700] training loss: 0.00001535
INFO:root:[238,   750] training loss: 0.00033764
INFO:root:[238,   800] training loss: 0.00032763
INFO:root:[238,   850] training loss: 0.00027279
INFO:root:[238,   900] training loss: 0.00454239
INFO:root:[238,   950] training loss: 0.00147582
INFO:root:[238,  1000] training loss: 0.00001774
INFO:root:[238,  1050] training loss: 0.00001571
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch238
INFO:root:[239,    50] training loss: 0.00756650
INFO:root:[239,   100] training loss: 0.00741942
INFO:root:[239,   150] training loss: 0.00731200
INFO:root:[239,   200] training loss: 0.00698824
INFO:root:[239,   250] training loss: 0.00740875
INFO:root:[239,   300] training loss: 0.00779998
INFO:root:[239,   350] training loss: 0.00728064
INFO:root:[239,   400] training loss: 0.00001042
INFO:root:[239,   450] training loss: 0.00001724
INFO:root:[239,   500] training loss: 0.00001775
INFO:root:[239,   550] training loss: 0.00014950
INFO:root:[239,   600] training loss: 0.00010253
INFO:root:[239,   650] training loss: 0.00001450
INFO:root:[239,   700] training loss: 0.00001602
INFO:root:[239,   750] training loss: 0.00032242
INFO:root:[239,   800] training loss: 0.00034440
INFO:root:[239,   850] training loss: 0.00025621
INFO:root:[239,   900] training loss: 0.00419448
INFO:root:[239,   950] training loss: 0.00152675
INFO:root:[239,  1000] training loss: 0.00001224
INFO:root:[239,  1050] training loss: 0.00001288
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch239
INFO:root:[240,    50] training loss: 0.00745977
INFO:root:[240,   100] training loss: 0.00754372
INFO:root:[240,   150] training loss: 0.00708344
INFO:root:[240,   200] training loss: 0.00712125
INFO:root:[240,   250] training loss: 0.00754053
INFO:root:[240,   300] training loss: 0.00782898
INFO:root:[240,   350] training loss: 0.00637585
INFO:root:[240,   400] training loss: 0.00000777
INFO:root:[240,   450] training loss: 0.00001415
INFO:root:[240,   500] training loss: 0.00002290
INFO:root:[240,   550] training loss: 0.00011044
INFO:root:[240,   600] training loss: 0.00015996
INFO:root:[240,   650] training loss: 0.00001250
INFO:root:[240,   700] training loss: 0.00001291
INFO:root:[240,   750] training loss: 0.00044804
INFO:root:[240,   800] training loss: 0.00030699
INFO:root:[240,   850] training loss: 0.00027254
INFO:root:[240,   900] training loss: 0.00429938
INFO:root:[240,   950] training loss: 0.00209323
INFO:root:[240,  1000] training loss: 0.00001628
INFO:root:[240,  1050] training loss: 0.00001298
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch240
INFO:root:[241,    50] training loss: 0.00775777
INFO:root:[241,   100] training loss: 0.00728767
INFO:root:[241,   150] training loss: 0.00732687
INFO:root:[241,   200] training loss: 0.00681996
INFO:root:[241,   250] training loss: 0.00727352
INFO:root:[241,   300] training loss: 0.00790921
INFO:root:[241,   350] training loss: 0.00747927
INFO:root:[241,   400] training loss: 0.00000957
INFO:root:[241,   450] training loss: 0.00001319
INFO:root:[241,   500] training loss: 0.00001887
INFO:root:[241,   550] training loss: 0.00013202
INFO:root:[241,   600] training loss: 0.00013693
INFO:root:[241,   650] training loss: 0.00001625
INFO:root:[241,   700] training loss: 0.00002328
INFO:root:[241,   750] training loss: 0.00034061
INFO:root:[241,   800] training loss: 0.00040717
INFO:root:[241,   850] training loss: 0.00036580
INFO:root:[241,   900] training loss: 0.00436331
INFO:root:[241,   950] training loss: 0.00138256
INFO:root:[241,  1000] training loss: 0.00001366
INFO:root:[241,  1050] training loss: 0.00001531
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch241
INFO:root:[242,    50] training loss: 0.00752442
INFO:root:[242,   100] training loss: 0.00717352
INFO:root:[242,   150] training loss: 0.00796191
INFO:root:[242,   200] training loss: 0.00705685
INFO:root:[242,   250] training loss: 0.00695607
INFO:root:[242,   300] training loss: 0.00865901
INFO:root:[242,   350] training loss: 0.00709641
INFO:root:[242,   400] training loss: 0.00001019
INFO:root:[242,   450] training loss: 0.00001285
INFO:root:[242,   500] training loss: 0.00003978
INFO:root:[242,   550] training loss: 0.00016103
INFO:root:[242,   600] training loss: 0.00014163
INFO:root:[242,   650] training loss: 0.00001526
INFO:root:[242,   700] training loss: 0.00001204
INFO:root:[242,   750] training loss: 0.00041935
INFO:root:[242,   800] training loss: 0.00026152
INFO:root:[242,   850] training loss: 0.00030748
INFO:root:[242,   900] training loss: 0.00376504
INFO:root:[242,   950] training loss: 0.00141276
INFO:root:[242,  1000] training loss: 0.00001395
INFO:root:[242,  1050] training loss: 0.00001272
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch242
INFO:root:[243,    50] training loss: 0.00785716
INFO:root:[243,   100] training loss: 0.00708171
INFO:root:[243,   150] training loss: 0.00865623
INFO:root:[243,   200] training loss: 0.00821829
INFO:root:[243,   250] training loss: 0.00742962
INFO:root:[243,   300] training loss: 0.00786109
INFO:root:[243,   350] training loss: 0.00654267
INFO:root:[243,   400] training loss: 0.00000848
INFO:root:[243,   450] training loss: 0.00004230
INFO:root:[243,   500] training loss: 0.00002097
INFO:root:[243,   550] training loss: 0.00014002
INFO:root:[243,   600] training loss: 0.00016398
INFO:root:[243,   650] training loss: 0.00001713
INFO:root:[243,   700] training loss: 0.00001594
INFO:root:[243,   750] training loss: 0.00047127
INFO:root:[243,   800] training loss: 0.00033240
INFO:root:[243,   850] training loss: 0.00030200
INFO:root:[243,   900] training loss: 0.00444699
INFO:root:[243,   950] training loss: 0.00204367
INFO:root:[243,  1000] training loss: 0.00002085
INFO:root:[243,  1050] training loss: 0.00001517
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch243
INFO:root:[244,    50] training loss: 0.00764588
INFO:root:[244,   100] training loss: 0.00746633
INFO:root:[244,   150] training loss: 0.00711864
INFO:root:[244,   200] training loss: 0.00706566
INFO:root:[244,   250] training loss: 0.00716578
INFO:root:[244,   300] training loss: 0.00865351
INFO:root:[244,   350] training loss: 0.00616377
INFO:root:[244,   400] training loss: 0.00001110
INFO:root:[244,   450] training loss: 0.00001369
INFO:root:[244,   500] training loss: 0.00002441
INFO:root:[244,   550] training loss: 0.00012162
INFO:root:[244,   600] training loss: 0.00016448
INFO:root:[244,   650] training loss: 0.00001527
INFO:root:[244,   700] training loss: 0.00001798
INFO:root:[244,   750] training loss: 0.00036712
INFO:root:[244,   800] training loss: 0.00031502
INFO:root:[244,   850] training loss: 0.00027326
INFO:root:[244,   900] training loss: 0.00432381
INFO:root:[244,   950] training loss: 0.00144378
INFO:root:[244,  1000] training loss: 0.00001469
INFO:root:[244,  1050] training loss: 0.00001308
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch244
INFO:root:[245,    50] training loss: 0.00708158
INFO:root:[245,   100] training loss: 0.00786434
INFO:root:[245,   150] training loss: 0.00728422
INFO:root:[245,   200] training loss: 0.00737756
INFO:root:[245,   250] training loss: 0.00704808
INFO:root:[245,   300] training loss: 0.00904004
INFO:root:[245,   350] training loss: 0.00635267
INFO:root:[245,   400] training loss: 0.00000854
INFO:root:[245,   450] training loss: 0.00001139
INFO:root:[245,   500] training loss: 0.00002044
INFO:root:[245,   550] training loss: 0.00018836
INFO:root:[245,   600] training loss: 0.00011558
INFO:root:[245,   650] training loss: 0.00001980
INFO:root:[245,   700] training loss: 0.00002155
INFO:root:[245,   750] training loss: 0.00044201
INFO:root:[245,   800] training loss: 0.00032171
INFO:root:[245,   850] training loss: 0.00028223
INFO:root:[245,   900] training loss: 0.00440346
INFO:root:[245,   950] training loss: 0.00113364
INFO:root:[245,  1000] training loss: 0.00001562
INFO:root:[245,  1050] training loss: 0.00001455
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch245
INFO:root:[246,    50] training loss: 0.00766290
INFO:root:[246,   100] training loss: 0.00765797
INFO:root:[246,   150] training loss: 0.00739893
INFO:root:[246,   200] training loss: 0.00689262
INFO:root:[246,   250] training loss: 0.00726087
INFO:root:[246,   300] training loss: 0.00763280
INFO:root:[246,   350] training loss: 0.00647745
INFO:root:[246,   400] training loss: 0.00000840
INFO:root:[246,   450] training loss: 0.00001203
INFO:root:[246,   500] training loss: 0.00005156
INFO:root:[246,   550] training loss: 0.00016829
INFO:root:[246,   600] training loss: 0.00014304
INFO:root:[246,   650] training loss: 0.00001707
INFO:root:[246,   700] training loss: 0.00001446
INFO:root:[246,   750] training loss: 0.00035793
INFO:root:[246,   800] training loss: 0.00029394
INFO:root:[246,   850] training loss: 0.00035290
INFO:root:[246,   900] training loss: 0.00370939
INFO:root:[246,   950] training loss: 0.00189618
INFO:root:[246,  1000] training loss: 0.00001900
INFO:root:[246,  1050] training loss: 0.00001061
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch246
INFO:root:[247,    50] training loss: 0.00742579
INFO:root:[247,   100] training loss: 0.00723233
INFO:root:[247,   150] training loss: 0.00724081
INFO:root:[247,   200] training loss: 0.00723305
INFO:root:[247,   250] training loss: 0.00724442
INFO:root:[247,   300] training loss: 0.00834890
INFO:root:[247,   350] training loss: 0.00740992
INFO:root:[247,   400] training loss: 0.00000924
INFO:root:[247,   450] training loss: 0.00001371
INFO:root:[247,   500] training loss: 0.00001675
INFO:root:[247,   550] training loss: 0.00016195
INFO:root:[247,   600] training loss: 0.00015236
INFO:root:[247,   650] training loss: 0.00001597
INFO:root:[247,   700] training loss: 0.00001393
INFO:root:[247,   750] training loss: 0.00033851
INFO:root:[247,   800] training loss: 0.00035510
INFO:root:[247,   850] training loss: 0.00033300
INFO:root:[247,   900] training loss: 0.00414188
INFO:root:[247,   950] training loss: 0.00142145
INFO:root:[247,  1000] training loss: 0.00001942
INFO:root:[247,  1050] training loss: 0.00001330
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch247
INFO:root:[248,    50] training loss: 0.00724272
INFO:root:[248,   100] training loss: 0.00776382
INFO:root:[248,   150] training loss: 0.00743591
INFO:root:[248,   200] training loss: 0.00685428
INFO:root:[248,   250] training loss: 0.00729433
INFO:root:[248,   300] training loss: 0.00814399
INFO:root:[248,   350] training loss: 0.00684060
INFO:root:[248,   400] training loss: 0.00000908
INFO:root:[248,   450] training loss: 0.00001264
INFO:root:[248,   500] training loss: 0.00001841
INFO:root:[248,   550] training loss: 0.00012300
INFO:root:[248,   600] training loss: 0.00012522
INFO:root:[248,   650] training loss: 0.00002003
INFO:root:[248,   700] training loss: 0.00001931
INFO:root:[248,   750] training loss: 0.00037293
INFO:root:[248,   800] training loss: 0.00040172
INFO:root:[248,   850] training loss: 0.00036890
INFO:root:[248,   900] training loss: 0.00371038
INFO:root:[248,   950] training loss: 0.00159722
INFO:root:[248,  1000] training loss: 0.00001607
INFO:root:[248,  1050] training loss: 0.00001341
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch248
INFO:root:[249,    50] training loss: 0.00727983
INFO:root:[249,   100] training loss: 0.00731889
INFO:root:[249,   150] training loss: 0.00714293
INFO:root:[249,   200] training loss: 0.00718776
INFO:root:[249,   250] training loss: 0.00717500
INFO:root:[249,   300] training loss: 0.00867030
INFO:root:[249,   350] training loss: 0.00665162
INFO:root:[249,   400] training loss: 0.00001051
INFO:root:[249,   450] training loss: 0.00009776
INFO:root:[249,   500] training loss: 0.00002043
INFO:root:[249,   550] training loss: 0.00017221
INFO:root:[249,   600] training loss: 0.00009443
INFO:root:[249,   650] training loss: 0.00001795
INFO:root:[249,   700] training loss: 0.00001863
INFO:root:[249,   750] training loss: 0.00036960
INFO:root:[249,   800] training loss: 0.00034810
INFO:root:[249,   850] training loss: 0.00030750
INFO:root:[249,   900] training loss: 0.00394429
INFO:root:[249,   950] training loss: 0.00118002
INFO:root:[249,  1000] training loss: 0.00001455
INFO:root:[249,  1050] training loss: 0.00001405
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch249
INFO:root:[250,    50] training loss: 0.00754783
INFO:root:[250,   100] training loss: 0.00767315
INFO:root:[250,   150] training loss: 0.00701340
INFO:root:[250,   200] training loss: 0.00703419
INFO:root:[250,   250] training loss: 0.00702785
INFO:root:[250,   300] training loss: 0.00812190
INFO:root:[250,   350] training loss: 0.00689008
INFO:root:[250,   400] training loss: 0.00000949
INFO:root:[250,   450] training loss: 0.00002025
INFO:root:[250,   500] training loss: 0.00002014
INFO:root:[250,   550] training loss: 0.00012278
INFO:root:[250,   600] training loss: 0.00021647
INFO:root:[250,   650] training loss: 0.00001809
INFO:root:[250,   700] training loss: 0.00002103
INFO:root:[250,   750] training loss: 0.00034552
INFO:root:[250,   800] training loss: 0.00032090
INFO:root:[250,   850] training loss: 0.00037156
INFO:root:[250,   900] training loss: 0.00405686
INFO:root:[250,   950] training loss: 0.00197545
INFO:root:[250,  1000] training loss: 0.00001367
INFO:root:[250,  1050] training loss: 0.00001304
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch250
INFO:root:[251,    50] training loss: 0.00763802
INFO:root:[251,   100] training loss: 0.00760714
INFO:root:[251,   150] training loss: 0.00758912
INFO:root:[251,   200] training loss: 0.00688644
INFO:root:[251,   250] training loss: 0.00752903
INFO:root:[251,   300] training loss: 0.00819368
INFO:root:[251,   350] training loss: 0.00654307
INFO:root:[251,   400] training loss: 0.00001024
INFO:root:[251,   450] training loss: 0.00001301
INFO:root:[251,   500] training loss: 0.00003214
INFO:root:[251,   550] training loss: 0.00014946
INFO:root:[251,   600] training loss: 0.00014883
INFO:root:[251,   650] training loss: 0.00001794
INFO:root:[251,   700] training loss: 0.00001737
INFO:root:[251,   750] training loss: 0.00035472
INFO:root:[251,   800] training loss: 0.00027761
INFO:root:[251,   850] training loss: 0.00040277
INFO:root:[251,   900] training loss: 0.00407056
INFO:root:[251,   950] training loss: 0.00143669
INFO:root:[251,  1000] training loss: 0.00001557
INFO:root:[251,  1050] training loss: 0.00001200
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch251
INFO:root:[252,    50] training loss: 0.00716817
INFO:root:[252,   100] training loss: 0.00769400
INFO:root:[252,   150] training loss: 0.00781087
INFO:root:[252,   200] training loss: 0.00718783
INFO:root:[252,   250] training loss: 0.00735547
INFO:root:[252,   300] training loss: 0.00797666
INFO:root:[252,   350] training loss: 0.00661212
INFO:root:[252,   400] training loss: 0.00000865
INFO:root:[252,   450] training loss: 0.00001300
INFO:root:[252,   500] training loss: 0.00001745
INFO:root:[252,   550] training loss: 0.00011602
INFO:root:[252,   600] training loss: 0.00013877
INFO:root:[252,   650] training loss: 0.00001718
INFO:root:[252,   700] training loss: 0.00001494
INFO:root:[252,   750] training loss: 0.00043512
INFO:root:[252,   800] training loss: 0.00033423
INFO:root:[252,   850] training loss: 0.00031006
INFO:root:[252,   900] training loss: 0.00427962
INFO:root:[252,   950] training loss: 0.00135929
INFO:root:[252,  1000] training loss: 0.00001823
INFO:root:[252,  1050] training loss: 0.00001419
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch252
INFO:root:[253,    50] training loss: 0.00772867
INFO:root:[253,   100] training loss: 0.00789111
INFO:root:[253,   150] training loss: 0.00746412
INFO:root:[253,   200] training loss: 0.00747206
INFO:root:[253,   250] training loss: 0.00726963
INFO:root:[253,   300] training loss: 0.00847169
INFO:root:[253,   350] training loss: 0.00697336
INFO:root:[253,   400] training loss: 0.00000839
INFO:root:[253,   450] training loss: 0.00000936
INFO:root:[253,   500] training loss: 0.00002117
INFO:root:[253,   550] training loss: 0.00021827
INFO:root:[253,   600] training loss: 0.00011835
INFO:root:[253,   650] training loss: 0.00001570
INFO:root:[253,   700] training loss: 0.00001734
INFO:root:[253,   750] training loss: 0.00034505
INFO:root:[253,   800] training loss: 0.00026130
INFO:root:[253,   850] training loss: 0.00030891
INFO:root:[253,   900] training loss: 0.00361628
INFO:root:[253,   950] training loss: 0.00168410
INFO:root:[253,  1000] training loss: 0.00002855
INFO:root:[253,  1050] training loss: 0.00001456
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch253
INFO:root:[254,    50] training loss: 0.00729983
INFO:root:[254,   100] training loss: 0.00715486
INFO:root:[254,   150] training loss: 0.00775491
INFO:root:[254,   200] training loss: 0.00787384
INFO:root:[254,   250] training loss: 0.00743253
INFO:root:[254,   300] training loss: 0.00871167
INFO:root:[254,   350] training loss: 0.00696512
INFO:root:[254,   400] training loss: 0.00000906
INFO:root:[254,   450] training loss: 0.00001302
INFO:root:[254,   500] training loss: 0.00002216
INFO:root:[254,   550] training loss: 0.00021127
INFO:root:[254,   600] training loss: 0.00013514
INFO:root:[254,   650] training loss: 0.00001422
INFO:root:[254,   700] training loss: 0.00001513
INFO:root:[254,   750] training loss: 0.00047388
INFO:root:[254,   800] training loss: 0.00027618
INFO:root:[254,   850] training loss: 0.00036611
INFO:root:[254,   900] training loss: 0.00423875
INFO:root:[254,   950] training loss: 0.00173309
INFO:root:[254,  1000] training loss: 0.00001726
INFO:root:[254,  1050] training loss: 0.00001476
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch254
INFO:root:[255,    50] training loss: 0.00782381
INFO:root:[255,   100] training loss: 0.00716138
INFO:root:[255,   150] training loss: 0.00696523
INFO:root:[255,   200] training loss: 0.00685838
INFO:root:[255,   250] training loss: 0.00730724
INFO:root:[255,   300] training loss: 0.00752616
INFO:root:[255,   350] training loss: 0.00689056
INFO:root:[255,   400] training loss: 0.00000951
INFO:root:[255,   450] training loss: 0.00001403
INFO:root:[255,   500] training loss: 0.00001649
INFO:root:[255,   550] training loss: 0.00015476
INFO:root:[255,   600] training loss: 0.00012830
INFO:root:[255,   650] training loss: 0.00001622
INFO:root:[255,   700] training loss: 0.00001540
INFO:root:[255,   750] training loss: 0.00032825
INFO:root:[255,   800] training loss: 0.00026149
INFO:root:[255,   850] training loss: 0.00027713
INFO:root:[255,   900] training loss: 0.00439373
INFO:root:[255,   950] training loss: 0.00115295
INFO:root:[255,  1000] training loss: 0.00001501
INFO:root:[255,  1050] training loss: 0.00001432
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch255
INFO:root:[256,    50] training loss: 0.00738239
INFO:root:[256,   100] training loss: 0.00728011
INFO:root:[256,   150] training loss: 0.00720368
INFO:root:[256,   200] training loss: 0.00716049
INFO:root:[256,   250] training loss: 0.00707164
INFO:root:[256,   300] training loss: 0.00759828
INFO:root:[256,   350] training loss: 0.00653162
INFO:root:[256,   400] training loss: 0.00000884
INFO:root:[256,   450] training loss: 0.00001170
INFO:root:[256,   500] training loss: 0.00003784
INFO:root:[256,   550] training loss: 0.00013926
INFO:root:[256,   600] training loss: 0.00015921
INFO:root:[256,   650] training loss: 0.00002455
INFO:root:[256,   700] training loss: 0.00001750
INFO:root:[256,   750] training loss: 0.00036313
INFO:root:[256,   800] training loss: 0.00025652
INFO:root:[256,   850] training loss: 0.00039714
INFO:root:[256,   900] training loss: 0.00382977
INFO:root:[256,   950] training loss: 0.00114174
INFO:root:[256,  1000] training loss: 0.00002364
INFO:root:[256,  1050] training loss: 0.00001237
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch256
INFO:root:[257,    50] training loss: 0.00762029
INFO:root:[257,   100] training loss: 0.00763722
INFO:root:[257,   150] training loss: 0.00720115
INFO:root:[257,   200] training loss: 0.00716441
INFO:root:[257,   250] training loss: 0.00754131
INFO:root:[257,   300] training loss: 0.00786387
INFO:root:[257,   350] training loss: 0.00748609
INFO:root:[257,   400] training loss: 0.00000844
INFO:root:[257,   450] training loss: 0.00001238
INFO:root:[257,   500] training loss: 0.00003193
INFO:root:[257,   550] training loss: 0.00011048
INFO:root:[257,   600] training loss: 0.00013113
INFO:root:[257,   650] training loss: 0.00001998
INFO:root:[257,   700] training loss: 0.00001630
INFO:root:[257,   750] training loss: 0.00038062
INFO:root:[257,   800] training loss: 0.00031439
INFO:root:[257,   850] training loss: 0.00030717
INFO:root:[257,   900] training loss: 0.00409443
INFO:root:[257,   950] training loss: 0.00134357
INFO:root:[257,  1000] training loss: 0.00001624
INFO:root:[257,  1050] training loss: 0.00001379
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch257
INFO:root:[258,    50] training loss: 0.00802896
INFO:root:[258,   100] training loss: 0.00883481
INFO:root:[258,   150] training loss: 0.00758673
INFO:root:[258,   200] training loss: 0.00696824
INFO:root:[258,   250] training loss: 0.00725596
INFO:root:[258,   300] training loss: 0.00820326
INFO:root:[258,   350] training loss: 0.00682950
INFO:root:[258,   400] training loss: 0.00000934
INFO:root:[258,   450] training loss: 0.00001110
INFO:root:[258,   500] training loss: 0.00002298
INFO:root:[258,   550] training loss: 0.00010908
INFO:root:[258,   600] training loss: 0.00015281
INFO:root:[258,   650] training loss: 0.00001525
INFO:root:[258,   700] training loss: 0.00001577
INFO:root:[258,   750] training loss: 0.00027173
INFO:root:[258,   800] training loss: 0.00030555
INFO:root:[258,   850] training loss: 0.00034367
INFO:root:[258,   900] training loss: 0.00427025
INFO:root:[258,   950] training loss: 0.00143012
INFO:root:[258,  1000] training loss: 0.00001649
INFO:root:[258,  1050] training loss: 0.00001533
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch258
INFO:root:[259,    50] training loss: 0.00755290
INFO:root:[259,   100] training loss: 0.00754359
INFO:root:[259,   150] training loss: 0.00733744
INFO:root:[259,   200] training loss: 0.00724323
INFO:root:[259,   250] training loss: 0.00751467
INFO:root:[259,   300] training loss: 0.00840064
INFO:root:[259,   350] training loss: 0.00625003
INFO:root:[259,   400] training loss: 0.00000944
INFO:root:[259,   450] training loss: 0.00001020
INFO:root:[259,   500] training loss: 0.00001820
INFO:root:[259,   550] training loss: 0.00012120
INFO:root:[259,   600] training loss: 0.00015223
INFO:root:[259,   650] training loss: 0.00002168
INFO:root:[259,   700] training loss: 0.00001793
INFO:root:[259,   750] training loss: 0.00036884
INFO:root:[259,   800] training loss: 0.00031181
INFO:root:[259,   850] training loss: 0.00025321
INFO:root:[259,   900] training loss: 0.00443299
INFO:root:[259,   950] training loss: 0.00146248
INFO:root:[259,  1000] training loss: 0.00001754
INFO:root:[259,  1050] training loss: 0.00001430
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch259
INFO:root:[260,    50] training loss: 0.00711857
INFO:root:[260,   100] training loss: 0.00751580
INFO:root:[260,   150] training loss: 0.00791984
INFO:root:[260,   200] training loss: 0.00710404
INFO:root:[260,   250] training loss: 0.00712629
INFO:root:[260,   300] training loss: 0.00782868
INFO:root:[260,   350] training loss: 0.00687104
INFO:root:[260,   400] training loss: 0.00000875
INFO:root:[260,   450] training loss: 0.00001210
INFO:root:[260,   500] training loss: 0.00002264
INFO:root:[260,   550] training loss: 0.00012337
INFO:root:[260,   600] training loss: 0.00020444
INFO:root:[260,   650] training loss: 0.00001436
INFO:root:[260,   700] training loss: 0.00001631
INFO:root:[260,   750] training loss: 0.00030139
INFO:root:[260,   800] training loss: 0.00028264
INFO:root:[260,   850] training loss: 0.00030128
INFO:root:[260,   900] training loss: 0.00396163
INFO:root:[260,   950] training loss: 0.00158802
INFO:root:[260,  1000] training loss: 0.00001249
INFO:root:[260,  1050] training loss: 0.00001322
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch260
INFO:root:[261,    50] training loss: 0.00747608
INFO:root:[261,   100] training loss: 0.00762439
INFO:root:[261,   150] training loss: 0.00735848
INFO:root:[261,   200] training loss: 0.00714499
INFO:root:[261,   250] training loss: 0.00743659
INFO:root:[261,   300] training loss: 0.00757333
INFO:root:[261,   350] training loss: 0.00647566
INFO:root:[261,   400] training loss: 0.00000870
INFO:root:[261,   450] training loss: 0.00001218
INFO:root:[261,   500] training loss: 0.00002400
INFO:root:[261,   550] training loss: 0.00017998
INFO:root:[261,   600] training loss: 0.00012879
INFO:root:[261,   650] training loss: 0.00001514
INFO:root:[261,   700] training loss: 0.00001596
INFO:root:[261,   750] training loss: 0.00034412
INFO:root:[261,   800] training loss: 0.00036280
INFO:root:[261,   850] training loss: 0.00033565
INFO:root:[261,   900] training loss: 0.00411581
INFO:root:[261,   950] training loss: 0.00147712
INFO:root:[261,  1000] training loss: 0.00001870
INFO:root:[261,  1050] training loss: 0.00001355
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch261
INFO:root:[262,    50] training loss: 0.00734005
INFO:root:[262,   100] training loss: 0.00755422
INFO:root:[262,   150] training loss: 0.00726407
INFO:root:[262,   200] training loss: 0.00716800
INFO:root:[262,   250] training loss: 0.00720680
INFO:root:[262,   300] training loss: 0.00745560
INFO:root:[262,   350] training loss: 0.00663167
INFO:root:[262,   400] training loss: 0.00000845
INFO:root:[262,   450] training loss: 0.00001599
INFO:root:[262,   500] training loss: 0.00001710
INFO:root:[262,   550] training loss: 0.00017678
INFO:root:[262,   600] training loss: 0.00012758
INFO:root:[262,   650] training loss: 0.00001814
INFO:root:[262,   700] training loss: 0.00001577
INFO:root:[262,   750] training loss: 0.00040144
INFO:root:[262,   800] training loss: 0.00028700
INFO:root:[262,   850] training loss: 0.00036616
INFO:root:[262,   900] training loss: 0.00423806
INFO:root:[262,   950] training loss: 0.00125914
INFO:root:[262,  1000] training loss: 0.00002164
INFO:root:[262,  1050] training loss: 0.00001412
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch262
INFO:root:[263,    50] training loss: 0.00757158
INFO:root:[263,   100] training loss: 0.00752548
INFO:root:[263,   150] training loss: 0.00748724
INFO:root:[263,   200] training loss: 0.00733784
INFO:root:[263,   250] training loss: 0.00727160
INFO:root:[263,   300] training loss: 0.00769995
INFO:root:[263,   350] training loss: 0.00756330
INFO:root:[263,   400] training loss: 0.00000739
INFO:root:[263,   450] training loss: 0.00001598
INFO:root:[263,   500] training loss: 0.00001885
INFO:root:[263,   550] training loss: 0.00014227
INFO:root:[263,   600] training loss: 0.00024065
INFO:root:[263,   650] training loss: 0.00001574
INFO:root:[263,   700] training loss: 0.00001563
INFO:root:[263,   750] training loss: 0.00033898
INFO:root:[263,   800] training loss: 0.00036947
INFO:root:[263,   850] training loss: 0.00026778
INFO:root:[263,   900] training loss: 0.00382766
INFO:root:[263,   950] training loss: 0.00132227
INFO:root:[263,  1000] training loss: 0.00001627
INFO:root:[263,  1050] training loss: 0.00001779
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch263
INFO:root:[264,    50] training loss: 0.00711933
INFO:root:[264,   100] training loss: 0.00782701
INFO:root:[264,   150] training loss: 0.00820861
INFO:root:[264,   200] training loss: 0.00699318
INFO:root:[264,   250] training loss: 0.00705601
INFO:root:[264,   300] training loss: 0.00774798
INFO:root:[264,   350] training loss: 0.00636794
INFO:root:[264,   400] training loss: 0.00000822
INFO:root:[264,   450] training loss: 0.00001313
INFO:root:[264,   500] training loss: 0.00001576
INFO:root:[264,   550] training loss: 0.00011131
INFO:root:[264,   600] training loss: 0.00016669
INFO:root:[264,   650] training loss: 0.00001693
INFO:root:[264,   700] training loss: 0.00001481
INFO:root:[264,   750] training loss: 0.00036785
INFO:root:[264,   800] training loss: 0.00032780
INFO:root:[264,   850] training loss: 0.00027966
INFO:root:[264,   900] training loss: 0.00439898
INFO:root:[264,   950] training loss: 0.00125715
INFO:root:[264,  1000] training loss: 0.00001409
INFO:root:[264,  1050] training loss: 0.00001459
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch264
INFO:root:[265,    50] training loss: 0.00719025
INFO:root:[265,   100] training loss: 0.00753106
INFO:root:[265,   150] training loss: 0.00731451
INFO:root:[265,   200] training loss: 0.00711732
INFO:root:[265,   250] training loss: 0.00714612
INFO:root:[265,   300] training loss: 0.00762098
INFO:root:[265,   350] training loss: 0.00655583
INFO:root:[265,   400] training loss: 0.00000949
INFO:root:[265,   450] training loss: 0.00001090
INFO:root:[265,   500] training loss: 0.00002572
INFO:root:[265,   550] training loss: 0.00014413
INFO:root:[265,   600] training loss: 0.00010815
INFO:root:[265,   650] training loss: 0.00001972
INFO:root:[265,   700] training loss: 0.00001401
INFO:root:[265,   750] training loss: 0.00058588
INFO:root:[265,   800] training loss: 0.00028958
INFO:root:[265,   850] training loss: 0.00030018
INFO:root:[265,   900] training loss: 0.00352737
INFO:root:[265,   950] training loss: 0.00126583
INFO:root:[265,  1000] training loss: 0.00001534
INFO:root:[265,  1050] training loss: 0.00001323
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch265
INFO:root:[266,    50] training loss: 0.00735425
INFO:root:[266,   100] training loss: 0.00706484
INFO:root:[266,   150] training loss: 0.00724584
INFO:root:[266,   200] training loss: 0.00692372
INFO:root:[266,   250] training loss: 0.00773210
INFO:root:[266,   300] training loss: 0.00747596
INFO:root:[266,   350] training loss: 0.00674021
INFO:root:[266,   400] training loss: 0.00001074
INFO:root:[266,   450] training loss: 0.00001273
INFO:root:[266,   500] training loss: 0.00001693
INFO:root:[266,   550] training loss: 0.00015259
INFO:root:[266,   600] training loss: 0.00014603
INFO:root:[266,   650] training loss: 0.00001516
INFO:root:[266,   700] training loss: 0.00001406
INFO:root:[266,   750] training loss: 0.00039945
INFO:root:[266,   800] training loss: 0.00025900
INFO:root:[266,   850] training loss: 0.00035846
INFO:root:[266,   900] training loss: 0.00427828
INFO:root:[266,   950] training loss: 0.00117386
INFO:root:[266,  1000] training loss: 0.00001379
INFO:root:[266,  1050] training loss: 0.00001252
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch266
INFO:root:[267,    50] training loss: 0.00716400
INFO:root:[267,   100] training loss: 0.00719310
INFO:root:[267,   150] training loss: 0.00696561
INFO:root:[267,   200] training loss: 0.00691738
INFO:root:[267,   250] training loss: 0.00727672
INFO:root:[267,   300] training loss: 0.00770610
INFO:root:[267,   350] training loss: 0.00632030
INFO:root:[267,   400] training loss: 0.00001011
INFO:root:[267,   450] training loss: 0.00001042
INFO:root:[267,   500] training loss: 0.00002335
INFO:root:[267,   550] training loss: 0.00012799
INFO:root:[267,   600] training loss: 0.00021221
INFO:root:[267,   650] training loss: 0.00002355
INFO:root:[267,   700] training loss: 0.00001376
INFO:root:[267,   750] training loss: 0.00038598
INFO:root:[267,   800] training loss: 0.00037287
INFO:root:[267,   850] training loss: 0.00035850
INFO:root:[267,   900] training loss: 0.00381568
INFO:root:[267,   950] training loss: 0.00173522
INFO:root:[267,  1000] training loss: 0.00001669
INFO:root:[267,  1050] training loss: 0.00001093
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch267
INFO:root:[268,    50] training loss: 0.00748392
INFO:root:[268,   100] training loss: 0.00737419
INFO:root:[268,   150] training loss: 0.00756985
INFO:root:[268,   200] training loss: 0.00687773
INFO:root:[268,   250] training loss: 0.00738065
INFO:root:[268,   300] training loss: 0.00757428
INFO:root:[268,   350] training loss: 0.00654990
INFO:root:[268,   400] training loss: 0.00000907
INFO:root:[268,   450] training loss: 0.00001129
INFO:root:[268,   500] training loss: 0.00001587
INFO:root:[268,   550] training loss: 0.00012629
INFO:root:[268,   600] training loss: 0.00015293
INFO:root:[268,   650] training loss: 0.00001767
INFO:root:[268,   700] training loss: 0.00001899
INFO:root:[268,   750] training loss: 0.00037101
INFO:root:[268,   800] training loss: 0.00031665
INFO:root:[268,   850] training loss: 0.00028663
INFO:root:[268,   900] training loss: 0.00389295
INFO:root:[268,   950] training loss: 0.00130944
INFO:root:[268,  1000] training loss: 0.00001279
INFO:root:[268,  1050] training loss: 0.00001448
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch268
INFO:root:[269,    50] training loss: 0.00728852
INFO:root:[269,   100] training loss: 0.00725175
INFO:root:[269,   150] training loss: 0.00741618
INFO:root:[269,   200] training loss: 0.00697089
INFO:root:[269,   250] training loss: 0.00717896
INFO:root:[269,   300] training loss: 0.00852489
INFO:root:[269,   350] training loss: 0.00660351
INFO:root:[269,   400] training loss: 0.00000946
INFO:root:[269,   450] training loss: 0.00001320
INFO:root:[269,   500] training loss: 0.00002625
INFO:root:[269,   550] training loss: 0.00013749
INFO:root:[269,   600] training loss: 0.00013768
INFO:root:[269,   650] training loss: 0.00001528
INFO:root:[269,   700] training loss: 0.00001431
INFO:root:[269,   750] training loss: 0.00042905
INFO:root:[269,   800] training loss: 0.00047203
INFO:root:[269,   850] training loss: 0.00032884
INFO:root:[269,   900] training loss: 0.00363437
INFO:root:[269,   950] training loss: 0.00132200
INFO:root:[269,  1000] training loss: 0.00002067
INFO:root:[269,  1050] training loss: 0.00001294
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch269
INFO:root:[270,    50] training loss: 0.00893918
INFO:root:[270,   100] training loss: 0.00819039
INFO:root:[270,   150] training loss: 0.00717924
INFO:root:[270,   200] training loss: 0.00674195
INFO:root:[270,   250] training loss: 0.00705912
INFO:root:[270,   300] training loss: 0.00768316
INFO:root:[270,   350] training loss: 0.00650401
INFO:root:[270,   400] training loss: 0.00000951
INFO:root:[270,   450] training loss: 0.00001102
INFO:root:[270,   500] training loss: 0.00001943
INFO:root:[270,   550] training loss: 0.00014653
INFO:root:[270,   600] training loss: 0.00016422
INFO:root:[270,   650] training loss: 0.00001425
INFO:root:[270,   700] training loss: 0.00001459
INFO:root:[270,   750] training loss: 0.00046239
INFO:root:[270,   800] training loss: 0.00031754
INFO:root:[270,   850] training loss: 0.00027331
INFO:root:[270,   900] training loss: 0.00408491
INFO:root:[270,   950] training loss: 0.00132689
INFO:root:[270,  1000] training loss: 0.00001596
INFO:root:[270,  1050] training loss: 0.00001371
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch270
INFO:root:[271,    50] training loss: 0.00747013
INFO:root:[271,   100] training loss: 0.00743744
INFO:root:[271,   150] training loss: 0.00717444
INFO:root:[271,   200] training loss: 0.00727594
INFO:root:[271,   250] training loss: 0.00679881
INFO:root:[271,   300] training loss: 0.00788770
INFO:root:[271,   350] training loss: 0.00676038
INFO:root:[271,   400] training loss: 0.00001060
INFO:root:[271,   450] training loss: 0.00001185
INFO:root:[271,   500] training loss: 0.00001968
INFO:root:[271,   550] training loss: 0.00011103
INFO:root:[271,   600] training loss: 0.00015169
INFO:root:[271,   650] training loss: 0.00001558
INFO:root:[271,   700] training loss: 0.00001411
INFO:root:[271,   750] training loss: 0.00045806
INFO:root:[271,   800] training loss: 0.00032172
INFO:root:[271,   850] training loss: 0.00031926
INFO:root:[271,   900] training loss: 0.00405883
INFO:root:[271,   950] training loss: 0.00149367
INFO:root:[271,  1000] training loss: 0.00001391
INFO:root:[271,  1050] training loss: 0.00001162
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch271
INFO:root:[272,    50] training loss: 0.00726802
INFO:root:[272,   100] training loss: 0.00772744
INFO:root:[272,   150] training loss: 0.00742501
INFO:root:[272,   200] training loss: 0.00810247
INFO:root:[272,   250] training loss: 0.00685381
INFO:root:[272,   300] training loss: 0.00808495
INFO:root:[272,   350] training loss: 0.00740886
INFO:root:[272,   400] training loss: 0.00001062
INFO:root:[272,   450] training loss: 0.00001175
INFO:root:[272,   500] training loss: 0.00002121
INFO:root:[272,   550] training loss: 0.00013052
INFO:root:[272,   600] training loss: 0.00016406
INFO:root:[272,   650] training loss: 0.00001612
INFO:root:[272,   700] training loss: 0.00001580
INFO:root:[272,   750] training loss: 0.00031564
INFO:root:[272,   800] training loss: 0.00027258
INFO:root:[272,   850] training loss: 0.00034645
INFO:root:[272,   900] training loss: 0.00359781
INFO:root:[272,   950] training loss: 0.00131885
INFO:root:[272,  1000] training loss: 0.00002394
INFO:root:[272,  1050] training loss: 0.00001154
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch272
INFO:root:[273,    50] training loss: 0.00744587
INFO:root:[273,   100] training loss: 0.00749296
INFO:root:[273,   150] training loss: 0.00688240
INFO:root:[273,   200] training loss: 0.00716651
INFO:root:[273,   250] training loss: 0.00705883
INFO:root:[273,   300] training loss: 0.00781388
INFO:root:[273,   350] training loss: 0.00668530
INFO:root:[273,   400] training loss: 0.00000873
INFO:root:[273,   450] training loss: 0.00001681
INFO:root:[273,   500] training loss: 0.00002642
INFO:root:[273,   550] training loss: 0.00013819
INFO:root:[273,   600] training loss: 0.00019370
INFO:root:[273,   650] training loss: 0.00001606
INFO:root:[273,   700] training loss: 0.00001473
INFO:root:[273,   750] training loss: 0.00042292
INFO:root:[273,   800] training loss: 0.00039301
INFO:root:[273,   850] training loss: 0.00041534
INFO:root:[273,   900] training loss: 0.00369361
INFO:root:[273,   950] training loss: 0.00143430
INFO:root:[273,  1000] training loss: 0.00002244
INFO:root:[273,  1050] training loss: 0.00001411
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch273
INFO:root:[274,    50] training loss: 0.00704471
INFO:root:[274,   100] training loss: 0.00735155
INFO:root:[274,   150] training loss: 0.00710473
INFO:root:[274,   200] training loss: 0.00701340
INFO:root:[274,   250] training loss: 0.00706867
INFO:root:[274,   300] training loss: 0.00859337
INFO:root:[274,   350] training loss: 0.00683118
INFO:root:[274,   400] training loss: 0.00000993
INFO:root:[274,   450] training loss: 0.00001105
INFO:root:[274,   500] training loss: 0.00001515
INFO:root:[274,   550] training loss: 0.00012730
INFO:root:[274,   600] training loss: 0.00013094
INFO:root:[274,   650] training loss: 0.00002314
INFO:root:[274,   700] training loss: 0.00001530
INFO:root:[274,   750] training loss: 0.00032635
INFO:root:[274,   800] training loss: 0.00031907
INFO:root:[274,   850] training loss: 0.00030781
INFO:root:[274,   900] training loss: 0.00371368
INFO:root:[274,   950] training loss: 0.00167369
INFO:root:[274,  1000] training loss: 0.00001491
INFO:root:[274,  1050] training loss: 0.00001244
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch274
INFO:root:[275,    50] training loss: 0.00723042
INFO:root:[275,   100] training loss: 0.00745877
INFO:root:[275,   150] training loss: 0.00746299
INFO:root:[275,   200] training loss: 0.00712593
INFO:root:[275,   250] training loss: 0.00713029
INFO:root:[275,   300] training loss: 0.00806675
INFO:root:[275,   350] training loss: 0.00648139
INFO:root:[275,   400] training loss: 0.00000892
INFO:root:[275,   450] training loss: 0.00002008
INFO:root:[275,   500] training loss: 0.00001622
INFO:root:[275,   550] training loss: 0.00012451
INFO:root:[275,   600] training loss: 0.00015123
INFO:root:[275,   650] training loss: 0.00001621
INFO:root:[275,   700] training loss: 0.00001636
INFO:root:[275,   750] training loss: 0.00031915
INFO:root:[275,   800] training loss: 0.00031617
INFO:root:[275,   850] training loss: 0.00033890
INFO:root:[275,   900] training loss: 0.00411325
INFO:root:[275,   950] training loss: 0.00121609
INFO:root:[275,  1000] training loss: 0.00001577
INFO:root:[275,  1050] training loss: 0.00001160
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch275
INFO:root:[276,    50] training loss: 0.00751153
INFO:root:[276,   100] training loss: 0.00713503
INFO:root:[276,   150] training loss: 0.00721184
INFO:root:[276,   200] training loss: 0.00704709
INFO:root:[276,   250] training loss: 0.00706232
INFO:root:[276,   300] training loss: 0.00757993
INFO:root:[276,   350] training loss: 0.00640929
INFO:root:[276,   400] training loss: 0.00000785
INFO:root:[276,   450] training loss: 0.00001214
INFO:root:[276,   500] training loss: 0.00008681
INFO:root:[276,   550] training loss: 0.00012832
INFO:root:[276,   600] training loss: 0.00013823
INFO:root:[276,   650] training loss: 0.00001656
INFO:root:[276,   700] training loss: 0.00001678
INFO:root:[276,   750] training loss: 0.00041050
INFO:root:[276,   800] training loss: 0.00022103
INFO:root:[276,   850] training loss: 0.00030298
INFO:root:[276,   900] training loss: 0.00340781
INFO:root:[276,   950] training loss: 0.00165422
INFO:root:[276,  1000] training loss: 0.00002355
INFO:root:[276,  1050] training loss: 0.00001327
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch276
INFO:root:[277,    50] training loss: 0.00752011
INFO:root:[277,   100] training loss: 0.00729993
INFO:root:[277,   150] training loss: 0.00707630
INFO:root:[277,   200] training loss: 0.00718544
INFO:root:[277,   250] training loss: 0.00715919
INFO:root:[277,   300] training loss: 0.00830859
INFO:root:[277,   350] training loss: 0.00610935
INFO:root:[277,   400] training loss: 0.00001108
INFO:root:[277,   450] training loss: 0.00001415
INFO:root:[277,   500] training loss: 0.00001847
INFO:root:[277,   550] training loss: 0.00011635
INFO:root:[277,   600] training loss: 0.00011000
INFO:root:[277,   650] training loss: 0.00001503
INFO:root:[277,   700] training loss: 0.00002026
INFO:root:[277,   750] training loss: 0.00035017
INFO:root:[277,   800] training loss: 0.00034216
INFO:root:[277,   850] training loss: 0.00028947
INFO:root:[277,   900] training loss: 0.00344569
INFO:root:[277,   950] training loss: 0.00167290
INFO:root:[277,  1000] training loss: 0.00001769
INFO:root:[277,  1050] training loss: 0.00001421
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch277
INFO:root:[278,    50] training loss: 0.00782239
INFO:root:[278,   100] training loss: 0.00730205
INFO:root:[278,   150] training loss: 0.00722043
INFO:root:[278,   200] training loss: 0.00692574
INFO:root:[278,   250] training loss: 0.00696025
INFO:root:[278,   300] training loss: 0.00761395
INFO:root:[278,   350] training loss: 0.00612847
INFO:root:[278,   400] training loss: 0.00000933
INFO:root:[278,   450] training loss: 0.00001569
INFO:root:[278,   500] training loss: 0.00001480
INFO:root:[278,   550] training loss: 0.00014561
INFO:root:[278,   600] training loss: 0.00012667
INFO:root:[278,   650] training loss: 0.00001448
INFO:root:[278,   700] training loss: 0.00001711
INFO:root:[278,   750] training loss: 0.00034400
INFO:root:[278,   800] training loss: 0.00038022
INFO:root:[278,   850] training loss: 0.00042805
INFO:root:[278,   900] training loss: 0.00453615
INFO:root:[278,   950] training loss: 0.00119861
INFO:root:[278,  1000] training loss: 0.00001761
INFO:root:[278,  1050] training loss: 0.00001283
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch278
INFO:root:[279,    50] training loss: 0.00811951
INFO:root:[279,   100] training loss: 0.00711487
INFO:root:[279,   150] training loss: 0.00746103
INFO:root:[279,   200] training loss: 0.00717313
INFO:root:[279,   250] training loss: 0.00727718
INFO:root:[279,   300] training loss: 0.00771078
INFO:root:[279,   350] training loss: 0.00672695
INFO:root:[279,   400] training loss: 0.00000918
INFO:root:[279,   450] training loss: 0.00001481
INFO:root:[279,   500] training loss: 0.00001747
INFO:root:[279,   550] training loss: 0.00010925
INFO:root:[279,   600] training loss: 0.00009533
INFO:root:[279,   650] training loss: 0.00001588
INFO:root:[279,   700] training loss: 0.00001428
INFO:root:[279,   750] training loss: 0.00036793
INFO:root:[279,   800] training loss: 0.00032139
INFO:root:[279,   850] training loss: 0.00033450
INFO:root:[279,   900] training loss: 0.00394886
INFO:root:[279,   950] training loss: 0.00148987
INFO:root:[279,  1000] training loss: 0.00001782
INFO:root:[279,  1050] training loss: 0.00001349
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch279
INFO:root:[280,    50] training loss: 0.00763578
INFO:root:[280,   100] training loss: 0.00748146
INFO:root:[280,   150] training loss: 0.00730010
INFO:root:[280,   200] training loss: 0.00720643
INFO:root:[280,   250] training loss: 0.00733364
INFO:root:[280,   300] training loss: 0.00813787
INFO:root:[280,   350] training loss: 0.00656055
INFO:root:[280,   400] training loss: 0.00000716
INFO:root:[280,   450] training loss: 0.00001150
INFO:root:[280,   500] training loss: 0.00005381
INFO:root:[280,   550] training loss: 0.00013358
INFO:root:[280,   600] training loss: 0.00012587
INFO:root:[280,   650] training loss: 0.00001815
INFO:root:[280,   700] training loss: 0.00001327
INFO:root:[280,   750] training loss: 0.00035111
INFO:root:[280,   800] training loss: 0.00033808
INFO:root:[280,   850] training loss: 0.00033434
INFO:root:[280,   900] training loss: 0.00456698
INFO:root:[280,   950] training loss: 0.00133718
INFO:root:[280,  1000] training loss: 0.00001670
INFO:root:[280,  1050] training loss: 0.00001470
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch280
INFO:root:[281,    50] training loss: 0.00737733
INFO:root:[281,   100] training loss: 0.00734230
INFO:root:[281,   150] training loss: 0.00761071
INFO:root:[281,   200] training loss: 0.00751530
INFO:root:[281,   250] training loss: 0.00718844
INFO:root:[281,   300] training loss: 0.00816103
INFO:root:[281,   350] training loss: 0.00650873
INFO:root:[281,   400] training loss: 0.00001030
INFO:root:[281,   450] training loss: 0.00002040
INFO:root:[281,   500] training loss: 0.00002140
INFO:root:[281,   550] training loss: 0.00017315
INFO:root:[281,   600] training loss: 0.00014926
INFO:root:[281,   650] training loss: 0.00002396
INFO:root:[281,   700] training loss: 0.00001257
INFO:root:[281,   750] training loss: 0.00035043
INFO:root:[281,   800] training loss: 0.00032224
INFO:root:[281,   850] training loss: 0.00025413
INFO:root:[281,   900] training loss: 0.00409267
INFO:root:[281,   950] training loss: 0.00139507
INFO:root:[281,  1000] training loss: 0.00002486
INFO:root:[281,  1050] training loss: 0.00001199
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch281
INFO:root:[282,    50] training loss: 0.00742137
INFO:root:[282,   100] training loss: 0.00774773
INFO:root:[282,   150] training loss: 0.00732432
INFO:root:[282,   200] training loss: 0.00709771
INFO:root:[282,   250] training loss: 0.00732182
INFO:root:[282,   300] training loss: 0.00826734
INFO:root:[282,   350] training loss: 0.00685743
INFO:root:[282,   400] training loss: 0.00001019
INFO:root:[282,   450] training loss: 0.00001177
INFO:root:[282,   500] training loss: 0.00002007
INFO:root:[282,   550] training loss: 0.00012168
INFO:root:[282,   600] training loss: 0.00016792
INFO:root:[282,   650] training loss: 0.00002263
INFO:root:[282,   700] training loss: 0.00001987
INFO:root:[282,   750] training loss: 0.00032435
INFO:root:[282,   800] training loss: 0.00032206
INFO:root:[282,   850] training loss: 0.00036983
INFO:root:[282,   900] training loss: 0.00383184
INFO:root:[282,   950] training loss: 0.00139158
INFO:root:[282,  1000] training loss: 0.00001729
INFO:root:[282,  1050] training loss: 0.00001661
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch282
INFO:root:[283,    50] training loss: 0.00757133
INFO:root:[283,   100] training loss: 0.00730808
INFO:root:[283,   150] training loss: 0.00735891
INFO:root:[283,   200] training loss: 0.00683499
INFO:root:[283,   250] training loss: 0.00727575
INFO:root:[283,   300] training loss: 0.00757989
INFO:root:[283,   350] training loss: 0.00641237
INFO:root:[283,   400] training loss: 0.00000949
INFO:root:[283,   450] training loss: 0.00001178
INFO:root:[283,   500] training loss: 0.00002479
INFO:root:[283,   550] training loss: 0.00016545
INFO:root:[283,   600] training loss: 0.00014462
INFO:root:[283,   650] training loss: 0.00001457
INFO:root:[283,   700] training loss: 0.00001625
INFO:root:[283,   750] training loss: 0.00043227
INFO:root:[283,   800] training loss: 0.00032950
INFO:root:[283,   850] training loss: 0.00035646
INFO:root:[283,   900] training loss: 0.00455004
INFO:root:[283,   950] training loss: 0.00141199
INFO:root:[283,  1000] training loss: 0.00001749
INFO:root:[283,  1050] training loss: 0.00001329
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch283
INFO:root:[284,    50] training loss: 0.00727049
INFO:root:[284,   100] training loss: 0.00758040
INFO:root:[284,   150] training loss: 0.00771965
INFO:root:[284,   200] training loss: 0.00718339
INFO:root:[284,   250] training loss: 0.00758813
INFO:root:[284,   300] training loss: 0.00762360
INFO:root:[284,   350] training loss: 0.00641649
INFO:root:[284,   400] training loss: 0.00000984
INFO:root:[284,   450] training loss: 0.00001122
INFO:root:[284,   500] training loss: 0.00002447
INFO:root:[284,   550] training loss: 0.00011864
INFO:root:[284,   600] training loss: 0.00013258
INFO:root:[284,   650] training loss: 0.00001393
INFO:root:[284,   700] training loss: 0.00001541
INFO:root:[284,   750] training loss: 0.00045621
INFO:root:[284,   800] training loss: 0.00028356
INFO:root:[284,   850] training loss: 0.00034242
INFO:root:[284,   900] training loss: 0.00409638
INFO:root:[284,   950] training loss: 0.00293538
INFO:root:[284,  1000] training loss: 0.00001726
INFO:root:[284,  1050] training loss: 0.00001101
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch284
INFO:root:[285,    50] training loss: 0.00769898
INFO:root:[285,   100] training loss: 0.00778668
INFO:root:[285,   150] training loss: 0.00711186
INFO:root:[285,   200] training loss: 0.00764328
INFO:root:[285,   250] training loss: 0.00779220
INFO:root:[285,   300] training loss: 0.00778002
INFO:root:[285,   350] training loss: 0.00659189
INFO:root:[285,   400] training loss: 0.00001001
INFO:root:[285,   450] training loss: 0.00001157
INFO:root:[285,   500] training loss: 0.00002689
INFO:root:[285,   550] training loss: 0.00014797
INFO:root:[285,   600] training loss: 0.00010610
INFO:root:[285,   650] training loss: 0.00001977
INFO:root:[285,   700] training loss: 0.00001538
INFO:root:[285,   750] training loss: 0.00033330
INFO:root:[285,   800] training loss: 0.00037683
INFO:root:[285,   850] training loss: 0.00039915
INFO:root:[285,   900] training loss: 0.00367367
INFO:root:[285,   950] training loss: 0.00120239
INFO:root:[285,  1000] training loss: 0.00002147
INFO:root:[285,  1050] training loss: 0.00001465
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch285
INFO:root:[286,    50] training loss: 0.00739280
INFO:root:[286,   100] training loss: 0.00772575
INFO:root:[286,   150] training loss: 0.00806519
INFO:root:[286,   200] training loss: 0.00727003
INFO:root:[286,   250] training loss: 0.00742509
INFO:root:[286,   300] training loss: 0.00755945
INFO:root:[286,   350] training loss: 0.00665205
INFO:root:[286,   400] training loss: 0.00001011
INFO:root:[286,   450] training loss: 0.00000940
INFO:root:[286,   500] training loss: 0.00002056
INFO:root:[286,   550] training loss: 0.00019929
INFO:root:[286,   600] training loss: 0.00016899
INFO:root:[286,   650] training loss: 0.00002567
INFO:root:[286,   700] training loss: 0.00001935
INFO:root:[286,   750] training loss: 0.00035760
INFO:root:[286,   800] training loss: 0.00036970
INFO:root:[286,   850] training loss: 0.00026781
INFO:root:[286,   900] training loss: 0.00364740
INFO:root:[286,   950] training loss: 0.00151978
INFO:root:[286,  1000] training loss: 0.00001276
INFO:root:[286,  1050] training loss: 0.00001421
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch286
INFO:root:[287,    50] training loss: 0.00733749
INFO:root:[287,   100] training loss: 0.00739736
INFO:root:[287,   150] training loss: 0.00746217
INFO:root:[287,   200] training loss: 0.00720640
INFO:root:[287,   250] training loss: 0.00721373
INFO:root:[287,   300] training loss: 0.00767843
INFO:root:[287,   350] training loss: 0.00635426
INFO:root:[287,   400] training loss: 0.00000912
INFO:root:[287,   450] training loss: 0.00001118
INFO:root:[287,   500] training loss: 0.00002008
INFO:root:[287,   550] training loss: 0.00012911
INFO:root:[287,   600] training loss: 0.00017637
INFO:root:[287,   650] training loss: 0.00001453
INFO:root:[287,   700] training loss: 0.00001847
INFO:root:[287,   750] training loss: 0.00037886
INFO:root:[287,   800] training loss: 0.00031789
INFO:root:[287,   850] training loss: 0.00033024
INFO:root:[287,   900] training loss: 0.00396687
INFO:root:[287,   950] training loss: 0.00114121
INFO:root:[287,  1000] training loss: 0.00001761
INFO:root:[287,  1050] training loss: 0.00001299
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch287
INFO:root:[288,    50] training loss: 0.00725610
INFO:root:[288,   100] training loss: 0.00703780
INFO:root:[288,   150] training loss: 0.00755492
INFO:root:[288,   200] training loss: 0.00697638
INFO:root:[288,   250] training loss: 0.00758450
INFO:root:[288,   300] training loss: 0.00747955
INFO:root:[288,   350] training loss: 0.00679636
INFO:root:[288,   400] training loss: 0.00000810
INFO:root:[288,   450] training loss: 0.00001291
INFO:root:[288,   500] training loss: 0.00001831
INFO:root:[288,   550] training loss: 0.00012421
INFO:root:[288,   600] training loss: 0.00013327
INFO:root:[288,   650] training loss: 0.00001505
INFO:root:[288,   700] training loss: 0.00001996
INFO:root:[288,   750] training loss: 0.00043264
INFO:root:[288,   800] training loss: 0.00031966
INFO:root:[288,   850] training loss: 0.00027033
INFO:root:[288,   900] training loss: 0.00454055
INFO:root:[288,   950] training loss: 0.00143025
INFO:root:[288,  1000] training loss: 0.00006091
INFO:root:[288,  1050] training loss: 0.00001782
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch288
INFO:root:[289,    50] training loss: 0.00700961
INFO:root:[289,   100] training loss: 0.00743385
INFO:root:[289,   150] training loss: 0.00704973
INFO:root:[289,   200] training loss: 0.00784664
INFO:root:[289,   250] training loss: 0.00733338
INFO:root:[289,   300] training loss: 0.00772283
INFO:root:[289,   350] training loss: 0.00695440
INFO:root:[289,   400] training loss: 0.00000860
INFO:root:[289,   450] training loss: 0.00001436
INFO:root:[289,   500] training loss: 0.00002024
INFO:root:[289,   550] training loss: 0.00012326
INFO:root:[289,   600] training loss: 0.00014850
INFO:root:[289,   650] training loss: 0.00001490
INFO:root:[289,   700] training loss: 0.00001751
INFO:root:[289,   750] training loss: 0.00039377
INFO:root:[289,   800] training loss: 0.00035341
INFO:root:[289,   850] training loss: 0.00031047
INFO:root:[289,   900] training loss: 0.00411922
INFO:root:[289,   950] training loss: 0.00145087
INFO:root:[289,  1000] training loss: 0.00001592
INFO:root:[289,  1050] training loss: 0.00001572
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch289
INFO:root:[290,    50] training loss: 0.00753174
INFO:root:[290,   100] training loss: 0.00702297
INFO:root:[290,   150] training loss: 0.00785760
INFO:root:[290,   200] training loss: 0.00702388
INFO:root:[290,   250] training loss: 0.00725324
INFO:root:[290,   300] training loss: 0.00846208
INFO:root:[290,   350] training loss: 0.00658200
INFO:root:[290,   400] training loss: 0.00000997
INFO:root:[290,   450] training loss: 0.00001432
INFO:root:[290,   500] training loss: 0.00001858
INFO:root:[290,   550] training loss: 0.00010199
INFO:root:[290,   600] training loss: 0.00013556
INFO:root:[290,   650] training loss: 0.00001475
INFO:root:[290,   700] training loss: 0.00001527
INFO:root:[290,   750] training loss: 0.00034722
INFO:root:[290,   800] training loss: 0.00041031
INFO:root:[290,   850] training loss: 0.00037112
INFO:root:[290,   900] training loss: 0.00385056
INFO:root:[290,   950] training loss: 0.00099764
INFO:root:[290,  1000] training loss: 0.00001481
INFO:root:[290,  1050] training loss: 0.00001342
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch290
INFO:root:[291,    50] training loss: 0.00727255
INFO:root:[291,   100] training loss: 0.00750824
INFO:root:[291,   150] training loss: 0.00722113
INFO:root:[291,   200] training loss: 0.00692802
INFO:root:[291,   250] training loss: 0.00726244
INFO:root:[291,   300] training loss: 0.00760214
INFO:root:[291,   350] training loss: 0.00658938
INFO:root:[291,   400] training loss: 0.00001051
INFO:root:[291,   450] training loss: 0.00001467
INFO:root:[291,   500] training loss: 0.00001769
INFO:root:[291,   550] training loss: 0.00017503
INFO:root:[291,   600] training loss: 0.00011746
INFO:root:[291,   650] training loss: 0.00001561
INFO:root:[291,   700] training loss: 0.00001292
INFO:root:[291,   750] training loss: 0.00041882
INFO:root:[291,   800] training loss: 0.00036964
INFO:root:[291,   850] training loss: 0.00032592
INFO:root:[291,   900] training loss: 0.00374091
INFO:root:[291,   950] training loss: 0.00125461
INFO:root:[291,  1000] training loss: 0.00002190
INFO:root:[291,  1050] training loss: 0.00001658
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch291
INFO:root:[292,    50] training loss: 0.00725304
INFO:root:[292,   100] training loss: 0.00909738
INFO:root:[292,   150] training loss: 0.00716683
INFO:root:[292,   200] training loss: 0.00724341
INFO:root:[292,   250] training loss: 0.00705845
INFO:root:[292,   300] training loss: 0.00769124
INFO:root:[292,   350] training loss: 0.00717460
INFO:root:[292,   400] training loss: 0.00000913
INFO:root:[292,   450] training loss: 0.00001311
INFO:root:[292,   500] training loss: 0.00002265
INFO:root:[292,   550] training loss: 0.00014883
INFO:root:[292,   600] training loss: 0.00014573
INFO:root:[292,   650] training loss: 0.00001434
INFO:root:[292,   700] training loss: 0.00001459
INFO:root:[292,   750] training loss: 0.00044248
INFO:root:[292,   800] training loss: 0.00027212
INFO:root:[292,   850] training loss: 0.00030176
INFO:root:[292,   900] training loss: 0.00341793
INFO:root:[292,   950] training loss: 0.00165268
INFO:root:[292,  1000] training loss: 0.00004833
INFO:root:[292,  1050] training loss: 0.00001492
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch292
INFO:root:[293,    50] training loss: 0.00730190
INFO:root:[293,   100] training loss: 0.00859882
INFO:root:[293,   150] training loss: 0.00778890
INFO:root:[293,   200] training loss: 0.00669718
INFO:root:[293,   250] training loss: 0.00727480
INFO:root:[293,   300] training loss: 0.00803724
INFO:root:[293,   350] training loss: 0.00682296
INFO:root:[293,   400] training loss: 0.00000763
INFO:root:[293,   450] training loss: 0.00001168
INFO:root:[293,   500] training loss: 0.00004509
INFO:root:[293,   550] training loss: 0.00015755
INFO:root:[293,   600] training loss: 0.00009665
INFO:root:[293,   650] training loss: 0.00001531
INFO:root:[293,   700] training loss: 0.00001661
INFO:root:[293,   750] training loss: 0.00034708
INFO:root:[293,   800] training loss: 0.00035406
INFO:root:[293,   850] training loss: 0.00027445
INFO:root:[293,   900] training loss: 0.00365486
INFO:root:[293,   950] training loss: 0.00129760
INFO:root:[293,  1000] training loss: 0.00001678
INFO:root:[293,  1050] training loss: 0.00001331
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch293
INFO:root:[294,    50] training loss: 0.00959057
INFO:root:[294,   100] training loss: 0.00887447
INFO:root:[294,   150] training loss: 0.00724558
INFO:root:[294,   200] training loss: 0.00753118
INFO:root:[294,   250] training loss: 0.00739904
INFO:root:[294,   300] training loss: 0.00733044
INFO:root:[294,   350] training loss: 0.00628589
INFO:root:[294,   400] training loss: 0.00000932
INFO:root:[294,   450] training loss: 0.00001803
INFO:root:[294,   500] training loss: 0.00001843
INFO:root:[294,   550] training loss: 0.00013937
INFO:root:[294,   600] training loss: 0.00019356
INFO:root:[294,   650] training loss: 0.00001674
INFO:root:[294,   700] training loss: 0.00002367
INFO:root:[294,   750] training loss: 0.00035977
INFO:root:[294,   800] training loss: 0.00034155
INFO:root:[294,   850] training loss: 0.00031452
INFO:root:[294,   900] training loss: 0.00393453
INFO:root:[294,   950] training loss: 0.00173603
INFO:root:[294,  1000] training loss: 0.00001707
INFO:root:[294,  1050] training loss: 0.00001404
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch294
INFO:root:[295,    50] training loss: 0.00732747
INFO:root:[295,   100] training loss: 0.00766366
INFO:root:[295,   150] training loss: 0.00785990
INFO:root:[295,   200] training loss: 0.00716475
INFO:root:[295,   250] training loss: 0.00674938
INFO:root:[295,   300] training loss: 0.00756665
INFO:root:[295,   350] training loss: 0.00719374
INFO:root:[295,   400] training loss: 0.00000960
INFO:root:[295,   450] training loss: 0.00001153
INFO:root:[295,   500] training loss: 0.00001668
INFO:root:[295,   550] training loss: 0.00011686
INFO:root:[295,   600] training loss: 0.00012365
INFO:root:[295,   650] training loss: 0.00001565
INFO:root:[295,   700] training loss: 0.00001516
INFO:root:[295,   750] training loss: 0.00041852
INFO:root:[295,   800] training loss: 0.00029962
INFO:root:[295,   850] training loss: 0.00039479
INFO:root:[295,   900] training loss: 0.00407099
INFO:root:[295,   950] training loss: 0.00161386
INFO:root:[295,  1000] training loss: 0.00001750
INFO:root:[295,  1050] training loss: 0.00001721
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch295
INFO:root:[296,    50] training loss: 0.00858568
INFO:root:[296,   100] training loss: 0.00697873
INFO:root:[296,   150] training loss: 0.00710023
INFO:root:[296,   200] training loss: 0.00692868
INFO:root:[296,   250] training loss: 0.00700768
INFO:root:[296,   300] training loss: 0.00844346
INFO:root:[296,   350] training loss: 0.00680027
INFO:root:[296,   400] training loss: 0.00000955
INFO:root:[296,   450] training loss: 0.00001397
INFO:root:[296,   500] training loss: 0.00001445
INFO:root:[296,   550] training loss: 0.00016442
INFO:root:[296,   600] training loss: 0.00015243
INFO:root:[296,   650] training loss: 0.00001423
INFO:root:[296,   700] training loss: 0.00002646
INFO:root:[296,   750] training loss: 0.00031016
INFO:root:[296,   800] training loss: 0.00035857
INFO:root:[296,   850] training loss: 0.00026312
INFO:root:[296,   900] training loss: 0.00438385
INFO:root:[296,   950] training loss: 0.00167286
INFO:root:[296,  1000] training loss: 0.00001371
INFO:root:[296,  1050] training loss: 0.00001723
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch296
INFO:root:[297,    50] training loss: 0.00731042
INFO:root:[297,   100] training loss: 0.00709194
INFO:root:[297,   150] training loss: 0.00752167
INFO:root:[297,   200] training loss: 0.00694577
INFO:root:[297,   250] training loss: 0.00725424
INFO:root:[297,   300] training loss: 0.00801143
INFO:root:[297,   350] training loss: 0.00655652
INFO:root:[297,   400] training loss: 0.00000875
INFO:root:[297,   450] training loss: 0.00001188
INFO:root:[297,   500] training loss: 0.00007142
INFO:root:[297,   550] training loss: 0.00018205
INFO:root:[297,   600] training loss: 0.00011725
INFO:root:[297,   650] training loss: 0.00001788
INFO:root:[297,   700] training loss: 0.00001433
INFO:root:[297,   750] training loss: 0.00033756
INFO:root:[297,   800] training loss: 0.00039367
INFO:root:[297,   850] training loss: 0.00033254
INFO:root:[297,   900] training loss: 0.00371428
INFO:root:[297,   950] training loss: 0.00097594
INFO:root:[297,  1000] training loss: 0.00001670
INFO:root:[297,  1050] training loss: 0.00002101
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch297
INFO:root:[298,    50] training loss: 0.00715742
INFO:root:[298,   100] training loss: 0.00744660
INFO:root:[298,   150] training loss: 0.00715925
INFO:root:[298,   200] training loss: 0.00702958
INFO:root:[298,   250] training loss: 0.00728129
INFO:root:[298,   300] training loss: 0.00805910
INFO:root:[298,   350] training loss: 0.00636209
INFO:root:[298,   400] training loss: 0.00000944
INFO:root:[298,   450] training loss: 0.00001213
INFO:root:[298,   500] training loss: 0.00002331
INFO:root:[298,   550] training loss: 0.00016745
INFO:root:[298,   600] training loss: 0.00012221
INFO:root:[298,   650] training loss: 0.00001529
INFO:root:[298,   700] training loss: 0.00001718
INFO:root:[298,   750] training loss: 0.00033986
INFO:root:[298,   800] training loss: 0.00034412
INFO:root:[298,   850] training loss: 0.00031357
INFO:root:[298,   900] training loss: 0.00403406
INFO:root:[298,   950] training loss: 0.00141620
INFO:root:[298,  1000] training loss: 0.00002170
INFO:root:[298,  1050] training loss: 0.00001417
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch298
INFO:root:[299,    50] training loss: 0.00768467
INFO:root:[299,   100] training loss: 0.00739065
INFO:root:[299,   150] training loss: 0.00700045
INFO:root:[299,   200] training loss: 0.00703764
INFO:root:[299,   250] training loss: 0.00737037
INFO:root:[299,   300] training loss: 0.00768317
INFO:root:[299,   350] training loss: 0.00704211
INFO:root:[299,   400] training loss: 0.00000942
INFO:root:[299,   450] training loss: 0.00001072
INFO:root:[299,   500] training loss: 0.00006493
INFO:root:[299,   550] training loss: 0.00013106
INFO:root:[299,   600] training loss: 0.00015198
INFO:root:[299,   650] training loss: 0.00001740
INFO:root:[299,   700] training loss: 0.00002369
INFO:root:[299,   750] training loss: 0.00035302
INFO:root:[299,   800] training loss: 0.00029831
INFO:root:[299,   850] training loss: 0.00038310
INFO:root:[299,   900] training loss: 0.00448025
INFO:root:[299,   950] training loss: 0.00122238
INFO:root:[299,  1000] training loss: 0.00001977
INFO:root:[299,  1050] training loss: 0.00001702
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:epoch299
INFO:root:[300,    50] training loss: 0.00760559
INFO:root:[300,   100] training loss: 0.00775147
INFO:root:[300,   150] training loss: 0.00755566
INFO:root:[300,   200] training loss: 0.00728972
INFO:root:[300,   250] training loss: 0.00695242
INFO:root:[300,   300] training loss: 0.00766620
INFO:root:[300,   350] training loss: 0.00659777
INFO:root:[300,   400] training loss: 0.00000853
INFO:root:[300,   450] training loss: 0.00001108
INFO:root:[300,   500] training loss: 0.00003363
INFO:root:[300,   550] training loss: 0.00018635
INFO:root:[300,   600] training loss: 0.00013779
INFO:root:[300,   650] training loss: 0.00001519
INFO:root:[300,   700] training loss: 0.00001795
INFO:root:[300,   750] training loss: 0.00033637
INFO:root:[300,   800] training loss: 0.00033562
INFO:root:[300,   850] training loss: 0.00031522
INFO:root:[300,   900] training loss: 0.00421315
INFO:root:[300,   950] training loss: 0.00130594
INFO:root:[300,  1000] training loss: 0.00001902
INFO:root:[300,  1050] training loss: 0.00001462
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    1.0000    0.8000         2
           S     0.9027    0.8250    0.8621      1720
   Metaphase     0.8035    0.7965    0.8000      1032
          G1     0.4444    0.5000    0.4706         8
    Anaphase     0.3942    0.7397    0.5143        73
          G2     0.6249    0.6799    0.6512      1034
   Telophase     1.0000    1.0000    1.0000         3

    accuracy                         0.7766      3872
   macro avg     0.6909    0.7916    0.7283      3872
weighted avg     0.7915    0.7766    0.7819      3872

INFO:root:Accuracy of the network on the 3872 validation images: 77 %
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6454 test images: 78 %
INFO:root:The model saved: final_model_dict_jcd_h5_all.pth
INFO:root:              precision    recall  f1-score   support

    Prophase     0.6667    0.6667    0.6667         3
           S     0.9151    0.8270    0.8688      2867
   Metaphase     0.7999    0.8110    0.8054      1720
          G1     0.5500    0.7857    0.6471        14
    Anaphase     0.3850    0.7190    0.5014       121
          G2     0.6413    0.6937    0.6665      1724
   Telophase     1.0000    1.0000    1.0000         5

    accuracy                         0.7851      6454
   macro avg     0.7083    0.7862    0.7366      6454
weighted avg     0.8005    0.7851    0.7905      6454

INFO:root:   Prophase         S  Metaphase        G1  Anaphase        G2  Telophase
0  0.666667  0.868816   0.805427  0.647059  0.501441  0.666481        1.0
